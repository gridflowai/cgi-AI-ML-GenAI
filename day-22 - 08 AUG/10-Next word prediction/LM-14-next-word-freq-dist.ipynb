{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calulates the freq of the (i+1)th \n",
    "# word in the whole corpus, where i is the index of \n",
    "# the sentence or the word. \n",
    "  \n",
    "def next_word_freq(array, sentence): \n",
    "      \n",
    "    sen_len, word_list = len(sentence.split()), [] \n",
    "      \n",
    "    for i in range(len(array)): \n",
    "  \n",
    "        # If the sentence matches the sentence in the range (i, i+x) \n",
    "        # and the length is less than the length of the corpus, append \n",
    "        # the word to word_list. \n",
    "          \n",
    "        if ' '.join(array[i : i + sen_len]).lower() == sentence.lower(): \n",
    "  \n",
    "            if i + sen_len < len(array) - 1: \n",
    "  \n",
    "                word_list.append(array[i + sen_len]) \n",
    "  \n",
    "    # Return the count of each word in word_list \n",
    "      \n",
    "    return dict(Counter(word_list)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the CDF of each word in the \n",
    "# Counter dictionary. \n",
    "  \n",
    "def CDF(d): \n",
    "      \n",
    "    prob_sum, sum_vals = 0, sum(d.values()) \n",
    "      \n",
    "    for k, v in d.items(): \n",
    "  \n",
    "        # Calculate the PMF of each word by dividing \n",
    "        # the freq. by total of all frequencies then add \n",
    "        # all the PMFs till ith word which is the CDF of \n",
    "        # the ith word. \n",
    "          \n",
    "        pmf = v / sum_vals \n",
    "        prob_sum += pmf \n",
    "        d[k] = prob_sum \n",
    "  \n",
    "    # Return cdf dictionary \n",
    "      \n",
    "    return d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '''text The chance is unlikely if not done programmatically.  \n",
    "    However, imagine the game spawning multiple players at a spawn point, \n",
    "    this would be the exact same location. I'm not quite sure what you  \n",
    "    mean with spin,     what does the integer reflect? Why is it a  \n",
    "    mismatch between data and structure? The structure does not \n",
    "    assume a set amount of objects, it can be anything, that's why new \n",
    "    nodes are created. It simply makes sure that there are not more than \n",
    "    X leafs inside 1 node. The random is no option of course. \n",
    "    My splitting algorithm always created the maximum amount of nodes  \n",
    "    already, split over the current node. But I guess I have to change \n",
    "    this behaviour? Actually, all the books have different authors. And \n",
    "    most have a different location too. There will be some with the same \n",
    "    location, but different authors, though. I think my library should be \n",
    "    able to store books with the same position. There are never  \n",
    "    equally-attractive leaf nodes. If a node is split, all childs will \n",
    "    reflect a different part of the parent node.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = corpus.split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(sent, x, n): \n",
    "# \"temp_out\" will be used to store each partial sentence \n",
    "    # which will later be stored into \"sent\". \"out\" is used to store \n",
    "    # the final output. \n",
    "      \n",
    "    temp_out = '' \n",
    "    out = sent + ' '\n",
    "      \n",
    "    for i in range(n - x): \n",
    "  \n",
    "        # calling the next_word_freq method that returns \n",
    "        # the frequency of each word next to sent in the \n",
    "        # whole word corpus. \n",
    "          \n",
    "        func_out = next_word_freq(l, sent) \n",
    "  \n",
    "        # cdf_dict stores the cdf of each word in the above map \n",
    "        # that is calulated using method CDF. \n",
    "          \n",
    "        cdf_dict = CDF(func_out) \n",
    "          \n",
    "        # We use a random number to predict the next word. \n",
    "        # The word having its CDF greater than or equal to rand \n",
    "        # and less than or equal to 1. \n",
    "          \n",
    "        rand = random.uniform(0, 1) \n",
    "  \n",
    "        # If cdf_dict is empty, it means the word.sentence entered by you \n",
    "        # does not exist in the corpus. Hence, break the loop and just print \n",
    "        # the word entered by you. To implement this we use try-except block. \n",
    "        # If an error occurs it implies there aren't enough values to unpack \n",
    "        # and this can happen only when your input is absent from the corpus. \n",
    "          \n",
    "        try: key, val = zip(*cdf_dict.items()) \n",
    "        except: break\n",
    "  \n",
    "        # Iterate through the cdf values and find the smallest value \n",
    "        # greater than or equal to the random number. That value is the \n",
    "        # cdf of your predicted word. Add the key of the value to the output \n",
    "        # string and update the \"sent\" variable as \"temp_out\". \n",
    "          \n",
    "        for j in range(len(val)): \n",
    "              \n",
    "            if rand <= val[j]: \n",
    "                pos = j \n",
    "                break\n",
    "                      \n",
    "        temp_out = key[pos] \n",
    "        out = out + temp_out + ' '\n",
    "        sent = temp_out \n",
    "          \n",
    "    print(out, end = '\\n\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is no option of objects, it simply makes sure \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inp_sent = 'is'\n",
    "# The output will have 10 words, including the input sentence/word. \n",
    "main(inp_sent, len(inp_sent), 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
