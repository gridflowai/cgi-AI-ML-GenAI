{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bigrams and trigrams using Phraser models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to create a dictionary from a list of sentences?\n",
    "documents = [\"The Saudi Arabia are preparing a report that will acknowledge that\", \n",
    "             \"Saudi Arabia journalist Jamal Khashoggi's death was the result of an\", \n",
    "             \"interrogation that went wrong, one that was intended to lead\", \n",
    "             \"to his abduction from Turkey, according to two sources in Saudi Arabia.\"]\n",
    "\n",
    "documents_2 = [\"One source says the report will likely conclude that\", \n",
    "                \"the operation was carried out without clearance and\", \n",
    "                \"transparency and that those involved will be held\", \n",
    "                \"responsible. One of the sources acknowledged that the\", \n",
    "                \"report is still being prepared and cautioned that\", \n",
    "                \"things could change.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The', 'Saudi', 'Arabia', 'are', 'preparing', 'a', 'report', 'that', 'will', 'acknowledge', 'that'], ['Saudi', 'Arabia', 'journalist', 'Jamal', \"Khashoggi's\", 'death', 'was', 'the', 'result', 'of', 'an'], ['interrogation', 'that', 'went', 'wrong,', 'one', 'that', 'was', 'intended', 'to', 'lead'], ['to', 'his', 'abduction', 'from', 'Turkey,', 'according', 'to', 'two', 'sources', 'in', 'Saudi', 'Arabia.']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize(split) the sentences into words\n",
    "texts = [[text for text in doc.split()] for doc in documents]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(35 unique tokens: ['Arabia', 'Saudi', 'The', 'a', 'acknowledge']...)\n"
     ]
    }
   ],
   "source": [
    "# Get information about the dictionary\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arabia': 0, 'Saudi': 1, 'The': 2, 'a': 3, 'acknowledge': 4, 'are': 5, 'preparing': 6, 'report': 7, 'that': 8, 'will': 9, 'Jamal': 10, \"Khashoggi's\": 11, 'an': 12, 'death': 13, 'journalist': 14, 'of': 15, 'result': 16, 'the': 17, 'was': 18, 'intended': 19, 'interrogation': 20, 'lead': 21, 'one': 22, 'to': 23, 'went': 24, 'wrong,': 25, 'Arabia.': 26, 'Turkey,': 27, 'abduction': 28, 'according': 29, 'from': 30, 'his': 31, 'in': 32, 'sources': 33, 'two': 34}\n"
     ]
    }
   ],
   "source": [
    "# Show the word to id map\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get new documents in the future, it is also possible to update an existing dictionary to include the new words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_2 = [\"The intersection graph of paths in trees\",\n",
    "               \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "               \"Graph minors A survey\"]\n",
    "\n",
    "texts_2 = [[text for text in doc.split()] for doc in documents_2]\n",
    "\n",
    "dictionary.add_documents(texts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Arabia': 0, 'Saudi': 1, 'The': 2, 'a': 3, 'acknowledge': 4, 'are': 5, 'preparing': 6, 'report': 7, 'that': 8, 'will': 9, 'Jamal': 10, \"Khashoggi's\": 11, 'an': 12, 'death': 13, 'journalist': 14, 'of': 15, 'result': 16, 'the': 17, 'was': 18, 'intended': 19, 'interrogation': 20, 'lead': 21, 'one': 22, 'to': 23, 'went': 24, 'wrong,': 25, 'Arabia.': 26, 'Turkey,': 27, 'abduction': 28, 'according': 29, 'from': 30, 'his': 31, 'in': 32, 'sources': 33, 'two': 34, 'graph': 35, 'intersection': 36, 'paths': 37, 'trees': 38, 'Graph': 39, 'IV': 40, 'Widths': 41, 'and': 42, 'minors': 43, 'ordering': 44, 'quasi': 45, 'well': 46, 'A': 47, 'survey': 48}\n"
     ]
    }
   ],
   "source": [
    "# Show the word to id map\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(line) for line in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1)], [(0, 1), (1, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1)], [(8, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1)], [(1, 1), (23, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__min_count__ ignore all words and bigrams with total collected count lower than this. Bydefault it value is 5\n",
    "\n",
    "__threshold__ represents a threshold for forming the phrases (higher means fewer phrases). \n",
    "\n",
    "A phrase of words a and b is accepted if (cnt(a, b) - min_count) * N / (cnt(a) * cnt(b)) > threshold, where N is the total vocabulary size. Bydefault it value is 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram models\n",
    "# Detect phrases based on collocation counts\n",
    "bigram = gensim.models.phrases.Phrases(texts, min_count=1, threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Saudi_Arabia',\n",
       " 'are',\n",
       " 'preparing',\n",
       " 'a',\n",
       " 'report',\n",
       " 'that',\n",
       " 'will',\n",
       " 'acknowledge',\n",
       " 'that']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[texts[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Saudi_Arabia', 'are', 'preparing', 'a', 'report', 'that', 'will', 'acknowledge', 'that']\n"
     ]
    }
   ],
   "source": [
    "# Construct bigram\n",
    "print(bigram[texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Saudi_Arabia', 'are', 'preparing', 'a', 'report', 'that', 'will', 'acknowledge', 'that']\n"
     ]
    }
   ],
   "source": [
    "# Build the trigram models\n",
    "trigram = gensim.models.phrases.Phrases(bigram[texts], threshold=5)\n",
    "\n",
    "# Construct trigram\n",
    "print(trigram[bigram[texts[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = r'D:\\AI-DATASETS\\02-MISC-large\\Datafiniti_Hotel_Reviews.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load reviews data\n",
    "reviews = pd.read_csv(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>address</th>\n",
       "      <th>categories</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>keys</th>\n",
       "      <th>latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.dateSeen</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sourceURLs</th>\n",
       "      <th>websites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AVwc252WIN2L1WUfpqLP</td>\n",
       "      <td>2016-10-30T21:42:42Z</td>\n",
       "      <td>2018-09-10T21:06:27Z</td>\n",
       "      <td>5921 Valencia Cir</td>\n",
       "      <td>Hotels,Hotels and motels,Hotel and motel reser...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Rancho Santa Fe</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/ranchosantafe/5921valenciacir/359754519</td>\n",
       "      <td>32.990959</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-08-03T00:00:00Z,2016-07-26T00:00:00Z,2016...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.hotels.com/hotel/125419/reviews%20/</td>\n",
       "      <td>Our experience at Rancho Valencia was absolute...</td>\n",
       "      <td>Best romantic vacation ever!!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paula</td>\n",
       "      <td>http://www.hotels.com/ho125419/%25252525253Flo...</td>\n",
       "      <td>http://www.ranchovalencia.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVwc252WIN2L1WUfpqLP</td>\n",
       "      <td>2016-10-30T21:42:42Z</td>\n",
       "      <td>2018-09-10T21:06:27Z</td>\n",
       "      <td>5921 Valencia Cir</td>\n",
       "      <td>Hotels,Hotels and motels,Hotel and motel reser...</td>\n",
       "      <td>Accommodation &amp; Food Services</td>\n",
       "      <td>Rancho Santa Fe</td>\n",
       "      <td>US</td>\n",
       "      <td>us/ca/ranchosantafe/5921valenciacir/359754519</td>\n",
       "      <td>32.990959</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-08-02T00:00:00Z,2016-08-26T00:00:00Z,2016...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>https://www.hotels.com/hotel/125419/reviews%20/</td>\n",
       "      <td>Amazing place. Everyone was extremely warm and...</td>\n",
       "      <td>Sweet sweet serenity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>http://www.hotels.com/ho125419/%25252525253Flo...</td>\n",
       "      <td>http://www.ranchovalencia.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id             dateAdded           dateUpdated  \\\n",
       "0  AVwc252WIN2L1WUfpqLP  2016-10-30T21:42:42Z  2018-09-10T21:06:27Z   \n",
       "1  AVwc252WIN2L1WUfpqLP  2016-10-30T21:42:42Z  2018-09-10T21:06:27Z   \n",
       "\n",
       "             address                                         categories  \\\n",
       "0  5921 Valencia Cir  Hotels,Hotels and motels,Hotel and motel reser...   \n",
       "1  5921 Valencia Cir  Hotels,Hotels and motels,Hotel and motel reser...   \n",
       "\n",
       "               primaryCategories             city country  \\\n",
       "0  Accommodation & Food Services  Rancho Santa Fe      US   \n",
       "1  Accommodation & Food Services  Rancho Santa Fe      US   \n",
       "\n",
       "                                            keys   latitude  ...  \\\n",
       "0  us/ca/ranchosantafe/5921valenciacir/359754519  32.990959  ...   \n",
       "1  us/ca/ranchosantafe/5921valenciacir/359754519  32.990959  ...   \n",
       "\n",
       "                                    reviews.dateSeen reviews.rating  \\\n",
       "0  2016-08-03T00:00:00Z,2016-07-26T00:00:00Z,2016...            5.0   \n",
       "1  2016-08-02T00:00:00Z,2016-08-26T00:00:00Z,2016...            5.0   \n",
       "\n",
       "                                reviews.sourceURLs  \\\n",
       "0  https://www.hotels.com/hotel/125419/reviews%20/   \n",
       "1  https://www.hotels.com/hotel/125419/reviews%20/   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0  Our experience at Rancho Valencia was absolute...   \n",
       "1  Amazing place. Everyone was extremely warm and...   \n",
       "\n",
       "                     reviews.title reviews.userCity  reviews.userProvince  \\\n",
       "0  Best romantic vacation ever!!!!              NaN                   NaN   \n",
       "1             Sweet sweet serenity              NaN                   NaN   \n",
       "\n",
       "  reviews.username                                         sourceURLs  \\\n",
       "0            Paula  http://www.hotels.com/ho125419/%25252525253Flo...   \n",
       "1                D  http://www.hotels.com/ho125419/%25252525253Flo...   \n",
       "\n",
       "                        websites  \n",
       "0  http://www.ranchovalencia.com  \n",
       "1  http://www.ranchovalencia.com  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = reviews['reviews.text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our experience at Rancho Valencia was absolutely perfect from beginning to end!!!! We felt special and very happy du...\n",
       "1    Amazing place. Everyone was extremely warm and welcoming. We've stayed at some top notch places and this is definite...\n",
       "2    We booked a 3 night stay at Rancho Valencia to play some tennis, since it is one of the highest rated tennis resorts...\n",
       "3    Currently in bed writing this for the past hr 1/2 there have been dogs barking and squealing call the front desk to ...\n",
       "4    I live in Md and the Aloft is my Home away from home...we stayed 1 night 7-7-16 ...Staff is great ! Especially Olivi...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean and lemmatize comments\n",
    "def clean_comments(text):\n",
    "    \n",
    "    # remove punctuations\n",
    "    regex   = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    \n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "    \n",
    "    # Init the Wordnet Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Tokenize: Split the sentence into words\n",
    "    word_list = nltk.word_tokenize(nopunct)\n",
    "    \n",
    "    # Lemmatize list of words and join\n",
    "    lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    \n",
    "    clean_text = lemmatized_output.lower()\n",
    "    \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the striped bat are hanging on their foot for best'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The striped bats are hanging on @@ ## their feet for best\"\n",
    "clean_comments(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# apply function to clean and lemmatize comments\n",
    "lemmatized = comments.map(clean_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    our experience at rancho valencia wa absolutely perfect from beginning to end we felt special and very happy during ...\n",
       "1    amazing place everyone wa extremely warm and welcoming we ve stayed at some top notch place and this is definitely i...\n",
       "2    we booked a 3 night stay at rancho valencia to play some tennis since it is one of the highest rated tennis resort i...\n",
       "3    currently in bed writing this for the past hr 1 2 there have been dog barking and squealing call the front desk to a...\n",
       "4    i live in md and the aloft is my home away from home we stayed 1 night 7 7 16 staff is great especially olivia who w...\n",
       "5    i stayed here with my family for my daughter wedding it had a very accommodating staff olivia wa excellent the room ...\n",
       "6    beautiful room and the nicest people working there the front desk lady olivia wa extremely patient and helpful we ha...\n",
       "7    we stayed here while visiting maryland live cute hotel in a great location clean with a very modern look upgraded ba...\n",
       "Name: reviews.text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = lemmatized.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize(split) the sentences into words\n",
    "texts = [[text for text in doc.split()] for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the bigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.phrases.Phrases(texts, min_count=3, threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['our', 'experience', 'at', 'rancho', 'valencia', 'wa', 'absolutely_perfect', 'from_beginning', 'to', 'end', 'we', 'felt', 'special', 'and', 'very', 'happy', 'during_our', 'stayed', 'i_would', 'come_back', 'in', 'a', 'heart_beat']\n"
     ]
    }
   ],
   "source": [
    "# Construct bigram for document 1\n",
    "print(bigram[texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_room</td>\n",
       "      <td>3154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in_the</td>\n",
       "      <td>2911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_hotel</td>\n",
       "      <td>2468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and_the</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of_the</td>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it_wa</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>room_wa</td>\n",
       "      <td>1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>to_the</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wa_very</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the_staff</td>\n",
       "      <td>1629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1\n",
       "0   the_room  3154\n",
       "1     in_the  2911\n",
       "2  the_hotel  2468\n",
       "3    and_the  2175\n",
       "4     of_the  2029\n",
       "5      it_wa  1943\n",
       "6    room_wa  1848\n",
       "7     to_the  1759\n",
       "8    wa_very  1669\n",
       "9  the_staff  1629"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "results = sorted(\n",
    "                {k:v for k,v in bigram.vocab.items() if '_' in k if v>=bigram.min_count}.items(),\n",
    "                key     = operator.itemgetter(1),\n",
    "                reverse = True)\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Bigram  Frequency\n",
      "0   the_room       3154\n",
      "1     in_the       2911\n",
      "2  the_hotel       2468\n",
      "3    and_the       2175\n",
      "4     of_the       2029\n",
      "5      it_wa       1943\n",
      "6    room_wa       1848\n",
      "7     to_the       1759\n",
      "8    wa_very       1669\n",
      "9  the_staff       1629\n"
     ]
    }
   ],
   "source": [
    "# Filter and sort bigrams based on frequency counts\n",
    "results = sorted(\n",
    "                {k:v for k,v in bigram.vocab.items() if '_' in k and v >= bigram.min_count}.items(),\n",
    "                key     = operator.itemgetter(1),\n",
    "                reverse = True)\n",
    "\n",
    "# Convert byte-like keys to strings before further processing\n",
    "#results = [(k.decode('utf-8'), v) for k, v in results]\n",
    "\n",
    "# Convert results to a pandas DataFrame\n",
    "res_df = pd.DataFrame(results, columns=['Bigram', 'Frequency'])\n",
    "# Display the top 10 bigrams\n",
    "print(res_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.phrases.Phrases(texts, min_count=3, threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['our', 'experience', 'at', 'rancho', 'valencia', 'wa', 'absolutely_perfect', 'from_beginning', 'to', 'end', 'we', 'felt', 'special', 'and', 'very', 'happy', 'during_our', 'stayed', 'i_would', 'come_back', 'in', 'a', 'heart_beat']\n"
     ]
    }
   ],
   "source": [
    "# Construct bigram for document 1\n",
    "print(bigram[texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the_room</td>\n",
       "      <td>3154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in_the</td>\n",
       "      <td>2911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the_hotel</td>\n",
       "      <td>2468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and_the</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of_the</td>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it_wa</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>room_wa</td>\n",
       "      <td>1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>to_the</td>\n",
       "      <td>1759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wa_very</td>\n",
       "      <td>1669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the_staff</td>\n",
       "      <td>1629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1\n",
       "0   the_room  3154\n",
       "1     in_the  2911\n",
       "2  the_hotel  2468\n",
       "3    and_the  2175\n",
       "4     of_the  2029\n",
       "5      it_wa  1943\n",
       "6    room_wa  1848\n",
       "7     to_the  1759\n",
       "8    wa_very  1669\n",
       "9  the_staff  1629"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "results = sorted(\n",
    "                {k:v for k,v in bigram.vocab.items() if '_' in k if v>=bigram.min_count}.items(),\n",
    "                key=operator.itemgetter(1),\n",
    "                reverse=True)\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does GENSIM detect n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text data\n",
    "sentences = [\n",
    "    \"the quick brown fox jumps over the lazy dog\",\n",
    "    \"the lazy dog slept in the shade of the tree\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary (unique words in the corpus)\n",
    "vocabulary = set()\n",
    "for sentence in sentences:\n",
    "    vocabulary.update(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map each word to an index\n",
    "word_to_index = {word: i for i, word in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'over': 0,\n",
       " 'shade': 1,\n",
       " 'fox': 2,\n",
       " 'brown': 3,\n",
       " 'dog': 4,\n",
       " 'lazy': 5,\n",
       " 'slept': 6,\n",
       " 'jumps': 7,\n",
       " 'in': 8,\n",
       " 'quick': 9,\n",
       " 'the': 10,\n",
       " 'of': 11,\n",
       " 'tree': 12}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize co-occurrence matrix with zeros\n",
    "co_occurrence_matrix = np.zeros((len(vocabulary), len(vocabulary)), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define window size for co-occurrence counting\n",
    "window_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each sentence to update co-occurrence counts\n",
    "for sentence in sentences:\n",
    "    words = sentence.split()\n",
    "    for i, word in enumerate(words):\n",
    "        current_index = word_to_index[word]\n",
    "        start = max(i - window_size, 0)\n",
    "        end = min(i + window_size + 1, len(words))\n",
    "        context = words[start:i] + words[i+1:end]\n",
    "        for context_word in context:\n",
    "            context_index = word_to_index[context_word]\n",
    "            co_occurrence_matrix[current_index][context_index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert co-occurrence matrix to DataFrame for better visualization\n",
    "co_occurrence_df = pd.DataFrame(co_occurrence_matrix, index=vocabulary, columns=vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>over</th>\n",
       "      <th>shade</th>\n",
       "      <th>fox</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>lazy</th>\n",
       "      <th>slept</th>\n",
       "      <th>jumps</th>\n",
       "      <th>in</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "      <th>of</th>\n",
       "      <th>tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shade</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brown</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lazy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slept</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumps</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quick</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       over  shade  fox  brown  dog  lazy  slept  jumps  in  quick  the  of  \\\n",
       "over      0      0    1      0    0     1      0      1   0      0    1   0   \n",
       "shade     0      0    0      0    0     0      0      0   1      0    2   1   \n",
       "fox       1      0    0      1    0     0      0      1   0      1    0   0   \n",
       "brown     0      0    1      0    0     0      0      1   0      1    1   0   \n",
       "dog       0      0    0      0    0     2      1      0   1      0    2   0   \n",
       "lazy      1      0    0      0    2     0      1      0   0      0    2   0   \n",
       "slept     0      0    0      0    1     1      0      0   1      0    1   0   \n",
       "jumps     1      0    1      1    0     0      0      0   0      0    1   0   \n",
       "in        0      1    0      0    1     0      1      0   0      0    1   0   \n",
       "quick     0      0    1      1    0     0      0      0   0      0    1   0   \n",
       "the       1      2    0      1    2     2      1      1   1      1    0   2   \n",
       "of        0      1    0      0    0     0      0      0   0      0    2   0   \n",
       "tree      0      0    0      0    0     0      0      0   0      0    1   1   \n",
       "\n",
       "       tree  \n",
       "over      0  \n",
       "shade     0  \n",
       "fox       0  \n",
       "brown     0  \n",
       "dog       0  \n",
       "lazy      0  \n",
       "slept     0  \n",
       "jumps     0  \n",
       "in        0  \n",
       "quick     0  \n",
       "the       1  \n",
       "of        1  \n",
       "tree      0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
