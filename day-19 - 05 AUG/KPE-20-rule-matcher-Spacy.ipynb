{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1a6e419-34ac-42c8-b746-8290354309e0",
   "metadata": {},
   "source": [
    "-------------\n",
    "#### Rule based - information extraction\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8483bc-66b2-40a3-9834-7caec0ff27aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def check_phone_number(str):\n",
    "    if re.match(r'^\\d{3}-\\d{3}-\\d{4}$', str):\n",
    "        print(\"Valid phone number\")\n",
    "    else:\n",
    "        print(\"Not valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d78a1f-332d-4f5a-b304-15d21ee52e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid phone number\n",
      "Valid phone number\n",
      "Not valid\n"
     ]
    }
   ],
   "source": [
    "check_phone_number(\"555-555-5555\")  # Valid phone number\n",
    "check_phone_number(\"123-456-7890\")  # Valid phone number\n",
    "check_phone_number(\"123-4256-7890\") # Not valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc71d618-bce8-46c5-974c-a533bd520eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_phone_number(str):\n",
    "    if re.match(r'^\\d{3}-\\d{3,4}-\\d{4}$', str):\n",
    "        print(\"Valid phone number\")\n",
    "    else:\n",
    "        print(\"Not valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a459de99-5a2c-4fc7-9e94-5190901d7515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid phone number\n",
      "Valid phone number\n",
      "Valid phone number\n"
     ]
    }
   ],
   "source": [
    "check_phone_number(\"555-555-5555\")  # Valid phone number\n",
    "check_phone_number(\"123-456-7890\")  # Valid phone number\n",
    "check_phone_number(\"123-4256-7890\") # Valid phone number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46d57f-e051-4213-94ad-090b1d715d2d",
   "metadata": {},
   "source": [
    "Example ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c857b6ad-fced-4456-9b13-57a855b43638",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Name: Bhupen\n",
    "Address: Doddaballapur Road, Yelahanka\n",
    "\n",
    "Hi, my name is Bhupen, and I'd like you to extract my name and address from this block of text!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a622cf6-f9f7-4d82-b11f-c389e185edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_match    = re.search(r'.*?Name:\\s*(.*?)\\n',    text)\n",
    "address_match = re.search(r'.*?Address:\\s*(.*?)\\n', text)\n",
    "\n",
    "name    = None\n",
    "address = None\n",
    "\n",
    "if name_match:\n",
    "    name = name_match.group(1)\n",
    "\n",
    "if address_match:\n",
    "    address = address_match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aec6960-5cc5-41cc-ba71-e36b4f424cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhupen lives at : Doddaballapur Road, Yelahanka\n"
     ]
    }
   ],
   "source": [
    "print('{} lives at : {}'.format(name, address))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e4db80-5fa7-4b10-8e60-5ed1f78dcf56",
   "metadata": {},
   "source": [
    "#### Using spacy \n",
    "\n",
    "**token matcher**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2ef47c-515f-4c15-88ea-4bed88460b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import filter_spans\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e4d078-1be3-4ef0-8d63-687625dd3479",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac9d089-3824-4dd6-bee3-19d08e6ceb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the matcher with the shared vocab\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53533cd1-1e18-407c-a3c5-9c5748581878",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_rule = {\n",
    "            \"date_rule\" : [\n",
    "                            {\"LOWER\": \"march\"}, \n",
    "                            {\"IS_DIGIT\": True}, \n",
    "                            {\"IS_PUNCT\": True}, \n",
    "                            {\"IS_DIGIT\": True}\n",
    "            ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed5821a-1f5c-4055-8837-f8c7f06e581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rule_name, rule_tags in date_rule.items(): # register rules in matcher\n",
    "    matcher.add(rule_name, [rule_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d55cb5e9-b3ae-45fb-b36f-4749fb3802f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process some text\n",
    "doc = nlp(\"SpaceX's Starlink 17 mission lifts off on a Falcon 9 rocket from Launch \\\n",
    "          Complex 39A at NASA's Kennedy Space Center in Florida, on March 4, 2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b872e6-3ea0-4639-b145-0723de0b8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the matcher on the doc\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e99e328-c806-4ce6-a79c-43a18c28af7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "March 4, 2021\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5390263-2efb-4690-9dd0-2da37dccf663",
   "metadata": {},
   "source": [
    "**phrase matching**\n",
    "\n",
    "The `phrase matcher` can be used when large terminologies have to be matched. \n",
    "\n",
    "It functions the same way as the token matcher, but instead of specifying rules and patterns, we can `input strings to match`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b238b39-52c4-4fb6-9f13-ab626ba44f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#import the phrase matcher\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "#load a model and create nlp object\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2cb2ece-a7ca-4bdd-b486-21228de1dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initilize the matcher with a shared vocab\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "318dacd8-0b12-4738-aeb4-3fa8d02a431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the list of words to match\n",
    "fruit_list = ['apple','orange','banana',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31720d47-784b-4956-aebb-e509b70e6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain doc object for each word in the list and store it in a list\n",
    "patterns = [nlp(fruit) for fruit in fruit_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9ba3851-a1d3-4d42-974d-e78d4a49ef78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[apple, orange, banana]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f088ad34-4c3f-4abb-834e-1aeb82812b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the pattern to the matcher\n",
    "matcher.add(\"FRUIT_PATTERN\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9dc874-6b5a-4694-a863-d14981605a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process some text\n",
    "doc = nlp(\"An orange contains citric acid and an apple contains banana oxalic acid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ead1ea8-049c-4500-bfc5-346b12cfcc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbcb5bd3-1dc7-4d9c-abe7-35e3977bdbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange\n",
      "apple\n",
      "banana\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f2c6d-2c6d-4203-ad4e-4d9c1c72ddf5",
   "metadata": {},
   "source": [
    "#### Example - Rule 1\n",
    "\n",
    "`Comment`: Great smartphone. I love the screen size.\n",
    "\n",
    "`Important attributes`: `smartphone` and `screen size`.\n",
    "\n",
    "We can create the rules:\n",
    "- Smartphone  = Noun\n",
    "- Screen Size = Compound + Noun\n",
    "\n",
    "We have a part-of-speech (POS) tag `noun` following an optional dependency label (DEP) `compound`. \n",
    "\n",
    "To make the DEP optional to appear, we can use the operator (OP) `?`. \n",
    "\n",
    "Letâ€™s call that rule `Noun and compound`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cd4c6e-add2-418c-a10f-969bc76ddf31",
   "metadata": {},
   "source": [
    "#### Example - Rule 2\n",
    "\n",
    "- `Comment`: This phone is water-resistant?\n",
    "    \n",
    "- `Important attributes`: `phone` and `water-resistant`.\n",
    "\n",
    "We can create the rules:\n",
    "\n",
    "- `Phone` = Noun\n",
    "- `Water Resistant` = Noun + Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1612f065-2a60-4f40-8767-7a1e9cbc6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "        \"Noun and compound\": [\n",
    "            { \"DEP\": \"compound\",  \"OP\": \"?\" },\n",
    "            { \"POS\": \"NOUN\" }\n",
    "        ],\n",
    "        \"Noun and adjective\": [\n",
    "            { \"POS\": \"NOUN\" },\n",
    "            { \"POS\": \"ADJ\"  }\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890a35ab-2c97-4118-ae27-9e35ba27224e",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "After defining all rules to extract our attributes, we need to code the `matcher` responsible for extracting it according to what we want. \n",
    "\n",
    "We can create a `Matcher` Spacy object and add all rules defined previously. \n",
    "\n",
    "Now the model is ready for extraction when we input a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2f2a18d-01c5-4316-9cba-d3623420514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9f9006c-1f2e-4ba5-bb31-04d1a266416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rule_name, rule_tags in rules.items(): # register rules in matcher\n",
    "    rule_matcher.add(rule_name, [rule_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa878df-22d9-4f6f-b3b8-3b017c4a2602",
   "metadata": {},
   "source": [
    "#### Extraction\n",
    "The model is ready and weâ€™re able to extract attributes using the code listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb1f9864-e857-456c-a61e-a506c0fab54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(text):\n",
    "    doc = nlp(text)  # Convert string to spacy 'doc' type\n",
    "    matches = rule_matcher(doc)  # Run matcher\n",
    "\n",
    "    result = []\n",
    "    for match_id, start, end in matches:  # For each attribute detected, save it in a list\n",
    "        attribute = doc[start:end]\n",
    "        result.append(attribute.text)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d35d83c8-0b86-496c-8779-62083aa3d853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['smartphone', 'screen', 'screen size', 'size']\n"
     ]
    }
   ],
   "source": [
    "print(extract(\"Great smartphone. I love the screen size.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3ccdb79-bfbf-4c25-a480-37407f780ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['phone', 'water', 'water resistant']\n"
     ]
    }
   ],
   "source": [
    "print(extract(\"This phone is water resistant?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff1897c2-e5b3-401d-8723-acbabdb8297e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sound', 'battery']\n"
     ]
    }
   ],
   "source": [
    "print(extract(\"Sound and battery are great\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b52f4-d940-41fb-a157-92268bec833e",
   "metadata": {},
   "source": [
    "#### Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a49551f-4f39-4901-a943-70dfed4607c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = {\n",
    "        \"Noun and adjective\": [\n",
    "                {'POS': 'DET', 'OP': '?'},\n",
    "                {'POS': 'ADJ', 'OP': '*'},\n",
    "                {'POS': 'NOUN'}\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6a2c22a-08d7-4441-9001-8f7909f016f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noun_chunks(text):\n",
    "    doc = nlp(text)\n",
    "    pattern = [\n",
    "                {'POS': 'DET', 'OP': '?'},\n",
    "                {'POS': 'ADJ', 'OP': '*'},\n",
    "                {'POS': 'NOUN'}\n",
    "    ]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add('NOUN_PHRASE', pattern)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    spans = [doc[start:end] for match_id, start, end in matches]\n",
    "\n",
    "    return filter_spans(spans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0841e412-336d-4fd7-a155-3e327c8e7da9",
   "metadata": {},
   "source": [
    "if you have a phrase like `the yellow dog`, you'll get `the yellow dog`, `yellow dog`, and `dog` as matches. \n",
    "\n",
    "what we want here, is to get `only the largest matching spans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d119128d-7c2d-4e7c-ae42-1242a545f0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "It was a rimy morning, and very damp. I had seen the damp lying on the\n",
    "outside of my little window, as if some goblin had been crying there all\n",
    "night, and using the window for a pocket-handkerchief. Now, I saw the\n",
    "damp lying on the bare hedges and spare grass, like a coarser sort of\n",
    "spiders' webs; hanging itself from twig to twig and blade to blade. On\n",
    "every rail and gate, wet lay clammy, and the marsh mist was so thick,\n",
    "that the wooden finger on the post directing people to our village--a\n",
    "direction which they never accepted, for they never came there--was\n",
    "invisible to me until I was quite close under it. Then, as I looked up\n",
    "at it, while it dripped, it seemed to my oppressed conscience like a\n",
    "phantom devoting me to the Hulks.\n",
    "\"\"\".replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db4e8536-5dbe-45f4-adf1-36637e5424c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E178] Each pattern should be a list of dicts, but got: {'POS': 'DET', 'OP': '?'}. Maybe you accidentally passed a single pattern to Matcher.add instead of a list of patterns? If you only want to add one pattern, make sure to wrap it in a list. For example: `matcher.add('NOUN_PHRASE', [pattern])`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37820\\2061604896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnoun_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_37820\\2691028880.py\u001b[0m in \u001b[0;36mnoun_chunks\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      7\u001b[0m     ]\n\u001b[0;32m      8\u001b[0m     \u001b[0mmatcher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NOUN_PHRASE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda-16-FEB\\lib\\site-packages\\spacy\\matcher\\matcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher.Matcher.add\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E178] Each pattern should be a list of dicts, but got: {'POS': 'DET', 'OP': '?'}. Maybe you accidentally passed a single pattern to Matcher.add instead of a list of patterns? If you only want to add one pattern, make sure to wrap it in a list. For example: `matcher.add('NOUN_PHRASE', [pattern])`"
     ]
    }
   ],
   "source": [
    "for chunk in noun_chunks(text):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ab558-49ed-4422-8f45-b2e6c3b4454f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
