{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "#### Textblob\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U textblob\n",
    "# python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the import.\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "\n",
    "from textblob.wordnet import VERB\n",
    "\n",
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let’s create our first TextBlob object.\n",
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Python is a high-level, general-purpose programming language.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "The titular threat of The Blob has always struck me as the ultimate movie\n",
    "monster: an insatiably hungry, amoeba-like mass able to penetrate\n",
    "virtually any safeguard, capable of--as a doomed doctor chillingly\n",
    "describes it--\"assimilating flesh on contact.\n",
    "Snide comparisons to gelatin be damned, it's a concept with the most\n",
    "devastating of potential consequences, not unlike the grey goo scenario\n",
    "proposed by technological theorists fearful of\n",
    "artificial intelligence run rampant.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['The', 'titular', 'threat', 'of', 'The', 'Blob', 'has', 'always', 'struck', 'me', 'as', 'the', 'ultimate', 'movie', 'monster', 'an', 'insatiably', 'hungry', 'amoeba-like', 'mass', 'able', 'to', 'penetrate', 'virtually', 'any', 'safeguard', 'capable', 'of', 'as', 'a', 'doomed', 'doctor', 'chillingly', 'describes', 'it', 'assimilating', 'flesh', 'on', 'contact', 'Snide', 'comparisons', 'to', 'gelatin', 'be', 'damned', 'it', \"'s\", 'a', 'concept', 'with', 'the', 'most', 'devastating', 'of', 'potential', 'consequences', 'not', 'unlike', 'the', 'grey', 'goo', 'scenario', 'proposed', 'by', 'technological', 'theorists', 'fearful', 'of', 'artificial', 'intelligence', 'run', 'rampant'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words.count('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(blob.sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = '''If you can force your heart and nerve and sinew to serve your turn long after they are gone. \\\n",
    "And so hold on when there is nothing in you except the Will which says to them: 'Hold on!'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['If', 'you', 'can', 'force', 'your', 'heart', 'and', 'nerve', 'and', 'sinew', 'to', 'serve', 'your', 'turn', 'long', 'after', 'they', 'are', 'gone', 'And', 'so', 'hold', 'on', 'when', 'there', 'is', 'nothing', 'in', 'you', 'except', 'the', 'Will', 'which', 'says', 'to', 'them', \"'Hold\", 'on'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TabTokenizer\n",
    "tokenizer = TabTokenizer()\n",
    "\n",
    "blob_object = TextBlob(corpus, tokenizer = tokenizer)\n",
    "\n",
    "blob_object.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "from nltk.tokenize import BlanklineTokenizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "from nltk.tokenize import line_tokenize\n",
    "from nltk.tokenize import LineTokenizer\n",
    "from nltk.tokenize import NLTKWordTokenizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['If', 'you', 'can', 'force', 'your', 'heart', 'and', 'nerve', 'and', 'sinew', 'to', 'serve', 'your', 'turn', 'long', 'after', 'they', 'are', 'gone', 'And', 'so', 'hold', 'on', 'when', 'there', 'is', 'nothing', 'in', 'you', 'except', 'the', 'Will', 'which', 'says', 'to', 'them', \"'Hold\", 'on'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = LineTokenizer()\n",
    "\n",
    "blob_object = TextBlob(corpus, tokenizer = tokenizer)\n",
    "\n",
    "blob_object.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['If', 'you', 'can', 'force', 'your', 'heart', 'and', 'nerve', 'and', 'sinew', 'to', 'serve', 'your', 'turn', 'long', 'after', 'they', 'are', 'gone', 'And', 'so', 'hold', 'on', 'when', 'there', 'is', 'nothing', 'in', 'you', 'except', 'the', 'Will', 'which', 'says', 'to', 'them', \"'Hold\", 'on'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = NLTKWordTokenizer()\n",
    "\n",
    "blob_object = TextBlob(corpus, tokenizer = tokenizer)\n",
    "\n",
    "blob_object.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Words and noun phrase counts - Using word_counts dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "monty = TextBlob(\"We are no longer the Knights who say Ni. \"\n",
    "                 \"We are now the Knights who say Ekki ekki ekki PTANG.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'we': 2,\n",
       "             'are': 2,\n",
       "             'no': 1,\n",
       "             'longer': 1,\n",
       "             'the': 2,\n",
       "             'knights': 2,\n",
       "             'who': 2,\n",
       "             'say': 2,\n",
       "             'ni': 1,\n",
       "             'now': 1,\n",
       "             'ekki': 3,\n",
       "             'ptang': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.word_counts['ekki']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you access the frequencies this way, the search will not be case sensitive, and words that are not found will have a frequency of 0.\n",
    "\n",
    "The second way is to use the count() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.words.count('ekki', case_sensitive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monty.noun_phrases.count('we')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Words Inflection and Lemmatization\n",
    "\n",
    "Each word in TextBlob.words or Sentence.words is a Word object (a subclass of unicode) with useful methods, e.g. for word inflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = TextBlob(\"Python is a high-level, general-purpose programming language.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Python', 'is', 'a', 'high-level', 'general-purpose', 'programming', 'language'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'languages'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[-1].pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words can be lemmatized by calling the lemmatize method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word(\"octopi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'octopus'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Word(\"purchased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'purchase'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.lemmatize(\"v\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS tagging\n",
    "\n",
    "Part-of-speech tags can be accessed through the tags property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen = TextBlob(\"Beautiful is better than ugly. \"\n",
    "               \"Explicit is better than implicit. \"\n",
    "               \"Simple is better than complex.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Beautiful', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('ugly', 'RB'),\n",
       " ('Explicit', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('implicit', 'NN'),\n",
       " ('Simple', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('complex', 'JJ')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zen.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful => NNP\n",
      "is => VBZ\n",
      "better => JJR\n",
      "than => IN\n",
      "ugly => RB\n",
      "Explicit => NNP\n",
      "is => VBZ\n",
      "better => JJR\n",
      "than => IN\n",
      "implicit => NN\n",
      "Simple => NN\n",
      "is => VBZ\n",
      "better => JJR\n",
      "than => IN\n",
      "complex => JJ\n"
     ]
    }
   ],
   "source": [
    "for word, pos in zen.tags:\n",
    "    print(word + \" => \" + pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noun Phrase Extraction\n",
    "\n",
    "noun phrases are accessed through the noun_phrases property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = (\"In computer science, artificial intelligence (AI), \\\n",
    "            sometimes called machine intelligence, is intelligence \\\n",
    "            demonstrated by machines, in contrast to the natural intelligence \\\n",
    "            displayed by humans and animals. Computer science defines AI \\\n",
    "            research as the study of \\\"intelligent agents\\\": any device that \\\n",
    "            perceives its environment and takes actions that maximize its\\\n",
    "            chance of successfully achieving its goals.[1] Colloquially,\\\n",
    "            the term \\\"artificial intelligence\\\" is used to describe machines\\\n",
    "            that mimic \\\"cognitive\\\" functions that humans associate with other\\\n",
    "            human minds, such as \\\"learning\\\" and \\\"problem solving\\\".[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_blob_object = TextBlob(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer science\n",
      "artificial intelligence\n",
      "ai\n",
      "machine intelligence\n",
      "natural intelligence\n",
      "computer\n",
      "science defines\n",
      "ai\n",
      "intelligent agents\n",
      "colloquially\n",
      "artificial intelligence\n",
      "describe machines\n",
      "human minds\n"
     ]
    }
   ],
   "source": [
    "text_blob_object = TextBlob(document)\n",
    "\n",
    "for noun_phrase in text_blob_object.noun_phrases:\n",
    "    print(noun_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spelling Correction\n",
    "Use the correct() method to attempt spelling correction.\n",
    "\n",
    "Spelling correction is based on Peter Norvig’s “How to Write a Spelling Corrector” as implemented in the pattern library. It is about 70% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word objects have a spellcheck() Word.spellcheck() method that returns a list of (word, confidence) tuples with spelling suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "w = Word('falibility')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fallibility', 1.0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation and Language Detection\n",
    "\n",
    "One of the most powerful capabilities of the TextBlob library is to translate from one language to another. On the backend, the TextBlob language translator uses the __Google Translate API__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_blob = TextBlob(u'Today I am feeling sleepy in the Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"اليوم أشعر بالنعاس في الفصل\")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_blob.translate(to='ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Beautiful is better than ugly\")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chinese_blob = TextBlob(u\"美丽优于丑陋\")\n",
    "chinese_blob.translate(from_lang=\"zh-CN\", to='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also attempt to detect a TextBlob’s language using TextBlob.detect_language()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ar'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(u\"اليوم أشعر بالنعاس في الفصل\")\n",
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bn'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(\"tumi kemon aachon\")\n",
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = TextBlob(u\"क्या हाल है\")\n",
    "b.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# क्या हाल है \n",
    "# توهان ڪيئن آهيو \n",
    "# আপনি কেমন আছেন \n",
    "# நீங்கள் எப்படி இருக்கிறீர்கள் \n",
    "# तिमीलाई कस्तो छ \n",
    "# તમે કેમ છો \n",
    "# तू कसा आहेस \n",
    "# ന്തൊക്കെയുണ്ട് \n",
    "# آپ کیسے ہو \n",
    "# ನೀವು ಹೇಗಿದ್ದೀರಿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n-grams\n",
    "\n",
    "N-Grams refer to n combination of words in a sentence. For instance, for a sentence \"I love watching football\", some 2-grams would be (I love), (love watching) and (watching football). \n",
    "\n",
    "N-Grams can play a crucial role in text classification.\n",
    "\n",
    "The TextBlob.ngrams() method returns a list of tuples of n successive words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"Now is better than never.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Now', 'is', 'better']),\n",
       " WordList(['is', 'better', 'than']),\n",
       " WordList(['better', 'than', 'never'])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WordNet Integration\n",
    "\n",
    "WordNet is a database of English words that are linked together by their semantic relationships. It is like a supercharged dictionary/thesaurus with a graph structure.\n",
    "\n",
    "TextBlob 0.7 now integrates __NLTK's WordNet__ interface, making it very simple to interact with WordNet.\n",
    "\n",
    "#### Synsets\n",
    "As you know, synonyms are words that have similar meanings. A synonym set, or synset, is a group of synonyms. A synset, therefore, corresponds to an abstract concept.\n",
    "\n",
    "In TextBlob, you can access the synsets that a word belongs to by accessing the synsets property of a Word object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('explain.v.01'), Synset('explain.v.02'), Synset('excuse.v.03')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "word = Word(\"explain\")\n",
    "word.synsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['make plain and comprehensible',\n",
       " 'define',\n",
       " 'serve as a reason or cause or justification of']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant = word.synsets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synonyms contained within a synset are called lemmas. You can access the string versions of these synonyms via a Synset's lemma_names property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Synset.lemma_names of Synset('plant.n.02')>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plant.lemma_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to Upper and Lowercase\n",
    "TextBlob objects are very similar to strings. You can convert them to upper case or lower case, change their values, and concatenate them together as well. In the following script, we convert the text from the TextBlob object to upper case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I LOVE TO WATCH FOOTBALL, BUT I HAVE NEVER PLAYED IT\n"
     ]
    }
   ],
   "source": [
    "text = \"I love to watch football, but I have never played it\"\n",
    "text_blob_object = TextBlob(text)\n",
    "\n",
    "print(text_blob_object.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love to watch football, but i have never played it\n"
     ]
    }
   ],
   "source": [
    "text = \"I LOVE TO WATCH FOOTBALL, BUT I HAVE NEVER PLAYED IT\"\n",
    "text_blob_object = TextBlob(text)\n",
    "\n",
    "print(text_blob_object.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis\n",
    "\n",
    "The sentiment property returns a named tuple of the form Sentiment(polarity, subjectivity). \n",
    "\n",
    "The polarity score is a float within the range [-1.0, 1.0]. \n",
    "\n",
    "The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "Polarity is a float value within the range [-1.0 to 1.0] where \n",
    "\n",
    "    0 indicates neutral, \n",
    "    +1 indicates a very positive sentiment and \n",
    "    -1 represents a very negative sentiment.\n",
    "\n",
    "Subjectivity is a float value within the range [0.0 to 1.0] where \n",
    "\n",
    "    0.0 is very objective and \n",
    "    1.0 is very subjective. \n",
    "\n",
    "Subjective sentence expresses some personal feelings, views, beliefs, opinions, allegations, desires, beliefs, suspicions, and speculations \n",
    "\n",
    "where as Objective sentences are factual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimonial1 = TextBlob(\"Textblob is amazingly simple to use.  !!!!\")\n",
    "testimonial2 = TextBlob(\"earth is round\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:  Sentiment(polarity=0.0, subjectivity=0.35714285714285715)\n",
      "Sentiment:  Sentiment(polarity=-0.2, subjectivity=0.4)\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment: ', testimonial1.sentiment)\n",
    "print('Sentiment: ', testimonial2.sentiment)\n",
    "\n",
    "#print('Polarity: ', testimonial1.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = TextBlob('Earth')\n",
    "word.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:  Sentiment(polarity=0.19285714285714287, subjectivity=0.6081632653061224)\n",
      "Polarity:  0.19285714285714287\n"
     ]
    }
   ],
   "source": [
    "# DLSA (Document level sentiment Analysis)\n",
    "\n",
    "print('Sentiment: ', zen.sentiment)\n",
    "print('Polarity: ', zen.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.2166666666666667, subjectivity=0.8333333333333334)\n",
      "Sentiment(polarity=0.5, subjectivity=0.5)\n",
      "Sentiment(polarity=0.06666666666666667, subjectivity=0.41904761904761906)\n"
     ]
    }
   ],
   "source": [
    "# SLSA (Sentence level sentiment analysis)\n",
    "for sentence in zen.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Text Classification System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some classifiers...\n",
    "\n",
    "    class textblob.classifiers.BaseClassifier\n",
    "    class textblob.classifiers.DecisionTreeClassifier\n",
    "    class textblob.classifiers.MaxEntClassifier\n",
    "    class textblob.classifiers.NLTKClassifier\n",
    "    class textblob.classifiers.NaiveBayesClassifier\n",
    "    class textblob.classifiers.PositiveNaiveBayesClassifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some training and test data.\n",
    "train = [\n",
    "     ('I love this sandwich.', 'pos'),\n",
    "     ('this is an amazing place!', 'pos'),\n",
    "     ('I feel very good about these beers.', 'pos'),\n",
    "     ('this is my best work.', 'pos'),\n",
    "     (\"what an awesome view\", 'pos'),\n",
    "     ('I do not like this restaurant', 'neg'),\n",
    "     ('I am tired of this stuff.', 'neg'),\n",
    "     (\"I can't deal with this\", 'neg'),\n",
    "     ('he is my sworn enemy!', 'neg'),\n",
    "     ('my boss is horrible.', 'neg')\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\n",
    "     ('the beer was good.', 'pos'),\n",
    "     ('I do not enjoy my job', 'neg'),\n",
    "     (\"I ain't feeling dandy today.\", 'neg'),\n",
    "     (\"I feel amazing!\", 'pos'),\n",
    "     ('Gary is a friend of mine.', 'pos'),\n",
    "     (\"I can't believe I'm doing this.\", 'neg')\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data from Files\n",
    "# You can also load data from common file formats including CSV, JSON, and TSV.\n",
    "\n",
    "# CSV files should be formatted like so:\n",
    "\n",
    "# I love this sandwich.,pos\n",
    "# This is an amazing place!,pos\n",
    "# I do not like this restaurant,neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifying Text\n",
    "# Call the classify(text) method to use the classifier.\n",
    "\n",
    "cl.classify(\"This is an worst library!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get the label probability distribution with the prob_classify(text) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dist = cl.prob_classify(\"This one's a doozy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob(\"pos\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(prob_dist.prob(\"neg\"), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating Classifiers\n",
    "# To compute the accuracy on our test set, use the accuracy(test_data) method.\n",
    "\n",
    "cl.accuracy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the show_informative_features() method to display a listing of the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "            contains(my) = True              neg : pos    =      1.7 : 1.0\n",
      "            contains(an) = False             neg : pos    =      1.6 : 1.0\n",
      "             contains(I) = False             pos : neg    =      1.4 : 1.0\n",
      "             contains(I) = True              neg : pos    =      1.4 : 1.0\n",
      "            contains(my) = False             pos : neg    =      1.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "cl.show_informative_features(5)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Classifiers with New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [('She is my best friend.', 'pos'),\n",
    "             (\"I'm happy to have a new friend.\", 'pos'),\n",
    "             (\"Stay thirsty, my friend.\", 'pos'),\n",
    "             (\"He ain't from around here.\", 'neg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.update(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.accuracy(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
