{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb74f3a5-c8d2-4403-88a7-e0b722e2463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "382e475a-ba65-42fa-933b-e8d8fb4b86f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "features = data.data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "scaled_features = torch.tensor(scaled_features, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2bef58d-3e90-4561-af4e-cb0dc77e48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(scaled_features.shape[1], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        validity = self.model(x)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28afa29b-7428-47f3-a81a-ebd1b714bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, scaled_features.shape[1]),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        generated_data = self.model(x)\n",
    "        return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f785b0b3-bee8-4efc-9809-d0abe01c83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the networks\n",
    "discriminator = Discriminator()\n",
    "generator     = Generator()\n",
    "\n",
    "# Loss function and optimizers\n",
    "adversarial_loss = nn.BCELoss()\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68d3ff6b-d94b-4bd0-86ef-0c5bc884622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 300\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f48f7696-c429-409a-9cd6-8f98f30f1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, real_data in enumerate(dataloader):\n",
    "#     print (i, real_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f10ebfe-1b18-4006-bd41-489937ad039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(scaled_features, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765e974-9f4d-4f26-b504-41b78d5c8f11",
   "metadata": {},
   "source": [
    "#### Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d631fa7-5105-4710-8a72-423c9e04b73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch [0/300], Batch Step [0/323], D_loss: 1.3959,  G_loss: 0.7651\n",
      " Epoch [0/300], Batch Step [10/323], D_loss: 1.3563,  G_loss: 0.7495\n",
      " Epoch [0/300], Batch Step [20/323], D_loss: 1.3299,  G_loss: 0.7361\n",
      " Epoch [0/300], Batch Step [30/323], D_loss: 1.3056,  G_loss: 0.7255\n",
      " Epoch [0/300], Batch Step [40/323], D_loss: 1.2624,  G_loss: 0.7251\n",
      " Epoch [0/300], Batch Step [50/323], D_loss: 1.2340,  G_loss: 0.7390\n",
      " Epoch [0/300], Batch Step [60/323], D_loss: 1.1917,  G_loss: 0.7627\n",
      " Epoch [0/300], Batch Step [70/323], D_loss: 1.1655,  G_loss: 0.7844\n",
      " Epoch [0/300], Batch Step [80/323], D_loss: 1.1252,  G_loss: 0.7972\n",
      " Epoch [0/300], Batch Step [90/323], D_loss: 1.0984,  G_loss: 0.8047\n",
      " Epoch [0/300], Batch Step [100/323], D_loss: 1.0722,  G_loss: 0.8124\n",
      " Epoch [0/300], Batch Step [110/323], D_loss: 1.0693,  G_loss: 0.8245\n",
      " Epoch [0/300], Batch Step [120/323], D_loss: 0.9984,  G_loss: 0.8323\n",
      " Epoch [0/300], Batch Step [130/323], D_loss: 0.9384,  G_loss: 0.8684\n",
      " Epoch [0/300], Batch Step [140/323], D_loss: 1.0065,  G_loss: 0.9039\n",
      " Epoch [0/300], Batch Step [150/323], D_loss: 0.9204,  G_loss: 0.9049\n",
      " Epoch [0/300], Batch Step [160/323], D_loss: 0.9795,  G_loss: 0.8708\n",
      " Epoch [0/300], Batch Step [170/323], D_loss: 1.0645,  G_loss: 0.8141\n",
      " Epoch [0/300], Batch Step [180/323], D_loss: 1.0627,  G_loss: 0.7675\n",
      " Epoch [0/300], Batch Step [190/323], D_loss: 1.0274,  G_loss: 0.7519\n",
      " Epoch [0/300], Batch Step [200/323], D_loss: 1.1922,  G_loss: 0.7593\n",
      " Epoch [0/300], Batch Step [210/323], D_loss: 1.0513,  G_loss: 0.8092\n",
      " Epoch [0/300], Batch Step [220/323], D_loss: 1.0292,  G_loss: 0.8734\n",
      " Epoch [0/300], Batch Step [230/323], D_loss: 0.9553,  G_loss: 0.9476\n",
      " Epoch [0/300], Batch Step [240/323], D_loss: 0.9760,  G_loss: 1.0032\n",
      " Epoch [0/300], Batch Step [250/323], D_loss: 0.9870,  G_loss: 1.0378\n",
      " Epoch [0/300], Batch Step [260/323], D_loss: 0.9350,  G_loss: 1.1112\n",
      " Epoch [0/300], Batch Step [270/323], D_loss: 0.8549,  G_loss: 1.1704\n",
      " Epoch [0/300], Batch Step [280/323], D_loss: 0.8367,  G_loss: 1.2055\n",
      " Epoch [0/300], Batch Step [290/323], D_loss: 0.7589,  G_loss: 1.1422\n",
      " Epoch [0/300], Batch Step [300/323], D_loss: 0.9589,  G_loss: 0.9438\n",
      " Epoch [0/300], Batch Step [310/323], D_loss: 1.0152,  G_loss: 0.7853\n",
      " Epoch [0/300], Batch Step [320/323], D_loss: 1.0958,  G_loss: 0.7786\n",
      " Epoch [1/300], Batch Step [0/323], D_loss: 1.0366,  G_loss: 0.7576\n",
      " Epoch [1/300], Batch Step [10/323], D_loss: 1.0322,  G_loss: 1.0093\n",
      " Epoch [1/300], Batch Step [20/323], D_loss: 0.8296,  G_loss: 1.3241\n",
      " Epoch [1/300], Batch Step [30/323], D_loss: 0.5984,  G_loss: 1.5764\n",
      " Epoch [1/300], Batch Step [40/323], D_loss: 0.5604,  G_loss: 1.6660\n",
      " Epoch [1/300], Batch Step [50/323], D_loss: 0.6008,  G_loss: 1.4076\n",
      " Epoch [1/300], Batch Step [60/323], D_loss: 0.6896,  G_loss: 1.2270\n",
      " Epoch [1/300], Batch Step [70/323], D_loss: 0.8718,  G_loss: 1.0433\n",
      " Epoch [1/300], Batch Step [80/323], D_loss: 0.9367,  G_loss: 0.9362\n",
      " Epoch [1/300], Batch Step [90/323], D_loss: 0.9145,  G_loss: 1.0970\n",
      " Epoch [1/300], Batch Step [100/323], D_loss: 0.8553,  G_loss: 1.2901\n",
      " Epoch [1/300], Batch Step [110/323], D_loss: 0.9253,  G_loss: 1.1761\n",
      " Epoch [1/300], Batch Step [120/323], D_loss: 0.8335,  G_loss: 1.2314\n",
      " Epoch [1/300], Batch Step [130/323], D_loss: 0.7173,  G_loss: 1.5859\n",
      " Epoch [1/300], Batch Step [140/323], D_loss: 0.6391,  G_loss: 1.9113\n",
      " Epoch [1/300], Batch Step [150/323], D_loss: 0.6743,  G_loss: 2.1027\n",
      " Epoch [1/300], Batch Step [160/323], D_loss: 0.5099,  G_loss: 2.1753\n",
      " Epoch [1/300], Batch Step [170/323], D_loss: 0.3388,  G_loss: 2.1970\n",
      " Epoch [1/300], Batch Step [180/323], D_loss: 0.3625,  G_loss: 2.1835\n",
      " Epoch [1/300], Batch Step [190/323], D_loss: 0.4171,  G_loss: 1.7857\n",
      " Epoch [1/300], Batch Step [200/323], D_loss: 0.6450,  G_loss: 1.1846\n",
      " Epoch [1/300], Batch Step [210/323], D_loss: 0.5395,  G_loss: 1.4361\n",
      " Epoch [1/300], Batch Step [220/323], D_loss: 0.6300,  G_loss: 1.5849\n",
      " Epoch [1/300], Batch Step [230/323], D_loss: 0.9544,  G_loss: 0.9466\n",
      " Epoch [1/300], Batch Step [240/323], D_loss: 1.3877,  G_loss: 0.5942\n",
      " Epoch [1/300], Batch Step [250/323], D_loss: 1.4626,  G_loss: 0.4847\n",
      " Epoch [1/300], Batch Step [260/323], D_loss: 1.2541,  G_loss: 0.7875\n",
      " Epoch [1/300], Batch Step [270/323], D_loss: 1.1526,  G_loss: 1.1969\n",
      " Epoch [1/300], Batch Step [280/323], D_loss: 1.0272,  G_loss: 1.5846\n",
      " Epoch [1/300], Batch Step [290/323], D_loss: 0.7717,  G_loss: 1.8419\n",
      " Epoch [1/300], Batch Step [300/323], D_loss: 0.5940,  G_loss: 1.9319\n",
      " Epoch [1/300], Batch Step [310/323], D_loss: 0.6718,  G_loss: 1.4562\n",
      " Epoch [1/300], Batch Step [320/323], D_loss: 0.8058,  G_loss: 1.0843\n",
      " Epoch [2/300], Batch Step [0/323], D_loss: 0.8053,  G_loss: 1.2047\n",
      " Epoch [2/300], Batch Step [10/323], D_loss: 0.5504,  G_loss: 2.0358\n",
      " Epoch [2/300], Batch Step [20/323], D_loss: 0.5164,  G_loss: 2.5111\n",
      " Epoch [2/300], Batch Step [30/323], D_loss: 0.3849,  G_loss: 2.5968\n",
      " Epoch [2/300], Batch Step [40/323], D_loss: 0.3902,  G_loss: 2.4947\n",
      " Epoch [2/300], Batch Step [50/323], D_loss: 0.2887,  G_loss: 2.2858\n",
      " Epoch [2/300], Batch Step [60/323], D_loss: 0.3564,  G_loss: 1.9754\n",
      " Epoch [2/300], Batch Step [70/323], D_loss: 0.3029,  G_loss: 2.0973\n",
      " Epoch [2/300], Batch Step [80/323], D_loss: 0.2587,  G_loss: 2.4339\n",
      " Epoch [2/300], Batch Step [90/323], D_loss: 0.3394,  G_loss: 2.5885\n",
      " Epoch [2/300], Batch Step [100/323], D_loss: 0.2671,  G_loss: 2.3303\n",
      " Epoch [2/300], Batch Step [110/323], D_loss: 0.5408,  G_loss: 1.4364\n",
      " Epoch [2/300], Batch Step [120/323], D_loss: 0.4438,  G_loss: 1.8920\n",
      " Epoch [2/300], Batch Step [130/323], D_loss: 0.3495,  G_loss: 2.6454\n",
      " Epoch [2/300], Batch Step [140/323], D_loss: 0.2453,  G_loss: 2.9482\n",
      " Epoch [2/300], Batch Step [150/323], D_loss: 0.2387,  G_loss: 3.0128\n",
      " Epoch [2/300], Batch Step [160/323], D_loss: 0.1846,  G_loss: 2.9311\n",
      " Epoch [2/300], Batch Step [170/323], D_loss: 0.1888,  G_loss: 2.6151\n",
      " Epoch [2/300], Batch Step [180/323], D_loss: 0.2795,  G_loss: 1.8632\n",
      " Epoch [2/300], Batch Step [190/323], D_loss: 0.3922,  G_loss: 1.7468\n",
      " Epoch [2/300], Batch Step [200/323], D_loss: 0.4554,  G_loss: 1.5101\n",
      " Epoch [2/300], Batch Step [210/323], D_loss: 1.0582,  G_loss: 0.7430\n",
      " Epoch [2/300], Batch Step [220/323], D_loss: 0.9365,  G_loss: 1.1445\n",
      " Epoch [2/300], Batch Step [230/323], D_loss: 0.7484,  G_loss: 1.9380\n",
      " Epoch [2/300], Batch Step [240/323], D_loss: 0.8365,  G_loss: 2.2151\n",
      " Epoch [2/300], Batch Step [250/323], D_loss: 0.6161,  G_loss: 2.0134\n",
      " Epoch [2/300], Batch Step [260/323], D_loss: 0.6323,  G_loss: 1.2904\n",
      " Epoch [2/300], Batch Step [270/323], D_loss: 0.7913,  G_loss: 1.0120\n",
      " Epoch [2/300], Batch Step [280/323], D_loss: 0.7266,  G_loss: 1.6076\n",
      " Epoch [2/300], Batch Step [290/323], D_loss: 0.5371,  G_loss: 2.0529\n",
      " Epoch [2/300], Batch Step [300/323], D_loss: 0.6159,  G_loss: 2.1666\n",
      " Epoch [2/300], Batch Step [310/323], D_loss: 0.5982,  G_loss: 1.8073\n",
      " Epoch [2/300], Batch Step [320/323], D_loss: 1.0316,  G_loss: 0.9592\n",
      " Epoch [3/300], Batch Step [0/323], D_loss: 1.0525,  G_loss: 0.7700\n",
      " Epoch [3/300], Batch Step [10/323], D_loss: 0.7987,  G_loss: 1.3460\n",
      " Epoch [3/300], Batch Step [20/323], D_loss: 0.8539,  G_loss: 2.2473\n",
      " Epoch [3/300], Batch Step [30/323], D_loss: 0.6206,  G_loss: 2.4684\n",
      " Epoch [3/300], Batch Step [40/323], D_loss: 0.7573,  G_loss: 2.3840\n",
      " Epoch [3/300], Batch Step [50/323], D_loss: 0.3986,  G_loss: 2.2719\n",
      " Epoch [3/300], Batch Step [60/323], D_loss: 0.5633,  G_loss: 2.2536\n",
      " Epoch [3/300], Batch Step [70/323], D_loss: 0.6307,  G_loss: 2.2945\n",
      " Epoch [3/300], Batch Step [80/323], D_loss: 0.6224,  G_loss: 2.3255\n",
      " Epoch [3/300], Batch Step [90/323], D_loss: 0.3398,  G_loss: 2.3297\n",
      " Epoch [3/300], Batch Step [100/323], D_loss: 0.2840,  G_loss: 2.2604\n",
      " Epoch [3/300], Batch Step [110/323], D_loss: 0.5018,  G_loss: 1.5716\n",
      " Epoch [3/300], Batch Step [120/323], D_loss: 0.9390,  G_loss: 0.9670\n",
      " Epoch [3/300], Batch Step [130/323], D_loss: 0.5933,  G_loss: 1.7704\n",
      " Epoch [3/300], Batch Step [140/323], D_loss: 0.4572,  G_loss: 2.4469\n",
      " Epoch [3/300], Batch Step [150/323], D_loss: 0.6123,  G_loss: 2.6783\n",
      " Epoch [3/300], Batch Step [160/323], D_loss: 0.5411,  G_loss: 2.6611\n",
      " Epoch [3/300], Batch Step [170/323], D_loss: 0.3643,  G_loss: 2.5728\n",
      " Epoch [3/300], Batch Step [180/323], D_loss: 0.3721,  G_loss: 2.5403\n",
      " Epoch [3/300], Batch Step [190/323], D_loss: 0.2219,  G_loss: 2.5824\n",
      " Epoch [3/300], Batch Step [200/323], D_loss: 0.2811,  G_loss: 2.6635\n",
      " Epoch [3/300], Batch Step [210/323], D_loss: 0.3009,  G_loss: 2.6973\n",
      " Epoch [3/300], Batch Step [220/323], D_loss: 0.2675,  G_loss: 2.7390\n",
      " Epoch [3/300], Batch Step [230/323], D_loss: 0.2229,  G_loss: 2.7577\n",
      " Epoch [3/300], Batch Step [240/323], D_loss: 0.2035,  G_loss: 2.8019\n",
      " Epoch [3/300], Batch Step [250/323], D_loss: 0.2139,  G_loss: 2.8387\n",
      " Epoch [3/300], Batch Step [260/323], D_loss: 0.2197,  G_loss: 2.8840\n",
      " Epoch [3/300], Batch Step [270/323], D_loss: 0.1372,  G_loss: 2.8523\n",
      " Epoch [3/300], Batch Step [280/323], D_loss: 0.2111,  G_loss: 2.7169\n",
      " Epoch [3/300], Batch Step [290/323], D_loss: 0.2665,  G_loss: 2.2346\n",
      " Epoch [3/300], Batch Step [300/323], D_loss: 0.5722,  G_loss: 1.1703\n",
      " Epoch [3/300], Batch Step [310/323], D_loss: 0.7277,  G_loss: 1.1205\n",
      " Epoch [3/300], Batch Step [320/323], D_loss: 0.4864,  G_loss: 1.8981\n",
      " Epoch [4/300], Batch Step [0/323], D_loss: 0.4060,  G_loss: 2.1790\n",
      " Epoch [4/300], Batch Step [10/323], D_loss: 0.3361,  G_loss: 2.6786\n",
      " Epoch [4/300], Batch Step [20/323], D_loss: 0.2922,  G_loss: 2.7613\n",
      " Epoch [4/300], Batch Step [30/323], D_loss: 0.4550,  G_loss: 2.7293\n",
      " Epoch [4/300], Batch Step [40/323], D_loss: 0.2567,  G_loss: 2.6990\n",
      " Epoch [4/300], Batch Step [50/323], D_loss: 0.2074,  G_loss: 2.7013\n",
      " Epoch [4/300], Batch Step [60/323], D_loss: 0.3641,  G_loss: 2.7027\n",
      " Epoch [4/300], Batch Step [70/323], D_loss: 0.2477,  G_loss: 2.6019\n",
      " Epoch [4/300], Batch Step [80/323], D_loss: 0.2615,  G_loss: 2.1612\n",
      " Epoch [4/300], Batch Step [90/323], D_loss: 0.6222,  G_loss: 1.2981\n",
      " Epoch [4/300], Batch Step [100/323], D_loss: 1.3568,  G_loss: 0.5224\n",
      " Epoch [4/300], Batch Step [110/323], D_loss: 1.5606,  G_loss: 0.7527\n",
      " Epoch [4/300], Batch Step [120/323], D_loss: 1.2196,  G_loss: 1.6557\n",
      " Epoch [4/300], Batch Step [130/323], D_loss: 1.4251,  G_loss: 2.3620\n",
      " Epoch [4/300], Batch Step [140/323], D_loss: 1.0516,  G_loss: 2.3290\n",
      " Epoch [4/300], Batch Step [150/323], D_loss: 0.8417,  G_loss: 2.1201\n",
      " Epoch [4/300], Batch Step [160/323], D_loss: 0.7543,  G_loss: 2.0776\n",
      " Epoch [4/300], Batch Step [170/323], D_loss: 0.6956,  G_loss: 2.1461\n",
      " Epoch [4/300], Batch Step [180/323], D_loss: 0.5293,  G_loss: 2.1866\n",
      " Epoch [4/300], Batch Step [190/323], D_loss: 0.4030,  G_loss: 2.2214\n",
      " Epoch [4/300], Batch Step [200/323], D_loss: 0.5333,  G_loss: 1.8412\n",
      " Epoch [4/300], Batch Step [210/323], D_loss: 0.5465,  G_loss: 1.2287\n",
      " Epoch [4/300], Batch Step [220/323], D_loss: 0.6211,  G_loss: 1.7051\n",
      " Epoch [4/300], Batch Step [230/323], D_loss: 0.5032,  G_loss: 2.3911\n",
      " Epoch [4/300], Batch Step [240/323], D_loss: 0.5243,  G_loss: 2.4382\n",
      " Epoch [4/300], Batch Step [250/323], D_loss: 0.5629,  G_loss: 2.3173\n",
      " Epoch [4/300], Batch Step [260/323], D_loss: 0.3410,  G_loss: 2.1538\n",
      " Epoch [4/300], Batch Step [270/323], D_loss: 0.4573,  G_loss: 1.8081\n",
      " Epoch [4/300], Batch Step [280/323], D_loss: 0.5659,  G_loss: 1.5732\n",
      " Epoch [4/300], Batch Step [290/323], D_loss: 0.4899,  G_loss: 1.6867\n",
      " Epoch [4/300], Batch Step [300/323], D_loss: 0.5523,  G_loss: 1.9182\n",
      " Epoch [4/300], Batch Step [310/323], D_loss: 0.5948,  G_loss: 2.0684\n",
      " Epoch [4/300], Batch Step [320/323], D_loss: 0.4920,  G_loss: 2.2879\n",
      " Epoch [5/300], Batch Step [0/323], D_loss: 0.3000,  G_loss: 2.3247\n",
      " Epoch [5/300], Batch Step [10/323], D_loss: 0.2626,  G_loss: 2.4283\n",
      " Epoch [5/300], Batch Step [20/323], D_loss: 0.3351,  G_loss: 2.4873\n",
      " Epoch [5/300], Batch Step [30/323], D_loss: 0.3768,  G_loss: 2.5227\n",
      " Epoch [5/300], Batch Step [40/323], D_loss: 0.2023,  G_loss: 2.3676\n",
      " Epoch [5/300], Batch Step [50/323], D_loss: 0.3510,  G_loss: 1.8326\n",
      " Epoch [5/300], Batch Step [60/323], D_loss: 0.6467,  G_loss: 1.2550\n",
      " Epoch [5/300], Batch Step [70/323], D_loss: 0.4059,  G_loss: 2.0465\n",
      " Epoch [5/300], Batch Step [80/323], D_loss: 0.4426,  G_loss: 2.2510\n",
      " Epoch [5/300], Batch Step [90/323], D_loss: 0.6079,  G_loss: 1.3997\n",
      " Epoch [5/300], Batch Step [100/323], D_loss: 0.7306,  G_loss: 1.4673\n",
      " Epoch [5/300], Batch Step [110/323], D_loss: 0.5190,  G_loss: 2.2742\n",
      " Epoch [5/300], Batch Step [120/323], D_loss: 0.4358,  G_loss: 2.5839\n",
      " Epoch [5/300], Batch Step [130/323], D_loss: 0.3305,  G_loss: 2.4832\n",
      " Epoch [5/300], Batch Step [140/323], D_loss: 0.4023,  G_loss: 1.9313\n",
      " Epoch [5/300], Batch Step [150/323], D_loss: 0.6469,  G_loss: 1.2728\n",
      " Epoch [5/300], Batch Step [160/323], D_loss: 0.4628,  G_loss: 1.7882\n",
      " Epoch [5/300], Batch Step [170/323], D_loss: 0.4880,  G_loss: 2.0377\n",
      " Epoch [5/300], Batch Step [180/323], D_loss: 0.6772,  G_loss: 1.5208\n",
      " Epoch [5/300], Batch Step [190/323], D_loss: 0.5942,  G_loss: 1.4641\n",
      " Epoch [5/300], Batch Step [200/323], D_loss: 0.5002,  G_loss: 1.9553\n",
      " Epoch [5/300], Batch Step [210/323], D_loss: 0.4367,  G_loss: 2.2440\n",
      " Epoch [5/300], Batch Step [220/323], D_loss: 0.2402,  G_loss: 2.2469\n",
      " Epoch [5/300], Batch Step [230/323], D_loss: 0.3332,  G_loss: 2.2864\n",
      " Epoch [5/300], Batch Step [240/323], D_loss: 0.2018,  G_loss: 2.3043\n",
      " Epoch [5/300], Batch Step [250/323], D_loss: 0.2681,  G_loss: 2.3697\n",
      " Epoch [5/300], Batch Step [260/323], D_loss: 0.1761,  G_loss: 2.5153\n",
      " Epoch [5/300], Batch Step [270/323], D_loss: 0.2512,  G_loss: 2.6838\n",
      " Epoch [5/300], Batch Step [280/323], D_loss: 0.1887,  G_loss: 2.7831\n",
      " Epoch [5/300], Batch Step [290/323], D_loss: 0.1665,  G_loss: 2.8907\n",
      " Epoch [5/300], Batch Step [300/323], D_loss: 0.1787,  G_loss: 2.9333\n",
      " Epoch [5/300], Batch Step [310/323], D_loss: 0.2006,  G_loss: 2.8931\n",
      " Epoch [5/300], Batch Step [320/323], D_loss: 0.1483,  G_loss: 2.8407\n",
      " Epoch [6/300], Batch Step [0/323], D_loss: 0.1194,  G_loss: 2.8314\n",
      " Epoch [6/300], Batch Step [10/323], D_loss: 0.1334,  G_loss: 2.4998\n",
      " Epoch [6/300], Batch Step [20/323], D_loss: 0.1809,  G_loss: 2.2807\n",
      " Epoch [6/300], Batch Step [30/323], D_loss: 0.1829,  G_loss: 2.5399\n",
      " Epoch [6/300], Batch Step [40/323], D_loss: 0.1299,  G_loss: 2.8142\n",
      " Epoch [6/300], Batch Step [50/323], D_loss: 0.1730,  G_loss: 3.0036\n",
      " Epoch [6/300], Batch Step [60/323], D_loss: 0.1071,  G_loss: 3.0751\n",
      " Epoch [6/300], Batch Step [70/323], D_loss: 0.1700,  G_loss: 3.1469\n",
      " Epoch [6/300], Batch Step [80/323], D_loss: 0.1966,  G_loss: 3.0601\n",
      " Epoch [6/300], Batch Step [90/323], D_loss: 0.0990,  G_loss: 2.9886\n",
      " Epoch [6/300], Batch Step [100/323], D_loss: 0.1000,  G_loss: 2.7861\n",
      " Epoch [6/300], Batch Step [110/323], D_loss: 0.1217,  G_loss: 2.8528\n",
      " Epoch [6/300], Batch Step [120/323], D_loss: 0.1497,  G_loss: 2.7363\n",
      " Epoch [6/300], Batch Step [130/323], D_loss: 0.1788,  G_loss: 2.5613\n",
      " Epoch [6/300], Batch Step [140/323], D_loss: 0.3190,  G_loss: 1.7575\n",
      " Epoch [6/300], Batch Step [150/323], D_loss: 0.5586,  G_loss: 1.1084\n",
      " Epoch [6/300], Batch Step [160/323], D_loss: 0.5527,  G_loss: 1.3458\n",
      " Epoch [6/300], Batch Step [170/323], D_loss: 0.6007,  G_loss: 1.6334\n",
      " Epoch [6/300], Batch Step [180/323], D_loss: 0.7266,  G_loss: 1.4606\n",
      " Epoch [6/300], Batch Step [190/323], D_loss: 0.8402,  G_loss: 1.2652\n",
      " Epoch [6/300], Batch Step [200/323], D_loss: 0.6917,  G_loss: 1.3015\n",
      " Epoch [6/300], Batch Step [210/323], D_loss: 0.8568,  G_loss: 1.4168\n",
      " Epoch [6/300], Batch Step [220/323], D_loss: 0.6576,  G_loss: 1.7427\n",
      " Epoch [6/300], Batch Step [230/323], D_loss: 0.6166,  G_loss: 1.9282\n",
      " Epoch [6/300], Batch Step [240/323], D_loss: 0.4841,  G_loss: 2.0217\n",
      " Epoch [6/300], Batch Step [250/323], D_loss: 0.4215,  G_loss: 1.9953\n",
      " Epoch [6/300], Batch Step [260/323], D_loss: 0.3936,  G_loss: 1.9691\n",
      " Epoch [6/300], Batch Step [270/323], D_loss: 0.2906,  G_loss: 1.9765\n",
      " Epoch [6/300], Batch Step [280/323], D_loss: 0.3348,  G_loss: 2.1340\n",
      " Epoch [6/300], Batch Step [290/323], D_loss: 0.3544,  G_loss: 2.1533\n",
      " Epoch [6/300], Batch Step [300/323], D_loss: 0.3441,  G_loss: 1.9423\n",
      " Epoch [6/300], Batch Step [310/323], D_loss: 0.5735,  G_loss: 1.8955\n",
      " Epoch [6/300], Batch Step [320/323], D_loss: 0.2244,  G_loss: 2.1405\n",
      " Epoch [7/300], Batch Step [0/323], D_loss: 0.4152,  G_loss: 2.2017\n",
      " Epoch [7/300], Batch Step [10/323], D_loss: 0.5489,  G_loss: 2.2133\n",
      " Epoch [7/300], Batch Step [20/323], D_loss: 0.4785,  G_loss: 1.9698\n",
      " Epoch [7/300], Batch Step [30/323], D_loss: 0.5776,  G_loss: 1.5785\n",
      " Epoch [7/300], Batch Step [40/323], D_loss: 0.4618,  G_loss: 1.7330\n",
      " Epoch [7/300], Batch Step [50/323], D_loss: 0.3686,  G_loss: 2.1732\n",
      " Epoch [7/300], Batch Step [60/323], D_loss: 0.5411,  G_loss: 2.3128\n",
      " Epoch [7/300], Batch Step [70/323], D_loss: 0.3109,  G_loss: 2.2776\n",
      " Epoch [7/300], Batch Step [80/323], D_loss: 0.2758,  G_loss: 2.1964\n",
      " Epoch [7/300], Batch Step [90/323], D_loss: 0.3580,  G_loss: 2.0352\n",
      " Epoch [7/300], Batch Step [100/323], D_loss: 0.3580,  G_loss: 2.2092\n",
      " Epoch [7/300], Batch Step [110/323], D_loss: 0.2619,  G_loss: 2.5159\n",
      " Epoch [7/300], Batch Step [120/323], D_loss: 0.3161,  G_loss: 2.7617\n",
      " Epoch [7/300], Batch Step [130/323], D_loss: 0.2193,  G_loss: 2.7770\n",
      " Epoch [7/300], Batch Step [140/323], D_loss: 0.2602,  G_loss: 2.7591\n",
      " Epoch [7/300], Batch Step [150/323], D_loss: 0.1909,  G_loss: 2.7940\n",
      " Epoch [7/300], Batch Step [160/323], D_loss: 0.1960,  G_loss: 2.7513\n",
      " Epoch [7/300], Batch Step [170/323], D_loss: 0.2592,  G_loss: 2.4399\n",
      " Epoch [7/300], Batch Step [180/323], D_loss: 0.2459,  G_loss: 2.0654\n",
      " Epoch [7/300], Batch Step [190/323], D_loss: 0.3398,  G_loss: 1.8099\n",
      " Epoch [7/300], Batch Step [200/323], D_loss: 0.3203,  G_loss: 2.0564\n",
      " Epoch [7/300], Batch Step [210/323], D_loss: 0.2967,  G_loss: 2.4249\n",
      " Epoch [7/300], Batch Step [220/323], D_loss: 0.3474,  G_loss: 2.6255\n",
      " Epoch [7/300], Batch Step [230/323], D_loss: 0.3874,  G_loss: 2.7515\n",
      " Epoch [7/300], Batch Step [240/323], D_loss: 0.2308,  G_loss: 2.6958\n",
      " Epoch [7/300], Batch Step [250/323], D_loss: 0.2783,  G_loss: 2.6320\n",
      " Epoch [7/300], Batch Step [260/323], D_loss: 0.2358,  G_loss: 2.6079\n",
      " Epoch [7/300], Batch Step [270/323], D_loss: 0.1610,  G_loss: 2.7784\n",
      " Epoch [7/300], Batch Step [280/323], D_loss: 0.2280,  G_loss: 2.6862\n",
      " Epoch [7/300], Batch Step [290/323], D_loss: 0.2445,  G_loss: 2.4998\n",
      " Epoch [7/300], Batch Step [300/323], D_loss: 0.2609,  G_loss: 2.3084\n",
      " Epoch [7/300], Batch Step [310/323], D_loss: 0.3893,  G_loss: 1.7507\n",
      " Epoch [7/300], Batch Step [320/323], D_loss: 0.6258,  G_loss: 1.4015\n",
      " Epoch [8/300], Batch Step [0/323], D_loss: 0.4365,  G_loss: 1.6044\n",
      " Epoch [8/300], Batch Step [10/323], D_loss: 0.4192,  G_loss: 2.1395\n",
      " Epoch [8/300], Batch Step [20/323], D_loss: 0.7019,  G_loss: 2.2526\n",
      " Epoch [8/300], Batch Step [30/323], D_loss: 0.2950,  G_loss: 1.9845\n",
      " Epoch [8/300], Batch Step [40/323], D_loss: 0.8130,  G_loss: 1.9081\n",
      " Epoch [8/300], Batch Step [50/323], D_loss: 0.5112,  G_loss: 1.8096\n",
      " Epoch [8/300], Batch Step [60/323], D_loss: 0.7255,  G_loss: 1.5210\n",
      " Epoch [8/300], Batch Step [70/323], D_loss: 0.9372,  G_loss: 1.1147\n",
      " Epoch [8/300], Batch Step [80/323], D_loss: 0.9115,  G_loss: 1.5993\n",
      " Epoch [8/300], Batch Step [90/323], D_loss: 0.9038,  G_loss: 2.3775\n",
      " Epoch [8/300], Batch Step [100/323], D_loss: 0.5454,  G_loss: 2.4101\n",
      " Epoch [8/300], Batch Step [110/323], D_loss: 0.6354,  G_loss: 1.9187\n",
      " Epoch [8/300], Batch Step [120/323], D_loss: 0.8298,  G_loss: 1.7793\n",
      " Epoch [8/300], Batch Step [130/323], D_loss: 0.6901,  G_loss: 2.0011\n",
      " Epoch [8/300], Batch Step [140/323], D_loss: 0.4212,  G_loss: 2.3335\n",
      " Epoch [8/300], Batch Step [150/323], D_loss: 0.4338,  G_loss: 2.4499\n",
      " Epoch [8/300], Batch Step [160/323], D_loss: 0.3571,  G_loss: 2.4555\n",
      " Epoch [8/300], Batch Step [170/323], D_loss: 0.3393,  G_loss: 2.4276\n",
      " Epoch [8/300], Batch Step [180/323], D_loss: 0.3215,  G_loss: 2.2565\n",
      " Epoch [8/300], Batch Step [190/323], D_loss: 0.3071,  G_loss: 2.1141\n",
      " Epoch [8/300], Batch Step [200/323], D_loss: 0.5596,  G_loss: 1.9563\n",
      " Epoch [8/300], Batch Step [210/323], D_loss: 0.4273,  G_loss: 2.2544\n",
      " Epoch [8/300], Batch Step [220/323], D_loss: 0.4259,  G_loss: 2.3753\n",
      " Epoch [8/300], Batch Step [230/323], D_loss: 0.2913,  G_loss: 2.5372\n",
      " Epoch [8/300], Batch Step [240/323], D_loss: 0.3049,  G_loss: 2.6497\n",
      " Epoch [8/300], Batch Step [250/323], D_loss: 0.4557,  G_loss: 2.3209\n",
      " Epoch [8/300], Batch Step [260/323], D_loss: 0.3819,  G_loss: 2.2831\n",
      " Epoch [8/300], Batch Step [270/323], D_loss: 0.4454,  G_loss: 2.0667\n",
      " Epoch [8/300], Batch Step [280/323], D_loss: 0.5280,  G_loss: 1.6555\n",
      " Epoch [8/300], Batch Step [290/323], D_loss: 0.8078,  G_loss: 1.7097\n",
      " Epoch [8/300], Batch Step [300/323], D_loss: 0.7891,  G_loss: 1.7436\n",
      " Epoch [8/300], Batch Step [310/323], D_loss: 0.6018,  G_loss: 1.7996\n",
      " Epoch [8/300], Batch Step [320/323], D_loss: 0.6282,  G_loss: 2.1525\n",
      " Epoch [9/300], Batch Step [0/323], D_loss: 0.7165,  G_loss: 2.1025\n",
      " Epoch [9/300], Batch Step [10/323], D_loss: 0.6193,  G_loss: 2.1877\n",
      " Epoch [9/300], Batch Step [20/323], D_loss: 0.4027,  G_loss: 2.1555\n",
      " Epoch [9/300], Batch Step [30/323], D_loss: 0.3765,  G_loss: 2.1338\n",
      " Epoch [9/300], Batch Step [40/323], D_loss: 0.3604,  G_loss: 2.2377\n",
      " Epoch [9/300], Batch Step [50/323], D_loss: 0.2358,  G_loss: 2.4000\n",
      " Epoch [9/300], Batch Step [60/323], D_loss: 0.1959,  G_loss: 2.5236\n",
      " Epoch [9/300], Batch Step [70/323], D_loss: 0.2541,  G_loss: 2.5017\n",
      " Epoch [9/300], Batch Step [80/323], D_loss: 0.2600,  G_loss: 2.5431\n",
      " Epoch [9/300], Batch Step [90/323], D_loss: 0.2849,  G_loss: 2.5241\n",
      " Epoch [9/300], Batch Step [100/323], D_loss: 0.2079,  G_loss: 2.5447\n",
      " Epoch [9/300], Batch Step [110/323], D_loss: 0.1582,  G_loss: 2.6237\n",
      " Epoch [9/300], Batch Step [120/323], D_loss: 0.1925,  G_loss: 2.2342\n",
      " Epoch [9/300], Batch Step [130/323], D_loss: 0.2983,  G_loss: 2.4726\n",
      " Epoch [9/300], Batch Step [140/323], D_loss: 0.3662,  G_loss: 2.2667\n",
      " Epoch [9/300], Batch Step [150/323], D_loss: 0.4404,  G_loss: 2.1415\n",
      " Epoch [9/300], Batch Step [160/323], D_loss: 0.3915,  G_loss: 2.2044\n",
      " Epoch [9/300], Batch Step [170/323], D_loss: 0.3109,  G_loss: 2.3312\n",
      " Epoch [9/300], Batch Step [180/323], D_loss: 0.2821,  G_loss: 2.4530\n",
      " Epoch [9/300], Batch Step [190/323], D_loss: 0.2855,  G_loss: 2.2931\n",
      " Epoch [9/300], Batch Step [200/323], D_loss: 0.3446,  G_loss: 1.9700\n",
      " Epoch [9/300], Batch Step [210/323], D_loss: 0.3500,  G_loss: 2.0026\n",
      " Epoch [9/300], Batch Step [220/323], D_loss: 0.4542,  G_loss: 2.0115\n",
      " Epoch [9/300], Batch Step [230/323], D_loss: 0.2923,  G_loss: 2.2190\n",
      " Epoch [9/300], Batch Step [240/323], D_loss: 0.2255,  G_loss: 2.3182\n",
      " Epoch [9/300], Batch Step [250/323], D_loss: 0.2964,  G_loss: 2.3207\n",
      " Epoch [9/300], Batch Step [260/323], D_loss: 0.2552,  G_loss: 2.1905\n",
      " Epoch [9/300], Batch Step [270/323], D_loss: 0.2426,  G_loss: 2.1120\n",
      " Epoch [9/300], Batch Step [280/323], D_loss: 0.3916,  G_loss: 1.7639\n",
      " Epoch [9/300], Batch Step [290/323], D_loss: 0.6601,  G_loss: 1.2645\n",
      " Epoch [9/300], Batch Step [300/323], D_loss: 0.8180,  G_loss: 1.2752\n",
      " Epoch [9/300], Batch Step [310/323], D_loss: 0.6459,  G_loss: 2.0773\n",
      " Epoch [9/300], Batch Step [320/323], D_loss: 0.4507,  G_loss: 2.2797\n",
      " Epoch [10/300], Batch Step [0/323], D_loss: 0.4426,  G_loss: 2.4918\n",
      " Epoch [10/300], Batch Step [10/323], D_loss: 0.4127,  G_loss: 2.4659\n",
      " Epoch [10/300], Batch Step [20/323], D_loss: 0.2116,  G_loss: 2.4185\n",
      " Epoch [10/300], Batch Step [30/323], D_loss: 0.1899,  G_loss: 2.3465\n",
      " Epoch [10/300], Batch Step [40/323], D_loss: 0.3903,  G_loss: 2.2459\n",
      " Epoch [10/300], Batch Step [50/323], D_loss: 0.2649,  G_loss: 2.2019\n",
      " Epoch [10/300], Batch Step [60/323], D_loss: 0.2137,  G_loss: 2.0475\n",
      " Epoch [10/300], Batch Step [70/323], D_loss: 0.4229,  G_loss: 1.9626\n",
      " Epoch [10/300], Batch Step [80/323], D_loss: 0.2486,  G_loss: 2.0670\n",
      " Epoch [10/300], Batch Step [90/323], D_loss: 0.5572,  G_loss: 2.3088\n",
      " Epoch [10/300], Batch Step [100/323], D_loss: 0.2960,  G_loss: 2.3489\n",
      " Epoch [10/300], Batch Step [110/323], D_loss: 0.3820,  G_loss: 2.0446\n",
      " Epoch [10/300], Batch Step [120/323], D_loss: 0.6428,  G_loss: 1.4409\n",
      " Epoch [10/300], Batch Step [130/323], D_loss: 0.5193,  G_loss: 1.7012\n",
      " Epoch [10/300], Batch Step [140/323], D_loss: 0.5240,  G_loss: 2.1220\n",
      " Epoch [10/300], Batch Step [150/323], D_loss: 0.3531,  G_loss: 2.1804\n",
      " Epoch [10/300], Batch Step [160/323], D_loss: 0.3588,  G_loss: 2.2642\n",
      " Epoch [10/300], Batch Step [170/323], D_loss: 0.4761,  G_loss: 2.2524\n",
      " Epoch [10/300], Batch Step [180/323], D_loss: 0.3333,  G_loss: 2.0535\n",
      " Epoch [10/300], Batch Step [190/323], D_loss: 0.4391,  G_loss: 1.9073\n",
      " Epoch [10/300], Batch Step [200/323], D_loss: 0.6261,  G_loss: 1.9212\n",
      " Epoch [10/300], Batch Step [210/323], D_loss: 0.4774,  G_loss: 2.0975\n",
      " Epoch [10/300], Batch Step [220/323], D_loss: 0.4063,  G_loss: 2.3673\n",
      " Epoch [10/300], Batch Step [230/323], D_loss: 0.5241,  G_loss: 2.4570\n",
      " Epoch [10/300], Batch Step [240/323], D_loss: 0.3964,  G_loss: 2.3112\n",
      " Epoch [10/300], Batch Step [250/323], D_loss: 0.4681,  G_loss: 2.2436\n",
      " Epoch [10/300], Batch Step [260/323], D_loss: 0.3717,  G_loss: 2.1795\n",
      " Epoch [10/300], Batch Step [270/323], D_loss: 0.3362,  G_loss: 2.2777\n",
      " Epoch [10/300], Batch Step [280/323], D_loss: 0.3063,  G_loss: 2.3680\n",
      " Epoch [10/300], Batch Step [290/323], D_loss: 0.3725,  G_loss: 2.5790\n",
      " Epoch [10/300], Batch Step [300/323], D_loss: 0.2120,  G_loss: 2.6463\n",
      " Epoch [10/300], Batch Step [310/323], D_loss: 0.2681,  G_loss: 2.6839\n",
      " Epoch [10/300], Batch Step [320/323], D_loss: 0.2748,  G_loss: 2.7810\n",
      " Epoch [11/300], Batch Step [0/323], D_loss: 0.2332,  G_loss: 2.8061\n",
      " Epoch [11/300], Batch Step [10/323], D_loss: 0.1926,  G_loss: 2.8576\n",
      " Epoch [11/300], Batch Step [20/323], D_loss: 0.2134,  G_loss: 2.8401\n",
      " Epoch [11/300], Batch Step [30/323], D_loss: 0.1817,  G_loss: 2.8481\n",
      " Epoch [11/300], Batch Step [40/323], D_loss: 0.2128,  G_loss: 3.0843\n",
      " Epoch [11/300], Batch Step [50/323], D_loss: 0.1967,  G_loss: 3.1952\n",
      " Epoch [11/300], Batch Step [60/323], D_loss: 0.3026,  G_loss: 3.1367\n",
      " Epoch [11/300], Batch Step [70/323], D_loss: 0.2054,  G_loss: 3.2001\n",
      " Epoch [11/300], Batch Step [80/323], D_loss: 0.1256,  G_loss: 3.0348\n",
      " Epoch [11/300], Batch Step [90/323], D_loss: 0.1329,  G_loss: 3.1317\n",
      " Epoch [11/300], Batch Step [100/323], D_loss: 0.2324,  G_loss: 3.0044\n",
      " Epoch [11/300], Batch Step [110/323], D_loss: 0.1425,  G_loss: 2.8915\n",
      " Epoch [11/300], Batch Step [120/323], D_loss: 0.1975,  G_loss: 3.0520\n",
      " Epoch [11/300], Batch Step [130/323], D_loss: 0.3028,  G_loss: 3.1270\n",
      " Epoch [11/300], Batch Step [140/323], D_loss: 0.2628,  G_loss: 2.8679\n",
      " Epoch [11/300], Batch Step [150/323], D_loss: 0.2767,  G_loss: 2.9356\n",
      " Epoch [11/300], Batch Step [160/323], D_loss: 0.2829,  G_loss: 2.6211\n",
      " Epoch [11/300], Batch Step [170/323], D_loss: 0.4117,  G_loss: 2.3921\n",
      " Epoch [11/300], Batch Step [180/323], D_loss: 0.2349,  G_loss: 2.3235\n",
      " Epoch [11/300], Batch Step [190/323], D_loss: 0.2770,  G_loss: 2.5570\n",
      " Epoch [11/300], Batch Step [200/323], D_loss: 0.2637,  G_loss: 2.3122\n",
      " Epoch [11/300], Batch Step [210/323], D_loss: 0.3640,  G_loss: 2.2874\n",
      " Epoch [11/300], Batch Step [220/323], D_loss: 0.3054,  G_loss: 2.4112\n",
      " Epoch [11/300], Batch Step [230/323], D_loss: 0.3431,  G_loss: 2.2394\n",
      " Epoch [11/300], Batch Step [240/323], D_loss: 0.3435,  G_loss: 2.4373\n",
      " Epoch [11/300], Batch Step [250/323], D_loss: 0.3280,  G_loss: 2.3262\n",
      " Epoch [11/300], Batch Step [260/323], D_loss: 0.3970,  G_loss: 2.0231\n",
      " Epoch [11/300], Batch Step [270/323], D_loss: 0.4594,  G_loss: 2.0902\n",
      " Epoch [11/300], Batch Step [280/323], D_loss: 0.2775,  G_loss: 2.1228\n",
      " Epoch [11/300], Batch Step [290/323], D_loss: 0.2923,  G_loss: 2.1908\n",
      " Epoch [11/300], Batch Step [300/323], D_loss: 0.4458,  G_loss: 2.1994\n",
      " Epoch [11/300], Batch Step [310/323], D_loss: 0.4855,  G_loss: 2.3252\n",
      " Epoch [11/300], Batch Step [320/323], D_loss: 0.4278,  G_loss: 2.3361\n",
      " Epoch [12/300], Batch Step [0/323], D_loss: 0.2599,  G_loss: 2.4353\n",
      " Epoch [12/300], Batch Step [10/323], D_loss: 0.2044,  G_loss: 2.5404\n",
      " Epoch [12/300], Batch Step [20/323], D_loss: 0.4758,  G_loss: 2.4898\n",
      " Epoch [12/300], Batch Step [30/323], D_loss: 0.3139,  G_loss: 2.5446\n",
      " Epoch [12/300], Batch Step [40/323], D_loss: 0.2417,  G_loss: 2.4007\n",
      " Epoch [12/300], Batch Step [50/323], D_loss: 0.4138,  G_loss: 2.3944\n",
      " Epoch [12/300], Batch Step [60/323], D_loss: 0.4360,  G_loss: 2.6495\n",
      " Epoch [12/300], Batch Step [70/323], D_loss: 0.2653,  G_loss: 2.3080\n",
      " Epoch [12/300], Batch Step [80/323], D_loss: 0.4261,  G_loss: 2.3481\n",
      " Epoch [12/300], Batch Step [90/323], D_loss: 0.3332,  G_loss: 2.2041\n",
      " Epoch [12/300], Batch Step [100/323], D_loss: 0.5140,  G_loss: 2.1202\n",
      " Epoch [12/300], Batch Step [110/323], D_loss: 0.6807,  G_loss: 2.0449\n",
      " Epoch [12/300], Batch Step [120/323], D_loss: 0.6201,  G_loss: 1.9796\n",
      " Epoch [12/300], Batch Step [130/323], D_loss: 0.5962,  G_loss: 2.1460\n",
      " Epoch [12/300], Batch Step [140/323], D_loss: 0.5787,  G_loss: 2.1219\n",
      " Epoch [12/300], Batch Step [150/323], D_loss: 0.6460,  G_loss: 1.8549\n",
      " Epoch [12/300], Batch Step [160/323], D_loss: 0.3679,  G_loss: 1.8966\n",
      " Epoch [12/300], Batch Step [170/323], D_loss: 0.5882,  G_loss: 1.8857\n",
      " Epoch [12/300], Batch Step [180/323], D_loss: 0.3421,  G_loss: 2.0085\n",
      " Epoch [12/300], Batch Step [190/323], D_loss: 0.5187,  G_loss: 2.0090\n",
      " Epoch [12/300], Batch Step [200/323], D_loss: 0.6305,  G_loss: 2.0969\n",
      " Epoch [12/300], Batch Step [210/323], D_loss: 0.6785,  G_loss: 2.0359\n",
      " Epoch [12/300], Batch Step [220/323], D_loss: 0.5223,  G_loss: 1.9194\n",
      " Epoch [12/300], Batch Step [230/323], D_loss: 0.5610,  G_loss: 2.0848\n",
      " Epoch [12/300], Batch Step [240/323], D_loss: 0.4417,  G_loss: 1.7572\n",
      " Epoch [12/300], Batch Step [250/323], D_loss: 0.5663,  G_loss: 2.0570\n",
      " Epoch [12/300], Batch Step [260/323], D_loss: 0.3936,  G_loss: 2.0033\n",
      " Epoch [12/300], Batch Step [270/323], D_loss: 0.4248,  G_loss: 2.0600\n",
      " Epoch [12/300], Batch Step [280/323], D_loss: 0.5193,  G_loss: 2.2596\n",
      " Epoch [12/300], Batch Step [290/323], D_loss: 0.3363,  G_loss: 2.1646\n",
      " Epoch [12/300], Batch Step [300/323], D_loss: 0.3736,  G_loss: 2.3473\n",
      " Epoch [12/300], Batch Step [310/323], D_loss: 0.2969,  G_loss: 2.2541\n",
      " Epoch [12/300], Batch Step [320/323], D_loss: 0.4321,  G_loss: 2.2824\n",
      " Epoch [13/300], Batch Step [0/323], D_loss: 0.4918,  G_loss: 2.2500\n",
      " Epoch [13/300], Batch Step [10/323], D_loss: 0.3735,  G_loss: 2.2915\n",
      " Epoch [13/300], Batch Step [20/323], D_loss: 0.3197,  G_loss: 2.1266\n",
      " Epoch [13/300], Batch Step [30/323], D_loss: 0.3729,  G_loss: 2.1531\n",
      " Epoch [13/300], Batch Step [40/323], D_loss: 0.6056,  G_loss: 2.2287\n",
      " Epoch [13/300], Batch Step [50/323], D_loss: 0.3838,  G_loss: 2.1107\n",
      " Epoch [13/300], Batch Step [60/323], D_loss: 0.4420,  G_loss: 2.1761\n",
      " Epoch [13/300], Batch Step [70/323], D_loss: 0.5408,  G_loss: 2.0465\n",
      " Epoch [13/300], Batch Step [80/323], D_loss: 0.3778,  G_loss: 1.9965\n",
      " Epoch [13/300], Batch Step [90/323], D_loss: 0.4466,  G_loss: 2.2125\n",
      " Epoch [13/300], Batch Step [100/323], D_loss: 0.4809,  G_loss: 2.2508\n",
      " Epoch [13/300], Batch Step [110/323], D_loss: 0.3856,  G_loss: 2.1476\n",
      " Epoch [13/300], Batch Step [120/323], D_loss: 0.2581,  G_loss: 2.1851\n",
      " Epoch [13/300], Batch Step [130/323], D_loss: 0.3903,  G_loss: 2.0812\n",
      " Epoch [13/300], Batch Step [140/323], D_loss: 0.2445,  G_loss: 2.1023\n",
      " Epoch [13/300], Batch Step [150/323], D_loss: 0.3749,  G_loss: 2.1981\n",
      " Epoch [13/300], Batch Step [160/323], D_loss: 0.2461,  G_loss: 2.1608\n",
      " Epoch [13/300], Batch Step [170/323], D_loss: 0.2186,  G_loss: 2.1123\n",
      " Epoch [13/300], Batch Step [180/323], D_loss: 0.3171,  G_loss: 2.2200\n",
      " Epoch [13/300], Batch Step [190/323], D_loss: 0.2837,  G_loss: 2.2526\n",
      " Epoch [13/300], Batch Step [200/323], D_loss: 0.3619,  G_loss: 1.9821\n",
      " Epoch [13/300], Batch Step [210/323], D_loss: 0.4457,  G_loss: 2.2877\n",
      " Epoch [13/300], Batch Step [220/323], D_loss: 0.6231,  G_loss: 2.3419\n",
      " Epoch [13/300], Batch Step [230/323], D_loss: 0.6381,  G_loss: 2.4040\n",
      " Epoch [13/300], Batch Step [240/323], D_loss: 0.6531,  G_loss: 2.2297\n",
      " Epoch [13/300], Batch Step [250/323], D_loss: 0.6455,  G_loss: 1.9470\n",
      " Epoch [13/300], Batch Step [260/323], D_loss: 0.9096,  G_loss: 1.5412\n",
      " Epoch [13/300], Batch Step [270/323], D_loss: 0.7154,  G_loss: 1.9064\n",
      " Epoch [13/300], Batch Step [280/323], D_loss: 0.7494,  G_loss: 2.0628\n",
      " Epoch [13/300], Batch Step [290/323], D_loss: 0.6367,  G_loss: 2.1026\n",
      " Epoch [13/300], Batch Step [300/323], D_loss: 0.3293,  G_loss: 1.8357\n",
      " Epoch [13/300], Batch Step [310/323], D_loss: 0.3873,  G_loss: 2.1107\n",
      " Epoch [13/300], Batch Step [320/323], D_loss: 0.3897,  G_loss: 2.0347\n",
      " Epoch [14/300], Batch Step [0/323], D_loss: 0.2585,  G_loss: 2.1205\n",
      " Epoch [14/300], Batch Step [10/323], D_loss: 0.3960,  G_loss: 2.2022\n",
      " Epoch [14/300], Batch Step [20/323], D_loss: 0.4598,  G_loss: 2.3434\n",
      " Epoch [14/300], Batch Step [30/323], D_loss: 0.4582,  G_loss: 2.2068\n",
      " Epoch [14/300], Batch Step [40/323], D_loss: 0.4204,  G_loss: 2.2496\n",
      " Epoch [14/300], Batch Step [50/323], D_loss: 0.3476,  G_loss: 2.1512\n",
      " Epoch [14/300], Batch Step [60/323], D_loss: 0.5263,  G_loss: 2.3233\n",
      " Epoch [14/300], Batch Step [70/323], D_loss: 0.5060,  G_loss: 1.9567\n",
      " Epoch [14/300], Batch Step [80/323], D_loss: 0.4045,  G_loss: 2.0751\n",
      " Epoch [14/300], Batch Step [90/323], D_loss: 0.5431,  G_loss: 1.9592\n",
      " Epoch [14/300], Batch Step [100/323], D_loss: 0.6153,  G_loss: 2.1395\n",
      " Epoch [14/300], Batch Step [110/323], D_loss: 0.3483,  G_loss: 1.9059\n",
      " Epoch [14/300], Batch Step [120/323], D_loss: 0.6267,  G_loss: 1.9164\n",
      " Epoch [14/300], Batch Step [130/323], D_loss: 0.4628,  G_loss: 2.0147\n",
      " Epoch [14/300], Batch Step [140/323], D_loss: 0.5025,  G_loss: 1.9030\n",
      " Epoch [14/300], Batch Step [150/323], D_loss: 0.4252,  G_loss: 1.9660\n",
      " Epoch [14/300], Batch Step [160/323], D_loss: 0.5123,  G_loss: 2.0669\n",
      " Epoch [14/300], Batch Step [170/323], D_loss: 0.4292,  G_loss: 1.9267\n",
      " Epoch [14/300], Batch Step [180/323], D_loss: 0.4830,  G_loss: 1.9254\n",
      " Epoch [14/300], Batch Step [190/323], D_loss: 0.4766,  G_loss: 2.0314\n",
      " Epoch [14/300], Batch Step [200/323], D_loss: 0.4683,  G_loss: 2.1631\n",
      " Epoch [14/300], Batch Step [210/323], D_loss: 0.4686,  G_loss: 2.0624\n",
      " Epoch [14/300], Batch Step [220/323], D_loss: 0.3739,  G_loss: 1.8352\n",
      " Epoch [14/300], Batch Step [230/323], D_loss: 0.3631,  G_loss: 1.8650\n",
      " Epoch [14/300], Batch Step [240/323], D_loss: 0.6093,  G_loss: 2.0050\n",
      " Epoch [14/300], Batch Step [250/323], D_loss: 0.5330,  G_loss: 1.9428\n",
      " Epoch [14/300], Batch Step [260/323], D_loss: 0.4972,  G_loss: 1.8433\n",
      " Epoch [14/300], Batch Step [270/323], D_loss: 0.3044,  G_loss: 2.0096\n",
      " Epoch [14/300], Batch Step [280/323], D_loss: 0.4555,  G_loss: 2.0618\n",
      " Epoch [14/300], Batch Step [290/323], D_loss: 0.3580,  G_loss: 1.9639\n",
      " Epoch [14/300], Batch Step [300/323], D_loss: 0.5248,  G_loss: 2.1983\n",
      " Epoch [14/300], Batch Step [310/323], D_loss: 0.5843,  G_loss: 2.2004\n",
      " Epoch [14/300], Batch Step [320/323], D_loss: 0.4238,  G_loss: 2.2609\n",
      " Epoch [15/300], Batch Step [0/323], D_loss: 0.4244,  G_loss: 2.0993\n",
      " Epoch [15/300], Batch Step [10/323], D_loss: 0.5044,  G_loss: 2.1692\n",
      " Epoch [15/300], Batch Step [20/323], D_loss: 0.4704,  G_loss: 1.8774\n",
      " Epoch [15/300], Batch Step [30/323], D_loss: 0.5364,  G_loss: 2.0877\n",
      " Epoch [15/300], Batch Step [40/323], D_loss: 0.4039,  G_loss: 2.1279\n",
      " Epoch [15/300], Batch Step [50/323], D_loss: 0.5119,  G_loss: 2.0572\n",
      " Epoch [15/300], Batch Step [60/323], D_loss: 0.4239,  G_loss: 2.0871\n",
      " Epoch [15/300], Batch Step [70/323], D_loss: 0.5650,  G_loss: 2.0421\n",
      " Epoch [15/300], Batch Step [80/323], D_loss: 0.4621,  G_loss: 1.9505\n",
      " Epoch [15/300], Batch Step [90/323], D_loss: 0.4286,  G_loss: 2.1522\n",
      " Epoch [15/300], Batch Step [100/323], D_loss: 0.3934,  G_loss: 2.2395\n",
      " Epoch [15/300], Batch Step [110/323], D_loss: 0.3826,  G_loss: 2.1173\n",
      " Epoch [15/300], Batch Step [120/323], D_loss: 0.3217,  G_loss: 1.9738\n",
      " Epoch [15/300], Batch Step [130/323], D_loss: 0.6513,  G_loss: 2.0101\n",
      " Epoch [15/300], Batch Step [140/323], D_loss: 0.3769,  G_loss: 2.0215\n",
      " Epoch [15/300], Batch Step [150/323], D_loss: 0.4266,  G_loss: 2.2306\n",
      " Epoch [15/300], Batch Step [160/323], D_loss: 0.3913,  G_loss: 2.3500\n",
      " Epoch [15/300], Batch Step [170/323], D_loss: 0.4483,  G_loss: 2.3215\n",
      " Epoch [15/300], Batch Step [180/323], D_loss: 0.4311,  G_loss: 2.0626\n",
      " Epoch [15/300], Batch Step [190/323], D_loss: 0.3203,  G_loss: 2.3563\n",
      " Epoch [15/300], Batch Step [200/323], D_loss: 0.3497,  G_loss: 2.1563\n",
      " Epoch [15/300], Batch Step [210/323], D_loss: 0.4353,  G_loss: 2.1896\n",
      " Epoch [15/300], Batch Step [220/323], D_loss: 0.4321,  G_loss: 2.2169\n",
      " Epoch [15/300], Batch Step [230/323], D_loss: 0.3386,  G_loss: 2.1550\n",
      " Epoch [15/300], Batch Step [240/323], D_loss: 0.2802,  G_loss: 2.2709\n",
      " Epoch [15/300], Batch Step [250/323], D_loss: 0.3971,  G_loss: 2.2654\n",
      " Epoch [15/300], Batch Step [260/323], D_loss: 0.4369,  G_loss: 2.2534\n",
      " Epoch [15/300], Batch Step [270/323], D_loss: 0.4993,  G_loss: 2.1139\n",
      " Epoch [15/300], Batch Step [280/323], D_loss: 0.3487,  G_loss: 2.3179\n",
      " Epoch [15/300], Batch Step [290/323], D_loss: 0.3739,  G_loss: 2.4494\n",
      " Epoch [15/300], Batch Step [300/323], D_loss: 0.3978,  G_loss: 2.3317\n",
      " Epoch [15/300], Batch Step [310/323], D_loss: 0.4905,  G_loss: 2.2843\n",
      " Epoch [15/300], Batch Step [320/323], D_loss: 0.4035,  G_loss: 2.5151\n",
      " Epoch [16/300], Batch Step [0/323], D_loss: 0.3570,  G_loss: 2.3766\n",
      " Epoch [16/300], Batch Step [10/323], D_loss: 0.3635,  G_loss: 2.3432\n",
      " Epoch [16/300], Batch Step [20/323], D_loss: 0.4160,  G_loss: 2.2415\n",
      " Epoch [16/300], Batch Step [30/323], D_loss: 0.3228,  G_loss: 2.1169\n",
      " Epoch [16/300], Batch Step [40/323], D_loss: 0.2517,  G_loss: 2.2520\n",
      " Epoch [16/300], Batch Step [50/323], D_loss: 0.3647,  G_loss: 2.2570\n",
      " Epoch [16/300], Batch Step [60/323], D_loss: 0.3575,  G_loss: 2.2843\n",
      " Epoch [16/300], Batch Step [70/323], D_loss: 0.3651,  G_loss: 2.2944\n",
      " Epoch [16/300], Batch Step [80/323], D_loss: 0.3047,  G_loss: 2.3523\n",
      " Epoch [16/300], Batch Step [90/323], D_loss: 0.4211,  G_loss: 2.5099\n",
      " Epoch [16/300], Batch Step [100/323], D_loss: 0.2092,  G_loss: 2.4061\n",
      " Epoch [16/300], Batch Step [110/323], D_loss: 0.2855,  G_loss: 2.4002\n",
      " Epoch [16/300], Batch Step [120/323], D_loss: 0.2776,  G_loss: 2.4135\n",
      " Epoch [16/300], Batch Step [130/323], D_loss: 0.3012,  G_loss: 2.3395\n",
      " Epoch [16/300], Batch Step [140/323], D_loss: 0.3911,  G_loss: 2.4339\n",
      " Epoch [16/300], Batch Step [150/323], D_loss: 0.2743,  G_loss: 2.1621\n",
      " Epoch [16/300], Batch Step [160/323], D_loss: 0.3753,  G_loss: 2.1744\n",
      " Epoch [16/300], Batch Step [170/323], D_loss: 0.3561,  G_loss: 2.2632\n",
      " Epoch [16/300], Batch Step [180/323], D_loss: 0.4332,  G_loss: 2.3038\n",
      " Epoch [16/300], Batch Step [190/323], D_loss: 0.4101,  G_loss: 2.4294\n",
      " Epoch [16/300], Batch Step [200/323], D_loss: 0.4080,  G_loss: 2.1808\n",
      " Epoch [16/300], Batch Step [210/323], D_loss: 0.3970,  G_loss: 2.3614\n",
      " Epoch [16/300], Batch Step [220/323], D_loss: 0.2910,  G_loss: 2.3850\n",
      " Epoch [16/300], Batch Step [230/323], D_loss: 0.3700,  G_loss: 2.3058\n",
      " Epoch [16/300], Batch Step [240/323], D_loss: 0.4739,  G_loss: 2.2269\n",
      " Epoch [16/300], Batch Step [250/323], D_loss: 0.4498,  G_loss: 2.1931\n",
      " Epoch [16/300], Batch Step [260/323], D_loss: 0.7573,  G_loss: 2.2371\n",
      " Epoch [16/300], Batch Step [270/323], D_loss: 0.8579,  G_loss: 2.1962\n",
      " Epoch [16/300], Batch Step [280/323], D_loss: 0.6414,  G_loss: 2.1558\n",
      " Epoch [16/300], Batch Step [290/323], D_loss: 0.5422,  G_loss: 2.1100\n",
      " Epoch [16/300], Batch Step [300/323], D_loss: 0.5550,  G_loss: 2.1183\n",
      " Epoch [16/300], Batch Step [310/323], D_loss: 0.4617,  G_loss: 2.1666\n",
      " Epoch [16/300], Batch Step [320/323], D_loss: 0.4291,  G_loss: 2.0840\n",
      " Epoch [17/300], Batch Step [0/323], D_loss: 0.5268,  G_loss: 2.0288\n",
      " Epoch [17/300], Batch Step [10/323], D_loss: 0.3738,  G_loss: 2.0781\n",
      " Epoch [17/300], Batch Step [20/323], D_loss: 0.4240,  G_loss: 1.9571\n",
      " Epoch [17/300], Batch Step [30/323], D_loss: 0.5599,  G_loss: 2.0212\n",
      " Epoch [17/300], Batch Step [40/323], D_loss: 0.4626,  G_loss: 2.0092\n",
      " Epoch [17/300], Batch Step [50/323], D_loss: 0.3682,  G_loss: 2.0693\n",
      " Epoch [17/300], Batch Step [60/323], D_loss: 0.3834,  G_loss: 1.9708\n",
      " Epoch [17/300], Batch Step [70/323], D_loss: 0.4689,  G_loss: 2.1228\n",
      " Epoch [17/300], Batch Step [80/323], D_loss: 0.6409,  G_loss: 2.0159\n",
      " Epoch [17/300], Batch Step [90/323], D_loss: 0.4530,  G_loss: 1.9862\n",
      " Epoch [17/300], Batch Step [100/323], D_loss: 0.3783,  G_loss: 2.0381\n",
      " Epoch [17/300], Batch Step [110/323], D_loss: 0.3691,  G_loss: 2.0790\n",
      " Epoch [17/300], Batch Step [120/323], D_loss: 0.5368,  G_loss: 2.1031\n",
      " Epoch [17/300], Batch Step [130/323], D_loss: 0.3043,  G_loss: 2.0777\n",
      " Epoch [17/300], Batch Step [140/323], D_loss: 0.3280,  G_loss: 2.0830\n",
      " Epoch [17/300], Batch Step [150/323], D_loss: 0.4779,  G_loss: 2.1466\n",
      " Epoch [17/300], Batch Step [160/323], D_loss: 0.4412,  G_loss: 2.1842\n",
      " Epoch [17/300], Batch Step [170/323], D_loss: 0.3691,  G_loss: 2.0371\n",
      " Epoch [17/300], Batch Step [180/323], D_loss: 0.3609,  G_loss: 2.2445\n",
      " Epoch [17/300], Batch Step [190/323], D_loss: 0.2613,  G_loss: 2.2576\n",
      " Epoch [17/300], Batch Step [200/323], D_loss: 0.4696,  G_loss: 2.1770\n",
      " Epoch [17/300], Batch Step [210/323], D_loss: 0.3316,  G_loss: 2.1795\n",
      " Epoch [17/300], Batch Step [220/323], D_loss: 0.3613,  G_loss: 2.2073\n",
      " Epoch [17/300], Batch Step [230/323], D_loss: 0.3562,  G_loss: 2.2302\n",
      " Epoch [17/300], Batch Step [240/323], D_loss: 0.2805,  G_loss: 2.1988\n",
      " Epoch [17/300], Batch Step [250/323], D_loss: 0.3284,  G_loss: 2.2356\n",
      " Epoch [17/300], Batch Step [260/323], D_loss: 0.2905,  G_loss: 2.2884\n",
      " Epoch [17/300], Batch Step [270/323], D_loss: 0.3797,  G_loss: 2.2226\n",
      " Epoch [17/300], Batch Step [280/323], D_loss: 0.2411,  G_loss: 2.2382\n",
      " Epoch [17/300], Batch Step [290/323], D_loss: 0.2833,  G_loss: 2.3570\n",
      " Epoch [17/300], Batch Step [300/323], D_loss: 0.2750,  G_loss: 2.1970\n",
      " Epoch [17/300], Batch Step [310/323], D_loss: 0.3072,  G_loss: 2.1709\n",
      " Epoch [17/300], Batch Step [320/323], D_loss: 0.2373,  G_loss: 2.3698\n",
      " Epoch [18/300], Batch Step [0/323], D_loss: 0.2175,  G_loss: 2.3513\n",
      " Epoch [18/300], Batch Step [10/323], D_loss: 0.2570,  G_loss: 2.3180\n",
      " Epoch [18/300], Batch Step [20/323], D_loss: 0.3350,  G_loss: 2.4232\n",
      " Epoch [18/300], Batch Step [30/323], D_loss: 0.2158,  G_loss: 2.4418\n",
      " Epoch [18/300], Batch Step [40/323], D_loss: 0.3698,  G_loss: 2.3625\n",
      " Epoch [18/300], Batch Step [50/323], D_loss: 0.3029,  G_loss: 2.3369\n",
      " Epoch [18/300], Batch Step [60/323], D_loss: 0.3141,  G_loss: 2.4185\n",
      " Epoch [18/300], Batch Step [70/323], D_loss: 0.2606,  G_loss: 2.3581\n",
      " Epoch [18/300], Batch Step [80/323], D_loss: 0.2585,  G_loss: 2.4186\n",
      " Epoch [18/300], Batch Step [90/323], D_loss: 0.4290,  G_loss: 2.3316\n",
      " Epoch [18/300], Batch Step [100/323], D_loss: 0.3267,  G_loss: 2.4516\n",
      " Epoch [18/300], Batch Step [110/323], D_loss: 0.2960,  G_loss: 2.5616\n",
      " Epoch [18/300], Batch Step [120/323], D_loss: 0.3284,  G_loss: 2.5175\n",
      " Epoch [18/300], Batch Step [130/323], D_loss: 0.1996,  G_loss: 2.5637\n",
      " Epoch [18/300], Batch Step [140/323], D_loss: 0.1474,  G_loss: 2.6383\n",
      " Epoch [18/300], Batch Step [150/323], D_loss: 0.1327,  G_loss: 2.5858\n",
      " Epoch [18/300], Batch Step [160/323], D_loss: 0.3255,  G_loss: 3.0018\n",
      " Epoch [18/300], Batch Step [170/323], D_loss: 0.2590,  G_loss: 2.7272\n",
      " Epoch [18/300], Batch Step [180/323], D_loss: 0.2039,  G_loss: 2.7866\n",
      " Epoch [18/300], Batch Step [190/323], D_loss: 0.4582,  G_loss: 2.1859\n",
      " Epoch [18/300], Batch Step [200/323], D_loss: 0.3993,  G_loss: 2.0363\n",
      " Epoch [18/300], Batch Step [210/323], D_loss: 0.3968,  G_loss: 2.3699\n",
      " Epoch [18/300], Batch Step [220/323], D_loss: 0.4399,  G_loss: 2.6058\n",
      " Epoch [18/300], Batch Step [230/323], D_loss: 0.3025,  G_loss: 2.3642\n",
      " Epoch [18/300], Batch Step [240/323], D_loss: 0.3343,  G_loss: 2.4569\n",
      " Epoch [18/300], Batch Step [250/323], D_loss: 0.1982,  G_loss: 2.6237\n",
      " Epoch [18/300], Batch Step [260/323], D_loss: 0.2402,  G_loss: 2.2566\n",
      " Epoch [18/300], Batch Step [270/323], D_loss: 0.3686,  G_loss: 2.3300\n",
      " Epoch [18/300], Batch Step [280/323], D_loss: 0.5065,  G_loss: 2.1075\n",
      " Epoch [18/300], Batch Step [290/323], D_loss: 0.4230,  G_loss: 2.2628\n",
      " Epoch [18/300], Batch Step [300/323], D_loss: 0.4307,  G_loss: 2.2926\n",
      " Epoch [18/300], Batch Step [310/323], D_loss: 0.3358,  G_loss: 2.2389\n",
      " Epoch [18/300], Batch Step [320/323], D_loss: 0.3312,  G_loss: 2.3958\n",
      " Epoch [19/300], Batch Step [0/323], D_loss: 0.2718,  G_loss: 2.5717\n",
      " Epoch [19/300], Batch Step [10/323], D_loss: 0.3474,  G_loss: 2.2415\n",
      " Epoch [19/300], Batch Step [20/323], D_loss: 0.3552,  G_loss: 2.3270\n",
      " Epoch [19/300], Batch Step [30/323], D_loss: 0.3009,  G_loss: 2.4194\n",
      " Epoch [19/300], Batch Step [40/323], D_loss: 0.2448,  G_loss: 2.4752\n",
      " Epoch [19/300], Batch Step [50/323], D_loss: 0.2865,  G_loss: 2.6082\n",
      " Epoch [19/300], Batch Step [60/323], D_loss: 0.2083,  G_loss: 2.4799\n",
      " Epoch [19/300], Batch Step [70/323], D_loss: 0.1979,  G_loss: 2.6112\n",
      " Epoch [19/300], Batch Step [80/323], D_loss: 0.1549,  G_loss: 2.5143\n",
      " Epoch [19/300], Batch Step [90/323], D_loss: 0.2259,  G_loss: 2.7012\n",
      " Epoch [19/300], Batch Step [100/323], D_loss: 0.4597,  G_loss: 2.6812\n",
      " Epoch [19/300], Batch Step [110/323], D_loss: 0.1942,  G_loss: 2.4468\n",
      " Epoch [19/300], Batch Step [120/323], D_loss: 0.4516,  G_loss: 2.4795\n",
      " Epoch [19/300], Batch Step [130/323], D_loss: 0.3118,  G_loss: 2.4179\n",
      " Epoch [19/300], Batch Step [140/323], D_loss: 0.2769,  G_loss: 2.6579\n",
      " Epoch [19/300], Batch Step [150/323], D_loss: 0.1935,  G_loss: 2.8202\n",
      " Epoch [19/300], Batch Step [160/323], D_loss: 0.2281,  G_loss: 2.6723\n",
      " Epoch [19/300], Batch Step [170/323], D_loss: 0.2466,  G_loss: 2.6236\n",
      " Epoch [19/300], Batch Step [180/323], D_loss: 0.3965,  G_loss: 2.5153\n",
      " Epoch [19/300], Batch Step [190/323], D_loss: 0.3377,  G_loss: 2.4278\n",
      " Epoch [19/300], Batch Step [200/323], D_loss: 0.2404,  G_loss: 2.5385\n",
      " Epoch [19/300], Batch Step [210/323], D_loss: 0.1893,  G_loss: 2.6946\n",
      " Epoch [19/300], Batch Step [220/323], D_loss: 0.3281,  G_loss: 2.5708\n",
      " Epoch [19/300], Batch Step [230/323], D_loss: 0.2148,  G_loss: 2.3102\n",
      " Epoch [19/300], Batch Step [240/323], D_loss: 0.3715,  G_loss: 2.7374\n",
      " Epoch [19/300], Batch Step [250/323], D_loss: 0.3498,  G_loss: 2.4860\n",
      " Epoch [19/300], Batch Step [260/323], D_loss: 0.2499,  G_loss: 2.4547\n",
      " Epoch [19/300], Batch Step [270/323], D_loss: 0.3025,  G_loss: 2.7456\n",
      " Epoch [19/300], Batch Step [280/323], D_loss: 0.2175,  G_loss: 2.6214\n",
      " Epoch [19/300], Batch Step [290/323], D_loss: 0.3112,  G_loss: 2.3565\n",
      " Epoch [19/300], Batch Step [300/323], D_loss: 0.3527,  G_loss: 2.4037\n",
      " Epoch [19/300], Batch Step [310/323], D_loss: 0.4415,  G_loss: 2.6588\n",
      " Epoch [19/300], Batch Step [320/323], D_loss: 0.3210,  G_loss: 2.2757\n",
      " Epoch [20/300], Batch Step [0/323], D_loss: 0.3084,  G_loss: 2.3734\n",
      " Epoch [20/300], Batch Step [10/323], D_loss: 0.2959,  G_loss: 2.5847\n",
      " Epoch [20/300], Batch Step [20/323], D_loss: 0.3848,  G_loss: 2.4314\n",
      " Epoch [20/300], Batch Step [30/323], D_loss: 0.3384,  G_loss: 2.4676\n",
      " Epoch [20/300], Batch Step [40/323], D_loss: 0.2699,  G_loss: 2.5978\n",
      " Epoch [20/300], Batch Step [50/323], D_loss: 0.1952,  G_loss: 2.4082\n",
      " Epoch [20/300], Batch Step [60/323], D_loss: 0.2889,  G_loss: 2.5613\n",
      " Epoch [20/300], Batch Step [70/323], D_loss: 0.3333,  G_loss: 2.6092\n",
      " Epoch [20/300], Batch Step [80/323], D_loss: 0.4895,  G_loss: 2.4135\n",
      " Epoch [20/300], Batch Step [90/323], D_loss: 0.2255,  G_loss: 2.5747\n",
      " Epoch [20/300], Batch Step [100/323], D_loss: 0.4219,  G_loss: 2.2785\n",
      " Epoch [20/300], Batch Step [110/323], D_loss: 0.3106,  G_loss: 2.3395\n",
      " Epoch [20/300], Batch Step [120/323], D_loss: 0.1669,  G_loss: 2.5356\n",
      " Epoch [20/300], Batch Step [130/323], D_loss: 0.2867,  G_loss: 2.5183\n",
      " Epoch [20/300], Batch Step [140/323], D_loss: 0.1381,  G_loss: 2.3687\n",
      " Epoch [20/300], Batch Step [150/323], D_loss: 0.1842,  G_loss: 2.4118\n",
      " Epoch [20/300], Batch Step [160/323], D_loss: 0.2400,  G_loss: 2.4241\n",
      " Epoch [20/300], Batch Step [170/323], D_loss: 0.2783,  G_loss: 2.3277\n",
      " Epoch [20/300], Batch Step [180/323], D_loss: 0.3148,  G_loss: 2.5765\n",
      " Epoch [20/300], Batch Step [190/323], D_loss: 0.1741,  G_loss: 2.4403\n",
      " Epoch [20/300], Batch Step [200/323], D_loss: 0.2513,  G_loss: 2.5050\n",
      " Epoch [20/300], Batch Step [210/323], D_loss: 0.2475,  G_loss: 2.3585\n",
      " Epoch [20/300], Batch Step [220/323], D_loss: 0.2455,  G_loss: 2.5283\n",
      " Epoch [20/300], Batch Step [230/323], D_loss: 0.2812,  G_loss: 2.6967\n",
      " Epoch [20/300], Batch Step [240/323], D_loss: 0.1984,  G_loss: 2.5042\n",
      " Epoch [20/300], Batch Step [250/323], D_loss: 0.4050,  G_loss: 2.5385\n",
      " Epoch [20/300], Batch Step [260/323], D_loss: 0.2434,  G_loss: 2.5652\n",
      " Epoch [20/300], Batch Step [270/323], D_loss: 0.3066,  G_loss: 2.7400\n",
      " Epoch [20/300], Batch Step [280/323], D_loss: 0.1825,  G_loss: 2.4968\n",
      " Epoch [20/300], Batch Step [290/323], D_loss: 0.1687,  G_loss: 2.4380\n",
      " Epoch [20/300], Batch Step [300/323], D_loss: 0.1674,  G_loss: 2.5081\n",
      " Epoch [20/300], Batch Step [310/323], D_loss: 0.2673,  G_loss: 2.3474\n",
      " Epoch [20/300], Batch Step [320/323], D_loss: 0.2075,  G_loss: 2.2638\n",
      " Epoch [21/300], Batch Step [0/323], D_loss: 0.2610,  G_loss: 2.3848\n",
      " Epoch [21/300], Batch Step [10/323], D_loss: 0.2505,  G_loss: 2.6070\n",
      " Epoch [21/300], Batch Step [20/323], D_loss: 0.1256,  G_loss: 2.8176\n",
      " Epoch [21/300], Batch Step [30/323], D_loss: 0.1873,  G_loss: 2.8418\n",
      " Epoch [21/300], Batch Step [40/323], D_loss: 0.1713,  G_loss: 3.0080\n",
      " Epoch [21/300], Batch Step [50/323], D_loss: 0.2608,  G_loss: 2.9583\n",
      " Epoch [21/300], Batch Step [60/323], D_loss: 0.1344,  G_loss: 2.8322\n",
      " Epoch [21/300], Batch Step [70/323], D_loss: 0.2029,  G_loss: 2.6382\n",
      " Epoch [21/300], Batch Step [80/323], D_loss: 0.3492,  G_loss: 2.7503\n",
      " Epoch [21/300], Batch Step [90/323], D_loss: 0.3003,  G_loss: 2.4141\n",
      " Epoch [21/300], Batch Step [100/323], D_loss: 0.2760,  G_loss: 2.5796\n",
      " Epoch [21/300], Batch Step [110/323], D_loss: 0.1899,  G_loss: 2.7908\n",
      " Epoch [21/300], Batch Step [120/323], D_loss: 0.1920,  G_loss: 2.8516\n",
      " Epoch [21/300], Batch Step [130/323], D_loss: 0.2098,  G_loss: 2.8498\n",
      " Epoch [21/300], Batch Step [140/323], D_loss: 0.1287,  G_loss: 2.9228\n",
      " Epoch [21/300], Batch Step [150/323], D_loss: 0.2628,  G_loss: 2.9605\n",
      " Epoch [21/300], Batch Step [160/323], D_loss: 0.2388,  G_loss: 2.9373\n",
      " Epoch [21/300], Batch Step [170/323], D_loss: 0.1708,  G_loss: 2.6393\n",
      " Epoch [21/300], Batch Step [180/323], D_loss: 0.3439,  G_loss: 2.4655\n",
      " Epoch [21/300], Batch Step [190/323], D_loss: 0.2220,  G_loss: 2.6830\n",
      " Epoch [21/300], Batch Step [200/323], D_loss: 0.2727,  G_loss: 2.8205\n",
      " Epoch [21/300], Batch Step [210/323], D_loss: 0.1440,  G_loss: 2.7801\n",
      " Epoch [21/300], Batch Step [220/323], D_loss: 0.2095,  G_loss: 2.7114\n",
      " Epoch [21/300], Batch Step [230/323], D_loss: 0.3263,  G_loss: 2.3609\n",
      " Epoch [21/300], Batch Step [240/323], D_loss: 0.2475,  G_loss: 2.6847\n",
      " Epoch [21/300], Batch Step [250/323], D_loss: 0.2581,  G_loss: 3.0241\n",
      " Epoch [21/300], Batch Step [260/323], D_loss: 0.2654,  G_loss: 2.6867\n",
      " Epoch [21/300], Batch Step [270/323], D_loss: 0.1998,  G_loss: 2.6561\n",
      " Epoch [21/300], Batch Step [280/323], D_loss: 0.2395,  G_loss: 2.8107\n",
      " Epoch [21/300], Batch Step [290/323], D_loss: 0.2249,  G_loss: 2.8118\n",
      " Epoch [21/300], Batch Step [300/323], D_loss: 0.1809,  G_loss: 2.9440\n",
      " Epoch [21/300], Batch Step [310/323], D_loss: 0.1761,  G_loss: 2.6898\n",
      " Epoch [21/300], Batch Step [320/323], D_loss: 0.2146,  G_loss: 2.6131\n",
      " Epoch [22/300], Batch Step [0/323], D_loss: 0.1576,  G_loss: 2.6496\n",
      " Epoch [22/300], Batch Step [10/323], D_loss: 0.4017,  G_loss: 2.8335\n",
      " Epoch [22/300], Batch Step [20/323], D_loss: 0.3659,  G_loss: 2.6830\n",
      " Epoch [22/300], Batch Step [30/323], D_loss: 0.3602,  G_loss: 3.0060\n",
      " Epoch [22/300], Batch Step [40/323], D_loss: 0.2617,  G_loss: 2.8255\n",
      " Epoch [22/300], Batch Step [50/323], D_loss: 0.1489,  G_loss: 2.6778\n",
      " Epoch [22/300], Batch Step [60/323], D_loss: 0.2333,  G_loss: 2.9607\n",
      " Epoch [22/300], Batch Step [70/323], D_loss: 0.1527,  G_loss: 2.6110\n",
      " Epoch [22/300], Batch Step [80/323], D_loss: 0.2375,  G_loss: 2.4015\n",
      " Epoch [22/300], Batch Step [90/323], D_loss: 0.3830,  G_loss: 2.5385\n",
      " Epoch [22/300], Batch Step [100/323], D_loss: 0.2644,  G_loss: 2.7393\n",
      " Epoch [22/300], Batch Step [110/323], D_loss: 0.2862,  G_loss: 2.7023\n",
      " Epoch [22/300], Batch Step [120/323], D_loss: 0.2716,  G_loss: 2.5378\n",
      " Epoch [22/300], Batch Step [130/323], D_loss: 0.1963,  G_loss: 2.6418\n",
      " Epoch [22/300], Batch Step [140/323], D_loss: 0.1907,  G_loss: 2.7591\n",
      " Epoch [22/300], Batch Step [150/323], D_loss: 0.1905,  G_loss: 2.8173\n",
      " Epoch [22/300], Batch Step [160/323], D_loss: 0.2954,  G_loss: 2.7875\n",
      " Epoch [22/300], Batch Step [170/323], D_loss: 0.2315,  G_loss: 2.9501\n",
      " Epoch [22/300], Batch Step [180/323], D_loss: 0.1735,  G_loss: 2.8497\n",
      " Epoch [22/300], Batch Step [190/323], D_loss: 0.3451,  G_loss: 2.5626\n",
      " Epoch [22/300], Batch Step [200/323], D_loss: 0.3008,  G_loss: 2.5880\n",
      " Epoch [22/300], Batch Step [210/323], D_loss: 0.2224,  G_loss: 2.7211\n",
      " Epoch [22/300], Batch Step [220/323], D_loss: 0.2140,  G_loss: 2.6860\n",
      " Epoch [22/300], Batch Step [230/323], D_loss: 0.2655,  G_loss: 2.5084\n",
      " Epoch [22/300], Batch Step [240/323], D_loss: 0.1573,  G_loss: 2.9045\n",
      " Epoch [22/300], Batch Step [250/323], D_loss: 0.2464,  G_loss: 2.7721\n",
      " Epoch [22/300], Batch Step [260/323], D_loss: 0.1919,  G_loss: 2.7168\n",
      " Epoch [22/300], Batch Step [270/323], D_loss: 0.1742,  G_loss: 2.6379\n",
      " Epoch [22/300], Batch Step [280/323], D_loss: 0.2041,  G_loss: 2.7082\n",
      " Epoch [22/300], Batch Step [290/323], D_loss: 0.2017,  G_loss: 2.6063\n",
      " Epoch [22/300], Batch Step [300/323], D_loss: 0.2198,  G_loss: 2.5933\n",
      " Epoch [22/300], Batch Step [310/323], D_loss: 0.2017,  G_loss: 2.7017\n",
      " Epoch [22/300], Batch Step [320/323], D_loss: 0.3107,  G_loss: 2.6119\n",
      " Epoch [23/300], Batch Step [0/323], D_loss: 0.1635,  G_loss: 2.5516\n",
      " Epoch [23/300], Batch Step [10/323], D_loss: 0.1845,  G_loss: 2.6751\n",
      " Epoch [23/300], Batch Step [20/323], D_loss: 0.1382,  G_loss: 2.7434\n",
      " Epoch [23/300], Batch Step [30/323], D_loss: 0.2861,  G_loss: 2.5705\n",
      " Epoch [23/300], Batch Step [40/323], D_loss: 0.2146,  G_loss: 2.7479\n",
      " Epoch [23/300], Batch Step [50/323], D_loss: 0.2466,  G_loss: 2.7236\n",
      " Epoch [23/300], Batch Step [60/323], D_loss: 0.1559,  G_loss: 2.7990\n",
      " Epoch [23/300], Batch Step [70/323], D_loss: 0.2107,  G_loss: 2.8177\n",
      " Epoch [23/300], Batch Step [80/323], D_loss: 0.1507,  G_loss: 2.7454\n",
      " Epoch [23/300], Batch Step [90/323], D_loss: 0.1784,  G_loss: 2.9187\n",
      " Epoch [23/300], Batch Step [100/323], D_loss: 0.1416,  G_loss: 2.7387\n",
      " Epoch [23/300], Batch Step [110/323], D_loss: 0.2007,  G_loss: 2.7786\n",
      " Epoch [23/300], Batch Step [120/323], D_loss: 0.2285,  G_loss: 2.7668\n",
      " Epoch [23/300], Batch Step [130/323], D_loss: 0.1622,  G_loss: 2.7805\n",
      " Epoch [23/300], Batch Step [140/323], D_loss: 0.1546,  G_loss: 2.9380\n",
      " Epoch [23/300], Batch Step [150/323], D_loss: 0.1563,  G_loss: 2.7752\n",
      " Epoch [23/300], Batch Step [160/323], D_loss: 0.1759,  G_loss: 2.8135\n",
      " Epoch [23/300], Batch Step [170/323], D_loss: 0.1570,  G_loss: 2.8865\n",
      " Epoch [23/300], Batch Step [180/323], D_loss: 0.1801,  G_loss: 2.8921\n",
      " Epoch [23/300], Batch Step [190/323], D_loss: 0.1915,  G_loss: 2.8989\n",
      " Epoch [23/300], Batch Step [200/323], D_loss: 0.1303,  G_loss: 2.9208\n",
      " Epoch [23/300], Batch Step [210/323], D_loss: 0.1259,  G_loss: 2.8239\n",
      " Epoch [23/300], Batch Step [220/323], D_loss: 0.1960,  G_loss: 2.8250\n",
      " Epoch [23/300], Batch Step [230/323], D_loss: 0.1850,  G_loss: 2.5900\n",
      " Epoch [23/300], Batch Step [240/323], D_loss: 0.1137,  G_loss: 2.6753\n",
      " Epoch [23/300], Batch Step [250/323], D_loss: 0.1576,  G_loss: 2.8476\n",
      " Epoch [23/300], Batch Step [260/323], D_loss: 0.1919,  G_loss: 2.8202\n",
      " Epoch [23/300], Batch Step [270/323], D_loss: 0.1306,  G_loss: 2.9223\n",
      " Epoch [23/300], Batch Step [280/323], D_loss: 0.1368,  G_loss: 2.6520\n",
      " Epoch [23/300], Batch Step [290/323], D_loss: 0.1463,  G_loss: 2.8193\n",
      " Epoch [23/300], Batch Step [300/323], D_loss: 0.1727,  G_loss: 2.9215\n",
      " Epoch [23/300], Batch Step [310/323], D_loss: 0.1558,  G_loss: 2.7757\n",
      " Epoch [23/300], Batch Step [320/323], D_loss: 0.2744,  G_loss: 2.9747\n",
      " Epoch [24/300], Batch Step [0/323], D_loss: 0.1714,  G_loss: 2.9881\n",
      " Epoch [24/300], Batch Step [10/323], D_loss: 0.2496,  G_loss: 3.0183\n",
      " Epoch [24/300], Batch Step [20/323], D_loss: 0.1910,  G_loss: 2.7207\n",
      " Epoch [24/300], Batch Step [30/323], D_loss: 0.2894,  G_loss: 2.7006\n",
      " Epoch [24/300], Batch Step [40/323], D_loss: 0.1934,  G_loss: 2.7544\n",
      " Epoch [24/300], Batch Step [50/323], D_loss: 0.2048,  G_loss: 2.9842\n",
      " Epoch [24/300], Batch Step [60/323], D_loss: 0.2500,  G_loss: 2.9363\n",
      " Epoch [24/300], Batch Step [70/323], D_loss: 0.1312,  G_loss: 2.8232\n",
      " Epoch [24/300], Batch Step [80/323], D_loss: 0.1278,  G_loss: 2.9962\n",
      " Epoch [24/300], Batch Step [90/323], D_loss: 0.0941,  G_loss: 3.2472\n",
      " Epoch [24/300], Batch Step [100/323], D_loss: 0.1173,  G_loss: 3.0925\n",
      " Epoch [24/300], Batch Step [110/323], D_loss: 0.1495,  G_loss: 2.8471\n",
      " Epoch [24/300], Batch Step [120/323], D_loss: 0.0991,  G_loss: 2.7948\n",
      " Epoch [24/300], Batch Step [130/323], D_loss: 0.1737,  G_loss: 3.1442\n",
      " Epoch [24/300], Batch Step [140/323], D_loss: 0.1650,  G_loss: 2.9443\n",
      " Epoch [24/300], Batch Step [150/323], D_loss: 0.2290,  G_loss: 2.8748\n",
      " Epoch [24/300], Batch Step [160/323], D_loss: 0.1625,  G_loss: 2.9420\n",
      " Epoch [24/300], Batch Step [170/323], D_loss: 0.1671,  G_loss: 3.0537\n",
      " Epoch [24/300], Batch Step [180/323], D_loss: 0.1032,  G_loss: 3.0639\n",
      " Epoch [24/300], Batch Step [190/323], D_loss: 0.1503,  G_loss: 3.1427\n",
      " Epoch [24/300], Batch Step [200/323], D_loss: 0.1488,  G_loss: 3.2955\n",
      " Epoch [24/300], Batch Step [210/323], D_loss: 0.2413,  G_loss: 2.9826\n",
      " Epoch [24/300], Batch Step [220/323], D_loss: 0.1190,  G_loss: 2.9273\n",
      " Epoch [24/300], Batch Step [230/323], D_loss: 0.1307,  G_loss: 3.0348\n",
      " Epoch [24/300], Batch Step [240/323], D_loss: 0.3259,  G_loss: 2.8435\n",
      " Epoch [24/300], Batch Step [250/323], D_loss: 0.0989,  G_loss: 3.0389\n",
      " Epoch [24/300], Batch Step [260/323], D_loss: 0.1128,  G_loss: 2.9369\n",
      " Epoch [24/300], Batch Step [270/323], D_loss: 0.1106,  G_loss: 2.7952\n",
      " Epoch [24/300], Batch Step [280/323], D_loss: 0.1185,  G_loss: 3.0305\n",
      " Epoch [24/300], Batch Step [290/323], D_loss: 0.1671,  G_loss: 3.0633\n",
      " Epoch [24/300], Batch Step [300/323], D_loss: 0.1327,  G_loss: 3.0139\n",
      " Epoch [24/300], Batch Step [310/323], D_loss: 0.2046,  G_loss: 2.8053\n",
      " Epoch [24/300], Batch Step [320/323], D_loss: 0.1513,  G_loss: 2.8818\n",
      " Epoch [25/300], Batch Step [0/323], D_loss: 0.1224,  G_loss: 2.9782\n",
      " Epoch [25/300], Batch Step [10/323], D_loss: 0.0999,  G_loss: 3.0602\n",
      " Epoch [25/300], Batch Step [20/323], D_loss: 0.3116,  G_loss: 3.0815\n",
      " Epoch [25/300], Batch Step [30/323], D_loss: 0.1731,  G_loss: 3.0727\n",
      " Epoch [25/300], Batch Step [40/323], D_loss: 0.1075,  G_loss: 2.9483\n",
      " Epoch [25/300], Batch Step [50/323], D_loss: 0.1769,  G_loss: 3.1343\n",
      " Epoch [25/300], Batch Step [60/323], D_loss: 0.1500,  G_loss: 3.1451\n",
      " Epoch [25/300], Batch Step [70/323], D_loss: 0.1704,  G_loss: 2.8881\n",
      " Epoch [25/300], Batch Step [80/323], D_loss: 0.1394,  G_loss: 2.9201\n",
      " Epoch [25/300], Batch Step [90/323], D_loss: 0.1436,  G_loss: 3.1334\n",
      " Epoch [25/300], Batch Step [100/323], D_loss: 0.1161,  G_loss: 2.9206\n",
      " Epoch [25/300], Batch Step [110/323], D_loss: 0.1159,  G_loss: 2.9924\n",
      " Epoch [25/300], Batch Step [120/323], D_loss: 0.1777,  G_loss: 3.1991\n",
      " Epoch [25/300], Batch Step [130/323], D_loss: 0.0937,  G_loss: 3.1546\n",
      " Epoch [25/300], Batch Step [140/323], D_loss: 0.1407,  G_loss: 3.0890\n",
      " Epoch [25/300], Batch Step [150/323], D_loss: 0.2234,  G_loss: 3.1735\n",
      " Epoch [25/300], Batch Step [160/323], D_loss: 0.1340,  G_loss: 3.0490\n",
      " Epoch [25/300], Batch Step [170/323], D_loss: 0.1857,  G_loss: 3.1826\n",
      " Epoch [25/300], Batch Step [180/323], D_loss: 0.1172,  G_loss: 3.0980\n",
      " Epoch [25/300], Batch Step [190/323], D_loss: 0.1366,  G_loss: 3.1702\n",
      " Epoch [25/300], Batch Step [200/323], D_loss: 0.1856,  G_loss: 3.0327\n",
      " Epoch [25/300], Batch Step [210/323], D_loss: 0.1599,  G_loss: 3.2585\n",
      " Epoch [25/300], Batch Step [220/323], D_loss: 0.2002,  G_loss: 3.1745\n",
      " Epoch [25/300], Batch Step [230/323], D_loss: 0.1485,  G_loss: 3.1406\n",
      " Epoch [25/300], Batch Step [240/323], D_loss: 0.2082,  G_loss: 3.2281\n",
      " Epoch [25/300], Batch Step [250/323], D_loss: 0.1077,  G_loss: 3.0868\n",
      " Epoch [25/300], Batch Step [260/323], D_loss: 0.1487,  G_loss: 3.2378\n",
      " Epoch [25/300], Batch Step [270/323], D_loss: 0.1640,  G_loss: 3.2175\n",
      " Epoch [25/300], Batch Step [280/323], D_loss: 0.2290,  G_loss: 3.0538\n",
      " Epoch [25/300], Batch Step [290/323], D_loss: 0.1612,  G_loss: 2.9826\n",
      " Epoch [25/300], Batch Step [300/323], D_loss: 0.0823,  G_loss: 3.1878\n",
      " Epoch [25/300], Batch Step [310/323], D_loss: 0.1103,  G_loss: 3.4211\n",
      " Epoch [25/300], Batch Step [320/323], D_loss: 0.0704,  G_loss: 3.0373\n",
      " Epoch [26/300], Batch Step [0/323], D_loss: 0.1810,  G_loss: 3.0172\n",
      " Epoch [26/300], Batch Step [10/323], D_loss: 0.0969,  G_loss: 3.2865\n",
      " Epoch [26/300], Batch Step [20/323], D_loss: 0.0846,  G_loss: 3.1431\n",
      " Epoch [26/300], Batch Step [30/323], D_loss: 0.1240,  G_loss: 3.3431\n",
      " Epoch [26/300], Batch Step [40/323], D_loss: 0.0795,  G_loss: 3.3677\n",
      " Epoch [26/300], Batch Step [50/323], D_loss: 0.1026,  G_loss: 3.3469\n",
      " Epoch [26/300], Batch Step [60/323], D_loss: 0.1018,  G_loss: 3.2549\n",
      " Epoch [26/300], Batch Step [70/323], D_loss: 0.1523,  G_loss: 3.4292\n",
      " Epoch [26/300], Batch Step [80/323], D_loss: 0.1208,  G_loss: 3.1878\n",
      " Epoch [26/300], Batch Step [90/323], D_loss: 0.1430,  G_loss: 3.1851\n",
      " Epoch [26/300], Batch Step [100/323], D_loss: 0.1410,  G_loss: 3.2440\n",
      " Epoch [26/300], Batch Step [110/323], D_loss: 0.1199,  G_loss: 3.0395\n",
      " Epoch [26/300], Batch Step [120/323], D_loss: 0.1586,  G_loss: 3.4028\n",
      " Epoch [26/300], Batch Step [130/323], D_loss: 0.1381,  G_loss: 3.3888\n",
      " Epoch [26/300], Batch Step [140/323], D_loss: 0.1287,  G_loss: 3.2451\n",
      " Epoch [26/300], Batch Step [150/323], D_loss: 0.0756,  G_loss: 3.1452\n",
      " Epoch [26/300], Batch Step [160/323], D_loss: 0.1655,  G_loss: 3.1033\n",
      " Epoch [26/300], Batch Step [170/323], D_loss: 0.0640,  G_loss: 3.0552\n",
      " Epoch [26/300], Batch Step [180/323], D_loss: 0.1132,  G_loss: 3.2343\n",
      " Epoch [26/300], Batch Step [190/323], D_loss: 0.1010,  G_loss: 3.2181\n",
      " Epoch [26/300], Batch Step [200/323], D_loss: 0.0907,  G_loss: 3.2509\n",
      " Epoch [26/300], Batch Step [210/323], D_loss: 0.0605,  G_loss: 3.1938\n",
      " Epoch [26/300], Batch Step [220/323], D_loss: 0.0867,  G_loss: 3.1755\n",
      " Epoch [26/300], Batch Step [230/323], D_loss: 0.2364,  G_loss: 3.2576\n",
      " Epoch [26/300], Batch Step [240/323], D_loss: 0.0840,  G_loss: 3.2255\n",
      " Epoch [26/300], Batch Step [250/323], D_loss: 0.1212,  G_loss: 3.2488\n",
      " Epoch [26/300], Batch Step [260/323], D_loss: 0.1157,  G_loss: 3.0808\n",
      " Epoch [26/300], Batch Step [270/323], D_loss: 0.0649,  G_loss: 3.2327\n",
      " Epoch [26/300], Batch Step [280/323], D_loss: 0.0546,  G_loss: 3.4257\n",
      " Epoch [26/300], Batch Step [290/323], D_loss: 0.0607,  G_loss: 3.4747\n",
      " Epoch [26/300], Batch Step [300/323], D_loss: 0.0640,  G_loss: 3.2759\n",
      " Epoch [26/300], Batch Step [310/323], D_loss: 0.1151,  G_loss: 3.3461\n",
      " Epoch [26/300], Batch Step [320/323], D_loss: 0.0781,  G_loss: 3.2891\n",
      " Epoch [27/300], Batch Step [0/323], D_loss: 0.1350,  G_loss: 3.2798\n",
      " Epoch [27/300], Batch Step [10/323], D_loss: 0.0602,  G_loss: 3.4729\n",
      " Epoch [27/300], Batch Step [20/323], D_loss: 0.0970,  G_loss: 3.4611\n",
      " Epoch [27/300], Batch Step [30/323], D_loss: 0.1188,  G_loss: 3.3709\n",
      " Epoch [27/300], Batch Step [40/323], D_loss: 0.1858,  G_loss: 3.3238\n",
      " Epoch [27/300], Batch Step [50/323], D_loss: 0.1074,  G_loss: 3.3896\n",
      " Epoch [27/300], Batch Step [60/323], D_loss: 0.1406,  G_loss: 3.3461\n",
      " Epoch [27/300], Batch Step [70/323], D_loss: 0.0646,  G_loss: 3.3234\n",
      " Epoch [27/300], Batch Step [80/323], D_loss: 0.1135,  G_loss: 3.5631\n",
      " Epoch [27/300], Batch Step [90/323], D_loss: 0.0715,  G_loss: 3.6312\n",
      " Epoch [27/300], Batch Step [100/323], D_loss: 0.0447,  G_loss: 3.4972\n",
      " Epoch [27/300], Batch Step [110/323], D_loss: 0.1705,  G_loss: 3.6738\n",
      " Epoch [27/300], Batch Step [120/323], D_loss: 0.1006,  G_loss: 3.4738\n",
      " Epoch [27/300], Batch Step [130/323], D_loss: 0.1300,  G_loss: 3.2993\n",
      " Epoch [27/300], Batch Step [140/323], D_loss: 0.0856,  G_loss: 3.3510\n",
      " Epoch [27/300], Batch Step [150/323], D_loss: 0.0613,  G_loss: 3.2987\n",
      " Epoch [27/300], Batch Step [160/323], D_loss: 0.0726,  G_loss: 3.3369\n",
      " Epoch [27/300], Batch Step [170/323], D_loss: 0.0608,  G_loss: 3.3530\n",
      " Epoch [27/300], Batch Step [180/323], D_loss: 0.0700,  G_loss: 3.3308\n",
      " Epoch [27/300], Batch Step [190/323], D_loss: 0.1062,  G_loss: 3.3669\n",
      " Epoch [27/300], Batch Step [200/323], D_loss: 0.1116,  G_loss: 3.4886\n",
      " Epoch [27/300], Batch Step [210/323], D_loss: 0.0562,  G_loss: 3.4829\n",
      " Epoch [27/300], Batch Step [220/323], D_loss: 0.0643,  G_loss: 3.3488\n",
      " Epoch [27/300], Batch Step [230/323], D_loss: 0.1108,  G_loss: 3.4867\n",
      " Epoch [27/300], Batch Step [240/323], D_loss: 0.0529,  G_loss: 3.2627\n",
      " Epoch [27/300], Batch Step [250/323], D_loss: 0.0961,  G_loss: 3.4464\n",
      " Epoch [27/300], Batch Step [260/323], D_loss: 0.0719,  G_loss: 3.4109\n",
      " Epoch [27/300], Batch Step [270/323], D_loss: 0.0884,  G_loss: 3.5084\n",
      " Epoch [27/300], Batch Step [280/323], D_loss: 0.1269,  G_loss: 3.4109\n",
      " Epoch [27/300], Batch Step [290/323], D_loss: 0.0777,  G_loss: 3.4514\n",
      " Epoch [27/300], Batch Step [300/323], D_loss: 0.0689,  G_loss: 3.4195\n",
      " Epoch [27/300], Batch Step [310/323], D_loss: 0.0811,  G_loss: 3.5370\n",
      " Epoch [27/300], Batch Step [320/323], D_loss: 0.1895,  G_loss: 3.3784\n",
      " Epoch [28/300], Batch Step [0/323], D_loss: 0.1189,  G_loss: 3.3100\n",
      " Epoch [28/300], Batch Step [10/323], D_loss: 0.0381,  G_loss: 3.4035\n",
      " Epoch [28/300], Batch Step [20/323], D_loss: 0.0924,  G_loss: 3.4475\n",
      " Epoch [28/300], Batch Step [30/323], D_loss: 0.1267,  G_loss: 3.5977\n",
      " Epoch [28/300], Batch Step [40/323], D_loss: 0.1070,  G_loss: 3.5932\n",
      " Epoch [28/300], Batch Step [50/323], D_loss: 0.1163,  G_loss: 3.4292\n",
      " Epoch [28/300], Batch Step [60/323], D_loss: 0.0723,  G_loss: 3.4647\n",
      " Epoch [28/300], Batch Step [70/323], D_loss: 0.0891,  G_loss: 3.7338\n",
      " Epoch [28/300], Batch Step [80/323], D_loss: 0.0498,  G_loss: 3.6737\n",
      " Epoch [28/300], Batch Step [90/323], D_loss: 0.0655,  G_loss: 3.4478\n",
      " Epoch [28/300], Batch Step [100/323], D_loss: 0.0811,  G_loss: 3.4697\n",
      " Epoch [28/300], Batch Step [110/323], D_loss: 0.0893,  G_loss: 3.3494\n",
      " Epoch [28/300], Batch Step [120/323], D_loss: 0.1060,  G_loss: 3.5904\n",
      " Epoch [28/300], Batch Step [130/323], D_loss: 0.0564,  G_loss: 3.8464\n",
      " Epoch [28/300], Batch Step [140/323], D_loss: 0.0598,  G_loss: 3.5213\n",
      " Epoch [28/300], Batch Step [150/323], D_loss: 0.2257,  G_loss: 3.4601\n",
      " Epoch [28/300], Batch Step [160/323], D_loss: 0.0538,  G_loss: 3.3599\n",
      " Epoch [28/300], Batch Step [170/323], D_loss: 0.0859,  G_loss: 3.5176\n",
      " Epoch [28/300], Batch Step [180/323], D_loss: 0.0718,  G_loss: 3.6806\n",
      " Epoch [28/300], Batch Step [190/323], D_loss: 0.0798,  G_loss: 3.5808\n",
      " Epoch [28/300], Batch Step [200/323], D_loss: 0.0689,  G_loss: 3.5512\n",
      " Epoch [28/300], Batch Step [210/323], D_loss: 0.0694,  G_loss: 3.6071\n",
      " Epoch [28/300], Batch Step [220/323], D_loss: 0.1484,  G_loss: 3.5215\n",
      " Epoch [28/300], Batch Step [230/323], D_loss: 0.0426,  G_loss: 3.5419\n",
      " Epoch [28/300], Batch Step [240/323], D_loss: 0.0893,  G_loss: 3.5656\n",
      " Epoch [28/300], Batch Step [250/323], D_loss: 0.1101,  G_loss: 3.5188\n",
      " Epoch [28/300], Batch Step [260/323], D_loss: 0.0589,  G_loss: 3.5341\n",
      " Epoch [28/300], Batch Step [270/323], D_loss: 0.0624,  G_loss: 3.5565\n",
      " Epoch [28/300], Batch Step [280/323], D_loss: 0.0666,  G_loss: 3.7268\n",
      " Epoch [28/300], Batch Step [290/323], D_loss: 0.0652,  G_loss: 3.5284\n",
      " Epoch [28/300], Batch Step [300/323], D_loss: 0.1032,  G_loss: 3.6856\n",
      " Epoch [28/300], Batch Step [310/323], D_loss: 0.0770,  G_loss: 3.6468\n",
      " Epoch [28/300], Batch Step [320/323], D_loss: 0.0719,  G_loss: 3.4784\n",
      " Epoch [29/300], Batch Step [0/323], D_loss: 0.1326,  G_loss: 3.5549\n",
      " Epoch [29/300], Batch Step [10/323], D_loss: 0.0716,  G_loss: 3.6205\n",
      " Epoch [29/300], Batch Step [20/323], D_loss: 0.0580,  G_loss: 3.8957\n",
      " Epoch [29/300], Batch Step [30/323], D_loss: 0.0826,  G_loss: 3.7688\n",
      " Epoch [29/300], Batch Step [40/323], D_loss: 0.0630,  G_loss: 3.6479\n",
      " Epoch [29/300], Batch Step [50/323], D_loss: 0.0853,  G_loss: 3.7779\n",
      " Epoch [29/300], Batch Step [60/323], D_loss: 0.0392,  G_loss: 3.5920\n",
      " Epoch [29/300], Batch Step [70/323], D_loss: 0.0740,  G_loss: 3.5271\n",
      " Epoch [29/300], Batch Step [80/323], D_loss: 0.0510,  G_loss: 3.7094\n",
      " Epoch [29/300], Batch Step [90/323], D_loss: 0.0923,  G_loss: 3.8993\n",
      " Epoch [29/300], Batch Step [100/323], D_loss: 0.0568,  G_loss: 3.8664\n",
      " Epoch [29/300], Batch Step [110/323], D_loss: 0.0707,  G_loss: 3.8826\n",
      " Epoch [29/300], Batch Step [120/323], D_loss: 0.0677,  G_loss: 3.7164\n",
      " Epoch [29/300], Batch Step [130/323], D_loss: 0.0884,  G_loss: 3.7653\n",
      " Epoch [29/300], Batch Step [140/323], D_loss: 0.0641,  G_loss: 3.7410\n",
      " Epoch [29/300], Batch Step [150/323], D_loss: 0.0704,  G_loss: 3.5963\n",
      " Epoch [29/300], Batch Step [160/323], D_loss: 0.0554,  G_loss: 3.4138\n",
      " Epoch [29/300], Batch Step [170/323], D_loss: 0.0681,  G_loss: 3.6943\n",
      " Epoch [29/300], Batch Step [180/323], D_loss: 0.0878,  G_loss: 3.6416\n",
      " Epoch [29/300], Batch Step [190/323], D_loss: 0.1018,  G_loss: 3.5926\n",
      " Epoch [29/300], Batch Step [200/323], D_loss: 0.0778,  G_loss: 3.7964\n",
      " Epoch [29/300], Batch Step [210/323], D_loss: 0.0886,  G_loss: 3.9246\n",
      " Epoch [29/300], Batch Step [220/323], D_loss: 0.0309,  G_loss: 3.7805\n",
      " Epoch [29/300], Batch Step [230/323], D_loss: 0.0255,  G_loss: 3.8225\n",
      " Epoch [29/300], Batch Step [240/323], D_loss: 0.0557,  G_loss: 3.7303\n",
      " Epoch [29/300], Batch Step [250/323], D_loss: 0.0758,  G_loss: 3.6681\n",
      " Epoch [29/300], Batch Step [260/323], D_loss: 0.0327,  G_loss: 3.8146\n",
      " Epoch [29/300], Batch Step [270/323], D_loss: 0.0940,  G_loss: 3.6347\n",
      " Epoch [29/300], Batch Step [280/323], D_loss: 0.0692,  G_loss: 3.7656\n",
      " Epoch [29/300], Batch Step [290/323], D_loss: 0.0496,  G_loss: 3.8255\n",
      " Epoch [29/300], Batch Step [300/323], D_loss: 0.0661,  G_loss: 3.8210\n",
      " Epoch [29/300], Batch Step [310/323], D_loss: 0.0544,  G_loss: 3.8050\n",
      " Epoch [29/300], Batch Step [320/323], D_loss: 0.0571,  G_loss: 3.7402\n",
      " Epoch [30/300], Batch Step [0/323], D_loss: 0.0398,  G_loss: 3.8854\n",
      " Epoch [30/300], Batch Step [10/323], D_loss: 0.0399,  G_loss: 3.9202\n",
      " Epoch [30/300], Batch Step [20/323], D_loss: 0.0535,  G_loss: 3.8037\n",
      " Epoch [30/300], Batch Step [30/323], D_loss: 0.0730,  G_loss: 3.7984\n",
      " Epoch [30/300], Batch Step [40/323], D_loss: 0.0713,  G_loss: 3.5492\n",
      " Epoch [30/300], Batch Step [50/323], D_loss: 0.0372,  G_loss: 3.7979\n",
      " Epoch [30/300], Batch Step [60/323], D_loss: 0.0808,  G_loss: 3.9380\n",
      " Epoch [30/300], Batch Step [70/323], D_loss: 0.0692,  G_loss: 3.6179\n",
      " Epoch [30/300], Batch Step [80/323], D_loss: 0.0936,  G_loss: 3.9901\n",
      " Epoch [30/300], Batch Step [90/323], D_loss: 0.0765,  G_loss: 3.9620\n",
      " Epoch [30/300], Batch Step [100/323], D_loss: 0.0715,  G_loss: 3.6920\n",
      " Epoch [30/300], Batch Step [110/323], D_loss: 0.0717,  G_loss: 3.7227\n",
      " Epoch [30/300], Batch Step [120/323], D_loss: 0.0656,  G_loss: 3.8224\n",
      " Epoch [30/300], Batch Step [130/323], D_loss: 0.0453,  G_loss: 3.9182\n",
      " Epoch [30/300], Batch Step [140/323], D_loss: 0.0286,  G_loss: 3.7691\n",
      " Epoch [30/300], Batch Step [150/323], D_loss: 0.1879,  G_loss: 4.0865\n",
      " Epoch [30/300], Batch Step [160/323], D_loss: 0.0538,  G_loss: 3.8239\n",
      " Epoch [30/300], Batch Step [170/323], D_loss: 0.0601,  G_loss: 3.9562\n",
      " Epoch [30/300], Batch Step [180/323], D_loss: 0.0779,  G_loss: 3.8825\n",
      " Epoch [30/300], Batch Step [190/323], D_loss: 0.0916,  G_loss: 3.5887\n",
      " Epoch [30/300], Batch Step [200/323], D_loss: 0.0401,  G_loss: 3.8499\n",
      " Epoch [30/300], Batch Step [210/323], D_loss: 0.0456,  G_loss: 4.0447\n",
      " Epoch [30/300], Batch Step [220/323], D_loss: 0.0478,  G_loss: 3.7483\n",
      " Epoch [30/300], Batch Step [230/323], D_loss: 0.0249,  G_loss: 3.9892\n",
      " Epoch [30/300], Batch Step [240/323], D_loss: 0.0253,  G_loss: 4.0129\n",
      " Epoch [30/300], Batch Step [250/323], D_loss: 0.0582,  G_loss: 3.8678\n",
      " Epoch [30/300], Batch Step [260/323], D_loss: 0.0792,  G_loss: 3.8335\n",
      " Epoch [30/300], Batch Step [270/323], D_loss: 0.0879,  G_loss: 3.9582\n",
      " Epoch [30/300], Batch Step [280/323], D_loss: 0.0602,  G_loss: 3.9731\n",
      " Epoch [30/300], Batch Step [290/323], D_loss: 0.0451,  G_loss: 3.8662\n",
      " Epoch [30/300], Batch Step [300/323], D_loss: 0.1007,  G_loss: 3.9133\n",
      " Epoch [30/300], Batch Step [310/323], D_loss: 0.1330,  G_loss: 3.8268\n",
      " Epoch [30/300], Batch Step [320/323], D_loss: 0.0634,  G_loss: 3.8833\n",
      " Epoch [31/300], Batch Step [0/323], D_loss: 0.0550,  G_loss: 3.9232\n",
      " Epoch [31/300], Batch Step [10/323], D_loss: 0.0485,  G_loss: 3.8214\n",
      " Epoch [31/300], Batch Step [20/323], D_loss: 0.0709,  G_loss: 3.8624\n",
      " Epoch [31/300], Batch Step [30/323], D_loss: 0.0543,  G_loss: 3.8072\n",
      " Epoch [31/300], Batch Step [40/323], D_loss: 0.1310,  G_loss: 4.1896\n",
      " Epoch [31/300], Batch Step [50/323], D_loss: 0.0395,  G_loss: 3.8856\n",
      " Epoch [31/300], Batch Step [60/323], D_loss: 0.0849,  G_loss: 3.8594\n",
      " Epoch [31/300], Batch Step [70/323], D_loss: 0.0723,  G_loss: 4.0036\n",
      " Epoch [31/300], Batch Step [80/323], D_loss: 0.0638,  G_loss: 4.0899\n",
      " Epoch [31/300], Batch Step [90/323], D_loss: 0.0900,  G_loss: 3.9186\n",
      " Epoch [31/300], Batch Step [100/323], D_loss: 0.0800,  G_loss: 4.0040\n",
      " Epoch [31/300], Batch Step [110/323], D_loss: 0.0422,  G_loss: 3.8982\n",
      " Epoch [31/300], Batch Step [120/323], D_loss: 0.0269,  G_loss: 3.9047\n",
      " Epoch [31/300], Batch Step [130/323], D_loss: 0.0283,  G_loss: 4.0748\n",
      " Epoch [31/300], Batch Step [140/323], D_loss: 0.0707,  G_loss: 4.2733\n",
      " Epoch [31/300], Batch Step [150/323], D_loss: 0.0239,  G_loss: 4.0701\n",
      " Epoch [31/300], Batch Step [160/323], D_loss: 0.0406,  G_loss: 3.9934\n",
      " Epoch [31/300], Batch Step [170/323], D_loss: 0.0363,  G_loss: 4.0996\n",
      " Epoch [31/300], Batch Step [180/323], D_loss: 0.0986,  G_loss: 4.1051\n",
      " Epoch [31/300], Batch Step [190/323], D_loss: 0.0633,  G_loss: 3.7659\n",
      " Epoch [31/300], Batch Step [200/323], D_loss: 0.1109,  G_loss: 3.9443\n",
      " Epoch [31/300], Batch Step [210/323], D_loss: 0.0353,  G_loss: 4.1969\n",
      " Epoch [31/300], Batch Step [220/323], D_loss: 0.0329,  G_loss: 4.1960\n",
      " Epoch [31/300], Batch Step [230/323], D_loss: 0.0632,  G_loss: 4.2203\n",
      " Epoch [31/300], Batch Step [240/323], D_loss: 0.0662,  G_loss: 4.0079\n",
      " Epoch [31/300], Batch Step [250/323], D_loss: 0.0418,  G_loss: 3.9300\n",
      " Epoch [31/300], Batch Step [260/323], D_loss: 0.0233,  G_loss: 4.0086\n",
      " Epoch [31/300], Batch Step [270/323], D_loss: 0.0484,  G_loss: 4.2593\n",
      " Epoch [31/300], Batch Step [280/323], D_loss: 0.0202,  G_loss: 3.8839\n",
      " Epoch [31/300], Batch Step [290/323], D_loss: 0.0304,  G_loss: 4.1238\n",
      " Epoch [31/300], Batch Step [300/323], D_loss: 0.0380,  G_loss: 4.0629\n",
      " Epoch [31/300], Batch Step [310/323], D_loss: 0.0937,  G_loss: 3.7696\n",
      " Epoch [31/300], Batch Step [320/323], D_loss: 0.1402,  G_loss: 4.1724\n",
      " Epoch [32/300], Batch Step [0/323], D_loss: 0.0773,  G_loss: 3.9870\n",
      " Epoch [32/300], Batch Step [10/323], D_loss: 0.0201,  G_loss: 4.1213\n",
      " Epoch [32/300], Batch Step [20/323], D_loss: 0.0423,  G_loss: 4.4316\n",
      " Epoch [32/300], Batch Step [30/323], D_loss: 0.0456,  G_loss: 4.2699\n",
      " Epoch [32/300], Batch Step [40/323], D_loss: 0.0768,  G_loss: 4.1696\n",
      " Epoch [32/300], Batch Step [50/323], D_loss: 0.0841,  G_loss: 4.1601\n",
      " Epoch [32/300], Batch Step [60/323], D_loss: 0.0469,  G_loss: 4.1365\n",
      " Epoch [32/300], Batch Step [70/323], D_loss: 0.0290,  G_loss: 4.3224\n",
      " Epoch [32/300], Batch Step [80/323], D_loss: 0.0434,  G_loss: 4.2877\n",
      " Epoch [32/300], Batch Step [90/323], D_loss: 0.0576,  G_loss: 4.2505\n",
      " Epoch [32/300], Batch Step [100/323], D_loss: 0.0737,  G_loss: 4.1227\n",
      " Epoch [32/300], Batch Step [110/323], D_loss: 0.0210,  G_loss: 4.0050\n",
      " Epoch [32/300], Batch Step [120/323], D_loss: 0.1106,  G_loss: 3.9943\n",
      " Epoch [32/300], Batch Step [130/323], D_loss: 0.0475,  G_loss: 4.0078\n",
      " Epoch [32/300], Batch Step [140/323], D_loss: 0.1377,  G_loss: 4.0533\n",
      " Epoch [32/300], Batch Step [150/323], D_loss: 0.0232,  G_loss: 4.1971\n",
      " Epoch [32/300], Batch Step [160/323], D_loss: 0.0413,  G_loss: 4.1580\n",
      " Epoch [32/300], Batch Step [170/323], D_loss: 0.0472,  G_loss: 4.1978\n",
      " Epoch [32/300], Batch Step [180/323], D_loss: 0.0745,  G_loss: 3.9131\n",
      " Epoch [32/300], Batch Step [190/323], D_loss: 0.0445,  G_loss: 4.3129\n",
      " Epoch [32/300], Batch Step [200/323], D_loss: 0.0425,  G_loss: 4.0817\n",
      " Epoch [32/300], Batch Step [210/323], D_loss: 0.0255,  G_loss: 3.9949\n",
      " Epoch [32/300], Batch Step [220/323], D_loss: 0.0274,  G_loss: 4.2445\n",
      " Epoch [32/300], Batch Step [230/323], D_loss: 0.0572,  G_loss: 4.2000\n",
      " Epoch [32/300], Batch Step [240/323], D_loss: 0.0563,  G_loss: 4.2281\n",
      " Epoch [32/300], Batch Step [250/323], D_loss: 0.0302,  G_loss: 4.0070\n",
      " Epoch [32/300], Batch Step [260/323], D_loss: 0.0401,  G_loss: 4.2548\n",
      " Epoch [32/300], Batch Step [270/323], D_loss: 0.0237,  G_loss: 4.5056\n",
      " Epoch [32/300], Batch Step [280/323], D_loss: 0.0741,  G_loss: 4.1180\n",
      " Epoch [32/300], Batch Step [290/323], D_loss: 0.0911,  G_loss: 3.9226\n",
      " Epoch [32/300], Batch Step [300/323], D_loss: 0.0873,  G_loss: 4.2230\n",
      " Epoch [32/300], Batch Step [310/323], D_loss: 0.0495,  G_loss: 4.0942\n",
      " Epoch [32/300], Batch Step [320/323], D_loss: 0.0752,  G_loss: 4.0077\n",
      " Epoch [33/300], Batch Step [0/323], D_loss: 0.0703,  G_loss: 4.0738\n",
      " Epoch [33/300], Batch Step [10/323], D_loss: 0.0314,  G_loss: 4.3404\n",
      " Epoch [33/300], Batch Step [20/323], D_loss: 0.0533,  G_loss: 4.4601\n",
      " Epoch [33/300], Batch Step [30/323], D_loss: 0.0234,  G_loss: 4.3607\n",
      " Epoch [33/300], Batch Step [40/323], D_loss: 0.0603,  G_loss: 4.4056\n",
      " Epoch [33/300], Batch Step [50/323], D_loss: 0.0457,  G_loss: 4.1364\n",
      " Epoch [33/300], Batch Step [60/323], D_loss: 0.0225,  G_loss: 4.3409\n",
      " Epoch [33/300], Batch Step [70/323], D_loss: 0.0143,  G_loss: 4.4349\n",
      " Epoch [33/300], Batch Step [80/323], D_loss: 0.0544,  G_loss: 4.2128\n",
      " Epoch [33/300], Batch Step [90/323], D_loss: 0.0506,  G_loss: 4.0926\n",
      " Epoch [33/300], Batch Step [100/323], D_loss: 0.1129,  G_loss: 4.3017\n",
      " Epoch [33/300], Batch Step [110/323], D_loss: 0.0748,  G_loss: 4.1711\n",
      " Epoch [33/300], Batch Step [120/323], D_loss: 0.0350,  G_loss: 4.2081\n",
      " Epoch [33/300], Batch Step [130/323], D_loss: 0.0227,  G_loss: 4.4991\n",
      " Epoch [33/300], Batch Step [140/323], D_loss: 0.0416,  G_loss: 4.5901\n",
      " Epoch [33/300], Batch Step [150/323], D_loss: 0.0183,  G_loss: 4.4182\n",
      " Epoch [33/300], Batch Step [160/323], D_loss: 0.0258,  G_loss: 4.5296\n",
      " Epoch [33/300], Batch Step [170/323], D_loss: 0.0421,  G_loss: 4.3189\n",
      " Epoch [33/300], Batch Step [180/323], D_loss: 0.0884,  G_loss: 4.0845\n",
      " Epoch [33/300], Batch Step [190/323], D_loss: 0.0176,  G_loss: 4.3033\n",
      " Epoch [33/300], Batch Step [200/323], D_loss: 0.0469,  G_loss: 4.6616\n",
      " Epoch [33/300], Batch Step [210/323], D_loss: 0.0472,  G_loss: 4.5328\n",
      " Epoch [33/300], Batch Step [220/323], D_loss: 0.0315,  G_loss: 4.1551\n",
      " Epoch [33/300], Batch Step [230/323], D_loss: 0.0488,  G_loss: 4.4444\n",
      " Epoch [33/300], Batch Step [240/323], D_loss: 0.0744,  G_loss: 4.5874\n",
      " Epoch [33/300], Batch Step [250/323], D_loss: 0.0552,  G_loss: 4.1853\n",
      " Epoch [33/300], Batch Step [260/323], D_loss: 0.0490,  G_loss: 4.1438\n",
      " Epoch [33/300], Batch Step [270/323], D_loss: 0.0556,  G_loss: 4.1556\n",
      " Epoch [33/300], Batch Step [280/323], D_loss: 0.0264,  G_loss: 4.1744\n",
      " Epoch [33/300], Batch Step [290/323], D_loss: 0.0172,  G_loss: 4.3685\n",
      " Epoch [33/300], Batch Step [300/323], D_loss: 0.0174,  G_loss: 4.2610\n",
      " Epoch [33/300], Batch Step [310/323], D_loss: 0.1073,  G_loss: 4.2879\n",
      " Epoch [33/300], Batch Step [320/323], D_loss: 0.0247,  G_loss: 4.2581\n",
      " Epoch [34/300], Batch Step [0/323], D_loss: 0.0156,  G_loss: 4.3337\n",
      " Epoch [34/300], Batch Step [10/323], D_loss: 0.0774,  G_loss: 4.4082\n",
      " Epoch [34/300], Batch Step [20/323], D_loss: 0.0185,  G_loss: 4.4617\n",
      " Epoch [34/300], Batch Step [30/323], D_loss: 0.0171,  G_loss: 4.3995\n",
      " Epoch [34/300], Batch Step [40/323], D_loss: 0.0217,  G_loss: 4.0278\n",
      " Epoch [34/300], Batch Step [50/323], D_loss: 0.0701,  G_loss: 4.3577\n",
      " Epoch [34/300], Batch Step [60/323], D_loss: 0.0364,  G_loss: 4.3186\n",
      " Epoch [34/300], Batch Step [70/323], D_loss: 0.0424,  G_loss: 4.1519\n",
      " Epoch [34/300], Batch Step [80/323], D_loss: 0.0162,  G_loss: 4.3203\n",
      " Epoch [34/300], Batch Step [90/323], D_loss: 0.0391,  G_loss: 4.1770\n",
      " Epoch [34/300], Batch Step [100/323], D_loss: 0.0162,  G_loss: 4.3323\n",
      " Epoch [34/300], Batch Step [110/323], D_loss: 0.0152,  G_loss: 4.7383\n",
      " Epoch [34/300], Batch Step [120/323], D_loss: 0.0935,  G_loss: 4.3771\n",
      " Epoch [34/300], Batch Step [130/323], D_loss: 0.0168,  G_loss: 4.2190\n",
      " Epoch [34/300], Batch Step [140/323], D_loss: 0.0155,  G_loss: 4.6266\n",
      " Epoch [34/300], Batch Step [150/323], D_loss: 0.0255,  G_loss: 4.5768\n",
      " Epoch [34/300], Batch Step [160/323], D_loss: 0.0551,  G_loss: 4.4927\n",
      " Epoch [34/300], Batch Step [170/323], D_loss: 0.0202,  G_loss: 4.3462\n",
      " Epoch [34/300], Batch Step [180/323], D_loss: 0.0417,  G_loss: 4.2957\n",
      " Epoch [34/300], Batch Step [190/323], D_loss: 0.0141,  G_loss: 4.4791\n",
      " Epoch [34/300], Batch Step [200/323], D_loss: 0.0180,  G_loss: 4.6580\n",
      " Epoch [34/300], Batch Step [210/323], D_loss: 0.0278,  G_loss: 4.5160\n",
      " Epoch [34/300], Batch Step [220/323], D_loss: 0.0278,  G_loss: 4.3311\n",
      " Epoch [34/300], Batch Step [230/323], D_loss: 0.0411,  G_loss: 4.1541\n",
      " Epoch [34/300], Batch Step [240/323], D_loss: 0.0128,  G_loss: 4.4907\n",
      " Epoch [34/300], Batch Step [250/323], D_loss: 0.0711,  G_loss: 4.5989\n",
      " Epoch [34/300], Batch Step [260/323], D_loss: 0.0364,  G_loss: 4.4915\n",
      " Epoch [34/300], Batch Step [270/323], D_loss: 0.0155,  G_loss: 4.3051\n",
      " Epoch [34/300], Batch Step [280/323], D_loss: 0.0175,  G_loss: 4.5172\n",
      " Epoch [34/300], Batch Step [290/323], D_loss: 0.0760,  G_loss: 4.5692\n",
      " Epoch [34/300], Batch Step [300/323], D_loss: 0.0716,  G_loss: 4.3344\n",
      " Epoch [34/300], Batch Step [310/323], D_loss: 0.0356,  G_loss: 4.2990\n",
      " Epoch [34/300], Batch Step [320/323], D_loss: 0.0258,  G_loss: 4.2660\n",
      " Epoch [35/300], Batch Step [0/323], D_loss: 0.0196,  G_loss: 4.4349\n",
      " Epoch [35/300], Batch Step [10/323], D_loss: 0.0363,  G_loss: 4.3996\n",
      " Epoch [35/300], Batch Step [20/323], D_loss: 0.0692,  G_loss: 4.1785\n",
      " Epoch [35/300], Batch Step [30/323], D_loss: 0.0228,  G_loss: 4.2024\n",
      " Epoch [35/300], Batch Step [40/323], D_loss: 0.0170,  G_loss: 4.2978\n",
      " Epoch [35/300], Batch Step [50/323], D_loss: 0.0109,  G_loss: 4.6220\n",
      " Epoch [35/300], Batch Step [60/323], D_loss: 0.0385,  G_loss: 4.8083\n",
      " Epoch [35/300], Batch Step [70/323], D_loss: 0.0230,  G_loss: 4.3828\n",
      " Epoch [35/300], Batch Step [80/323], D_loss: 0.0115,  G_loss: 4.5009\n",
      " Epoch [35/300], Batch Step [90/323], D_loss: 0.0196,  G_loss: 4.2883\n",
      " Epoch [35/300], Batch Step [100/323], D_loss: 0.0890,  G_loss: 4.6072\n",
      " Epoch [35/300], Batch Step [110/323], D_loss: 0.0201,  G_loss: 4.5082\n",
      " Epoch [35/300], Batch Step [120/323], D_loss: 0.0121,  G_loss: 4.4689\n",
      " Epoch [35/300], Batch Step [130/323], D_loss: 0.0137,  G_loss: 4.6216\n",
      " Epoch [35/300], Batch Step [140/323], D_loss: 0.0234,  G_loss: 4.6597\n",
      " Epoch [35/300], Batch Step [150/323], D_loss: 0.0282,  G_loss: 4.4791\n",
      " Epoch [35/300], Batch Step [160/323], D_loss: 0.0256,  G_loss: 4.8047\n",
      " Epoch [35/300], Batch Step [170/323], D_loss: 0.0098,  G_loss: 4.6700\n",
      " Epoch [35/300], Batch Step [180/323], D_loss: 0.0255,  G_loss: 4.4648\n",
      " Epoch [35/300], Batch Step [190/323], D_loss: 0.0169,  G_loss: 4.4600\n",
      " Epoch [35/300], Batch Step [200/323], D_loss: 0.0279,  G_loss: 4.5094\n",
      " Epoch [35/300], Batch Step [210/323], D_loss: 0.0606,  G_loss: 4.6634\n",
      " Epoch [35/300], Batch Step [220/323], D_loss: 0.0792,  G_loss: 4.6635\n",
      " Epoch [35/300], Batch Step [230/323], D_loss: 0.0244,  G_loss: 4.4204\n",
      " Epoch [35/300], Batch Step [240/323], D_loss: 0.0201,  G_loss: 4.4992\n",
      " Epoch [35/300], Batch Step [250/323], D_loss: 0.0385,  G_loss: 4.3804\n",
      " Epoch [35/300], Batch Step [260/323], D_loss: 0.0351,  G_loss: 4.4877\n",
      " Epoch [35/300], Batch Step [270/323], D_loss: 0.1152,  G_loss: 4.1820\n",
      " Epoch [35/300], Batch Step [280/323], D_loss: 0.1161,  G_loss: 4.6952\n",
      " Epoch [35/300], Batch Step [290/323], D_loss: 0.3345,  G_loss: 6.4857\n",
      " Epoch [35/300], Batch Step [300/323], D_loss: 0.7825,  G_loss: 6.4436\n",
      " Epoch [35/300], Batch Step [310/323], D_loss: 2.0398,  G_loss: 3.8605\n",
      " Epoch [35/300], Batch Step [320/323], D_loss: 3.4842,  G_loss: 2.8515\n",
      " Epoch [36/300], Batch Step [0/323], D_loss: 3.5480,  G_loss: 3.2690\n",
      " Epoch [36/300], Batch Step [10/323], D_loss: 3.8446,  G_loss: 3.1676\n",
      " Epoch [36/300], Batch Step [20/323], D_loss: 7.2126,  G_loss: 3.7242\n",
      " Epoch [36/300], Batch Step [30/323], D_loss: 4.3062,  G_loss: 3.7213\n",
      " Epoch [36/300], Batch Step [40/323], D_loss: 1.5993,  G_loss: 3.7672\n",
      " Epoch [36/300], Batch Step [50/323], D_loss: 1.4765,  G_loss: 4.8659\n",
      " Epoch [36/300], Batch Step [60/323], D_loss: 0.9656,  G_loss: 4.4762\n",
      " Epoch [36/300], Batch Step [70/323], D_loss: 1.3102,  G_loss: 4.9619\n",
      " Epoch [36/300], Batch Step [80/323], D_loss: 0.4299,  G_loss: 4.7620\n",
      " Epoch [36/300], Batch Step [90/323], D_loss: 0.8701,  G_loss: 3.6845\n",
      " Epoch [36/300], Batch Step [100/323], D_loss: 1.4614,  G_loss: 3.8857\n",
      " Epoch [36/300], Batch Step [110/323], D_loss: 0.4693,  G_loss: 3.5845\n",
      " Epoch [36/300], Batch Step [120/323], D_loss: 0.7737,  G_loss: 4.1646\n",
      " Epoch [36/300], Batch Step [130/323], D_loss: 1.0797,  G_loss: 3.5548\n",
      " Epoch [36/300], Batch Step [140/323], D_loss: 0.4875,  G_loss: 3.8137\n",
      " Epoch [36/300], Batch Step [150/323], D_loss: 0.5620,  G_loss: 3.6521\n",
      " Epoch [36/300], Batch Step [160/323], D_loss: 0.9755,  G_loss: 3.1048\n",
      " Epoch [36/300], Batch Step [170/323], D_loss: 0.5075,  G_loss: 3.0285\n",
      " Epoch [36/300], Batch Step [180/323], D_loss: 1.1606,  G_loss: 3.0998\n",
      " Epoch [36/300], Batch Step [190/323], D_loss: 0.4083,  G_loss: 3.5691\n",
      " Epoch [36/300], Batch Step [200/323], D_loss: 0.7066,  G_loss: 2.9514\n",
      " Epoch [36/300], Batch Step [210/323], D_loss: 0.4757,  G_loss: 3.7630\n",
      " Epoch [36/300], Batch Step [220/323], D_loss: 0.7365,  G_loss: 4.2929\n",
      " Epoch [36/300], Batch Step [230/323], D_loss: 0.9796,  G_loss: 3.8551\n",
      " Epoch [36/300], Batch Step [240/323], D_loss: 0.7587,  G_loss: 2.8680\n",
      " Epoch [36/300], Batch Step [250/323], D_loss: 1.3838,  G_loss: 3.0720\n",
      " Epoch [36/300], Batch Step [260/323], D_loss: 2.7931,  G_loss: 4.3313\n",
      " Epoch [36/300], Batch Step [270/323], D_loss: 1.6347,  G_loss: 3.8771\n",
      " Epoch [36/300], Batch Step [280/323], D_loss: 1.6284,  G_loss: 4.7558\n",
      " Epoch [36/300], Batch Step [290/323], D_loss: 0.7852,  G_loss: 3.9177\n",
      " Epoch [36/300], Batch Step [300/323], D_loss: 1.2838,  G_loss: 4.9209\n",
      " Epoch [36/300], Batch Step [310/323], D_loss: 1.0231,  G_loss: 3.3865\n",
      " Epoch [36/300], Batch Step [320/323], D_loss: 1.3188,  G_loss: 3.2554\n",
      " Epoch [37/300], Batch Step [0/323], D_loss: 1.3798,  G_loss: 3.8065\n",
      " Epoch [37/300], Batch Step [10/323], D_loss: 1.9447,  G_loss: 3.6054\n",
      " Epoch [37/300], Batch Step [20/323], D_loss: 1.0806,  G_loss: 3.1129\n",
      " Epoch [37/300], Batch Step [30/323], D_loss: 2.3541,  G_loss: 2.6851\n",
      " Epoch [37/300], Batch Step [40/323], D_loss: 1.5763,  G_loss: 3.1597\n",
      " Epoch [37/300], Batch Step [50/323], D_loss: 1.7715,  G_loss: 2.7147\n",
      " Epoch [37/300], Batch Step [60/323], D_loss: 2.7250,  G_loss: 2.5229\n",
      " Epoch [37/300], Batch Step [70/323], D_loss: 2.5933,  G_loss: 2.9669\n",
      " Epoch [37/300], Batch Step [80/323], D_loss: 1.5186,  G_loss: 3.0449\n",
      " Epoch [37/300], Batch Step [90/323], D_loss: 1.2773,  G_loss: 2.3061\n",
      " Epoch [37/300], Batch Step [100/323], D_loss: 2.3149,  G_loss: 2.4212\n",
      " Epoch [37/300], Batch Step [110/323], D_loss: 2.7853,  G_loss: 2.7860\n",
      " Epoch [37/300], Batch Step [120/323], D_loss: 1.8133,  G_loss: 3.0956\n",
      " Epoch [37/300], Batch Step [130/323], D_loss: 2.4182,  G_loss: 1.9817\n",
      " Epoch [37/300], Batch Step [140/323], D_loss: 1.7782,  G_loss: 2.0622\n",
      " Epoch [37/300], Batch Step [150/323], D_loss: 1.4488,  G_loss: 2.7129\n",
      " Epoch [37/300], Batch Step [160/323], D_loss: 1.9918,  G_loss: 2.6856\n",
      " Epoch [37/300], Batch Step [170/323], D_loss: 1.1504,  G_loss: 2.1355\n",
      " Epoch [37/300], Batch Step [180/323], D_loss: 1.7471,  G_loss: 2.5969\n",
      " Epoch [37/300], Batch Step [190/323], D_loss: 1.3262,  G_loss: 2.3418\n",
      " Epoch [37/300], Batch Step [200/323], D_loss: 1.4260,  G_loss: 3.3076\n",
      " Epoch [37/300], Batch Step [210/323], D_loss: 1.2765,  G_loss: 3.3920\n",
      " Epoch [37/300], Batch Step [220/323], D_loss: 1.6856,  G_loss: 2.9785\n",
      " Epoch [37/300], Batch Step [230/323], D_loss: 1.6558,  G_loss: 3.5181\n",
      " Epoch [37/300], Batch Step [240/323], D_loss: 1.9892,  G_loss: 3.4333\n",
      " Epoch [37/300], Batch Step [250/323], D_loss: 1.3918,  G_loss: 2.5118\n",
      " Epoch [37/300], Batch Step [260/323], D_loss: 0.9181,  G_loss: 2.8089\n",
      " Epoch [37/300], Batch Step [270/323], D_loss: 1.3459,  G_loss: 2.7822\n",
      " Epoch [37/300], Batch Step [280/323], D_loss: 1.1344,  G_loss: 2.6389\n",
      " Epoch [37/300], Batch Step [290/323], D_loss: 1.5825,  G_loss: 2.5544\n",
      " Epoch [37/300], Batch Step [300/323], D_loss: 1.2704,  G_loss: 2.2337\n",
      " Epoch [37/300], Batch Step [310/323], D_loss: 1.9302,  G_loss: 2.1155\n",
      " Epoch [37/300], Batch Step [320/323], D_loss: 1.9399,  G_loss: 2.6496\n",
      " Epoch [38/300], Batch Step [0/323], D_loss: 1.6715,  G_loss: 2.7317\n",
      " Epoch [38/300], Batch Step [10/323], D_loss: 1.3811,  G_loss: 2.4389\n",
      " Epoch [38/300], Batch Step [20/323], D_loss: 1.7533,  G_loss: 2.7875\n",
      " Epoch [38/300], Batch Step [30/323], D_loss: 1.7884,  G_loss: 2.3928\n",
      " Epoch [38/300], Batch Step [40/323], D_loss: 1.5577,  G_loss: 2.1592\n",
      " Epoch [38/300], Batch Step [50/323], D_loss: 2.0125,  G_loss: 2.1962\n",
      " Epoch [38/300], Batch Step [60/323], D_loss: 1.6610,  G_loss: 2.1441\n",
      " Epoch [38/300], Batch Step [70/323], D_loss: 1.8604,  G_loss: 2.2812\n",
      " Epoch [38/300], Batch Step [80/323], D_loss: 1.6905,  G_loss: 2.1015\n",
      " Epoch [38/300], Batch Step [90/323], D_loss: 2.1519,  G_loss: 2.1477\n",
      " Epoch [38/300], Batch Step [100/323], D_loss: 1.6539,  G_loss: 1.8012\n",
      " Epoch [38/300], Batch Step [110/323], D_loss: 1.9269,  G_loss: 1.9679\n",
      " Epoch [38/300], Batch Step [120/323], D_loss: 1.3953,  G_loss: 1.6554\n",
      " Epoch [38/300], Batch Step [130/323], D_loss: 1.3429,  G_loss: 1.9806\n",
      " Epoch [38/300], Batch Step [140/323], D_loss: 1.0939,  G_loss: 2.0343\n",
      " Epoch [38/300], Batch Step [150/323], D_loss: 1.1812,  G_loss: 1.9005\n",
      " Epoch [38/300], Batch Step [160/323], D_loss: 1.0700,  G_loss: 2.3377\n",
      " Epoch [38/300], Batch Step [170/323], D_loss: 1.3919,  G_loss: 1.5098\n",
      " Epoch [38/300], Batch Step [180/323], D_loss: 1.5338,  G_loss: 2.0470\n",
      " Epoch [38/300], Batch Step [190/323], D_loss: 1.0827,  G_loss: 1.6840\n",
      " Epoch [38/300], Batch Step [200/323], D_loss: 1.5449,  G_loss: 1.5892\n",
      " Epoch [38/300], Batch Step [210/323], D_loss: 0.9869,  G_loss: 1.9380\n",
      " Epoch [38/300], Batch Step [220/323], D_loss: 1.2137,  G_loss: 1.8310\n",
      " Epoch [38/300], Batch Step [230/323], D_loss: 0.7824,  G_loss: 1.8508\n",
      " Epoch [38/300], Batch Step [240/323], D_loss: 1.0545,  G_loss: 1.9312\n",
      " Epoch [38/300], Batch Step [250/323], D_loss: 1.1060,  G_loss: 1.8593\n",
      " Epoch [38/300], Batch Step [260/323], D_loss: 1.3819,  G_loss: 2.0744\n",
      " Epoch [38/300], Batch Step [270/323], D_loss: 1.2958,  G_loss: 1.9890\n",
      " Epoch [38/300], Batch Step [280/323], D_loss: 1.1955,  G_loss: 2.2731\n",
      " Epoch [38/300], Batch Step [290/323], D_loss: 0.9897,  G_loss: 1.6639\n",
      " Epoch [38/300], Batch Step [300/323], D_loss: 0.9862,  G_loss: 1.6856\n",
      " Epoch [38/300], Batch Step [310/323], D_loss: 1.1014,  G_loss: 1.9933\n",
      " Epoch [38/300], Batch Step [320/323], D_loss: 1.2216,  G_loss: 1.6650\n",
      " Epoch [39/300], Batch Step [0/323], D_loss: 1.4620,  G_loss: 1.7572\n",
      " Epoch [39/300], Batch Step [10/323], D_loss: 1.0997,  G_loss: 2.0400\n",
      " Epoch [39/300], Batch Step [20/323], D_loss: 1.4668,  G_loss: 1.9441\n",
      " Epoch [39/300], Batch Step [30/323], D_loss: 1.0275,  G_loss: 1.7448\n",
      " Epoch [39/300], Batch Step [40/323], D_loss: 0.9606,  G_loss: 2.0892\n",
      " Epoch [39/300], Batch Step [50/323], D_loss: 0.8996,  G_loss: 1.7809\n",
      " Epoch [39/300], Batch Step [60/323], D_loss: 0.9300,  G_loss: 1.8125\n",
      " Epoch [39/300], Batch Step [70/323], D_loss: 1.1453,  G_loss: 2.0228\n",
      " Epoch [39/300], Batch Step [80/323], D_loss: 0.9709,  G_loss: 1.7781\n",
      " Epoch [39/300], Batch Step [90/323], D_loss: 1.1665,  G_loss: 1.9853\n",
      " Epoch [39/300], Batch Step [100/323], D_loss: 0.8351,  G_loss: 1.8592\n",
      " Epoch [39/300], Batch Step [110/323], D_loss: 0.8329,  G_loss: 1.7498\n",
      " Epoch [39/300], Batch Step [120/323], D_loss: 1.0538,  G_loss: 1.6180\n",
      " Epoch [39/300], Batch Step [130/323], D_loss: 1.3888,  G_loss: 1.5099\n",
      " Epoch [39/300], Batch Step [140/323], D_loss: 1.2728,  G_loss: 1.6777\n",
      " Epoch [39/300], Batch Step [150/323], D_loss: 1.2434,  G_loss: 1.5876\n",
      " Epoch [39/300], Batch Step [160/323], D_loss: 1.1037,  G_loss: 1.5990\n",
      " Epoch [39/300], Batch Step [170/323], D_loss: 0.8067,  G_loss: 1.6654\n",
      " Epoch [39/300], Batch Step [180/323], D_loss: 1.0212,  G_loss: 1.8593\n",
      " Epoch [39/300], Batch Step [190/323], D_loss: 0.9905,  G_loss: 2.0569\n",
      " Epoch [39/300], Batch Step [200/323], D_loss: 0.8206,  G_loss: 1.8098\n",
      " Epoch [39/300], Batch Step [210/323], D_loss: 1.4983,  G_loss: 1.7883\n",
      " Epoch [39/300], Batch Step [220/323], D_loss: 0.9495,  G_loss: 1.8669\n",
      " Epoch [39/300], Batch Step [230/323], D_loss: 0.8753,  G_loss: 1.8450\n",
      " Epoch [39/300], Batch Step [240/323], D_loss: 0.8704,  G_loss: 1.8642\n",
      " Epoch [39/300], Batch Step [250/323], D_loss: 1.1294,  G_loss: 1.5953\n",
      " Epoch [39/300], Batch Step [260/323], D_loss: 0.9305,  G_loss: 1.7383\n",
      " Epoch [39/300], Batch Step [270/323], D_loss: 1.0835,  G_loss: 1.8411\n",
      " Epoch [39/300], Batch Step [280/323], D_loss: 1.1392,  G_loss: 1.5390\n",
      " Epoch [39/300], Batch Step [290/323], D_loss: 1.2686,  G_loss: 1.8438\n",
      " Epoch [39/300], Batch Step [300/323], D_loss: 1.4002,  G_loss: 1.7522\n",
      " Epoch [39/300], Batch Step [310/323], D_loss: 1.3367,  G_loss: 1.6582\n",
      " Epoch [39/300], Batch Step [320/323], D_loss: 0.8945,  G_loss: 1.7127\n",
      " Epoch [40/300], Batch Step [0/323], D_loss: 0.9590,  G_loss: 1.8741\n",
      " Epoch [40/300], Batch Step [10/323], D_loss: 0.7739,  G_loss: 2.1271\n",
      " Epoch [40/300], Batch Step [20/323], D_loss: 1.1503,  G_loss: 1.7607\n",
      " Epoch [40/300], Batch Step [30/323], D_loss: 0.9368,  G_loss: 1.7291\n",
      " Epoch [40/300], Batch Step [40/323], D_loss: 0.7813,  G_loss: 1.6645\n",
      " Epoch [40/300], Batch Step [50/323], D_loss: 0.9845,  G_loss: 1.5083\n",
      " Epoch [40/300], Batch Step [60/323], D_loss: 0.8980,  G_loss: 1.6224\n",
      " Epoch [40/300], Batch Step [70/323], D_loss: 1.4961,  G_loss: 1.4531\n",
      " Epoch [40/300], Batch Step [80/323], D_loss: 1.1148,  G_loss: 1.4362\n",
      " Epoch [40/300], Batch Step [90/323], D_loss: 1.0650,  G_loss: 1.6942\n",
      " Epoch [40/300], Batch Step [100/323], D_loss: 0.9797,  G_loss: 1.3684\n",
      " Epoch [40/300], Batch Step [110/323], D_loss: 0.8188,  G_loss: 1.5128\n",
      " Epoch [40/300], Batch Step [120/323], D_loss: 0.9217,  G_loss: 1.8251\n",
      " Epoch [40/300], Batch Step [130/323], D_loss: 0.9416,  G_loss: 1.8167\n",
      " Epoch [40/300], Batch Step [140/323], D_loss: 1.1688,  G_loss: 1.7115\n",
      " Epoch [40/300], Batch Step [150/323], D_loss: 0.8791,  G_loss: 1.5758\n",
      " Epoch [40/300], Batch Step [160/323], D_loss: 0.8134,  G_loss: 1.4633\n",
      " Epoch [40/300], Batch Step [170/323], D_loss: 1.0908,  G_loss: 1.5319\n",
      " Epoch [40/300], Batch Step [180/323], D_loss: 0.9677,  G_loss: 1.3665\n",
      " Epoch [40/300], Batch Step [190/323], D_loss: 1.0786,  G_loss: 1.4883\n",
      " Epoch [40/300], Batch Step [200/323], D_loss: 1.0614,  G_loss: 1.4498\n",
      " Epoch [40/300], Batch Step [210/323], D_loss: 0.9834,  G_loss: 1.6476\n",
      " Epoch [40/300], Batch Step [220/323], D_loss: 1.1222,  G_loss: 1.5153\n",
      " Epoch [40/300], Batch Step [230/323], D_loss: 2.4632,  G_loss: 1.5586\n",
      " Epoch [40/300], Batch Step [240/323], D_loss: 1.0485,  G_loss: 1.4528\n",
      " Epoch [40/300], Batch Step [250/323], D_loss: 0.9371,  G_loss: 1.5224\n",
      " Epoch [40/300], Batch Step [260/323], D_loss: 0.8840,  G_loss: 1.7127\n",
      " Epoch [40/300], Batch Step [270/323], D_loss: 0.9927,  G_loss: 1.4221\n",
      " Epoch [40/300], Batch Step [280/323], D_loss: 1.1236,  G_loss: 1.5211\n",
      " Epoch [40/300], Batch Step [290/323], D_loss: 1.1024,  G_loss: 1.5945\n",
      " Epoch [40/300], Batch Step [300/323], D_loss: 0.9828,  G_loss: 1.3974\n",
      " Epoch [40/300], Batch Step [310/323], D_loss: 0.9139,  G_loss: 1.3877\n",
      " Epoch [40/300], Batch Step [320/323], D_loss: 0.8140,  G_loss: 1.4246\n",
      " Epoch [41/300], Batch Step [0/323], D_loss: 0.9660,  G_loss: 1.4606\n",
      " Epoch [41/300], Batch Step [10/323], D_loss: 0.8244,  G_loss: 1.4998\n",
      " Epoch [41/300], Batch Step [20/323], D_loss: 0.8752,  G_loss: 1.4586\n",
      " Epoch [41/300], Batch Step [30/323], D_loss: 0.9665,  G_loss: 1.4753\n",
      " Epoch [41/300], Batch Step [40/323], D_loss: 0.8987,  G_loss: 1.5263\n",
      " Epoch [41/300], Batch Step [50/323], D_loss: 0.8426,  G_loss: 1.2546\n",
      " Epoch [41/300], Batch Step [60/323], D_loss: 0.7532,  G_loss: 1.5863\n",
      " Epoch [41/300], Batch Step [70/323], D_loss: 0.9632,  G_loss: 1.3136\n",
      " Epoch [41/300], Batch Step [80/323], D_loss: 1.0707,  G_loss: 1.4486\n",
      " Epoch [41/300], Batch Step [90/323], D_loss: 0.8527,  G_loss: 1.4283\n",
      " Epoch [41/300], Batch Step [100/323], D_loss: 1.0736,  G_loss: 1.3252\n",
      " Epoch [41/300], Batch Step [110/323], D_loss: 1.0096,  G_loss: 1.4714\n",
      " Epoch [41/300], Batch Step [120/323], D_loss: 0.9414,  G_loss: 1.3428\n",
      " Epoch [41/300], Batch Step [130/323], D_loss: 0.8849,  G_loss: 1.5493\n",
      " Epoch [41/300], Batch Step [140/323], D_loss: 0.9482,  G_loss: 1.3464\n",
      " Epoch [41/300], Batch Step [150/323], D_loss: 0.8982,  G_loss: 1.4611\n",
      " Epoch [41/300], Batch Step [160/323], D_loss: 0.7867,  G_loss: 1.4182\n",
      " Epoch [41/300], Batch Step [170/323], D_loss: 0.9347,  G_loss: 1.4353\n",
      " Epoch [41/300], Batch Step [180/323], D_loss: 0.8303,  G_loss: 1.4087\n",
      " Epoch [41/300], Batch Step [190/323], D_loss: 0.9853,  G_loss: 1.3308\n",
      " Epoch [41/300], Batch Step [200/323], D_loss: 1.0812,  G_loss: 1.3385\n",
      " Epoch [41/300], Batch Step [210/323], D_loss: 0.7658,  G_loss: 1.5114\n",
      " Epoch [41/300], Batch Step [220/323], D_loss: 0.9099,  G_loss: 1.4844\n",
      " Epoch [41/300], Batch Step [230/323], D_loss: 0.8993,  G_loss: 1.4627\n",
      " Epoch [41/300], Batch Step [240/323], D_loss: 1.1124,  G_loss: 1.2395\n",
      " Epoch [41/300], Batch Step [250/323], D_loss: 0.9589,  G_loss: 1.2625\n",
      " Epoch [41/300], Batch Step [260/323], D_loss: 1.0511,  G_loss: 1.3685\n",
      " Epoch [41/300], Batch Step [270/323], D_loss: 0.9859,  G_loss: 1.1975\n",
      " Epoch [41/300], Batch Step [280/323], D_loss: 0.9321,  G_loss: 1.4376\n",
      " Epoch [41/300], Batch Step [290/323], D_loss: 2.1939,  G_loss: 1.3284\n",
      " Epoch [41/300], Batch Step [300/323], D_loss: 0.8757,  G_loss: 1.4078\n",
      " Epoch [41/300], Batch Step [310/323], D_loss: 0.8576,  G_loss: 1.4365\n",
      " Epoch [41/300], Batch Step [320/323], D_loss: 1.0598,  G_loss: 1.2877\n",
      " Epoch [42/300], Batch Step [0/323], D_loss: 1.0747,  G_loss: 1.3479\n",
      " Epoch [42/300], Batch Step [10/323], D_loss: 1.0721,  G_loss: 1.3520\n",
      " Epoch [42/300], Batch Step [20/323], D_loss: 1.2195,  G_loss: 1.3803\n",
      " Epoch [42/300], Batch Step [30/323], D_loss: 0.7698,  G_loss: 1.6031\n",
      " Epoch [42/300], Batch Step [40/323], D_loss: 0.7699,  G_loss: 1.3776\n",
      " Epoch [42/300], Batch Step [50/323], D_loss: 0.8920,  G_loss: 1.3551\n",
      " Epoch [42/300], Batch Step [60/323], D_loss: 0.8363,  G_loss: 1.2729\n",
      " Epoch [42/300], Batch Step [70/323], D_loss: 0.9817,  G_loss: 1.5484\n",
      " Epoch [42/300], Batch Step [80/323], D_loss: 0.8736,  G_loss: 1.4349\n",
      " Epoch [42/300], Batch Step [90/323], D_loss: 0.9267,  G_loss: 1.4380\n",
      " Epoch [42/300], Batch Step [100/323], D_loss: 0.8470,  G_loss: 1.4338\n",
      " Epoch [42/300], Batch Step [110/323], D_loss: 0.7919,  G_loss: 1.4335\n",
      " Epoch [42/300], Batch Step [120/323], D_loss: 0.9504,  G_loss: 1.3550\n",
      " Epoch [42/300], Batch Step [130/323], D_loss: 0.9215,  G_loss: 1.2280\n",
      " Epoch [42/300], Batch Step [140/323], D_loss: 1.1396,  G_loss: 1.3217\n",
      " Epoch [42/300], Batch Step [150/323], D_loss: 0.8971,  G_loss: 1.4679\n",
      " Epoch [42/300], Batch Step [160/323], D_loss: 0.9674,  G_loss: 1.3390\n",
      " Epoch [42/300], Batch Step [170/323], D_loss: 0.7443,  G_loss: 1.4657\n",
      " Epoch [42/300], Batch Step [180/323], D_loss: 0.7497,  G_loss: 1.3626\n",
      " Epoch [42/300], Batch Step [190/323], D_loss: 0.9360,  G_loss: 1.6295\n",
      " Epoch [42/300], Batch Step [200/323], D_loss: 0.9785,  G_loss: 1.2856\n",
      " Epoch [42/300], Batch Step [210/323], D_loss: 0.8693,  G_loss: 1.3208\n",
      " Epoch [42/300], Batch Step [220/323], D_loss: 1.0924,  G_loss: 1.3088\n",
      " Epoch [42/300], Batch Step [230/323], D_loss: 0.7789,  G_loss: 1.3814\n",
      " Epoch [42/300], Batch Step [240/323], D_loss: 0.9198,  G_loss: 1.5189\n",
      " Epoch [42/300], Batch Step [250/323], D_loss: 0.8376,  G_loss: 1.4435\n",
      " Epoch [42/300], Batch Step [260/323], D_loss: 0.9091,  G_loss: 1.3793\n",
      " Epoch [42/300], Batch Step [270/323], D_loss: 0.8861,  G_loss: 1.3736\n",
      " Epoch [42/300], Batch Step [280/323], D_loss: 0.8724,  G_loss: 1.3858\n",
      " Epoch [42/300], Batch Step [290/323], D_loss: 0.8987,  G_loss: 1.2492\n",
      " Epoch [42/300], Batch Step [300/323], D_loss: 0.9067,  G_loss: 1.3958\n",
      " Epoch [42/300], Batch Step [310/323], D_loss: 0.8088,  G_loss: 1.3253\n",
      " Epoch [42/300], Batch Step [320/323], D_loss: 0.8639,  G_loss: 1.3839\n",
      " Epoch [43/300], Batch Step [0/323], D_loss: 0.8004,  G_loss: 1.4556\n",
      " Epoch [43/300], Batch Step [10/323], D_loss: 0.9746,  G_loss: 1.3039\n",
      " Epoch [43/300], Batch Step [20/323], D_loss: 1.0010,  G_loss: 1.4000\n",
      " Epoch [43/300], Batch Step [30/323], D_loss: 0.9491,  G_loss: 1.3759\n",
      " Epoch [43/300], Batch Step [40/323], D_loss: 0.7783,  G_loss: 1.2654\n",
      " Epoch [43/300], Batch Step [50/323], D_loss: 0.8753,  G_loss: 1.3793\n",
      " Epoch [43/300], Batch Step [60/323], D_loss: 0.9631,  G_loss: 1.4672\n",
      " Epoch [43/300], Batch Step [70/323], D_loss: 0.7396,  G_loss: 1.3372\n",
      " Epoch [43/300], Batch Step [80/323], D_loss: 0.8476,  G_loss: 1.3550\n",
      " Epoch [43/300], Batch Step [90/323], D_loss: 0.7785,  G_loss: 1.3697\n",
      " Epoch [43/300], Batch Step [100/323], D_loss: 0.6972,  G_loss: 1.4202\n",
      " Epoch [43/300], Batch Step [110/323], D_loss: 0.8201,  G_loss: 1.3876\n",
      " Epoch [43/300], Batch Step [120/323], D_loss: 0.7125,  G_loss: 1.3487\n",
      " Epoch [43/300], Batch Step [130/323], D_loss: 0.8965,  G_loss: 1.4337\n",
      " Epoch [43/300], Batch Step [140/323], D_loss: 0.8832,  G_loss: 1.5211\n",
      " Epoch [43/300], Batch Step [150/323], D_loss: 0.9630,  G_loss: 1.3831\n",
      " Epoch [43/300], Batch Step [160/323], D_loss: 0.8210,  G_loss: 1.2746\n",
      " Epoch [43/300], Batch Step [170/323], D_loss: 0.7508,  G_loss: 1.4984\n",
      " Epoch [43/300], Batch Step [180/323], D_loss: 0.8340,  G_loss: 1.4308\n",
      " Epoch [43/300], Batch Step [190/323], D_loss: 0.9761,  G_loss: 1.4832\n",
      " Epoch [43/300], Batch Step [200/323], D_loss: 0.7243,  G_loss: 1.4799\n",
      " Epoch [43/300], Batch Step [210/323], D_loss: 0.8116,  G_loss: 1.5657\n",
      " Epoch [43/300], Batch Step [220/323], D_loss: 0.8015,  G_loss: 1.3163\n",
      " Epoch [43/300], Batch Step [230/323], D_loss: 0.8660,  G_loss: 1.4784\n",
      " Epoch [43/300], Batch Step [240/323], D_loss: 0.8470,  G_loss: 1.3930\n",
      " Epoch [43/300], Batch Step [250/323], D_loss: 0.8745,  G_loss: 1.4081\n",
      " Epoch [43/300], Batch Step [260/323], D_loss: 0.6149,  G_loss: 1.5038\n",
      " Epoch [43/300], Batch Step [270/323], D_loss: 0.7583,  G_loss: 1.4799\n",
      " Epoch [43/300], Batch Step [280/323], D_loss: 0.7600,  G_loss: 1.3916\n",
      " Epoch [43/300], Batch Step [290/323], D_loss: 0.7360,  G_loss: 1.4962\n",
      " Epoch [43/300], Batch Step [300/323], D_loss: 0.9113,  G_loss: 1.2907\n",
      " Epoch [43/300], Batch Step [310/323], D_loss: 0.8432,  G_loss: 1.4374\n",
      " Epoch [43/300], Batch Step [320/323], D_loss: 0.6672,  G_loss: 1.3960\n",
      " Epoch [44/300], Batch Step [0/323], D_loss: 0.9840,  G_loss: 1.5540\n",
      " Epoch [44/300], Batch Step [10/323], D_loss: 0.6867,  G_loss: 1.3189\n",
      " Epoch [44/300], Batch Step [20/323], D_loss: 0.7404,  G_loss: 1.2904\n",
      " Epoch [44/300], Batch Step [30/323], D_loss: 0.7473,  G_loss: 1.4053\n",
      " Epoch [44/300], Batch Step [40/323], D_loss: 0.8168,  G_loss: 1.3952\n",
      " Epoch [44/300], Batch Step [50/323], D_loss: 0.9091,  G_loss: 1.4124\n",
      " Epoch [44/300], Batch Step [60/323], D_loss: 0.8210,  G_loss: 1.3897\n",
      " Epoch [44/300], Batch Step [70/323], D_loss: 2.4724,  G_loss: 1.4231\n",
      " Epoch [44/300], Batch Step [80/323], D_loss: 0.7873,  G_loss: 1.6393\n",
      " Epoch [44/300], Batch Step [90/323], D_loss: 0.6983,  G_loss: 1.5499\n",
      " Epoch [44/300], Batch Step [100/323], D_loss: 0.5308,  G_loss: 1.5410\n",
      " Epoch [44/300], Batch Step [110/323], D_loss: 0.6313,  G_loss: 1.4551\n",
      " Epoch [44/300], Batch Step [120/323], D_loss: 0.8258,  G_loss: 1.4448\n",
      " Epoch [44/300], Batch Step [130/323], D_loss: 0.8767,  G_loss: 1.4642\n",
      " Epoch [44/300], Batch Step [140/323], D_loss: 0.9954,  G_loss: 1.5159\n",
      " Epoch [44/300], Batch Step [150/323], D_loss: 0.8460,  G_loss: 1.4223\n",
      " Epoch [44/300], Batch Step [160/323], D_loss: 0.8136,  G_loss: 1.4461\n",
      " Epoch [44/300], Batch Step [170/323], D_loss: 0.6385,  G_loss: 1.3621\n",
      " Epoch [44/300], Batch Step [180/323], D_loss: 0.8322,  G_loss: 1.4506\n",
      " Epoch [44/300], Batch Step [190/323], D_loss: 0.6142,  G_loss: 1.4122\n",
      " Epoch [44/300], Batch Step [200/323], D_loss: 0.8441,  G_loss: 1.4711\n",
      " Epoch [44/300], Batch Step [210/323], D_loss: 0.8379,  G_loss: 1.3798\n",
      " Epoch [44/300], Batch Step [220/323], D_loss: 0.7885,  G_loss: 1.3386\n",
      " Epoch [44/300], Batch Step [230/323], D_loss: 1.0017,  G_loss: 1.3448\n",
      " Epoch [44/300], Batch Step [240/323], D_loss: 0.9789,  G_loss: 1.5789\n",
      " Epoch [44/300], Batch Step [250/323], D_loss: 0.8063,  G_loss: 1.3121\n",
      " Epoch [44/300], Batch Step [260/323], D_loss: 0.8827,  G_loss: 1.4810\n",
      " Epoch [44/300], Batch Step [270/323], D_loss: 0.6024,  G_loss: 1.3543\n",
      " Epoch [44/300], Batch Step [280/323], D_loss: 0.7941,  G_loss: 1.5655\n",
      " Epoch [44/300], Batch Step [290/323], D_loss: 0.6103,  G_loss: 1.5054\n",
      " Epoch [44/300], Batch Step [300/323], D_loss: 0.7782,  G_loss: 1.4547\n",
      " Epoch [44/300], Batch Step [310/323], D_loss: 0.9004,  G_loss: 1.4002\n",
      " Epoch [44/300], Batch Step [320/323], D_loss: 1.0964,  G_loss: 1.3614\n",
      " Epoch [45/300], Batch Step [0/323], D_loss: 0.8927,  G_loss: 1.2949\n",
      " Epoch [45/300], Batch Step [10/323], D_loss: 0.9686,  G_loss: 1.2987\n",
      " Epoch [45/300], Batch Step [20/323], D_loss: 0.6845,  G_loss: 1.3247\n",
      " Epoch [45/300], Batch Step [30/323], D_loss: 0.6700,  G_loss: 1.4638\n",
      " Epoch [45/300], Batch Step [40/323], D_loss: 0.7072,  G_loss: 1.4387\n",
      " Epoch [45/300], Batch Step [50/323], D_loss: 0.6508,  G_loss: 1.4356\n",
      " Epoch [45/300], Batch Step [60/323], D_loss: 0.7945,  G_loss: 1.5869\n",
      " Epoch [45/300], Batch Step [70/323], D_loss: 0.8715,  G_loss: 1.3050\n",
      " Epoch [45/300], Batch Step [80/323], D_loss: 0.9673,  G_loss: 1.3152\n",
      " Epoch [45/300], Batch Step [90/323], D_loss: 0.9638,  G_loss: 1.3803\n",
      " Epoch [45/300], Batch Step [100/323], D_loss: 0.9088,  G_loss: 1.3989\n",
      " Epoch [45/300], Batch Step [110/323], D_loss: 0.7760,  G_loss: 1.3096\n",
      " Epoch [45/300], Batch Step [120/323], D_loss: 0.7775,  G_loss: 1.5819\n",
      " Epoch [45/300], Batch Step [130/323], D_loss: 0.7592,  G_loss: 1.4160\n",
      " Epoch [45/300], Batch Step [140/323], D_loss: 0.8126,  G_loss: 1.4479\n",
      " Epoch [45/300], Batch Step [150/323], D_loss: 0.7789,  G_loss: 1.3972\n",
      " Epoch [45/300], Batch Step [160/323], D_loss: 0.8476,  G_loss: 1.3887\n",
      " Epoch [45/300], Batch Step [170/323], D_loss: 1.0467,  G_loss: 1.3138\n",
      " Epoch [45/300], Batch Step [180/323], D_loss: 0.9406,  G_loss: 1.4461\n",
      " Epoch [45/300], Batch Step [190/323], D_loss: 1.0683,  G_loss: 1.2221\n",
      " Epoch [45/300], Batch Step [200/323], D_loss: 0.8285,  G_loss: 1.4400\n",
      " Epoch [45/300], Batch Step [210/323], D_loss: 0.8267,  G_loss: 1.4132\n",
      " Epoch [45/300], Batch Step [220/323], D_loss: 0.8306,  G_loss: 1.5745\n",
      " Epoch [45/300], Batch Step [230/323], D_loss: 0.8712,  G_loss: 1.3530\n",
      " Epoch [45/300], Batch Step [240/323], D_loss: 0.9001,  G_loss: 1.4032\n",
      " Epoch [45/300], Batch Step [250/323], D_loss: 0.8095,  G_loss: 1.3610\n",
      " Epoch [45/300], Batch Step [260/323], D_loss: 0.9205,  G_loss: 1.2780\n",
      " Epoch [45/300], Batch Step [270/323], D_loss: 0.9189,  G_loss: 1.5311\n",
      " Epoch [45/300], Batch Step [280/323], D_loss: 0.9505,  G_loss: 1.4250\n",
      " Epoch [45/300], Batch Step [290/323], D_loss: 0.8294,  G_loss: 1.3959\n",
      " Epoch [45/300], Batch Step [300/323], D_loss: 0.6969,  G_loss: 1.6080\n",
      " Epoch [45/300], Batch Step [310/323], D_loss: 0.7646,  G_loss: 1.4149\n",
      " Epoch [45/300], Batch Step [320/323], D_loss: 0.8756,  G_loss: 1.5035\n",
      " Epoch [46/300], Batch Step [0/323], D_loss: 0.7379,  G_loss: 1.3307\n",
      " Epoch [46/300], Batch Step [10/323], D_loss: 0.8367,  G_loss: 1.4235\n",
      " Epoch [46/300], Batch Step [20/323], D_loss: 0.8138,  G_loss: 1.3887\n",
      " Epoch [46/300], Batch Step [30/323], D_loss: 0.9050,  G_loss: 1.3691\n",
      " Epoch [46/300], Batch Step [40/323], D_loss: 0.9965,  G_loss: 1.3894\n",
      " Epoch [46/300], Batch Step [50/323], D_loss: 0.9021,  G_loss: 1.3215\n",
      " Epoch [46/300], Batch Step [60/323], D_loss: 0.9449,  G_loss: 1.6047\n",
      " Epoch [46/300], Batch Step [70/323], D_loss: 0.8425,  G_loss: 1.3965\n",
      " Epoch [46/300], Batch Step [80/323], D_loss: 0.7358,  G_loss: 1.3862\n",
      " Epoch [46/300], Batch Step [90/323], D_loss: 0.8579,  G_loss: 1.4980\n",
      " Epoch [46/300], Batch Step [100/323], D_loss: 0.8536,  G_loss: 1.4784\n",
      " Epoch [46/300], Batch Step [110/323], D_loss: 2.4946,  G_loss: 1.4283\n",
      " Epoch [46/300], Batch Step [120/323], D_loss: 0.8344,  G_loss: 1.3875\n",
      " Epoch [46/300], Batch Step [130/323], D_loss: 1.0113,  G_loss: 1.3309\n",
      " Epoch [46/300], Batch Step [140/323], D_loss: 0.7257,  G_loss: 1.4127\n",
      " Epoch [46/300], Batch Step [150/323], D_loss: 0.9095,  G_loss: 1.4209\n",
      " Epoch [46/300], Batch Step [160/323], D_loss: 0.8392,  G_loss: 1.5477\n",
      " Epoch [46/300], Batch Step [170/323], D_loss: 0.7935,  G_loss: 1.4006\n",
      " Epoch [46/300], Batch Step [180/323], D_loss: 0.8196,  G_loss: 1.3276\n",
      " Epoch [46/300], Batch Step [190/323], D_loss: 0.8980,  G_loss: 1.3421\n",
      " Epoch [46/300], Batch Step [200/323], D_loss: 0.7773,  G_loss: 1.2704\n",
      " Epoch [46/300], Batch Step [210/323], D_loss: 0.9545,  G_loss: 1.1946\n",
      " Epoch [46/300], Batch Step [220/323], D_loss: 0.8422,  G_loss: 1.5697\n",
      " Epoch [46/300], Batch Step [230/323], D_loss: 0.9850,  G_loss: 1.3276\n",
      " Epoch [46/300], Batch Step [240/323], D_loss: 0.6477,  G_loss: 1.3682\n",
      " Epoch [46/300], Batch Step [250/323], D_loss: 0.7958,  G_loss: 1.5379\n",
      " Epoch [46/300], Batch Step [260/323], D_loss: 2.2869,  G_loss: 1.4421\n",
      " Epoch [46/300], Batch Step [270/323], D_loss: 0.7778,  G_loss: 1.5141\n",
      " Epoch [46/300], Batch Step [280/323], D_loss: 0.7715,  G_loss: 1.2551\n",
      " Epoch [46/300], Batch Step [290/323], D_loss: 0.9631,  G_loss: 1.3422\n",
      " Epoch [46/300], Batch Step [300/323], D_loss: 0.9695,  G_loss: 1.4296\n",
      " Epoch [46/300], Batch Step [310/323], D_loss: 0.8797,  G_loss: 1.2992\n",
      " Epoch [46/300], Batch Step [320/323], D_loss: 0.8577,  G_loss: 1.4560\n",
      " Epoch [47/300], Batch Step [0/323], D_loss: 0.7769,  G_loss: 1.4216\n",
      " Epoch [47/300], Batch Step [10/323], D_loss: 0.8578,  G_loss: 1.5356\n",
      " Epoch [47/300], Batch Step [20/323], D_loss: 2.2515,  G_loss: 1.5267\n",
      " Epoch [47/300], Batch Step [30/323], D_loss: 0.7744,  G_loss: 1.4400\n",
      " Epoch [47/300], Batch Step [40/323], D_loss: 0.8576,  G_loss: 1.2281\n",
      " Epoch [47/300], Batch Step [50/323], D_loss: 0.9624,  G_loss: 1.2637\n",
      " Epoch [47/300], Batch Step [60/323], D_loss: 1.0618,  G_loss: 1.2340\n",
      " Epoch [47/300], Batch Step [70/323], D_loss: 0.8524,  G_loss: 1.2470\n",
      " Epoch [47/300], Batch Step [80/323], D_loss: 0.9020,  G_loss: 1.2951\n",
      " Epoch [47/300], Batch Step [90/323], D_loss: 0.8976,  G_loss: 1.4131\n",
      " Epoch [47/300], Batch Step [100/323], D_loss: 0.7029,  G_loss: 1.5188\n",
      " Epoch [47/300], Batch Step [110/323], D_loss: 0.7112,  G_loss: 1.4995\n",
      " Epoch [47/300], Batch Step [120/323], D_loss: 0.8333,  G_loss: 1.3076\n",
      " Epoch [47/300], Batch Step [130/323], D_loss: 0.8810,  G_loss: 1.3830\n",
      " Epoch [47/300], Batch Step [140/323], D_loss: 0.9371,  G_loss: 1.4360\n",
      " Epoch [47/300], Batch Step [150/323], D_loss: 0.7400,  G_loss: 1.2745\n",
      " Epoch [47/300], Batch Step [160/323], D_loss: 0.9745,  G_loss: 1.1487\n",
      " Epoch [47/300], Batch Step [170/323], D_loss: 1.1137,  G_loss: 1.2219\n",
      " Epoch [47/300], Batch Step [180/323], D_loss: 0.8922,  G_loss: 1.2928\n",
      " Epoch [47/300], Batch Step [190/323], D_loss: 0.8086,  G_loss: 1.4822\n",
      " Epoch [47/300], Batch Step [200/323], D_loss: 0.7627,  G_loss: 1.4304\n",
      " Epoch [47/300], Batch Step [210/323], D_loss: 0.7133,  G_loss: 1.3930\n",
      " Epoch [47/300], Batch Step [220/323], D_loss: 0.8096,  G_loss: 1.4286\n",
      " Epoch [47/300], Batch Step [230/323], D_loss: 0.9997,  G_loss: 1.1928\n",
      " Epoch [47/300], Batch Step [240/323], D_loss: 2.3072,  G_loss: 1.2654\n",
      " Epoch [47/300], Batch Step [250/323], D_loss: 0.9042,  G_loss: 1.2430\n",
      " Epoch [47/300], Batch Step [260/323], D_loss: 0.9592,  G_loss: 1.2357\n",
      " Epoch [47/300], Batch Step [270/323], D_loss: 0.8683,  G_loss: 1.4041\n",
      " Epoch [47/300], Batch Step [280/323], D_loss: 0.7728,  G_loss: 1.2914\n",
      " Epoch [47/300], Batch Step [290/323], D_loss: 0.7657,  G_loss: 1.3650\n",
      " Epoch [47/300], Batch Step [300/323], D_loss: 0.9015,  G_loss: 1.3997\n",
      " Epoch [47/300], Batch Step [310/323], D_loss: 0.7630,  G_loss: 1.3112\n",
      " Epoch [47/300], Batch Step [320/323], D_loss: 1.0309,  G_loss: 1.4807\n",
      " Epoch [48/300], Batch Step [0/323], D_loss: 1.0952,  G_loss: 1.2652\n",
      " Epoch [48/300], Batch Step [10/323], D_loss: 0.9309,  G_loss: 1.2359\n",
      " Epoch [48/300], Batch Step [20/323], D_loss: 1.1484,  G_loss: 1.2558\n",
      " Epoch [48/300], Batch Step [30/323], D_loss: 0.9383,  G_loss: 1.3315\n",
      " Epoch [48/300], Batch Step [40/323], D_loss: 0.9204,  G_loss: 1.2717\n",
      " Epoch [48/300], Batch Step [50/323], D_loss: 0.7882,  G_loss: 1.4333\n",
      " Epoch [48/300], Batch Step [60/323], D_loss: 0.9036,  G_loss: 1.4640\n",
      " Epoch [48/300], Batch Step [70/323], D_loss: 0.8037,  G_loss: 1.2410\n",
      " Epoch [48/300], Batch Step [80/323], D_loss: 0.9110,  G_loss: 1.3085\n",
      " Epoch [48/300], Batch Step [90/323], D_loss: 0.9309,  G_loss: 1.3899\n",
      " Epoch [48/300], Batch Step [100/323], D_loss: 0.9350,  G_loss: 1.2386\n",
      " Epoch [48/300], Batch Step [110/323], D_loss: 0.9946,  G_loss: 1.4064\n",
      " Epoch [48/300], Batch Step [120/323], D_loss: 0.8584,  G_loss: 1.1510\n",
      " Epoch [48/300], Batch Step [130/323], D_loss: 0.8642,  G_loss: 1.2339\n",
      " Epoch [48/300], Batch Step [140/323], D_loss: 0.7501,  G_loss: 1.3857\n",
      " Epoch [48/300], Batch Step [150/323], D_loss: 0.7594,  G_loss: 1.4883\n",
      " Epoch [48/300], Batch Step [160/323], D_loss: 0.8520,  G_loss: 1.3288\n",
      " Epoch [48/300], Batch Step [170/323], D_loss: 0.9732,  G_loss: 1.4666\n",
      " Epoch [48/300], Batch Step [180/323], D_loss: 0.9084,  G_loss: 1.3176\n",
      " Epoch [48/300], Batch Step [190/323], D_loss: 0.9799,  G_loss: 1.2343\n",
      " Epoch [48/300], Batch Step [200/323], D_loss: 0.6727,  G_loss: 1.3873\n",
      " Epoch [48/300], Batch Step [210/323], D_loss: 0.8492,  G_loss: 1.2980\n",
      " Epoch [48/300], Batch Step [220/323], D_loss: 0.8574,  G_loss: 1.4725\n",
      " Epoch [48/300], Batch Step [230/323], D_loss: 0.7998,  G_loss: 1.5137\n",
      " Epoch [48/300], Batch Step [240/323], D_loss: 0.8316,  G_loss: 1.4713\n",
      " Epoch [48/300], Batch Step [250/323], D_loss: 0.8066,  G_loss: 1.3654\n",
      " Epoch [48/300], Batch Step [260/323], D_loss: 0.8421,  G_loss: 1.3503\n",
      " Epoch [48/300], Batch Step [270/323], D_loss: 0.6771,  G_loss: 1.4092\n",
      " Epoch [48/300], Batch Step [280/323], D_loss: 0.9181,  G_loss: 1.2162\n",
      " Epoch [48/300], Batch Step [290/323], D_loss: 0.9804,  G_loss: 1.2061\n",
      " Epoch [48/300], Batch Step [300/323], D_loss: 0.7586,  G_loss: 1.3197\n",
      " Epoch [48/300], Batch Step [310/323], D_loss: 0.9847,  G_loss: 1.3512\n",
      " Epoch [48/300], Batch Step [320/323], D_loss: 0.8085,  G_loss: 1.2447\n",
      " Epoch [49/300], Batch Step [0/323], D_loss: 0.7325,  G_loss: 1.2942\n",
      " Epoch [49/300], Batch Step [10/323], D_loss: 0.8608,  G_loss: 1.3247\n",
      " Epoch [49/300], Batch Step [20/323], D_loss: 0.7302,  G_loss: 1.4477\n",
      " Epoch [49/300], Batch Step [30/323], D_loss: 0.8113,  G_loss: 1.4193\n",
      " Epoch [49/300], Batch Step [40/323], D_loss: 0.8118,  G_loss: 1.5198\n",
      " Epoch [49/300], Batch Step [50/323], D_loss: 0.9234,  G_loss: 1.2097\n",
      " Epoch [49/300], Batch Step [60/323], D_loss: 0.8310,  G_loss: 1.3945\n",
      " Epoch [49/300], Batch Step [70/323], D_loss: 0.8294,  G_loss: 1.3401\n",
      " Epoch [49/300], Batch Step [80/323], D_loss: 0.8531,  G_loss: 1.3285\n",
      " Epoch [49/300], Batch Step [90/323], D_loss: 0.7921,  G_loss: 1.4217\n",
      " Epoch [49/300], Batch Step [100/323], D_loss: 0.8504,  G_loss: 1.3659\n",
      " Epoch [49/300], Batch Step [110/323], D_loss: 0.7656,  G_loss: 1.4858\n",
      " Epoch [49/300], Batch Step [120/323], D_loss: 0.8611,  G_loss: 1.3398\n",
      " Epoch [49/300], Batch Step [130/323], D_loss: 0.7254,  G_loss: 1.3583\n",
      " Epoch [49/300], Batch Step [140/323], D_loss: 0.8217,  G_loss: 1.2661\n",
      " Epoch [49/300], Batch Step [150/323], D_loss: 1.0002,  G_loss: 1.2331\n",
      " Epoch [49/300], Batch Step [160/323], D_loss: 0.8004,  G_loss: 1.2163\n",
      " Epoch [49/300], Batch Step [170/323], D_loss: 1.0023,  G_loss: 1.2916\n",
      " Epoch [49/300], Batch Step [180/323], D_loss: 0.8837,  G_loss: 1.4608\n",
      " Epoch [49/300], Batch Step [190/323], D_loss: 0.7888,  G_loss: 1.3802\n",
      " Epoch [49/300], Batch Step [200/323], D_loss: 0.7412,  G_loss: 1.4719\n",
      " Epoch [49/300], Batch Step [210/323], D_loss: 1.0069,  G_loss: 1.1630\n",
      " Epoch [49/300], Batch Step [220/323], D_loss: 0.9088,  G_loss: 1.5202\n",
      " Epoch [49/300], Batch Step [230/323], D_loss: 0.9087,  G_loss: 1.2962\n",
      " Epoch [49/300], Batch Step [240/323], D_loss: 0.7425,  G_loss: 1.3353\n",
      " Epoch [49/300], Batch Step [250/323], D_loss: 0.9780,  G_loss: 1.1838\n",
      " Epoch [49/300], Batch Step [260/323], D_loss: 0.8924,  G_loss: 1.2984\n",
      " Epoch [49/300], Batch Step [270/323], D_loss: 0.8410,  G_loss: 1.3853\n",
      " Epoch [49/300], Batch Step [280/323], D_loss: 0.7072,  G_loss: 1.3250\n",
      " Epoch [49/300], Batch Step [290/323], D_loss: 0.7291,  G_loss: 1.2989\n",
      " Epoch [49/300], Batch Step [300/323], D_loss: 0.8204,  G_loss: 1.3341\n",
      " Epoch [49/300], Batch Step [310/323], D_loss: 0.9025,  G_loss: 1.2556\n",
      " Epoch [49/300], Batch Step [320/323], D_loss: 0.7087,  G_loss: 1.3157\n",
      " Epoch [50/300], Batch Step [0/323], D_loss: 0.7329,  G_loss: 1.2657\n",
      " Epoch [50/300], Batch Step [10/323], D_loss: 0.9046,  G_loss: 1.3109\n",
      " Epoch [50/300], Batch Step [20/323], D_loss: 0.9031,  G_loss: 1.0508\n",
      " Epoch [50/300], Batch Step [30/323], D_loss: 0.8072,  G_loss: 1.4037\n",
      " Epoch [50/300], Batch Step [40/323], D_loss: 0.7855,  G_loss: 1.3158\n",
      " Epoch [50/300], Batch Step [50/323], D_loss: 0.7383,  G_loss: 1.4257\n",
      " Epoch [50/300], Batch Step [60/323], D_loss: 0.6835,  G_loss: 1.4560\n",
      " Epoch [50/300], Batch Step [70/323], D_loss: 0.7945,  G_loss: 1.4604\n",
      " Epoch [50/300], Batch Step [80/323], D_loss: 0.7579,  G_loss: 1.3220\n",
      " Epoch [50/300], Batch Step [90/323], D_loss: 0.8464,  G_loss: 1.2517\n",
      " Epoch [50/300], Batch Step [100/323], D_loss: 0.9068,  G_loss: 1.4209\n",
      " Epoch [50/300], Batch Step [110/323], D_loss: 0.9115,  G_loss: 1.2296\n",
      " Epoch [50/300], Batch Step [120/323], D_loss: 0.8715,  G_loss: 1.2928\n",
      " Epoch [50/300], Batch Step [130/323], D_loss: 0.7987,  G_loss: 1.3430\n",
      " Epoch [50/300], Batch Step [140/323], D_loss: 0.9362,  G_loss: 1.4485\n",
      " Epoch [50/300], Batch Step [150/323], D_loss: 0.7806,  G_loss: 1.3883\n",
      " Epoch [50/300], Batch Step [160/323], D_loss: 0.6437,  G_loss: 1.4681\n",
      " Epoch [50/300], Batch Step [170/323], D_loss: 0.6411,  G_loss: 1.3999\n",
      " Epoch [50/300], Batch Step [180/323], D_loss: 0.7781,  G_loss: 1.5342\n",
      " Epoch [50/300], Batch Step [190/323], D_loss: 0.9236,  G_loss: 1.1594\n",
      " Epoch [50/300], Batch Step [200/323], D_loss: 0.9109,  G_loss: 1.2051\n",
      " Epoch [50/300], Batch Step [210/323], D_loss: 0.8455,  G_loss: 1.1822\n",
      " Epoch [50/300], Batch Step [220/323], D_loss: 0.8411,  G_loss: 1.3462\n",
      " Epoch [50/300], Batch Step [230/323], D_loss: 0.8438,  G_loss: 1.2790\n",
      " Epoch [50/300], Batch Step [240/323], D_loss: 0.7294,  G_loss: 1.6581\n",
      " Epoch [50/300], Batch Step [250/323], D_loss: 0.7402,  G_loss: 1.5847\n",
      " Epoch [50/300], Batch Step [260/323], D_loss: 0.7529,  G_loss: 1.4955\n",
      " Epoch [50/300], Batch Step [270/323], D_loss: 0.7737,  G_loss: 1.5078\n",
      " Epoch [50/300], Batch Step [280/323], D_loss: 0.7584,  G_loss: 1.4878\n",
      " Epoch [50/300], Batch Step [290/323], D_loss: 0.7531,  G_loss: 1.4869\n",
      " Epoch [50/300], Batch Step [300/323], D_loss: 0.7582,  G_loss: 1.2999\n",
      " Epoch [50/300], Batch Step [310/323], D_loss: 0.9472,  G_loss: 1.3118\n",
      " Epoch [50/300], Batch Step [320/323], D_loss: 0.9318,  G_loss: 1.2020\n",
      " Epoch [51/300], Batch Step [0/323], D_loss: 0.9039,  G_loss: 1.3161\n",
      " Epoch [51/300], Batch Step [10/323], D_loss: 0.8388,  G_loss: 1.3831\n",
      " Epoch [51/300], Batch Step [20/323], D_loss: 0.7943,  G_loss: 1.5119\n",
      " Epoch [51/300], Batch Step [30/323], D_loss: 0.7254,  G_loss: 1.4558\n",
      " Epoch [51/300], Batch Step [40/323], D_loss: 0.6429,  G_loss: 1.3963\n",
      " Epoch [51/300], Batch Step [50/323], D_loss: 0.7211,  G_loss: 1.4358\n",
      " Epoch [51/300], Batch Step [60/323], D_loss: 0.8266,  G_loss: 1.2691\n",
      " Epoch [51/300], Batch Step [70/323], D_loss: 0.8122,  G_loss: 1.3177\n",
      " Epoch [51/300], Batch Step [80/323], D_loss: 0.9216,  G_loss: 1.2308\n",
      " Epoch [51/300], Batch Step [90/323], D_loss: 0.8675,  G_loss: 1.3995\n",
      " Epoch [51/300], Batch Step [100/323], D_loss: 0.8501,  G_loss: 1.3835\n",
      " Epoch [51/300], Batch Step [110/323], D_loss: 0.6356,  G_loss: 1.5525\n",
      " Epoch [51/300], Batch Step [120/323], D_loss: 0.8359,  G_loss: 1.3751\n",
      " Epoch [51/300], Batch Step [130/323], D_loss: 0.7991,  G_loss: 1.5832\n",
      " Epoch [51/300], Batch Step [140/323], D_loss: 0.8592,  G_loss: 1.2985\n",
      " Epoch [51/300], Batch Step [150/323], D_loss: 0.7556,  G_loss: 1.5256\n",
      " Epoch [51/300], Batch Step [160/323], D_loss: 0.7264,  G_loss: 1.4912\n",
      " Epoch [51/300], Batch Step [170/323], D_loss: 0.7483,  G_loss: 1.2686\n",
      " Epoch [51/300], Batch Step [180/323], D_loss: 0.7369,  G_loss: 1.5638\n",
      " Epoch [51/300], Batch Step [190/323], D_loss: 0.7939,  G_loss: 1.4670\n",
      " Epoch [51/300], Batch Step [200/323], D_loss: 0.6360,  G_loss: 1.3515\n",
      " Epoch [51/300], Batch Step [210/323], D_loss: 0.8076,  G_loss: 1.3130\n",
      " Epoch [51/300], Batch Step [220/323], D_loss: 0.7111,  G_loss: 1.2508\n",
      " Epoch [51/300], Batch Step [230/323], D_loss: 0.6778,  G_loss: 1.2660\n",
      " Epoch [51/300], Batch Step [240/323], D_loss: 0.7608,  G_loss: 1.2755\n",
      " Epoch [51/300], Batch Step [250/323], D_loss: 0.6585,  G_loss: 1.3540\n",
      " Epoch [51/300], Batch Step [260/323], D_loss: 0.8211,  G_loss: 1.3828\n",
      " Epoch [51/300], Batch Step [270/323], D_loss: 0.7538,  G_loss: 1.4560\n",
      " Epoch [51/300], Batch Step [280/323], D_loss: 0.6607,  G_loss: 1.4210\n",
      " Epoch [51/300], Batch Step [290/323], D_loss: 0.7660,  G_loss: 1.4727\n",
      " Epoch [51/300], Batch Step [300/323], D_loss: 0.8193,  G_loss: 1.2833\n",
      " Epoch [51/300], Batch Step [310/323], D_loss: 0.6737,  G_loss: 1.4677\n",
      " Epoch [51/300], Batch Step [320/323], D_loss: 0.9207,  G_loss: 1.2446\n",
      " Epoch [52/300], Batch Step [0/323], D_loss: 0.7559,  G_loss: 1.1979\n",
      " Epoch [52/300], Batch Step [10/323], D_loss: 0.7165,  G_loss: 1.4020\n",
      " Epoch [52/300], Batch Step [20/323], D_loss: 0.7523,  G_loss: 1.3582\n",
      " Epoch [52/300], Batch Step [30/323], D_loss: 0.7757,  G_loss: 1.3380\n",
      " Epoch [52/300], Batch Step [40/323], D_loss: 0.7536,  G_loss: 1.3296\n",
      " Epoch [52/300], Batch Step [50/323], D_loss: 0.7826,  G_loss: 1.5035\n",
      " Epoch [52/300], Batch Step [60/323], D_loss: 0.7388,  G_loss: 1.3619\n",
      " Epoch [52/300], Batch Step [70/323], D_loss: 0.7407,  G_loss: 1.2581\n",
      " Epoch [52/300], Batch Step [80/323], D_loss: 0.9075,  G_loss: 1.3775\n",
      " Epoch [52/300], Batch Step [90/323], D_loss: 0.6685,  G_loss: 1.2422\n",
      " Epoch [52/300], Batch Step [100/323], D_loss: 0.8061,  G_loss: 1.4170\n",
      " Epoch [52/300], Batch Step [110/323], D_loss: 0.8536,  G_loss: 1.2442\n",
      " Epoch [52/300], Batch Step [120/323], D_loss: 1.0240,  G_loss: 1.4268\n",
      " Epoch [52/300], Batch Step [130/323], D_loss: 0.6635,  G_loss: 1.3344\n",
      " Epoch [52/300], Batch Step [140/323], D_loss: 0.7525,  G_loss: 1.4421\n",
      " Epoch [52/300], Batch Step [150/323], D_loss: 0.8895,  G_loss: 1.4647\n",
      " Epoch [52/300], Batch Step [160/323], D_loss: 0.6186,  G_loss: 1.5041\n",
      " Epoch [52/300], Batch Step [170/323], D_loss: 0.6630,  G_loss: 1.3976\n",
      " Epoch [52/300], Batch Step [180/323], D_loss: 0.7576,  G_loss: 1.4677\n",
      " Epoch [52/300], Batch Step [190/323], D_loss: 0.7697,  G_loss: 1.3816\n",
      " Epoch [52/300], Batch Step [200/323], D_loss: 0.8021,  G_loss: 1.4636\n",
      " Epoch [52/300], Batch Step [210/323], D_loss: 0.7647,  G_loss: 1.3374\n",
      " Epoch [52/300], Batch Step [220/323], D_loss: 0.7500,  G_loss: 1.3116\n",
      " Epoch [52/300], Batch Step [230/323], D_loss: 0.6607,  G_loss: 1.3443\n",
      " Epoch [52/300], Batch Step [240/323], D_loss: 0.7416,  G_loss: 1.4651\n",
      " Epoch [52/300], Batch Step [250/323], D_loss: 0.7289,  G_loss: 1.3803\n",
      " Epoch [52/300], Batch Step [260/323], D_loss: 0.7260,  G_loss: 1.4790\n",
      " Epoch [52/300], Batch Step [270/323], D_loss: 0.8952,  G_loss: 1.3836\n",
      " Epoch [52/300], Batch Step [280/323], D_loss: 0.8240,  G_loss: 1.4432\n",
      " Epoch [52/300], Batch Step [290/323], D_loss: 0.8573,  G_loss: 1.4103\n",
      " Epoch [52/300], Batch Step [300/323], D_loss: 0.8087,  G_loss: 1.3957\n",
      " Epoch [52/300], Batch Step [310/323], D_loss: 0.9136,  G_loss: 1.5611\n",
      " Epoch [52/300], Batch Step [320/323], D_loss: 0.8021,  G_loss: 1.2610\n",
      " Epoch [53/300], Batch Step [0/323], D_loss: 0.8370,  G_loss: 1.2965\n",
      " Epoch [53/300], Batch Step [10/323], D_loss: 0.9767,  G_loss: 1.3840\n",
      " Epoch [53/300], Batch Step [20/323], D_loss: 0.7927,  G_loss: 1.3848\n",
      " Epoch [53/300], Batch Step [30/323], D_loss: 0.7249,  G_loss: 1.4362\n",
      " Epoch [53/300], Batch Step [40/323], D_loss: 0.7236,  G_loss: 1.4754\n",
      " Epoch [53/300], Batch Step [50/323], D_loss: 0.9933,  G_loss: 1.3102\n",
      " Epoch [53/300], Batch Step [60/323], D_loss: 0.9569,  G_loss: 1.3472\n",
      " Epoch [53/300], Batch Step [70/323], D_loss: 0.9877,  G_loss: 1.3468\n",
      " Epoch [53/300], Batch Step [80/323], D_loss: 0.9853,  G_loss: 1.2779\n",
      " Epoch [53/300], Batch Step [90/323], D_loss: 1.1539,  G_loss: 1.3266\n",
      " Epoch [53/300], Batch Step [100/323], D_loss: 0.8430,  G_loss: 1.2950\n",
      " Epoch [53/300], Batch Step [110/323], D_loss: 0.7949,  G_loss: 1.4259\n",
      " Epoch [53/300], Batch Step [120/323], D_loss: 0.7341,  G_loss: 1.6077\n",
      " Epoch [53/300], Batch Step [130/323], D_loss: 0.8968,  G_loss: 1.5214\n",
      " Epoch [53/300], Batch Step [140/323], D_loss: 0.7418,  G_loss: 1.6751\n",
      " Epoch [53/300], Batch Step [150/323], D_loss: 0.9382,  G_loss: 1.6149\n",
      " Epoch [53/300], Batch Step [160/323], D_loss: 0.9356,  G_loss: 1.3701\n",
      " Epoch [53/300], Batch Step [170/323], D_loss: 0.9882,  G_loss: 1.5815\n",
      " Epoch [53/300], Batch Step [180/323], D_loss: 0.7835,  G_loss: 1.4838\n",
      " Epoch [53/300], Batch Step [190/323], D_loss: 0.7353,  G_loss: 1.6366\n",
      " Epoch [53/300], Batch Step [200/323], D_loss: 0.6260,  G_loss: 1.4703\n",
      " Epoch [53/300], Batch Step [210/323], D_loss: 0.8198,  G_loss: 1.6444\n",
      " Epoch [53/300], Batch Step [220/323], D_loss: 0.6151,  G_loss: 1.6164\n",
      " Epoch [53/300], Batch Step [230/323], D_loss: 0.6342,  G_loss: 1.6073\n",
      " Epoch [53/300], Batch Step [240/323], D_loss: 0.7787,  G_loss: 1.4548\n",
      " Epoch [53/300], Batch Step [250/323], D_loss: 2.2406,  G_loss: 1.3996\n",
      " Epoch [53/300], Batch Step [260/323], D_loss: 0.6774,  G_loss: 1.4613\n",
      " Epoch [53/300], Batch Step [270/323], D_loss: 0.8324,  G_loss: 1.4869\n",
      " Epoch [53/300], Batch Step [280/323], D_loss: 1.0186,  G_loss: 1.4306\n",
      " Epoch [53/300], Batch Step [290/323], D_loss: 0.7473,  G_loss: 1.3602\n",
      " Epoch [53/300], Batch Step [300/323], D_loss: 0.7087,  G_loss: 1.4196\n",
      " Epoch [53/300], Batch Step [310/323], D_loss: 0.7399,  G_loss: 1.4232\n",
      " Epoch [53/300], Batch Step [320/323], D_loss: 0.7706,  G_loss: 1.5168\n",
      " Epoch [54/300], Batch Step [0/323], D_loss: 0.6875,  G_loss: 1.5835\n",
      " Epoch [54/300], Batch Step [10/323], D_loss: 0.6368,  G_loss: 1.4004\n",
      " Epoch [54/300], Batch Step [20/323], D_loss: 0.6521,  G_loss: 1.4607\n",
      " Epoch [54/300], Batch Step [30/323], D_loss: 0.7217,  G_loss: 1.3828\n",
      " Epoch [54/300], Batch Step [40/323], D_loss: 0.8417,  G_loss: 1.3966\n",
      " Epoch [54/300], Batch Step [50/323], D_loss: 1.0701,  G_loss: 1.1951\n",
      " Epoch [54/300], Batch Step [60/323], D_loss: 0.9393,  G_loss: 1.3669\n",
      " Epoch [54/300], Batch Step [70/323], D_loss: 0.9988,  G_loss: 1.3979\n",
      " Epoch [54/300], Batch Step [80/323], D_loss: 1.0637,  G_loss: 1.3658\n",
      " Epoch [54/300], Batch Step [90/323], D_loss: 0.8075,  G_loss: 1.4855\n",
      " Epoch [54/300], Batch Step [100/323], D_loss: 0.7332,  G_loss: 1.3021\n",
      " Epoch [54/300], Batch Step [110/323], D_loss: 0.7001,  G_loss: 1.5522\n",
      " Epoch [54/300], Batch Step [120/323], D_loss: 0.7948,  G_loss: 1.5187\n",
      " Epoch [54/300], Batch Step [130/323], D_loss: 0.6395,  G_loss: 1.3980\n",
      " Epoch [54/300], Batch Step [140/323], D_loss: 0.8812,  G_loss: 1.4452\n",
      " Epoch [54/300], Batch Step [150/323], D_loss: 0.8502,  G_loss: 1.3099\n",
      " Epoch [54/300], Batch Step [160/323], D_loss: 0.8987,  G_loss: 1.3459\n",
      " Epoch [54/300], Batch Step [170/323], D_loss: 0.8320,  G_loss: 1.2816\n",
      " Epoch [54/300], Batch Step [180/323], D_loss: 2.2898,  G_loss: 1.3306\n",
      " Epoch [54/300], Batch Step [190/323], D_loss: 1.0710,  G_loss: 1.2873\n",
      " Epoch [54/300], Batch Step [200/323], D_loss: 0.9032,  G_loss: 1.2973\n",
      " Epoch [54/300], Batch Step [210/323], D_loss: 0.7574,  G_loss: 1.4688\n",
      " Epoch [54/300], Batch Step [220/323], D_loss: 0.8478,  G_loss: 1.3229\n",
      " Epoch [54/300], Batch Step [230/323], D_loss: 0.8120,  G_loss: 1.4180\n",
      " Epoch [54/300], Batch Step [240/323], D_loss: 0.8287,  G_loss: 1.4021\n",
      " Epoch [54/300], Batch Step [250/323], D_loss: 0.7891,  G_loss: 1.4943\n",
      " Epoch [54/300], Batch Step [260/323], D_loss: 0.8057,  G_loss: 1.3804\n",
      " Epoch [54/300], Batch Step [270/323], D_loss: 0.6947,  G_loss: 1.4505\n",
      " Epoch [54/300], Batch Step [280/323], D_loss: 0.8261,  G_loss: 1.3695\n",
      " Epoch [54/300], Batch Step [290/323], D_loss: 0.9195,  G_loss: 1.2172\n",
      " Epoch [54/300], Batch Step [300/323], D_loss: 0.7718,  G_loss: 1.3298\n",
      " Epoch [54/300], Batch Step [310/323], D_loss: 0.8302,  G_loss: 1.3028\n",
      " Epoch [54/300], Batch Step [320/323], D_loss: 0.8205,  G_loss: 1.3062\n",
      " Epoch [55/300], Batch Step [0/323], D_loss: 0.7741,  G_loss: 1.4551\n",
      " Epoch [55/300], Batch Step [10/323], D_loss: 0.8004,  G_loss: 1.4367\n",
      " Epoch [55/300], Batch Step [20/323], D_loss: 0.7952,  G_loss: 1.3823\n",
      " Epoch [55/300], Batch Step [30/323], D_loss: 0.8242,  G_loss: 1.3944\n",
      " Epoch [55/300], Batch Step [40/323], D_loss: 0.6858,  G_loss: 1.4681\n",
      " Epoch [55/300], Batch Step [50/323], D_loss: 0.7506,  G_loss: 1.2104\n",
      " Epoch [55/300], Batch Step [60/323], D_loss: 0.7795,  G_loss: 1.3577\n",
      " Epoch [55/300], Batch Step [70/323], D_loss: 0.8283,  G_loss: 1.2712\n",
      " Epoch [55/300], Batch Step [80/323], D_loss: 0.8904,  G_loss: 1.3094\n",
      " Epoch [55/300], Batch Step [90/323], D_loss: 0.9614,  G_loss: 1.2378\n",
      " Epoch [55/300], Batch Step [100/323], D_loss: 0.9262,  G_loss: 1.2591\n",
      " Epoch [55/300], Batch Step [110/323], D_loss: 0.8104,  G_loss: 1.3825\n",
      " Epoch [55/300], Batch Step [120/323], D_loss: 0.7082,  G_loss: 1.3446\n",
      " Epoch [55/300], Batch Step [130/323], D_loss: 0.7339,  G_loss: 1.4941\n",
      " Epoch [55/300], Batch Step [140/323], D_loss: 0.7441,  G_loss: 1.5135\n",
      " Epoch [55/300], Batch Step [150/323], D_loss: 0.8705,  G_loss: 1.5553\n",
      " Epoch [55/300], Batch Step [160/323], D_loss: 0.7913,  G_loss: 1.4329\n",
      " Epoch [55/300], Batch Step [170/323], D_loss: 0.8872,  G_loss: 1.4949\n",
      " Epoch [55/300], Batch Step [180/323], D_loss: 0.9600,  G_loss: 1.3261\n",
      " Epoch [55/300], Batch Step [190/323], D_loss: 0.8151,  G_loss: 1.3592\n",
      " Epoch [55/300], Batch Step [200/323], D_loss: 0.7490,  G_loss: 1.4459\n",
      " Epoch [55/300], Batch Step [210/323], D_loss: 0.7607,  G_loss: 1.4579\n",
      " Epoch [55/300], Batch Step [220/323], D_loss: 0.6775,  G_loss: 1.5285\n",
      " Epoch [55/300], Batch Step [230/323], D_loss: 0.6055,  G_loss: 1.3819\n",
      " Epoch [55/300], Batch Step [240/323], D_loss: 0.7423,  G_loss: 1.6039\n",
      " Epoch [55/300], Batch Step [250/323], D_loss: 0.7183,  G_loss: 1.3446\n",
      " Epoch [55/300], Batch Step [260/323], D_loss: 0.7924,  G_loss: 1.2727\n",
      " Epoch [55/300], Batch Step [270/323], D_loss: 0.7420,  G_loss: 1.3146\n",
      " Epoch [55/300], Batch Step [280/323], D_loss: 0.9305,  G_loss: 1.2514\n",
      " Epoch [55/300], Batch Step [290/323], D_loss: 0.8216,  G_loss: 1.3008\n",
      " Epoch [55/300], Batch Step [300/323], D_loss: 0.7325,  G_loss: 1.2825\n",
      " Epoch [55/300], Batch Step [310/323], D_loss: 0.8038,  G_loss: 1.3876\n",
      " Epoch [55/300], Batch Step [320/323], D_loss: 0.6453,  G_loss: 1.4226\n",
      " Epoch [56/300], Batch Step [0/323], D_loss: 0.8369,  G_loss: 1.4572\n",
      " Epoch [56/300], Batch Step [10/323], D_loss: 0.6412,  G_loss: 1.4557\n",
      " Epoch [56/300], Batch Step [20/323], D_loss: 0.6213,  G_loss: 1.3779\n",
      " Epoch [56/300], Batch Step [30/323], D_loss: 0.7217,  G_loss: 1.5134\n",
      " Epoch [56/300], Batch Step [40/323], D_loss: 0.8008,  G_loss: 1.3589\n",
      " Epoch [56/300], Batch Step [50/323], D_loss: 0.7032,  G_loss: 1.3083\n",
      " Epoch [56/300], Batch Step [60/323], D_loss: 0.8267,  G_loss: 1.3686\n",
      " Epoch [56/300], Batch Step [70/323], D_loss: 1.1031,  G_loss: 1.2926\n",
      " Epoch [56/300], Batch Step [80/323], D_loss: 0.8946,  G_loss: 1.3449\n",
      " Epoch [56/300], Batch Step [90/323], D_loss: 0.8506,  G_loss: 1.6237\n",
      " Epoch [56/300], Batch Step [100/323], D_loss: 0.6528,  G_loss: 1.4278\n",
      " Epoch [56/300], Batch Step [110/323], D_loss: 0.6399,  G_loss: 1.5515\n",
      " Epoch [56/300], Batch Step [120/323], D_loss: 0.7533,  G_loss: 1.4769\n",
      " Epoch [56/300], Batch Step [130/323], D_loss: 0.7419,  G_loss: 1.3925\n",
      " Epoch [56/300], Batch Step [140/323], D_loss: 0.7693,  G_loss: 1.2113\n",
      " Epoch [56/300], Batch Step [150/323], D_loss: 0.7696,  G_loss: 1.1417\n",
      " Epoch [56/300], Batch Step [160/323], D_loss: 0.7654,  G_loss: 1.3446\n",
      " Epoch [56/300], Batch Step [170/323], D_loss: 0.9260,  G_loss: 1.1872\n",
      " Epoch [56/300], Batch Step [180/323], D_loss: 0.7093,  G_loss: 1.3583\n",
      " Epoch [56/300], Batch Step [190/323], D_loss: 0.6174,  G_loss: 1.4673\n",
      " Epoch [56/300], Batch Step [200/323], D_loss: 0.8089,  G_loss: 1.4195\n",
      " Epoch [56/300], Batch Step [210/323], D_loss: 0.5867,  G_loss: 1.4953\n",
      " Epoch [56/300], Batch Step [220/323], D_loss: 0.7238,  G_loss: 1.6468\n",
      " Epoch [56/300], Batch Step [230/323], D_loss: 0.9542,  G_loss: 1.3154\n",
      " Epoch [56/300], Batch Step [240/323], D_loss: 0.8850,  G_loss: 1.5067\n",
      " Epoch [56/300], Batch Step [250/323], D_loss: 1.0318,  G_loss: 1.3050\n",
      " Epoch [56/300], Batch Step [260/323], D_loss: 0.7230,  G_loss: 1.5427\n",
      " Epoch [56/300], Batch Step [270/323], D_loss: 0.7273,  G_loss: 1.4148\n",
      " Epoch [56/300], Batch Step [280/323], D_loss: 0.8889,  G_loss: 1.5090\n",
      " Epoch [56/300], Batch Step [290/323], D_loss: 0.6993,  G_loss: 1.4304\n",
      " Epoch [56/300], Batch Step [300/323], D_loss: 0.6955,  G_loss: 1.5183\n",
      " Epoch [56/300], Batch Step [310/323], D_loss: 0.6593,  G_loss: 1.5708\n",
      " Epoch [56/300], Batch Step [320/323], D_loss: 0.7142,  G_loss: 1.5259\n",
      " Epoch [57/300], Batch Step [0/323], D_loss: 0.8431,  G_loss: 1.3870\n",
      " Epoch [57/300], Batch Step [10/323], D_loss: 1.1202,  G_loss: 1.2400\n",
      " Epoch [57/300], Batch Step [20/323], D_loss: 0.9065,  G_loss: 1.3058\n",
      " Epoch [57/300], Batch Step [30/323], D_loss: 0.9111,  G_loss: 1.3175\n",
      " Epoch [57/300], Batch Step [40/323], D_loss: 0.9280,  G_loss: 1.3488\n",
      " Epoch [57/300], Batch Step [50/323], D_loss: 0.8146,  G_loss: 1.4594\n",
      " Epoch [57/300], Batch Step [60/323], D_loss: 0.6819,  G_loss: 1.2642\n",
      " Epoch [57/300], Batch Step [70/323], D_loss: 0.7077,  G_loss: 1.4845\n",
      " Epoch [57/300], Batch Step [80/323], D_loss: 0.7178,  G_loss: 1.4348\n",
      " Epoch [57/300], Batch Step [90/323], D_loss: 0.7491,  G_loss: 1.4557\n",
      " Epoch [57/300], Batch Step [100/323], D_loss: 0.8294,  G_loss: 1.4612\n",
      " Epoch [57/300], Batch Step [110/323], D_loss: 0.6833,  G_loss: 1.4188\n",
      " Epoch [57/300], Batch Step [120/323], D_loss: 0.7527,  G_loss: 1.4207\n",
      " Epoch [57/300], Batch Step [130/323], D_loss: 0.7886,  G_loss: 1.2967\n",
      " Epoch [57/300], Batch Step [140/323], D_loss: 0.7302,  G_loss: 1.3078\n",
      " Epoch [57/300], Batch Step [150/323], D_loss: 0.8424,  G_loss: 1.2644\n",
      " Epoch [57/300], Batch Step [160/323], D_loss: 0.8374,  G_loss: 1.4814\n",
      " Epoch [57/300], Batch Step [170/323], D_loss: 0.6765,  G_loss: 1.3032\n",
      " Epoch [57/300], Batch Step [180/323], D_loss: 0.6836,  G_loss: 1.4823\n",
      " Epoch [57/300], Batch Step [190/323], D_loss: 0.7857,  G_loss: 1.2715\n",
      " Epoch [57/300], Batch Step [200/323], D_loss: 0.7015,  G_loss: 1.2771\n",
      " Epoch [57/300], Batch Step [210/323], D_loss: 0.8522,  G_loss: 1.5132\n",
      " Epoch [57/300], Batch Step [220/323], D_loss: 0.7178,  G_loss: 1.3125\n",
      " Epoch [57/300], Batch Step [230/323], D_loss: 0.7232,  G_loss: 1.4384\n",
      " Epoch [57/300], Batch Step [240/323], D_loss: 0.9028,  G_loss: 1.2712\n",
      " Epoch [57/300], Batch Step [250/323], D_loss: 0.8308,  G_loss: 1.3658\n",
      " Epoch [57/300], Batch Step [260/323], D_loss: 0.7828,  G_loss: 1.4738\n",
      " Epoch [57/300], Batch Step [270/323], D_loss: 0.7232,  G_loss: 1.3408\n",
      " Epoch [57/300], Batch Step [280/323], D_loss: 0.7961,  G_loss: 1.3472\n",
      " Epoch [57/300], Batch Step [290/323], D_loss: 0.8023,  G_loss: 1.4945\n",
      " Epoch [57/300], Batch Step [300/323], D_loss: 0.7315,  G_loss: 1.3934\n",
      " Epoch [57/300], Batch Step [310/323], D_loss: 0.7709,  G_loss: 1.2779\n",
      " Epoch [57/300], Batch Step [320/323], D_loss: 0.8847,  G_loss: 1.4862\n",
      " Epoch [58/300], Batch Step [0/323], D_loss: 0.7704,  G_loss: 1.4638\n",
      " Epoch [58/300], Batch Step [10/323], D_loss: 0.8237,  G_loss: 1.4330\n",
      " Epoch [58/300], Batch Step [20/323], D_loss: 1.0752,  G_loss: 1.3546\n",
      " Epoch [58/300], Batch Step [30/323], D_loss: 0.8112,  G_loss: 1.2446\n",
      " Epoch [58/300], Batch Step [40/323], D_loss: 0.7381,  G_loss: 1.3719\n",
      " Epoch [58/300], Batch Step [50/323], D_loss: 0.7142,  G_loss: 1.4163\n",
      " Epoch [58/300], Batch Step [60/323], D_loss: 0.6383,  G_loss: 1.3026\n",
      " Epoch [58/300], Batch Step [70/323], D_loss: 0.7292,  G_loss: 1.4723\n",
      " Epoch [58/300], Batch Step [80/323], D_loss: 0.8068,  G_loss: 1.3497\n",
      " Epoch [58/300], Batch Step [90/323], D_loss: 1.0000,  G_loss: 1.4459\n",
      " Epoch [58/300], Batch Step [100/323], D_loss: 0.7389,  G_loss: 1.3466\n",
      " Epoch [58/300], Batch Step [110/323], D_loss: 0.8372,  G_loss: 1.3787\n",
      " Epoch [58/300], Batch Step [120/323], D_loss: 0.6268,  G_loss: 1.2329\n",
      " Epoch [58/300], Batch Step [130/323], D_loss: 0.7945,  G_loss: 1.4403\n",
      " Epoch [58/300], Batch Step [140/323], D_loss: 0.9475,  G_loss: 1.3573\n",
      " Epoch [58/300], Batch Step [150/323], D_loss: 0.7703,  G_loss: 1.4746\n",
      " Epoch [58/300], Batch Step [160/323], D_loss: 0.7669,  G_loss: 1.3678\n",
      " Epoch [58/300], Batch Step [170/323], D_loss: 0.6804,  G_loss: 1.3029\n",
      " Epoch [58/300], Batch Step [180/323], D_loss: 0.6462,  G_loss: 1.4036\n",
      " Epoch [58/300], Batch Step [190/323], D_loss: 0.7740,  G_loss: 1.2842\n",
      " Epoch [58/300], Batch Step [200/323], D_loss: 0.9143,  G_loss: 1.3631\n",
      " Epoch [58/300], Batch Step [210/323], D_loss: 0.6784,  G_loss: 1.2858\n",
      " Epoch [58/300], Batch Step [220/323], D_loss: 0.9664,  G_loss: 1.4541\n",
      " Epoch [58/300], Batch Step [230/323], D_loss: 0.7370,  G_loss: 1.3714\n",
      " Epoch [58/300], Batch Step [240/323], D_loss: 0.7984,  G_loss: 1.2251\n",
      " Epoch [58/300], Batch Step [250/323], D_loss: 0.6552,  G_loss: 1.5139\n",
      " Epoch [58/300], Batch Step [260/323], D_loss: 0.7242,  G_loss: 1.4151\n",
      " Epoch [58/300], Batch Step [270/323], D_loss: 0.7578,  G_loss: 1.2374\n",
      " Epoch [58/300], Batch Step [280/323], D_loss: 0.7667,  G_loss: 1.3777\n",
      " Epoch [58/300], Batch Step [290/323], D_loss: 0.7639,  G_loss: 1.2626\n",
      " Epoch [58/300], Batch Step [300/323], D_loss: 0.6738,  G_loss: 1.3321\n",
      " Epoch [58/300], Batch Step [310/323], D_loss: 0.6632,  G_loss: 1.3999\n",
      " Epoch [58/300], Batch Step [320/323], D_loss: 0.7195,  G_loss: 1.4638\n",
      " Epoch [59/300], Batch Step [0/323], D_loss: 0.7626,  G_loss: 1.3639\n",
      " Epoch [59/300], Batch Step [10/323], D_loss: 0.6838,  G_loss: 1.3169\n",
      " Epoch [59/300], Batch Step [20/323], D_loss: 0.8432,  G_loss: 1.3922\n",
      " Epoch [59/300], Batch Step [30/323], D_loss: 0.8163,  G_loss: 1.3457\n",
      " Epoch [59/300], Batch Step [40/323], D_loss: 0.6569,  G_loss: 1.5937\n",
      " Epoch [59/300], Batch Step [50/323], D_loss: 0.8620,  G_loss: 1.3645\n",
      " Epoch [59/300], Batch Step [60/323], D_loss: 0.7394,  G_loss: 1.3923\n",
      " Epoch [59/300], Batch Step [70/323], D_loss: 0.7442,  G_loss: 1.2460\n",
      " Epoch [59/300], Batch Step [80/323], D_loss: 0.8758,  G_loss: 1.2755\n",
      " Epoch [59/300], Batch Step [90/323], D_loss: 0.7135,  G_loss: 1.3244\n",
      " Epoch [59/300], Batch Step [100/323], D_loss: 0.8940,  G_loss: 1.4036\n",
      " Epoch [59/300], Batch Step [110/323], D_loss: 0.8244,  G_loss: 1.3271\n",
      " Epoch [59/300], Batch Step [120/323], D_loss: 0.8001,  G_loss: 1.3716\n",
      " Epoch [59/300], Batch Step [130/323], D_loss: 0.8402,  G_loss: 1.4521\n",
      " Epoch [59/300], Batch Step [140/323], D_loss: 0.7754,  G_loss: 1.2729\n",
      " Epoch [59/300], Batch Step [150/323], D_loss: 0.8117,  G_loss: 1.4399\n",
      " Epoch [59/300], Batch Step [160/323], D_loss: 0.9871,  G_loss: 1.3094\n",
      " Epoch [59/300], Batch Step [170/323], D_loss: 0.8140,  G_loss: 1.3828\n",
      " Epoch [59/300], Batch Step [180/323], D_loss: 0.7475,  G_loss: 1.5066\n",
      " Epoch [59/300], Batch Step [190/323], D_loss: 0.6779,  G_loss: 1.4856\n",
      " Epoch [59/300], Batch Step [200/323], D_loss: 0.7301,  G_loss: 1.3402\n",
      " Epoch [59/300], Batch Step [210/323], D_loss: 0.7671,  G_loss: 1.5268\n",
      " Epoch [59/300], Batch Step [220/323], D_loss: 0.7670,  G_loss: 1.2788\n",
      " Epoch [59/300], Batch Step [230/323], D_loss: 0.8555,  G_loss: 1.4281\n",
      " Epoch [59/300], Batch Step [240/323], D_loss: 0.8649,  G_loss: 1.2628\n",
      " Epoch [59/300], Batch Step [250/323], D_loss: 0.8491,  G_loss: 1.2856\n",
      " Epoch [59/300], Batch Step [260/323], D_loss: 0.8837,  G_loss: 1.3750\n",
      " Epoch [59/300], Batch Step [270/323], D_loss: 0.9605,  G_loss: 1.3962\n",
      " Epoch [59/300], Batch Step [280/323], D_loss: 0.7825,  G_loss: 1.4471\n",
      " Epoch [59/300], Batch Step [290/323], D_loss: 0.6693,  G_loss: 1.5519\n",
      " Epoch [59/300], Batch Step [300/323], D_loss: 0.7218,  G_loss: 1.3717\n",
      " Epoch [59/300], Batch Step [310/323], D_loss: 0.6276,  G_loss: 1.6063\n",
      " Epoch [59/300], Batch Step [320/323], D_loss: 0.9060,  G_loss: 1.4225\n",
      " Epoch [60/300], Batch Step [0/323], D_loss: 0.8991,  G_loss: 1.4030\n",
      " Epoch [60/300], Batch Step [10/323], D_loss: 0.9470,  G_loss: 1.3778\n",
      " Epoch [60/300], Batch Step [20/323], D_loss: 0.8305,  G_loss: 1.3122\n",
      " Epoch [60/300], Batch Step [30/323], D_loss: 0.7476,  G_loss: 1.5206\n",
      " Epoch [60/300], Batch Step [40/323], D_loss: 0.8114,  G_loss: 1.2520\n",
      " Epoch [60/300], Batch Step [50/323], D_loss: 0.9364,  G_loss: 1.3903\n",
      " Epoch [60/300], Batch Step [60/323], D_loss: 1.0253,  G_loss: 1.4364\n",
      " Epoch [60/300], Batch Step [70/323], D_loss: 0.7700,  G_loss: 1.3076\n",
      " Epoch [60/300], Batch Step [80/323], D_loss: 0.7170,  G_loss: 1.4767\n",
      " Epoch [60/300], Batch Step [90/323], D_loss: 0.8510,  G_loss: 1.4806\n",
      " Epoch [60/300], Batch Step [100/323], D_loss: 0.7492,  G_loss: 1.3828\n",
      " Epoch [60/300], Batch Step [110/323], D_loss: 0.6002,  G_loss: 1.2024\n",
      " Epoch [60/300], Batch Step [120/323], D_loss: 0.9049,  G_loss: 1.4768\n",
      " Epoch [60/300], Batch Step [130/323], D_loss: 0.8438,  G_loss: 1.3513\n",
      " Epoch [60/300], Batch Step [140/323], D_loss: 0.7862,  G_loss: 1.5148\n",
      " Epoch [60/300], Batch Step [150/323], D_loss: 0.6772,  G_loss: 1.3198\n",
      " Epoch [60/300], Batch Step [160/323], D_loss: 0.7525,  G_loss: 1.4797\n",
      " Epoch [60/300], Batch Step [170/323], D_loss: 0.7236,  G_loss: 1.2821\n",
      " Epoch [60/300], Batch Step [180/323], D_loss: 0.8055,  G_loss: 1.5129\n",
      " Epoch [60/300], Batch Step [190/323], D_loss: 0.7742,  G_loss: 1.4816\n",
      " Epoch [60/300], Batch Step [200/323], D_loss: 0.7883,  G_loss: 1.2920\n",
      " Epoch [60/300], Batch Step [210/323], D_loss: 0.8473,  G_loss: 1.3138\n",
      " Epoch [60/300], Batch Step [220/323], D_loss: 0.7758,  G_loss: 1.3431\n",
      " Epoch [60/300], Batch Step [230/323], D_loss: 0.6657,  G_loss: 1.4512\n",
      " Epoch [60/300], Batch Step [240/323], D_loss: 0.6373,  G_loss: 1.3332\n",
      " Epoch [60/300], Batch Step [250/323], D_loss: 0.9162,  G_loss: 1.4378\n",
      " Epoch [60/300], Batch Step [260/323], D_loss: 0.9973,  G_loss: 1.5286\n",
      " Epoch [60/300], Batch Step [270/323], D_loss: 0.7767,  G_loss: 1.4552\n",
      " Epoch [60/300], Batch Step [280/323], D_loss: 0.7720,  G_loss: 1.2813\n",
      " Epoch [60/300], Batch Step [290/323], D_loss: 0.7132,  G_loss: 1.3519\n",
      " Epoch [60/300], Batch Step [300/323], D_loss: 0.7723,  G_loss: 1.3225\n",
      " Epoch [60/300], Batch Step [310/323], D_loss: 0.7793,  G_loss: 1.2125\n",
      " Epoch [60/300], Batch Step [320/323], D_loss: 0.7231,  G_loss: 1.3707\n",
      " Epoch [61/300], Batch Step [0/323], D_loss: 0.7157,  G_loss: 1.4041\n",
      " Epoch [61/300], Batch Step [10/323], D_loss: 0.8833,  G_loss: 1.3038\n",
      " Epoch [61/300], Batch Step [20/323], D_loss: 0.7033,  G_loss: 1.4583\n",
      " Epoch [61/300], Batch Step [30/323], D_loss: 0.7245,  G_loss: 1.3555\n",
      " Epoch [61/300], Batch Step [40/323], D_loss: 0.7311,  G_loss: 1.4316\n",
      " Epoch [61/300], Batch Step [50/323], D_loss: 0.6068,  G_loss: 1.3335\n",
      " Epoch [61/300], Batch Step [60/323], D_loss: 0.8021,  G_loss: 1.5243\n",
      " Epoch [61/300], Batch Step [70/323], D_loss: 0.7298,  G_loss: 1.2185\n",
      " Epoch [61/300], Batch Step [80/323], D_loss: 0.6919,  G_loss: 1.4664\n",
      " Epoch [61/300], Batch Step [90/323], D_loss: 0.7220,  G_loss: 1.3360\n",
      " Epoch [61/300], Batch Step [100/323], D_loss: 0.7237,  G_loss: 1.3855\n",
      " Epoch [61/300], Batch Step [110/323], D_loss: 0.6801,  G_loss: 1.3667\n",
      " Epoch [61/300], Batch Step [120/323], D_loss: 0.7162,  G_loss: 1.4302\n",
      " Epoch [61/300], Batch Step [130/323], D_loss: 0.6055,  G_loss: 1.5347\n",
      " Epoch [61/300], Batch Step [140/323], D_loss: 0.7369,  G_loss: 1.4067\n",
      " Epoch [61/300], Batch Step [150/323], D_loss: 0.8186,  G_loss: 1.4479\n",
      " Epoch [61/300], Batch Step [160/323], D_loss: 0.7481,  G_loss: 1.3623\n",
      " Epoch [61/300], Batch Step [170/323], D_loss: 0.7363,  G_loss: 1.3103\n",
      " Epoch [61/300], Batch Step [180/323], D_loss: 0.8556,  G_loss: 1.4034\n",
      " Epoch [61/300], Batch Step [190/323], D_loss: 0.7257,  G_loss: 1.4747\n",
      " Epoch [61/300], Batch Step [200/323], D_loss: 0.7440,  G_loss: 1.4997\n",
      " Epoch [61/300], Batch Step [210/323], D_loss: 0.7216,  G_loss: 1.3937\n",
      " Epoch [61/300], Batch Step [220/323], D_loss: 0.6572,  G_loss: 1.5185\n",
      " Epoch [61/300], Batch Step [230/323], D_loss: 0.5934,  G_loss: 1.3629\n",
      " Epoch [61/300], Batch Step [240/323], D_loss: 0.7345,  G_loss: 1.4764\n",
      " Epoch [61/300], Batch Step [250/323], D_loss: 0.7580,  G_loss: 1.3946\n",
      " Epoch [61/300], Batch Step [260/323], D_loss: 0.7075,  G_loss: 1.2946\n",
      " Epoch [61/300], Batch Step [270/323], D_loss: 0.7584,  G_loss: 1.3575\n",
      " Epoch [61/300], Batch Step [280/323], D_loss: 0.8757,  G_loss: 1.2522\n",
      " Epoch [61/300], Batch Step [290/323], D_loss: 0.7580,  G_loss: 1.3664\n",
      " Epoch [61/300], Batch Step [300/323], D_loss: 0.6791,  G_loss: 1.4065\n",
      " Epoch [61/300], Batch Step [310/323], D_loss: 0.6714,  G_loss: 1.4130\n",
      " Epoch [61/300], Batch Step [320/323], D_loss: 0.7441,  G_loss: 1.4242\n",
      " Epoch [62/300], Batch Step [0/323], D_loss: 0.8291,  G_loss: 1.4035\n",
      " Epoch [62/300], Batch Step [10/323], D_loss: 0.6242,  G_loss: 1.5674\n",
      " Epoch [62/300], Batch Step [20/323], D_loss: 0.8656,  G_loss: 1.4322\n",
      " Epoch [62/300], Batch Step [30/323], D_loss: 0.7167,  G_loss: 1.4164\n",
      " Epoch [62/300], Batch Step [40/323], D_loss: 0.8695,  G_loss: 1.2928\n",
      " Epoch [62/300], Batch Step [50/323], D_loss: 0.7103,  G_loss: 1.4527\n",
      " Epoch [62/300], Batch Step [60/323], D_loss: 0.8207,  G_loss: 1.4105\n",
      " Epoch [62/300], Batch Step [70/323], D_loss: 0.7800,  G_loss: 1.3048\n",
      " Epoch [62/300], Batch Step [80/323], D_loss: 0.6738,  G_loss: 1.4743\n",
      " Epoch [62/300], Batch Step [90/323], D_loss: 0.6807,  G_loss: 1.5045\n",
      " Epoch [62/300], Batch Step [100/323], D_loss: 0.6295,  G_loss: 1.5554\n",
      " Epoch [62/300], Batch Step [110/323], D_loss: 0.8146,  G_loss: 1.2689\n",
      " Epoch [62/300], Batch Step [120/323], D_loss: 0.8658,  G_loss: 1.2552\n",
      " Epoch [62/300], Batch Step [130/323], D_loss: 0.7598,  G_loss: 1.4263\n",
      " Epoch [62/300], Batch Step [140/323], D_loss: 0.8500,  G_loss: 1.2415\n",
      " Epoch [62/300], Batch Step [150/323], D_loss: 0.6341,  G_loss: 1.4452\n",
      " Epoch [62/300], Batch Step [160/323], D_loss: 0.8353,  G_loss: 1.4922\n",
      " Epoch [62/300], Batch Step [170/323], D_loss: 0.6705,  G_loss: 1.3866\n",
      " Epoch [62/300], Batch Step [180/323], D_loss: 0.9741,  G_loss: 1.4039\n",
      " Epoch [62/300], Batch Step [190/323], D_loss: 0.8211,  G_loss: 1.5322\n",
      " Epoch [62/300], Batch Step [200/323], D_loss: 0.8438,  G_loss: 1.5924\n",
      " Epoch [62/300], Batch Step [210/323], D_loss: 0.7685,  G_loss: 1.4431\n",
      " Epoch [62/300], Batch Step [220/323], D_loss: 0.7757,  G_loss: 1.4541\n",
      " Epoch [62/300], Batch Step [230/323], D_loss: 0.6146,  G_loss: 1.3664\n",
      " Epoch [62/300], Batch Step [240/323], D_loss: 0.7200,  G_loss: 1.3794\n",
      " Epoch [62/300], Batch Step [250/323], D_loss: 0.7159,  G_loss: 1.3789\n",
      " Epoch [62/300], Batch Step [260/323], D_loss: 0.7872,  G_loss: 1.2846\n",
      " Epoch [62/300], Batch Step [270/323], D_loss: 0.8758,  G_loss: 1.3389\n",
      " Epoch [62/300], Batch Step [280/323], D_loss: 0.7914,  G_loss: 1.3886\n",
      " Epoch [62/300], Batch Step [290/323], D_loss: 0.8223,  G_loss: 1.4297\n",
      " Epoch [62/300], Batch Step [300/323], D_loss: 0.7982,  G_loss: 1.4429\n",
      " Epoch [62/300], Batch Step [310/323], D_loss: 0.5837,  G_loss: 1.4048\n",
      " Epoch [62/300], Batch Step [320/323], D_loss: 0.7734,  G_loss: 1.3078\n",
      " Epoch [63/300], Batch Step [0/323], D_loss: 0.7310,  G_loss: 1.2384\n",
      " Epoch [63/300], Batch Step [10/323], D_loss: 0.8366,  G_loss: 1.4887\n",
      " Epoch [63/300], Batch Step [20/323], D_loss: 0.7942,  G_loss: 1.1938\n",
      " Epoch [63/300], Batch Step [30/323], D_loss: 0.6788,  G_loss: 1.5501\n",
      " Epoch [63/300], Batch Step [40/323], D_loss: 0.6230,  G_loss: 1.4064\n",
      " Epoch [63/300], Batch Step [50/323], D_loss: 0.6547,  G_loss: 1.5025\n",
      " Epoch [63/300], Batch Step [60/323], D_loss: 0.7666,  G_loss: 1.5529\n",
      " Epoch [63/300], Batch Step [70/323], D_loss: 0.7029,  G_loss: 1.3400\n",
      " Epoch [63/300], Batch Step [80/323], D_loss: 0.8582,  G_loss: 1.4830\n",
      " Epoch [63/300], Batch Step [90/323], D_loss: 0.7681,  G_loss: 1.3160\n",
      " Epoch [63/300], Batch Step [100/323], D_loss: 0.6940,  G_loss: 1.4578\n",
      " Epoch [63/300], Batch Step [110/323], D_loss: 0.8008,  G_loss: 1.3972\n",
      " Epoch [63/300], Batch Step [120/323], D_loss: 0.9175,  G_loss: 1.4390\n",
      " Epoch [63/300], Batch Step [130/323], D_loss: 0.6964,  G_loss: 1.4236\n",
      " Epoch [63/300], Batch Step [140/323], D_loss: 0.7244,  G_loss: 1.3470\n",
      " Epoch [63/300], Batch Step [150/323], D_loss: 0.8580,  G_loss: 1.4125\n",
      " Epoch [63/300], Batch Step [160/323], D_loss: 0.7883,  G_loss: 1.4715\n",
      " Epoch [63/300], Batch Step [170/323], D_loss: 0.6816,  G_loss: 1.3056\n",
      " Epoch [63/300], Batch Step [180/323], D_loss: 0.7314,  G_loss: 1.3857\n",
      " Epoch [63/300], Batch Step [190/323], D_loss: 0.7570,  G_loss: 1.4324\n",
      " Epoch [63/300], Batch Step [200/323], D_loss: 0.7672,  G_loss: 1.4487\n",
      " Epoch [63/300], Batch Step [210/323], D_loss: 0.7514,  G_loss: 1.3773\n",
      " Epoch [63/300], Batch Step [220/323], D_loss: 0.8097,  G_loss: 1.3717\n",
      " Epoch [63/300], Batch Step [230/323], D_loss: 0.7000,  G_loss: 1.3799\n",
      " Epoch [63/300], Batch Step [240/323], D_loss: 0.7280,  G_loss: 1.3520\n",
      " Epoch [63/300], Batch Step [250/323], D_loss: 0.7723,  G_loss: 1.4573\n",
      " Epoch [63/300], Batch Step [260/323], D_loss: 0.8060,  G_loss: 1.4030\n",
      " Epoch [63/300], Batch Step [270/323], D_loss: 0.7743,  G_loss: 1.4874\n",
      " Epoch [63/300], Batch Step [280/323], D_loss: 0.8162,  G_loss: 1.4131\n",
      " Epoch [63/300], Batch Step [290/323], D_loss: 0.7033,  G_loss: 1.4551\n",
      " Epoch [63/300], Batch Step [300/323], D_loss: 0.8529,  G_loss: 1.4081\n",
      " Epoch [63/300], Batch Step [310/323], D_loss: 0.7342,  G_loss: 1.3858\n",
      " Epoch [63/300], Batch Step [320/323], D_loss: 0.6484,  G_loss: 1.3290\n",
      " Epoch [64/300], Batch Step [0/323], D_loss: 0.6562,  G_loss: 1.3740\n",
      " Epoch [64/300], Batch Step [10/323], D_loss: 0.5145,  G_loss: 1.3966\n",
      " Epoch [64/300], Batch Step [20/323], D_loss: 0.7867,  G_loss: 1.4106\n",
      " Epoch [64/300], Batch Step [30/323], D_loss: 0.7427,  G_loss: 1.3975\n",
      " Epoch [64/300], Batch Step [40/323], D_loss: 0.7866,  G_loss: 1.4580\n",
      " Epoch [64/300], Batch Step [50/323], D_loss: 0.7633,  G_loss: 1.3417\n",
      " Epoch [64/300], Batch Step [60/323], D_loss: 0.7426,  G_loss: 1.4472\n",
      " Epoch [64/300], Batch Step [70/323], D_loss: 0.7876,  G_loss: 1.3230\n",
      " Epoch [64/300], Batch Step [80/323], D_loss: 0.7609,  G_loss: 1.3197\n",
      " Epoch [64/300], Batch Step [90/323], D_loss: 0.7031,  G_loss: 1.3483\n",
      " Epoch [64/300], Batch Step [100/323], D_loss: 0.6186,  G_loss: 1.5819\n",
      " Epoch [64/300], Batch Step [110/323], D_loss: 0.6761,  G_loss: 1.3212\n",
      " Epoch [64/300], Batch Step [120/323], D_loss: 0.9273,  G_loss: 1.4235\n",
      " Epoch [64/300], Batch Step [130/323], D_loss: 0.7486,  G_loss: 1.3419\n",
      " Epoch [64/300], Batch Step [140/323], D_loss: 0.8023,  G_loss: 1.4241\n",
      " Epoch [64/300], Batch Step [150/323], D_loss: 0.6983,  G_loss: 1.3170\n",
      " Epoch [64/300], Batch Step [160/323], D_loss: 0.7534,  G_loss: 1.4039\n",
      " Epoch [64/300], Batch Step [170/323], D_loss: 0.7945,  G_loss: 1.3713\n",
      " Epoch [64/300], Batch Step [180/323], D_loss: 0.8359,  G_loss: 1.4227\n",
      " Epoch [64/300], Batch Step [190/323], D_loss: 0.8687,  G_loss: 1.4156\n",
      " Epoch [64/300], Batch Step [200/323], D_loss: 0.7812,  G_loss: 1.4411\n",
      " Epoch [64/300], Batch Step [210/323], D_loss: 0.7723,  G_loss: 1.3341\n",
      " Epoch [64/300], Batch Step [220/323], D_loss: 0.7111,  G_loss: 1.4297\n",
      " Epoch [64/300], Batch Step [230/323], D_loss: 0.6436,  G_loss: 1.4536\n",
      " Epoch [64/300], Batch Step [240/323], D_loss: 0.7254,  G_loss: 1.3586\n",
      " Epoch [64/300], Batch Step [250/323], D_loss: 0.7730,  G_loss: 1.4510\n",
      " Epoch [64/300], Batch Step [260/323], D_loss: 0.7732,  G_loss: 1.5034\n",
      " Epoch [64/300], Batch Step [270/323], D_loss: 0.6964,  G_loss: 1.3644\n",
      " Epoch [64/300], Batch Step [280/323], D_loss: 0.7556,  G_loss: 1.3948\n",
      " Epoch [64/300], Batch Step [290/323], D_loss: 0.6499,  G_loss: 1.4452\n",
      " Epoch [64/300], Batch Step [300/323], D_loss: 0.6676,  G_loss: 1.4667\n",
      " Epoch [64/300], Batch Step [310/323], D_loss: 0.7179,  G_loss: 1.3228\n",
      " Epoch [64/300], Batch Step [320/323], D_loss: 0.6767,  G_loss: 1.5469\n",
      " Epoch [65/300], Batch Step [0/323], D_loss: 0.6326,  G_loss: 1.4676\n",
      " Epoch [65/300], Batch Step [10/323], D_loss: 0.8296,  G_loss: 1.4122\n",
      " Epoch [65/300], Batch Step [20/323], D_loss: 0.7184,  G_loss: 1.4000\n",
      " Epoch [65/300], Batch Step [30/323], D_loss: 0.7497,  G_loss: 1.4386\n",
      " Epoch [65/300], Batch Step [40/323], D_loss: 0.9076,  G_loss: 1.3285\n",
      " Epoch [65/300], Batch Step [50/323], D_loss: 0.7586,  G_loss: 1.4878\n",
      " Epoch [65/300], Batch Step [60/323], D_loss: 0.6992,  G_loss: 1.5325\n",
      " Epoch [65/300], Batch Step [70/323], D_loss: 0.6803,  G_loss: 1.4164\n",
      " Epoch [65/300], Batch Step [80/323], D_loss: 0.7835,  G_loss: 1.4844\n",
      " Epoch [65/300], Batch Step [90/323], D_loss: 0.6937,  G_loss: 1.4273\n",
      " Epoch [65/300], Batch Step [100/323], D_loss: 0.7140,  G_loss: 1.3724\n",
      " Epoch [65/300], Batch Step [110/323], D_loss: 0.7797,  G_loss: 1.4552\n",
      " Epoch [65/300], Batch Step [120/323], D_loss: 0.8299,  G_loss: 1.2782\n",
      " Epoch [65/300], Batch Step [130/323], D_loss: 0.7640,  G_loss: 1.3362\n",
      " Epoch [65/300], Batch Step [140/323], D_loss: 0.6405,  G_loss: 1.4561\n",
      " Epoch [65/300], Batch Step [150/323], D_loss: 0.7815,  G_loss: 1.5442\n",
      " Epoch [65/300], Batch Step [160/323], D_loss: 0.6398,  G_loss: 1.4145\n",
      " Epoch [65/300], Batch Step [170/323], D_loss: 0.7296,  G_loss: 1.5606\n",
      " Epoch [65/300], Batch Step [180/323], D_loss: 0.7041,  G_loss: 1.3841\n",
      " Epoch [65/300], Batch Step [190/323], D_loss: 0.7109,  G_loss: 1.5281\n",
      " Epoch [65/300], Batch Step [200/323], D_loss: 0.7700,  G_loss: 1.3147\n",
      " Epoch [65/300], Batch Step [210/323], D_loss: 0.7696,  G_loss: 1.4388\n",
      " Epoch [65/300], Batch Step [220/323], D_loss: 0.7587,  G_loss: 1.4823\n",
      " Epoch [65/300], Batch Step [230/323], D_loss: 0.7837,  G_loss: 1.5082\n",
      " Epoch [65/300], Batch Step [240/323], D_loss: 0.6743,  G_loss: 1.5182\n",
      " Epoch [65/300], Batch Step [250/323], D_loss: 0.7491,  G_loss: 1.4449\n",
      " Epoch [65/300], Batch Step [260/323], D_loss: 0.8118,  G_loss: 1.3736\n",
      " Epoch [65/300], Batch Step [270/323], D_loss: 0.7453,  G_loss: 1.3752\n",
      " Epoch [65/300], Batch Step [280/323], D_loss: 0.7698,  G_loss: 1.4680\n",
      " Epoch [65/300], Batch Step [290/323], D_loss: 0.7310,  G_loss: 1.3736\n",
      " Epoch [65/300], Batch Step [300/323], D_loss: 0.7342,  G_loss: 1.4345\n",
      " Epoch [65/300], Batch Step [310/323], D_loss: 0.7791,  G_loss: 1.4689\n",
      " Epoch [65/300], Batch Step [320/323], D_loss: 0.9287,  G_loss: 1.4409\n",
      " Epoch [66/300], Batch Step [0/323], D_loss: 0.7326,  G_loss: 1.4057\n",
      " Epoch [66/300], Batch Step [10/323], D_loss: 0.8592,  G_loss: 1.5611\n",
      " Epoch [66/300], Batch Step [20/323], D_loss: 0.7392,  G_loss: 1.4815\n",
      " Epoch [66/300], Batch Step [30/323], D_loss: 0.7623,  G_loss: 1.3348\n",
      " Epoch [66/300], Batch Step [40/323], D_loss: 0.7817,  G_loss: 1.4556\n",
      " Epoch [66/300], Batch Step [50/323], D_loss: 0.7398,  G_loss: 1.5134\n",
      " Epoch [66/300], Batch Step [60/323], D_loss: 0.8848,  G_loss: 1.3588\n",
      " Epoch [66/300], Batch Step [70/323], D_loss: 0.7318,  G_loss: 1.3876\n",
      " Epoch [66/300], Batch Step [80/323], D_loss: 0.8493,  G_loss: 1.3945\n",
      " Epoch [66/300], Batch Step [90/323], D_loss: 0.7253,  G_loss: 1.4526\n",
      " Epoch [66/300], Batch Step [100/323], D_loss: 0.6741,  G_loss: 1.6407\n",
      " Epoch [66/300], Batch Step [110/323], D_loss: 0.5975,  G_loss: 1.4892\n",
      " Epoch [66/300], Batch Step [120/323], D_loss: 0.7168,  G_loss: 1.5536\n",
      " Epoch [66/300], Batch Step [130/323], D_loss: 0.7267,  G_loss: 1.4962\n",
      " Epoch [66/300], Batch Step [140/323], D_loss: 0.7469,  G_loss: 1.3019\n",
      " Epoch [66/300], Batch Step [150/323], D_loss: 0.8389,  G_loss: 1.5517\n",
      " Epoch [66/300], Batch Step [160/323], D_loss: 0.8088,  G_loss: 1.4572\n",
      " Epoch [66/300], Batch Step [170/323], D_loss: 0.8238,  G_loss: 1.4215\n",
      " Epoch [66/300], Batch Step [180/323], D_loss: 0.8108,  G_loss: 1.5901\n",
      " Epoch [66/300], Batch Step [190/323], D_loss: 0.6656,  G_loss: 1.5578\n",
      " Epoch [66/300], Batch Step [200/323], D_loss: 0.6849,  G_loss: 1.4455\n",
      " Epoch [66/300], Batch Step [210/323], D_loss: 0.7105,  G_loss: 1.3780\n",
      " Epoch [66/300], Batch Step [220/323], D_loss: 0.7083,  G_loss: 1.4458\n",
      " Epoch [66/300], Batch Step [230/323], D_loss: 0.7978,  G_loss: 1.4425\n",
      " Epoch [66/300], Batch Step [240/323], D_loss: 0.9617,  G_loss: 1.4415\n",
      " Epoch [66/300], Batch Step [250/323], D_loss: 0.6623,  G_loss: 1.4779\n",
      " Epoch [66/300], Batch Step [260/323], D_loss: 0.7772,  G_loss: 1.3518\n",
      " Epoch [66/300], Batch Step [270/323], D_loss: 0.7586,  G_loss: 1.3323\n",
      " Epoch [66/300], Batch Step [280/323], D_loss: 0.6947,  G_loss: 1.4723\n",
      " Epoch [66/300], Batch Step [290/323], D_loss: 0.6545,  G_loss: 1.3805\n",
      " Epoch [66/300], Batch Step [300/323], D_loss: 0.6321,  G_loss: 1.5650\n",
      " Epoch [66/300], Batch Step [310/323], D_loss: 0.6234,  G_loss: 1.3814\n",
      " Epoch [66/300], Batch Step [320/323], D_loss: 0.7490,  G_loss: 1.5126\n",
      " Epoch [67/300], Batch Step [0/323], D_loss: 0.6897,  G_loss: 1.4738\n",
      " Epoch [67/300], Batch Step [10/323], D_loss: 0.6773,  G_loss: 1.3752\n",
      " Epoch [67/300], Batch Step [20/323], D_loss: 0.6601,  G_loss: 1.4462\n",
      " Epoch [67/300], Batch Step [30/323], D_loss: 0.8495,  G_loss: 1.3381\n",
      " Epoch [67/300], Batch Step [40/323], D_loss: 0.6825,  G_loss: 1.5049\n",
      " Epoch [67/300], Batch Step [50/323], D_loss: 0.6919,  G_loss: 1.4496\n",
      " Epoch [67/300], Batch Step [60/323], D_loss: 0.6956,  G_loss: 1.3825\n",
      " Epoch [67/300], Batch Step [70/323], D_loss: 0.5969,  G_loss: 1.5339\n",
      " Epoch [67/300], Batch Step [80/323], D_loss: 0.7212,  G_loss: 1.4449\n",
      " Epoch [67/300], Batch Step [90/323], D_loss: 0.6540,  G_loss: 1.4628\n",
      " Epoch [67/300], Batch Step [100/323], D_loss: 0.6024,  G_loss: 1.4268\n",
      " Epoch [67/300], Batch Step [110/323], D_loss: 0.8003,  G_loss: 1.4174\n",
      " Epoch [67/300], Batch Step [120/323], D_loss: 0.7274,  G_loss: 1.4034\n",
      " Epoch [67/300], Batch Step [130/323], D_loss: 0.7086,  G_loss: 1.3389\n",
      " Epoch [67/300], Batch Step [140/323], D_loss: 0.7606,  G_loss: 1.4519\n",
      " Epoch [67/300], Batch Step [150/323], D_loss: 0.7395,  G_loss: 1.4089\n",
      " Epoch [67/300], Batch Step [160/323], D_loss: 0.6252,  G_loss: 1.4346\n",
      " Epoch [67/300], Batch Step [170/323], D_loss: 0.6563,  G_loss: 1.3968\n",
      " Epoch [67/300], Batch Step [180/323], D_loss: 0.7948,  G_loss: 1.4571\n",
      " Epoch [67/300], Batch Step [190/323], D_loss: 0.6455,  G_loss: 1.3657\n",
      " Epoch [67/300], Batch Step [200/323], D_loss: 0.7235,  G_loss: 1.3696\n",
      " Epoch [67/300], Batch Step [210/323], D_loss: 0.7795,  G_loss: 1.4129\n",
      " Epoch [67/300], Batch Step [220/323], D_loss: 0.5904,  G_loss: 1.3688\n",
      " Epoch [67/300], Batch Step [230/323], D_loss: 0.8100,  G_loss: 1.4102\n",
      " Epoch [67/300], Batch Step [240/323], D_loss: 0.6902,  G_loss: 1.3766\n",
      " Epoch [67/300], Batch Step [250/323], D_loss: 0.8221,  G_loss: 1.3508\n",
      " Epoch [67/300], Batch Step [260/323], D_loss: 0.8019,  G_loss: 1.4480\n",
      " Epoch [67/300], Batch Step [270/323], D_loss: 0.6459,  G_loss: 1.4492\n",
      " Epoch [67/300], Batch Step [280/323], D_loss: 0.6345,  G_loss: 1.4286\n",
      " Epoch [67/300], Batch Step [290/323], D_loss: 0.7119,  G_loss: 1.4304\n",
      " Epoch [67/300], Batch Step [300/323], D_loss: 0.7061,  G_loss: 1.4515\n",
      " Epoch [67/300], Batch Step [310/323], D_loss: 0.7453,  G_loss: 1.4249\n",
      " Epoch [67/300], Batch Step [320/323], D_loss: 0.7242,  G_loss: 1.4432\n",
      " Epoch [68/300], Batch Step [0/323], D_loss: 0.6847,  G_loss: 1.5114\n",
      " Epoch [68/300], Batch Step [10/323], D_loss: 0.7823,  G_loss: 1.4243\n",
      " Epoch [68/300], Batch Step [20/323], D_loss: 0.6757,  G_loss: 1.3831\n",
      " Epoch [68/300], Batch Step [30/323], D_loss: 0.7702,  G_loss: 1.4086\n",
      " Epoch [68/300], Batch Step [40/323], D_loss: 0.7192,  G_loss: 1.4957\n",
      " Epoch [68/300], Batch Step [50/323], D_loss: 0.9160,  G_loss: 1.5278\n",
      " Epoch [68/300], Batch Step [60/323], D_loss: 0.6427,  G_loss: 1.4654\n",
      " Epoch [68/300], Batch Step [70/323], D_loss: 0.7927,  G_loss: 1.3255\n",
      " Epoch [68/300], Batch Step [80/323], D_loss: 0.7419,  G_loss: 1.4893\n",
      " Epoch [68/300], Batch Step [90/323], D_loss: 0.7587,  G_loss: 1.4827\n",
      " Epoch [68/300], Batch Step [100/323], D_loss: 0.7903,  G_loss: 1.4158\n",
      " Epoch [68/300], Batch Step [110/323], D_loss: 0.7037,  G_loss: 1.4317\n",
      " Epoch [68/300], Batch Step [120/323], D_loss: 0.6575,  G_loss: 1.4323\n",
      " Epoch [68/300], Batch Step [130/323], D_loss: 0.6248,  G_loss: 1.4971\n",
      " Epoch [68/300], Batch Step [140/323], D_loss: 0.8382,  G_loss: 1.5015\n",
      " Epoch [68/300], Batch Step [150/323], D_loss: 0.7663,  G_loss: 1.2635\n",
      " Epoch [68/300], Batch Step [160/323], D_loss: 0.7831,  G_loss: 1.4682\n",
      " Epoch [68/300], Batch Step [170/323], D_loss: 0.8026,  G_loss: 1.2888\n",
      " Epoch [68/300], Batch Step [180/323], D_loss: 0.8372,  G_loss: 1.5216\n",
      " Epoch [68/300], Batch Step [190/323], D_loss: 0.7990,  G_loss: 1.3877\n",
      " Epoch [68/300], Batch Step [200/323], D_loss: 0.7046,  G_loss: 1.3979\n",
      " Epoch [68/300], Batch Step [210/323], D_loss: 0.6702,  G_loss: 1.3383\n",
      " Epoch [68/300], Batch Step [220/323], D_loss: 0.5712,  G_loss: 1.4031\n",
      " Epoch [68/300], Batch Step [230/323], D_loss: 0.8320,  G_loss: 1.4246\n",
      " Epoch [68/300], Batch Step [240/323], D_loss: 0.6168,  G_loss: 1.3357\n",
      " Epoch [68/300], Batch Step [250/323], D_loss: 0.7185,  G_loss: 1.4975\n",
      " Epoch [68/300], Batch Step [260/323], D_loss: 0.8115,  G_loss: 1.3010\n",
      " Epoch [68/300], Batch Step [270/323], D_loss: 0.7768,  G_loss: 1.5532\n",
      " Epoch [68/300], Batch Step [280/323], D_loss: 0.6746,  G_loss: 1.3062\n",
      " Epoch [68/300], Batch Step [290/323], D_loss: 0.7057,  G_loss: 1.5482\n",
      " Epoch [68/300], Batch Step [300/323], D_loss: 0.7455,  G_loss: 1.3932\n",
      " Epoch [68/300], Batch Step [310/323], D_loss: 0.6597,  G_loss: 1.4449\n",
      " Epoch [68/300], Batch Step [320/323], D_loss: 0.6843,  G_loss: 1.4674\n",
      " Epoch [69/300], Batch Step [0/323], D_loss: 0.8493,  G_loss: 1.3845\n",
      " Epoch [69/300], Batch Step [10/323], D_loss: 0.8680,  G_loss: 1.2726\n",
      " Epoch [69/300], Batch Step [20/323], D_loss: 0.6681,  G_loss: 1.4893\n",
      " Epoch [69/300], Batch Step [30/323], D_loss: 0.6643,  G_loss: 1.4543\n",
      " Epoch [69/300], Batch Step [40/323], D_loss: 0.7547,  G_loss: 1.3806\n",
      " Epoch [69/300], Batch Step [50/323], D_loss: 0.7068,  G_loss: 1.5346\n",
      " Epoch [69/300], Batch Step [60/323], D_loss: 0.6612,  G_loss: 1.3661\n",
      " Epoch [69/300], Batch Step [70/323], D_loss: 0.6739,  G_loss: 1.5328\n",
      " Epoch [69/300], Batch Step [80/323], D_loss: 0.8487,  G_loss: 1.5466\n",
      " Epoch [69/300], Batch Step [90/323], D_loss: 0.6821,  G_loss: 1.3850\n",
      " Epoch [69/300], Batch Step [100/323], D_loss: 0.7669,  G_loss: 1.3882\n",
      " Epoch [69/300], Batch Step [110/323], D_loss: 0.5718,  G_loss: 1.5561\n",
      " Epoch [69/300], Batch Step [120/323], D_loss: 0.6546,  G_loss: 1.3520\n",
      " Epoch [69/300], Batch Step [130/323], D_loss: 0.7412,  G_loss: 1.4340\n",
      " Epoch [69/300], Batch Step [140/323], D_loss: 0.7569,  G_loss: 1.4894\n",
      " Epoch [69/300], Batch Step [150/323], D_loss: 0.7529,  G_loss: 1.4132\n",
      " Epoch [69/300], Batch Step [160/323], D_loss: 0.8126,  G_loss: 1.5232\n",
      " Epoch [69/300], Batch Step [170/323], D_loss: 0.8457,  G_loss: 1.4030\n",
      " Epoch [69/300], Batch Step [180/323], D_loss: 0.6977,  G_loss: 1.5294\n",
      " Epoch [69/300], Batch Step [190/323], D_loss: 0.8339,  G_loss: 1.3858\n",
      " Epoch [69/300], Batch Step [200/323], D_loss: 0.7433,  G_loss: 1.3390\n",
      " Epoch [69/300], Batch Step [210/323], D_loss: 0.7904,  G_loss: 1.4970\n",
      " Epoch [69/300], Batch Step [220/323], D_loss: 0.8841,  G_loss: 1.3552\n",
      " Epoch [69/300], Batch Step [230/323], D_loss: 0.7416,  G_loss: 1.5517\n",
      " Epoch [69/300], Batch Step [240/323], D_loss: 0.7939,  G_loss: 1.4595\n",
      " Epoch [69/300], Batch Step [250/323], D_loss: 0.8406,  G_loss: 1.4625\n",
      " Epoch [69/300], Batch Step [260/323], D_loss: 0.6506,  G_loss: 1.4020\n",
      " Epoch [69/300], Batch Step [270/323], D_loss: 0.6046,  G_loss: 1.4292\n",
      " Epoch [69/300], Batch Step [280/323], D_loss: 0.8427,  G_loss: 1.3192\n",
      " Epoch [69/300], Batch Step [290/323], D_loss: 0.8127,  G_loss: 1.4536\n",
      " Epoch [69/300], Batch Step [300/323], D_loss: 0.7503,  G_loss: 1.5486\n",
      " Epoch [69/300], Batch Step [310/323], D_loss: 0.6192,  G_loss: 1.6218\n",
      " Epoch [69/300], Batch Step [320/323], D_loss: 0.6531,  G_loss: 1.4035\n",
      " Epoch [70/300], Batch Step [0/323], D_loss: 0.7674,  G_loss: 1.3250\n",
      " Epoch [70/300], Batch Step [10/323], D_loss: 0.7902,  G_loss: 1.4312\n",
      " Epoch [70/300], Batch Step [20/323], D_loss: 0.7735,  G_loss: 1.4535\n",
      " Epoch [70/300], Batch Step [30/323], D_loss: 0.6883,  G_loss: 1.4278\n",
      " Epoch [70/300], Batch Step [40/323], D_loss: 0.7499,  G_loss: 1.4193\n",
      " Epoch [70/300], Batch Step [50/323], D_loss: 0.7474,  G_loss: 1.5875\n",
      " Epoch [70/300], Batch Step [60/323], D_loss: 0.6169,  G_loss: 1.2504\n",
      " Epoch [70/300], Batch Step [70/323], D_loss: 0.7507,  G_loss: 1.5039\n",
      " Epoch [70/300], Batch Step [80/323], D_loss: 0.7803,  G_loss: 1.2967\n",
      " Epoch [70/300], Batch Step [90/323], D_loss: 0.7642,  G_loss: 1.5093\n",
      " Epoch [70/300], Batch Step [100/323], D_loss: 0.7066,  G_loss: 1.5726\n",
      " Epoch [70/300], Batch Step [110/323], D_loss: 0.7467,  G_loss: 1.4676\n",
      " Epoch [70/300], Batch Step [120/323], D_loss: 0.7209,  G_loss: 1.3612\n",
      " Epoch [70/300], Batch Step [130/323], D_loss: 0.7349,  G_loss: 1.4343\n",
      " Epoch [70/300], Batch Step [140/323], D_loss: 0.6393,  G_loss: 1.3792\n",
      " Epoch [70/300], Batch Step [150/323], D_loss: 0.7471,  G_loss: 1.4694\n",
      " Epoch [70/300], Batch Step [160/323], D_loss: 0.7378,  G_loss: 1.3643\n",
      " Epoch [70/300], Batch Step [170/323], D_loss: 0.6280,  G_loss: 1.7367\n",
      " Epoch [70/300], Batch Step [180/323], D_loss: 0.7031,  G_loss: 1.4311\n",
      " Epoch [70/300], Batch Step [190/323], D_loss: 0.7411,  G_loss: 1.4679\n",
      " Epoch [70/300], Batch Step [200/323], D_loss: 0.6436,  G_loss: 1.5391\n",
      " Epoch [70/300], Batch Step [210/323], D_loss: 0.6839,  G_loss: 1.3493\n",
      " Epoch [70/300], Batch Step [220/323], D_loss: 0.7110,  G_loss: 1.3726\n",
      " Epoch [70/300], Batch Step [230/323], D_loss: 0.6716,  G_loss: 1.3335\n",
      " Epoch [70/300], Batch Step [240/323], D_loss: 0.5435,  G_loss: 1.3645\n",
      " Epoch [70/300], Batch Step [250/323], D_loss: 0.6225,  G_loss: 1.4418\n",
      " Epoch [70/300], Batch Step [260/323], D_loss: 0.6947,  G_loss: 1.4605\n",
      " Epoch [70/300], Batch Step [270/323], D_loss: 0.8208,  G_loss: 1.3252\n",
      " Epoch [70/300], Batch Step [280/323], D_loss: 0.7892,  G_loss: 1.4309\n",
      " Epoch [70/300], Batch Step [290/323], D_loss: 0.7789,  G_loss: 1.3519\n",
      " Epoch [70/300], Batch Step [300/323], D_loss: 0.7583,  G_loss: 1.4744\n",
      " Epoch [70/300], Batch Step [310/323], D_loss: 0.6934,  G_loss: 1.4426\n",
      " Epoch [70/300], Batch Step [320/323], D_loss: 0.6301,  G_loss: 1.4074\n",
      " Epoch [71/300], Batch Step [0/323], D_loss: 0.7660,  G_loss: 1.3814\n",
      " Epoch [71/300], Batch Step [10/323], D_loss: 0.7124,  G_loss: 1.3558\n",
      " Epoch [71/300], Batch Step [20/323], D_loss: 0.9605,  G_loss: 1.5196\n",
      " Epoch [71/300], Batch Step [30/323], D_loss: 0.7261,  G_loss: 1.2435\n",
      " Epoch [71/300], Batch Step [40/323], D_loss: 0.7407,  G_loss: 1.6338\n",
      " Epoch [71/300], Batch Step [50/323], D_loss: 0.7035,  G_loss: 1.3789\n",
      " Epoch [71/300], Batch Step [60/323], D_loss: 0.7285,  G_loss: 1.5299\n",
      " Epoch [71/300], Batch Step [70/323], D_loss: 0.7068,  G_loss: 1.4428\n",
      " Epoch [71/300], Batch Step [80/323], D_loss: 0.8399,  G_loss: 1.4630\n",
      " Epoch [71/300], Batch Step [90/323], D_loss: 0.8656,  G_loss: 1.5664\n",
      " Epoch [71/300], Batch Step [100/323], D_loss: 0.8380,  G_loss: 1.3671\n",
      " Epoch [71/300], Batch Step [110/323], D_loss: 0.6939,  G_loss: 1.4772\n",
      " Epoch [71/300], Batch Step [120/323], D_loss: 0.7845,  G_loss: 1.5327\n",
      " Epoch [71/300], Batch Step [130/323], D_loss: 0.5641,  G_loss: 1.4367\n",
      " Epoch [71/300], Batch Step [140/323], D_loss: 0.6513,  G_loss: 1.4455\n",
      " Epoch [71/300], Batch Step [150/323], D_loss: 0.7603,  G_loss: 1.5365\n",
      " Epoch [71/300], Batch Step [160/323], D_loss: 0.7486,  G_loss: 1.4087\n",
      " Epoch [71/300], Batch Step [170/323], D_loss: 0.7412,  G_loss: 1.4245\n",
      " Epoch [71/300], Batch Step [180/323], D_loss: 0.6377,  G_loss: 1.4750\n",
      " Epoch [71/300], Batch Step [190/323], D_loss: 0.6981,  G_loss: 1.5367\n",
      " Epoch [71/300], Batch Step [200/323], D_loss: 0.7169,  G_loss: 1.3768\n",
      " Epoch [71/300], Batch Step [210/323], D_loss: 0.7242,  G_loss: 1.5616\n",
      " Epoch [71/300], Batch Step [220/323], D_loss: 0.8475,  G_loss: 1.3948\n",
      " Epoch [71/300], Batch Step [230/323], D_loss: 0.7053,  G_loss: 1.4984\n",
      " Epoch [71/300], Batch Step [240/323], D_loss: 0.6221,  G_loss: 1.5376\n",
      " Epoch [71/300], Batch Step [250/323], D_loss: 0.5459,  G_loss: 1.6463\n",
      " Epoch [71/300], Batch Step [260/323], D_loss: 0.7615,  G_loss: 1.4431\n",
      " Epoch [71/300], Batch Step [270/323], D_loss: 0.7435,  G_loss: 1.5219\n",
      " Epoch [71/300], Batch Step [280/323], D_loss: 0.6550,  G_loss: 1.5270\n",
      " Epoch [71/300], Batch Step [290/323], D_loss: 0.7545,  G_loss: 1.2030\n",
      " Epoch [71/300], Batch Step [300/323], D_loss: 0.6177,  G_loss: 1.5211\n",
      " Epoch [71/300], Batch Step [310/323], D_loss: 0.7025,  G_loss: 1.4487\n",
      " Epoch [71/300], Batch Step [320/323], D_loss: 0.7225,  G_loss: 1.4759\n",
      " Epoch [72/300], Batch Step [0/323], D_loss: 0.7898,  G_loss: 1.5666\n",
      " Epoch [72/300], Batch Step [10/323], D_loss: 0.6874,  G_loss: 1.4685\n",
      " Epoch [72/300], Batch Step [20/323], D_loss: 0.7081,  G_loss: 1.5162\n",
      " Epoch [72/300], Batch Step [30/323], D_loss: 0.6778,  G_loss: 1.5030\n",
      " Epoch [72/300], Batch Step [40/323], D_loss: 0.6760,  G_loss: 1.6076\n",
      " Epoch [72/300], Batch Step [50/323], D_loss: 0.7370,  G_loss: 1.5064\n",
      " Epoch [72/300], Batch Step [60/323], D_loss: 0.7972,  G_loss: 1.4276\n",
      " Epoch [72/300], Batch Step [70/323], D_loss: 0.6421,  G_loss: 1.3572\n",
      " Epoch [72/300], Batch Step [80/323], D_loss: 0.7057,  G_loss: 1.5147\n",
      " Epoch [72/300], Batch Step [90/323], D_loss: 0.7306,  G_loss: 1.3894\n",
      " Epoch [72/300], Batch Step [100/323], D_loss: 0.8179,  G_loss: 1.6658\n",
      " Epoch [72/300], Batch Step [110/323], D_loss: 0.6617,  G_loss: 1.4746\n",
      " Epoch [72/300], Batch Step [120/323], D_loss: 0.7581,  G_loss: 1.6249\n",
      " Epoch [72/300], Batch Step [130/323], D_loss: 0.7024,  G_loss: 1.4264\n",
      " Epoch [72/300], Batch Step [140/323], D_loss: 0.7593,  G_loss: 1.3230\n",
      " Epoch [72/300], Batch Step [150/323], D_loss: 0.7683,  G_loss: 1.3976\n",
      " Epoch [72/300], Batch Step [160/323], D_loss: 0.6537,  G_loss: 1.4843\n",
      " Epoch [72/300], Batch Step [170/323], D_loss: 0.7191,  G_loss: 1.5405\n",
      " Epoch [72/300], Batch Step [180/323], D_loss: 0.8261,  G_loss: 1.5356\n",
      " Epoch [72/300], Batch Step [190/323], D_loss: 0.7205,  G_loss: 1.5271\n",
      " Epoch [72/300], Batch Step [200/323], D_loss: 0.8802,  G_loss: 1.3614\n",
      " Epoch [72/300], Batch Step [210/323], D_loss: 0.7935,  G_loss: 1.5773\n",
      " Epoch [72/300], Batch Step [220/323], D_loss: 0.8506,  G_loss: 1.6442\n",
      " Epoch [72/300], Batch Step [230/323], D_loss: 0.6299,  G_loss: 1.3812\n",
      " Epoch [72/300], Batch Step [240/323], D_loss: 0.8447,  G_loss: 1.4054\n",
      " Epoch [72/300], Batch Step [250/323], D_loss: 0.8064,  G_loss: 1.3331\n",
      " Epoch [72/300], Batch Step [260/323], D_loss: 0.7476,  G_loss: 1.4609\n",
      " Epoch [72/300], Batch Step [270/323], D_loss: 0.7767,  G_loss: 1.4274\n",
      " Epoch [72/300], Batch Step [280/323], D_loss: 0.6975,  G_loss: 1.5192\n",
      " Epoch [72/300], Batch Step [290/323], D_loss: 0.6079,  G_loss: 1.5389\n",
      " Epoch [72/300], Batch Step [300/323], D_loss: 0.8625,  G_loss: 1.5128\n",
      " Epoch [72/300], Batch Step [310/323], D_loss: 0.6474,  G_loss: 1.4811\n",
      " Epoch [72/300], Batch Step [320/323], D_loss: 0.7902,  G_loss: 1.5252\n",
      " Epoch [73/300], Batch Step [0/323], D_loss: 0.6472,  G_loss: 1.5213\n",
      " Epoch [73/300], Batch Step [10/323], D_loss: 0.7447,  G_loss: 1.4233\n",
      " Epoch [73/300], Batch Step [20/323], D_loss: 0.6990,  G_loss: 1.4548\n",
      " Epoch [73/300], Batch Step [30/323], D_loss: 0.7405,  G_loss: 1.4001\n",
      " Epoch [73/300], Batch Step [40/323], D_loss: 0.7673,  G_loss: 1.4272\n",
      " Epoch [73/300], Batch Step [50/323], D_loss: 0.8630,  G_loss: 1.5211\n",
      " Epoch [73/300], Batch Step [60/323], D_loss: 0.6534,  G_loss: 1.4212\n",
      " Epoch [73/300], Batch Step [70/323], D_loss: 0.6921,  G_loss: 1.4869\n",
      " Epoch [73/300], Batch Step [80/323], D_loss: 0.6756,  G_loss: 1.4416\n",
      " Epoch [73/300], Batch Step [90/323], D_loss: 0.6948,  G_loss: 1.4518\n",
      " Epoch [73/300], Batch Step [100/323], D_loss: 0.5771,  G_loss: 1.5504\n",
      " Epoch [73/300], Batch Step [110/323], D_loss: 0.8660,  G_loss: 1.3274\n",
      " Epoch [73/300], Batch Step [120/323], D_loss: 0.7877,  G_loss: 1.4687\n",
      " Epoch [73/300], Batch Step [130/323], D_loss: 0.7475,  G_loss: 1.3677\n",
      " Epoch [73/300], Batch Step [140/323], D_loss: 0.8221,  G_loss: 1.5925\n",
      " Epoch [73/300], Batch Step [150/323], D_loss: 0.6879,  G_loss: 1.2815\n",
      " Epoch [73/300], Batch Step [160/323], D_loss: 0.6510,  G_loss: 1.5332\n",
      " Epoch [73/300], Batch Step [170/323], D_loss: 0.6257,  G_loss: 1.4295\n",
      " Epoch [73/300], Batch Step [180/323], D_loss: 0.8835,  G_loss: 1.3633\n",
      " Epoch [73/300], Batch Step [190/323], D_loss: 0.7490,  G_loss: 1.4458\n",
      " Epoch [73/300], Batch Step [200/323], D_loss: 0.8044,  G_loss: 1.4582\n",
      " Epoch [73/300], Batch Step [210/323], D_loss: 0.7229,  G_loss: 1.4101\n",
      " Epoch [73/300], Batch Step [220/323], D_loss: 0.6268,  G_loss: 1.3786\n",
      " Epoch [73/300], Batch Step [230/323], D_loss: 0.6137,  G_loss: 1.5419\n",
      " Epoch [73/300], Batch Step [240/323], D_loss: 0.5927,  G_loss: 1.3559\n",
      " Epoch [73/300], Batch Step [250/323], D_loss: 0.8313,  G_loss: 1.4484\n",
      " Epoch [73/300], Batch Step [260/323], D_loss: 0.6813,  G_loss: 1.4159\n",
      " Epoch [73/300], Batch Step [270/323], D_loss: 0.6656,  G_loss: 1.5312\n",
      " Epoch [73/300], Batch Step [280/323], D_loss: 0.8689,  G_loss: 1.5588\n",
      " Epoch [73/300], Batch Step [290/323], D_loss: 0.6504,  G_loss: 1.3847\n",
      " Epoch [73/300], Batch Step [300/323], D_loss: 0.7248,  G_loss: 1.6552\n",
      " Epoch [73/300], Batch Step [310/323], D_loss: 0.8527,  G_loss: 1.4641\n",
      " Epoch [73/300], Batch Step [320/323], D_loss: 0.8706,  G_loss: 1.4567\n",
      " Epoch [74/300], Batch Step [0/323], D_loss: 0.9205,  G_loss: 1.3611\n",
      " Epoch [74/300], Batch Step [10/323], D_loss: 0.6976,  G_loss: 1.4695\n",
      " Epoch [74/300], Batch Step [20/323], D_loss: 0.9249,  G_loss: 1.6121\n",
      " Epoch [74/300], Batch Step [30/323], D_loss: 0.7217,  G_loss: 1.4445\n",
      " Epoch [74/300], Batch Step [40/323], D_loss: 0.9077,  G_loss: 1.4716\n",
      " Epoch [74/300], Batch Step [50/323], D_loss: 0.7097,  G_loss: 1.6031\n",
      " Epoch [74/300], Batch Step [60/323], D_loss: 0.7211,  G_loss: 1.4937\n",
      " Epoch [74/300], Batch Step [70/323], D_loss: 0.6277,  G_loss: 1.5108\n",
      " Epoch [74/300], Batch Step [80/323], D_loss: 0.7157,  G_loss: 1.6595\n",
      " Epoch [74/300], Batch Step [90/323], D_loss: 0.6875,  G_loss: 1.3846\n",
      " Epoch [74/300], Batch Step [100/323], D_loss: 0.7413,  G_loss: 1.6543\n",
      " Epoch [74/300], Batch Step [110/323], D_loss: 0.7895,  G_loss: 1.4963\n",
      " Epoch [74/300], Batch Step [120/323], D_loss: 0.7896,  G_loss: 1.3558\n",
      " Epoch [74/300], Batch Step [130/323], D_loss: 0.6789,  G_loss: 1.4811\n",
      " Epoch [74/300], Batch Step [140/323], D_loss: 0.7526,  G_loss: 1.5540\n",
      " Epoch [74/300], Batch Step [150/323], D_loss: 0.6249,  G_loss: 1.4770\n",
      " Epoch [74/300], Batch Step [160/323], D_loss: 0.6178,  G_loss: 1.5276\n",
      " Epoch [74/300], Batch Step [170/323], D_loss: 0.8232,  G_loss: 1.3771\n",
      " Epoch [74/300], Batch Step [180/323], D_loss: 0.8831,  G_loss: 1.5732\n",
      " Epoch [74/300], Batch Step [190/323], D_loss: 0.7203,  G_loss: 1.5203\n",
      " Epoch [74/300], Batch Step [200/323], D_loss: 0.7300,  G_loss: 1.4240\n",
      " Epoch [74/300], Batch Step [210/323], D_loss: 0.6587,  G_loss: 1.5756\n",
      " Epoch [74/300], Batch Step [220/323], D_loss: 0.8309,  G_loss: 1.3559\n",
      " Epoch [74/300], Batch Step [230/323], D_loss: 0.5598,  G_loss: 1.4755\n",
      " Epoch [74/300], Batch Step [240/323], D_loss: 0.6382,  G_loss: 1.5624\n",
      " Epoch [74/300], Batch Step [250/323], D_loss: 0.7097,  G_loss: 1.4958\n",
      " Epoch [74/300], Batch Step [260/323], D_loss: 0.6196,  G_loss: 1.5925\n",
      " Epoch [74/300], Batch Step [270/323], D_loss: 0.7799,  G_loss: 1.4143\n",
      " Epoch [74/300], Batch Step [280/323], D_loss: 0.8223,  G_loss: 1.4219\n",
      " Epoch [74/300], Batch Step [290/323], D_loss: 0.7697,  G_loss: 1.5732\n",
      " Epoch [74/300], Batch Step [300/323], D_loss: 0.8972,  G_loss: 1.3094\n",
      " Epoch [74/300], Batch Step [310/323], D_loss: 0.8706,  G_loss: 1.3537\n",
      " Epoch [74/300], Batch Step [320/323], D_loss: 0.6624,  G_loss: 1.4793\n",
      " Epoch [75/300], Batch Step [0/323], D_loss: 0.6902,  G_loss: 1.5213\n",
      " Epoch [75/300], Batch Step [10/323], D_loss: 0.6739,  G_loss: 1.4813\n",
      " Epoch [75/300], Batch Step [20/323], D_loss: 0.6867,  G_loss: 1.5274\n",
      " Epoch [75/300], Batch Step [30/323], D_loss: 0.5965,  G_loss: 1.5714\n",
      " Epoch [75/300], Batch Step [40/323], D_loss: 0.7047,  G_loss: 1.2680\n",
      " Epoch [75/300], Batch Step [50/323], D_loss: 0.7251,  G_loss: 1.5529\n",
      " Epoch [75/300], Batch Step [60/323], D_loss: 0.7166,  G_loss: 1.3542\n",
      " Epoch [75/300], Batch Step [70/323], D_loss: 0.9220,  G_loss: 1.3591\n",
      " Epoch [75/300], Batch Step [80/323], D_loss: 0.6919,  G_loss: 1.3689\n",
      " Epoch [75/300], Batch Step [90/323], D_loss: 0.7625,  G_loss: 1.6025\n",
      " Epoch [75/300], Batch Step [100/323], D_loss: 0.6619,  G_loss: 1.4298\n",
      " Epoch [75/300], Batch Step [110/323], D_loss: 0.6900,  G_loss: 1.5530\n",
      " Epoch [75/300], Batch Step [120/323], D_loss: 0.6832,  G_loss: 1.5488\n",
      " Epoch [75/300], Batch Step [130/323], D_loss: 0.7167,  G_loss: 1.3838\n",
      " Epoch [75/300], Batch Step [140/323], D_loss: 0.8361,  G_loss: 1.4957\n",
      " Epoch [75/300], Batch Step [150/323], D_loss: 0.9054,  G_loss: 1.5479\n",
      " Epoch [75/300], Batch Step [160/323], D_loss: 0.7436,  G_loss: 1.5846\n",
      " Epoch [75/300], Batch Step [170/323], D_loss: 0.6665,  G_loss: 1.4201\n",
      " Epoch [75/300], Batch Step [180/323], D_loss: 0.8180,  G_loss: 1.5807\n",
      " Epoch [75/300], Batch Step [190/323], D_loss: 0.8301,  G_loss: 1.3342\n",
      " Epoch [75/300], Batch Step [200/323], D_loss: 0.8040,  G_loss: 1.5569\n",
      " Epoch [75/300], Batch Step [210/323], D_loss: 0.7297,  G_loss: 1.2594\n",
      " Epoch [75/300], Batch Step [220/323], D_loss: 0.7376,  G_loss: 1.4781\n",
      " Epoch [75/300], Batch Step [230/323], D_loss: 0.7139,  G_loss: 1.5402\n",
      " Epoch [75/300], Batch Step [240/323], D_loss: 0.7299,  G_loss: 1.4090\n",
      " Epoch [75/300], Batch Step [250/323], D_loss: 0.6883,  G_loss: 1.5258\n",
      " Epoch [75/300], Batch Step [260/323], D_loss: 0.7145,  G_loss: 1.4678\n",
      " Epoch [75/300], Batch Step [270/323], D_loss: 0.6811,  G_loss: 1.5247\n",
      " Epoch [75/300], Batch Step [280/323], D_loss: 0.6853,  G_loss: 1.5465\n",
      " Epoch [75/300], Batch Step [290/323], D_loss: 0.7370,  G_loss: 1.3362\n",
      " Epoch [75/300], Batch Step [300/323], D_loss: 0.7949,  G_loss: 1.5077\n",
      " Epoch [75/300], Batch Step [310/323], D_loss: 0.8134,  G_loss: 1.5654\n",
      " Epoch [75/300], Batch Step [320/323], D_loss: 0.7620,  G_loss: 1.3858\n",
      " Epoch [76/300], Batch Step [0/323], D_loss: 0.6578,  G_loss: 1.4948\n",
      " Epoch [76/300], Batch Step [10/323], D_loss: 0.5454,  G_loss: 1.5736\n",
      " Epoch [76/300], Batch Step [20/323], D_loss: 0.7260,  G_loss: 1.5064\n",
      " Epoch [76/300], Batch Step [30/323], D_loss: 0.6259,  G_loss: 1.5823\n",
      " Epoch [76/300], Batch Step [40/323], D_loss: 0.6847,  G_loss: 1.4992\n",
      " Epoch [76/300], Batch Step [50/323], D_loss: 0.7494,  G_loss: 1.5368\n",
      " Epoch [76/300], Batch Step [60/323], D_loss: 0.6573,  G_loss: 1.5688\n",
      " Epoch [76/300], Batch Step [70/323], D_loss: 0.7890,  G_loss: 1.2443\n",
      " Epoch [76/300], Batch Step [80/323], D_loss: 0.7689,  G_loss: 1.4402\n",
      " Epoch [76/300], Batch Step [90/323], D_loss: 0.7289,  G_loss: 1.4828\n",
      " Epoch [76/300], Batch Step [100/323], D_loss: 0.6852,  G_loss: 1.3209\n",
      " Epoch [76/300], Batch Step [110/323], D_loss: 0.6662,  G_loss: 1.4682\n",
      " Epoch [76/300], Batch Step [120/323], D_loss: 0.8035,  G_loss: 1.5485\n",
      " Epoch [76/300], Batch Step [130/323], D_loss: 0.6830,  G_loss: 1.3895\n",
      " Epoch [76/300], Batch Step [140/323], D_loss: 0.6649,  G_loss: 1.5428\n",
      " Epoch [76/300], Batch Step [150/323], D_loss: 0.7492,  G_loss: 1.4530\n",
      " Epoch [76/300], Batch Step [160/323], D_loss: 0.7988,  G_loss: 1.3640\n",
      " Epoch [76/300], Batch Step [170/323], D_loss: 0.7356,  G_loss: 1.5301\n",
      " Epoch [76/300], Batch Step [180/323], D_loss: 0.6862,  G_loss: 1.3595\n",
      " Epoch [76/300], Batch Step [190/323], D_loss: 0.8022,  G_loss: 1.6068\n",
      " Epoch [76/300], Batch Step [200/323], D_loss: 0.7657,  G_loss: 1.4340\n",
      " Epoch [76/300], Batch Step [210/323], D_loss: 0.6557,  G_loss: 1.6894\n",
      " Epoch [76/300], Batch Step [220/323], D_loss: 0.6611,  G_loss: 1.6457\n",
      " Epoch [76/300], Batch Step [230/323], D_loss: 0.7805,  G_loss: 1.4673\n",
      " Epoch [76/300], Batch Step [240/323], D_loss: 0.7541,  G_loss: 1.4379\n",
      " Epoch [76/300], Batch Step [250/323], D_loss: 0.6397,  G_loss: 1.2814\n",
      " Epoch [76/300], Batch Step [260/323], D_loss: 0.5898,  G_loss: 1.4729\n",
      " Epoch [76/300], Batch Step [270/323], D_loss: 0.7502,  G_loss: 1.4601\n",
      " Epoch [76/300], Batch Step [280/323], D_loss: 0.7965,  G_loss: 1.4917\n",
      " Epoch [76/300], Batch Step [290/323], D_loss: 0.6199,  G_loss: 1.4427\n",
      " Epoch [76/300], Batch Step [300/323], D_loss: 0.8031,  G_loss: 1.3709\n",
      " Epoch [76/300], Batch Step [310/323], D_loss: 0.7230,  G_loss: 1.5236\n",
      " Epoch [76/300], Batch Step [320/323], D_loss: 0.7374,  G_loss: 1.4621\n",
      " Epoch [77/300], Batch Step [0/323], D_loss: 0.6328,  G_loss: 1.5038\n",
      " Epoch [77/300], Batch Step [10/323], D_loss: 0.7319,  G_loss: 1.5517\n",
      " Epoch [77/300], Batch Step [20/323], D_loss: 0.7085,  G_loss: 1.3789\n",
      " Epoch [77/300], Batch Step [30/323], D_loss: 0.8195,  G_loss: 1.6482\n",
      " Epoch [77/300], Batch Step [40/323], D_loss: 0.7267,  G_loss: 1.4341\n",
      " Epoch [77/300], Batch Step [50/323], D_loss: 0.8333,  G_loss: 1.7225\n",
      " Epoch [77/300], Batch Step [60/323], D_loss: 0.7459,  G_loss: 1.4379\n",
      " Epoch [77/300], Batch Step [70/323], D_loss: 0.6883,  G_loss: 1.5495\n",
      " Epoch [77/300], Batch Step [80/323], D_loss: 0.7383,  G_loss: 1.2888\n",
      " Epoch [77/300], Batch Step [90/323], D_loss: 0.5702,  G_loss: 1.4235\n",
      " Epoch [77/300], Batch Step [100/323], D_loss: 0.7628,  G_loss: 1.4219\n",
      " Epoch [77/300], Batch Step [110/323], D_loss: 0.5925,  G_loss: 1.5267\n",
      " Epoch [77/300], Batch Step [120/323], D_loss: 0.6601,  G_loss: 1.5495\n",
      " Epoch [77/300], Batch Step [130/323], D_loss: 0.8614,  G_loss: 1.5065\n",
      " Epoch [77/300], Batch Step [140/323], D_loss: 0.6599,  G_loss: 1.4065\n",
      " Epoch [77/300], Batch Step [150/323], D_loss: 0.6923,  G_loss: 1.5645\n",
      " Epoch [77/300], Batch Step [160/323], D_loss: 0.7944,  G_loss: 1.4033\n",
      " Epoch [77/300], Batch Step [170/323], D_loss: 0.5773,  G_loss: 1.4515\n",
      " Epoch [77/300], Batch Step [180/323], D_loss: 0.8132,  G_loss: 1.4298\n",
      " Epoch [77/300], Batch Step [190/323], D_loss: 0.7918,  G_loss: 1.4714\n",
      " Epoch [77/300], Batch Step [200/323], D_loss: 0.7888,  G_loss: 1.3999\n",
      " Epoch [77/300], Batch Step [210/323], D_loss: 0.6059,  G_loss: 1.5692\n",
      " Epoch [77/300], Batch Step [220/323], D_loss: 0.7520,  G_loss: 1.6103\n",
      " Epoch [77/300], Batch Step [230/323], D_loss: 0.6616,  G_loss: 1.3763\n",
      " Epoch [77/300], Batch Step [240/323], D_loss: 0.7034,  G_loss: 1.4927\n",
      " Epoch [77/300], Batch Step [250/323], D_loss: 0.5803,  G_loss: 1.5613\n",
      " Epoch [77/300], Batch Step [260/323], D_loss: 0.6997,  G_loss: 1.4316\n",
      " Epoch [77/300], Batch Step [270/323], D_loss: 0.6249,  G_loss: 1.4609\n",
      " Epoch [77/300], Batch Step [280/323], D_loss: 0.7322,  G_loss: 1.4165\n",
      " Epoch [77/300], Batch Step [290/323], D_loss: 0.5552,  G_loss: 1.4879\n",
      " Epoch [77/300], Batch Step [300/323], D_loss: 0.7520,  G_loss: 1.4277\n",
      " Epoch [77/300], Batch Step [310/323], D_loss: 0.7648,  G_loss: 1.4083\n",
      " Epoch [77/300], Batch Step [320/323], D_loss: 0.6038,  G_loss: 1.6058\n",
      " Epoch [78/300], Batch Step [0/323], D_loss: 0.7063,  G_loss: 1.5360\n",
      " Epoch [78/300], Batch Step [10/323], D_loss: 0.6930,  G_loss: 1.4159\n",
      " Epoch [78/300], Batch Step [20/323], D_loss: 0.6257,  G_loss: 1.6556\n",
      " Epoch [78/300], Batch Step [30/323], D_loss: 0.8203,  G_loss: 1.3397\n",
      " Epoch [78/300], Batch Step [40/323], D_loss: 0.6692,  G_loss: 1.6074\n",
      " Epoch [78/300], Batch Step [50/323], D_loss: 0.7142,  G_loss: 1.3781\n",
      " Epoch [78/300], Batch Step [60/323], D_loss: 0.6781,  G_loss: 1.5275\n",
      " Epoch [78/300], Batch Step [70/323], D_loss: 0.6581,  G_loss: 1.5043\n",
      " Epoch [78/300], Batch Step [80/323], D_loss: 0.7612,  G_loss: 1.3151\n",
      " Epoch [78/300], Batch Step [90/323], D_loss: 0.6837,  G_loss: 1.4014\n",
      " Epoch [78/300], Batch Step [100/323], D_loss: 0.6240,  G_loss: 1.4984\n",
      " Epoch [78/300], Batch Step [110/323], D_loss: 0.7149,  G_loss: 1.5451\n",
      " Epoch [78/300], Batch Step [120/323], D_loss: 0.7048,  G_loss: 1.5644\n",
      " Epoch [78/300], Batch Step [130/323], D_loss: 0.7090,  G_loss: 1.5006\n",
      " Epoch [78/300], Batch Step [140/323], D_loss: 0.6426,  G_loss: 1.4734\n",
      " Epoch [78/300], Batch Step [150/323], D_loss: 0.8476,  G_loss: 1.4601\n",
      " Epoch [78/300], Batch Step [160/323], D_loss: 0.6297,  G_loss: 1.6979\n",
      " Epoch [78/300], Batch Step [170/323], D_loss: 0.7050,  G_loss: 1.5064\n",
      " Epoch [78/300], Batch Step [180/323], D_loss: 0.8797,  G_loss: 1.5419\n",
      " Epoch [78/300], Batch Step [190/323], D_loss: 0.6831,  G_loss: 1.3932\n",
      " Epoch [78/300], Batch Step [200/323], D_loss: 0.5417,  G_loss: 1.6216\n",
      " Epoch [78/300], Batch Step [210/323], D_loss: 0.7085,  G_loss: 1.3297\n",
      " Epoch [78/300], Batch Step [220/323], D_loss: 0.7113,  G_loss: 1.5472\n",
      " Epoch [78/300], Batch Step [230/323], D_loss: 0.6185,  G_loss: 1.4449\n",
      " Epoch [78/300], Batch Step [240/323], D_loss: 0.6936,  G_loss: 1.5763\n",
      " Epoch [78/300], Batch Step [250/323], D_loss: 0.6876,  G_loss: 1.4504\n",
      " Epoch [78/300], Batch Step [260/323], D_loss: 0.8741,  G_loss: 1.4266\n",
      " Epoch [78/300], Batch Step [270/323], D_loss: 0.7672,  G_loss: 1.3595\n",
      " Epoch [78/300], Batch Step [280/323], D_loss: 0.5943,  G_loss: 1.5234\n",
      " Epoch [78/300], Batch Step [290/323], D_loss: 0.6484,  G_loss: 1.4570\n",
      " Epoch [78/300], Batch Step [300/323], D_loss: 0.8605,  G_loss: 1.3582\n",
      " Epoch [78/300], Batch Step [310/323], D_loss: 0.5908,  G_loss: 1.4170\n",
      " Epoch [78/300], Batch Step [320/323], D_loss: 0.7096,  G_loss: 1.5968\n",
      " Epoch [79/300], Batch Step [0/323], D_loss: 0.7710,  G_loss: 1.4697\n",
      " Epoch [79/300], Batch Step [10/323], D_loss: 0.6685,  G_loss: 1.2700\n",
      " Epoch [79/300], Batch Step [20/323], D_loss: 0.6591,  G_loss: 1.6728\n",
      " Epoch [79/300], Batch Step [30/323], D_loss: 0.7103,  G_loss: 1.4387\n",
      " Epoch [79/300], Batch Step [40/323], D_loss: 0.6374,  G_loss: 1.4811\n",
      " Epoch [79/300], Batch Step [50/323], D_loss: 0.6164,  G_loss: 1.5347\n",
      " Epoch [79/300], Batch Step [60/323], D_loss: 0.9507,  G_loss: 1.4507\n",
      " Epoch [79/300], Batch Step [70/323], D_loss: 0.7969,  G_loss: 1.5202\n",
      " Epoch [79/300], Batch Step [80/323], D_loss: 0.8471,  G_loss: 1.5144\n",
      " Epoch [79/300], Batch Step [90/323], D_loss: 0.7667,  G_loss: 1.5757\n",
      " Epoch [79/300], Batch Step [100/323], D_loss: 0.7635,  G_loss: 1.3241\n",
      " Epoch [79/300], Batch Step [110/323], D_loss: 0.6994,  G_loss: 1.4849\n",
      " Epoch [79/300], Batch Step [120/323], D_loss: 0.7730,  G_loss: 1.4559\n",
      " Epoch [79/300], Batch Step [130/323], D_loss: 0.8215,  G_loss: 1.4108\n",
      " Epoch [79/300], Batch Step [140/323], D_loss: 0.7741,  G_loss: 1.4570\n",
      " Epoch [79/300], Batch Step [150/323], D_loss: 0.7140,  G_loss: 1.4174\n",
      " Epoch [79/300], Batch Step [160/323], D_loss: 0.7146,  G_loss: 1.4310\n",
      " Epoch [79/300], Batch Step [170/323], D_loss: 0.7104,  G_loss: 1.4392\n",
      " Epoch [79/300], Batch Step [180/323], D_loss: 0.7964,  G_loss: 1.4459\n",
      " Epoch [79/300], Batch Step [190/323], D_loss: 0.7114,  G_loss: 1.3463\n",
      " Epoch [79/300], Batch Step [200/323], D_loss: 0.7156,  G_loss: 1.4310\n",
      " Epoch [79/300], Batch Step [210/323], D_loss: 0.7351,  G_loss: 1.4960\n",
      " Epoch [79/300], Batch Step [220/323], D_loss: 0.8007,  G_loss: 1.4683\n",
      " Epoch [79/300], Batch Step [230/323], D_loss: 0.6574,  G_loss: 1.3756\n",
      " Epoch [79/300], Batch Step [240/323], D_loss: 0.6350,  G_loss: 1.5487\n",
      " Epoch [79/300], Batch Step [250/323], D_loss: 0.7760,  G_loss: 1.5931\n",
      " Epoch [79/300], Batch Step [260/323], D_loss: 0.7999,  G_loss: 1.4662\n",
      " Epoch [79/300], Batch Step [270/323], D_loss: 0.7721,  G_loss: 1.4258\n",
      " Epoch [79/300], Batch Step [280/323], D_loss: 0.7201,  G_loss: 1.4935\n",
      " Epoch [79/300], Batch Step [290/323], D_loss: 0.7720,  G_loss: 1.3904\n",
      " Epoch [79/300], Batch Step [300/323], D_loss: 0.8875,  G_loss: 1.5301\n",
      " Epoch [79/300], Batch Step [310/323], D_loss: 0.6382,  G_loss: 1.2898\n",
      " Epoch [79/300], Batch Step [320/323], D_loss: 0.6680,  G_loss: 1.6215\n",
      " Epoch [80/300], Batch Step [0/323], D_loss: 0.8581,  G_loss: 1.5852\n",
      " Epoch [80/300], Batch Step [10/323], D_loss: 0.8499,  G_loss: 1.5350\n",
      " Epoch [80/300], Batch Step [20/323], D_loss: 0.7450,  G_loss: 1.4713\n",
      " Epoch [80/300], Batch Step [30/323], D_loss: 0.7668,  G_loss: 1.4278\n",
      " Epoch [80/300], Batch Step [40/323], D_loss: 0.6339,  G_loss: 1.3889\n",
      " Epoch [80/300], Batch Step [50/323], D_loss: 0.6673,  G_loss: 1.6629\n",
      " Epoch [80/300], Batch Step [60/323], D_loss: 0.6485,  G_loss: 1.3112\n",
      " Epoch [80/300], Batch Step [70/323], D_loss: 0.6068,  G_loss: 1.4339\n",
      " Epoch [80/300], Batch Step [80/323], D_loss: 0.8282,  G_loss: 1.5551\n",
      " Epoch [80/300], Batch Step [90/323], D_loss: 0.7221,  G_loss: 1.2501\n",
      " Epoch [80/300], Batch Step [100/323], D_loss: 0.6172,  G_loss: 1.6255\n",
      " Epoch [80/300], Batch Step [110/323], D_loss: 0.6592,  G_loss: 1.4349\n",
      " Epoch [80/300], Batch Step [120/323], D_loss: 0.6638,  G_loss: 1.4829\n",
      " Epoch [80/300], Batch Step [130/323], D_loss: 0.7227,  G_loss: 1.3835\n",
      " Epoch [80/300], Batch Step [140/323], D_loss: 0.6588,  G_loss: 1.5528\n",
      " Epoch [80/300], Batch Step [150/323], D_loss: 0.7900,  G_loss: 1.4969\n",
      " Epoch [80/300], Batch Step [160/323], D_loss: 0.5954,  G_loss: 1.2726\n",
      " Epoch [80/300], Batch Step [170/323], D_loss: 0.5696,  G_loss: 1.4903\n",
      " Epoch [80/300], Batch Step [180/323], D_loss: 0.7868,  G_loss: 1.5673\n",
      " Epoch [80/300], Batch Step [190/323], D_loss: 0.6798,  G_loss: 1.5091\n",
      " Epoch [80/300], Batch Step [200/323], D_loss: 0.7170,  G_loss: 1.4129\n",
      " Epoch [80/300], Batch Step [210/323], D_loss: 0.7102,  G_loss: 1.5633\n",
      " Epoch [80/300], Batch Step [220/323], D_loss: 0.7320,  G_loss: 1.4680\n",
      " Epoch [80/300], Batch Step [230/323], D_loss: 0.6929,  G_loss: 1.5124\n",
      " Epoch [80/300], Batch Step [240/323], D_loss: 0.7542,  G_loss: 1.4098\n",
      " Epoch [80/300], Batch Step [250/323], D_loss: 0.7014,  G_loss: 1.3820\n",
      " Epoch [80/300], Batch Step [260/323], D_loss: 0.6936,  G_loss: 1.4444\n",
      " Epoch [80/300], Batch Step [270/323], D_loss: 0.7515,  G_loss: 1.5313\n",
      " Epoch [80/300], Batch Step [280/323], D_loss: 0.7292,  G_loss: 1.4282\n",
      " Epoch [80/300], Batch Step [290/323], D_loss: 0.6052,  G_loss: 1.5505\n",
      " Epoch [80/300], Batch Step [300/323], D_loss: 0.6260,  G_loss: 1.3655\n",
      " Epoch [80/300], Batch Step [310/323], D_loss: 0.7738,  G_loss: 1.5589\n",
      " Epoch [80/300], Batch Step [320/323], D_loss: 0.7698,  G_loss: 1.4238\n",
      " Epoch [81/300], Batch Step [0/323], D_loss: 0.6558,  G_loss: 1.4201\n",
      " Epoch [81/300], Batch Step [10/323], D_loss: 0.7034,  G_loss: 1.5103\n",
      " Epoch [81/300], Batch Step [20/323], D_loss: 0.7568,  G_loss: 1.5002\n",
      " Epoch [81/300], Batch Step [30/323], D_loss: 0.5296,  G_loss: 1.5495\n",
      " Epoch [81/300], Batch Step [40/323], D_loss: 0.6689,  G_loss: 1.4616\n",
      " Epoch [81/300], Batch Step [50/323], D_loss: 0.7580,  G_loss: 1.5173\n",
      " Epoch [81/300], Batch Step [60/323], D_loss: 0.6929,  G_loss: 1.5220\n",
      " Epoch [81/300], Batch Step [70/323], D_loss: 0.9874,  G_loss: 1.3107\n",
      " Epoch [81/300], Batch Step [80/323], D_loss: 0.7539,  G_loss: 1.5954\n",
      " Epoch [81/300], Batch Step [90/323], D_loss: 0.7323,  G_loss: 1.4380\n",
      " Epoch [81/300], Batch Step [100/323], D_loss: 0.8110,  G_loss: 1.5499\n",
      " Epoch [81/300], Batch Step [110/323], D_loss: 0.9291,  G_loss: 1.4744\n",
      " Epoch [81/300], Batch Step [120/323], D_loss: 0.7129,  G_loss: 1.3476\n",
      " Epoch [81/300], Batch Step [130/323], D_loss: 0.5644,  G_loss: 1.6214\n",
      " Epoch [81/300], Batch Step [140/323], D_loss: 0.8050,  G_loss: 1.3609\n",
      " Epoch [81/300], Batch Step [150/323], D_loss: 0.7642,  G_loss: 1.6158\n",
      " Epoch [81/300], Batch Step [160/323], D_loss: 0.8590,  G_loss: 1.3786\n",
      " Epoch [81/300], Batch Step [170/323], D_loss: 0.7537,  G_loss: 1.5724\n",
      " Epoch [81/300], Batch Step [180/323], D_loss: 0.8580,  G_loss: 1.4537\n",
      " Epoch [81/300], Batch Step [190/323], D_loss: 0.6184,  G_loss: 1.5071\n",
      " Epoch [81/300], Batch Step [200/323], D_loss: 0.5898,  G_loss: 1.4531\n",
      " Epoch [81/300], Batch Step [210/323], D_loss: 0.6441,  G_loss: 1.3121\n",
      " Epoch [81/300], Batch Step [220/323], D_loss: 0.8007,  G_loss: 1.3760\n",
      " Epoch [81/300], Batch Step [230/323], D_loss: 0.8402,  G_loss: 1.3998\n",
      " Epoch [81/300], Batch Step [240/323], D_loss: 0.6750,  G_loss: 1.5669\n",
      " Epoch [81/300], Batch Step [250/323], D_loss: 0.6549,  G_loss: 1.5840\n",
      " Epoch [81/300], Batch Step [260/323], D_loss: 0.6865,  G_loss: 1.4579\n",
      " Epoch [81/300], Batch Step [270/323], D_loss: 0.7203,  G_loss: 1.6074\n",
      " Epoch [81/300], Batch Step [280/323], D_loss: 0.6913,  G_loss: 1.5308\n",
      " Epoch [81/300], Batch Step [290/323], D_loss: 0.8840,  G_loss: 1.3147\n",
      " Epoch [81/300], Batch Step [300/323], D_loss: 0.5399,  G_loss: 1.4606\n",
      " Epoch [81/300], Batch Step [310/323], D_loss: 0.6374,  G_loss: 1.5186\n",
      " Epoch [81/300], Batch Step [320/323], D_loss: 0.6552,  G_loss: 1.5137\n",
      " Epoch [82/300], Batch Step [0/323], D_loss: 0.7876,  G_loss: 1.4816\n",
      " Epoch [82/300], Batch Step [10/323], D_loss: 0.6174,  G_loss: 1.4133\n",
      " Epoch [82/300], Batch Step [20/323], D_loss: 0.7424,  G_loss: 1.6434\n",
      " Epoch [82/300], Batch Step [30/323], D_loss: 0.7016,  G_loss: 1.4496\n",
      " Epoch [82/300], Batch Step [40/323], D_loss: 0.6338,  G_loss: 1.6781\n",
      " Epoch [82/300], Batch Step [50/323], D_loss: 0.7235,  G_loss: 1.4529\n",
      " Epoch [82/300], Batch Step [60/323], D_loss: 0.6923,  G_loss: 1.4212\n",
      " Epoch [82/300], Batch Step [70/323], D_loss: 0.7735,  G_loss: 1.3807\n",
      " Epoch [82/300], Batch Step [80/323], D_loss: 0.7212,  G_loss: 1.4640\n",
      " Epoch [82/300], Batch Step [90/323], D_loss: 0.8196,  G_loss: 1.4119\n",
      " Epoch [82/300], Batch Step [100/323], D_loss: 0.7629,  G_loss: 1.4588\n",
      " Epoch [82/300], Batch Step [110/323], D_loss: 0.7231,  G_loss: 1.4816\n",
      " Epoch [82/300], Batch Step [120/323], D_loss: 0.7265,  G_loss: 1.5035\n",
      " Epoch [82/300], Batch Step [130/323], D_loss: 0.6829,  G_loss: 1.4629\n",
      " Epoch [82/300], Batch Step [140/323], D_loss: 0.5800,  G_loss: 1.5373\n",
      " Epoch [82/300], Batch Step [150/323], D_loss: 0.7856,  G_loss: 1.4445\n",
      " Epoch [82/300], Batch Step [160/323], D_loss: 0.6720,  G_loss: 1.5551\n",
      " Epoch [82/300], Batch Step [170/323], D_loss: 0.7124,  G_loss: 1.5557\n",
      " Epoch [82/300], Batch Step [180/323], D_loss: 0.7443,  G_loss: 1.4892\n",
      " Epoch [82/300], Batch Step [190/323], D_loss: 0.7340,  G_loss: 1.5469\n",
      " Epoch [82/300], Batch Step [200/323], D_loss: 0.7507,  G_loss: 1.3694\n",
      " Epoch [82/300], Batch Step [210/323], D_loss: 0.8655,  G_loss: 1.4595\n",
      " Epoch [82/300], Batch Step [220/323], D_loss: 0.7808,  G_loss: 1.5672\n",
      " Epoch [82/300], Batch Step [230/323], D_loss: 0.5563,  G_loss: 1.5121\n",
      " Epoch [82/300], Batch Step [240/323], D_loss: 0.5886,  G_loss: 1.4057\n",
      " Epoch [82/300], Batch Step [250/323], D_loss: 0.5719,  G_loss: 1.7294\n",
      " Epoch [82/300], Batch Step [260/323], D_loss: 0.6494,  G_loss: 1.4861\n",
      " Epoch [82/300], Batch Step [270/323], D_loss: 0.9137,  G_loss: 1.5204\n",
      " Epoch [82/300], Batch Step [280/323], D_loss: 0.8742,  G_loss: 1.4364\n",
      " Epoch [82/300], Batch Step [290/323], D_loss: 0.9247,  G_loss: 1.4566\n",
      " Epoch [82/300], Batch Step [300/323], D_loss: 0.6737,  G_loss: 1.5962\n",
      " Epoch [82/300], Batch Step [310/323], D_loss: 0.7477,  G_loss: 1.4310\n",
      " Epoch [82/300], Batch Step [320/323], D_loss: 0.8064,  G_loss: 1.4424\n",
      " Epoch [83/300], Batch Step [0/323], D_loss: 0.8391,  G_loss: 1.4525\n",
      " Epoch [83/300], Batch Step [10/323], D_loss: 0.6310,  G_loss: 1.5057\n",
      " Epoch [83/300], Batch Step [20/323], D_loss: 0.8016,  G_loss: 1.5926\n",
      " Epoch [83/300], Batch Step [30/323], D_loss: 0.7375,  G_loss: 1.5276\n",
      " Epoch [83/300], Batch Step [40/323], D_loss: 0.7801,  G_loss: 1.5567\n",
      " Epoch [83/300], Batch Step [50/323], D_loss: 0.7497,  G_loss: 1.4394\n",
      " Epoch [83/300], Batch Step [60/323], D_loss: 0.7372,  G_loss: 1.6898\n",
      " Epoch [83/300], Batch Step [70/323], D_loss: 0.7172,  G_loss: 1.4237\n",
      " Epoch [83/300], Batch Step [80/323], D_loss: 0.7231,  G_loss: 1.4512\n",
      " Epoch [83/300], Batch Step [90/323], D_loss: 0.8438,  G_loss: 1.5100\n",
      " Epoch [83/300], Batch Step [100/323], D_loss: 0.7146,  G_loss: 1.4589\n",
      " Epoch [83/300], Batch Step [110/323], D_loss: 0.7072,  G_loss: 1.5846\n",
      " Epoch [83/300], Batch Step [120/323], D_loss: 0.6953,  G_loss: 1.4121\n",
      " Epoch [83/300], Batch Step [130/323], D_loss: 0.7898,  G_loss: 1.4625\n",
      " Epoch [83/300], Batch Step [140/323], D_loss: 0.7210,  G_loss: 1.4809\n",
      " Epoch [83/300], Batch Step [150/323], D_loss: 0.6531,  G_loss: 1.6508\n",
      " Epoch [83/300], Batch Step [160/323], D_loss: 0.5078,  G_loss: 1.5204\n",
      " Epoch [83/300], Batch Step [170/323], D_loss: 0.5895,  G_loss: 1.5642\n",
      " Epoch [83/300], Batch Step [180/323], D_loss: 0.6372,  G_loss: 1.6290\n",
      " Epoch [83/300], Batch Step [190/323], D_loss: 0.7590,  G_loss: 1.6310\n",
      " Epoch [83/300], Batch Step [200/323], D_loss: 0.6927,  G_loss: 1.4831\n",
      " Epoch [83/300], Batch Step [210/323], D_loss: 0.6490,  G_loss: 1.4628\n",
      " Epoch [83/300], Batch Step [220/323], D_loss: 0.6825,  G_loss: 1.5285\n",
      " Epoch [83/300], Batch Step [230/323], D_loss: 0.9038,  G_loss: 1.4346\n",
      " Epoch [83/300], Batch Step [240/323], D_loss: 0.6833,  G_loss: 1.3319\n",
      " Epoch [83/300], Batch Step [250/323], D_loss: 0.7461,  G_loss: 1.5656\n",
      " Epoch [83/300], Batch Step [260/323], D_loss: 0.7025,  G_loss: 1.3260\n",
      " Epoch [83/300], Batch Step [270/323], D_loss: 0.7412,  G_loss: 1.4783\n",
      " Epoch [83/300], Batch Step [280/323], D_loss: 0.6347,  G_loss: 1.5233\n",
      " Epoch [83/300], Batch Step [290/323], D_loss: 0.5778,  G_loss: 1.4818\n",
      " Epoch [83/300], Batch Step [300/323], D_loss: 0.6108,  G_loss: 1.6973\n",
      " Epoch [83/300], Batch Step [310/323], D_loss: 0.8108,  G_loss: 1.4180\n",
      " Epoch [83/300], Batch Step [320/323], D_loss: 0.7220,  G_loss: 1.5292\n",
      " Epoch [84/300], Batch Step [0/323], D_loss: 0.6567,  G_loss: 1.5857\n",
      " Epoch [84/300], Batch Step [10/323], D_loss: 0.5926,  G_loss: 1.4425\n",
      " Epoch [84/300], Batch Step [20/323], D_loss: 0.8256,  G_loss: 1.5157\n",
      " Epoch [84/300], Batch Step [30/323], D_loss: 0.7601,  G_loss: 1.4479\n",
      " Epoch [84/300], Batch Step [40/323], D_loss: 0.7213,  G_loss: 1.5899\n",
      " Epoch [84/300], Batch Step [50/323], D_loss: 0.7954,  G_loss: 1.4455\n",
      " Epoch [84/300], Batch Step [60/323], D_loss: 0.5618,  G_loss: 1.4020\n",
      " Epoch [84/300], Batch Step [70/323], D_loss: 0.7565,  G_loss: 1.3514\n",
      " Epoch [84/300], Batch Step [80/323], D_loss: 0.7603,  G_loss: 1.6363\n",
      " Epoch [84/300], Batch Step [90/323], D_loss: 0.7453,  G_loss: 1.4427\n",
      " Epoch [84/300], Batch Step [100/323], D_loss: 0.6136,  G_loss: 1.4628\n",
      " Epoch [84/300], Batch Step [110/323], D_loss: 0.7769,  G_loss: 1.4993\n",
      " Epoch [84/300], Batch Step [120/323], D_loss: 0.7213,  G_loss: 1.5422\n",
      " Epoch [84/300], Batch Step [130/323], D_loss: 0.6279,  G_loss: 1.6139\n",
      " Epoch [84/300], Batch Step [140/323], D_loss: 0.6631,  G_loss: 1.5976\n",
      " Epoch [84/300], Batch Step [150/323], D_loss: 0.9719,  G_loss: 1.3525\n",
      " Epoch [84/300], Batch Step [160/323], D_loss: 0.9310,  G_loss: 1.4620\n",
      " Epoch [84/300], Batch Step [170/323], D_loss: 0.6997,  G_loss: 1.5242\n",
      " Epoch [84/300], Batch Step [180/323], D_loss: 0.7419,  G_loss: 1.5104\n",
      " Epoch [84/300], Batch Step [190/323], D_loss: 0.6467,  G_loss: 1.4940\n",
      " Epoch [84/300], Batch Step [200/323], D_loss: 0.7322,  G_loss: 1.4975\n",
      " Epoch [84/300], Batch Step [210/323], D_loss: 0.6811,  G_loss: 1.6574\n",
      " Epoch [84/300], Batch Step [220/323], D_loss: 0.7084,  G_loss: 1.4054\n",
      " Epoch [84/300], Batch Step [230/323], D_loss: 0.7506,  G_loss: 1.5430\n",
      " Epoch [84/300], Batch Step [240/323], D_loss: 0.6865,  G_loss: 1.4072\n",
      " Epoch [84/300], Batch Step [250/323], D_loss: 0.6931,  G_loss: 1.5875\n",
      " Epoch [84/300], Batch Step [260/323], D_loss: 0.7889,  G_loss: 1.4332\n",
      " Epoch [84/300], Batch Step [270/323], D_loss: 0.6695,  G_loss: 1.4732\n",
      " Epoch [84/300], Batch Step [280/323], D_loss: 0.7961,  G_loss: 1.3562\n",
      " Epoch [84/300], Batch Step [290/323], D_loss: 0.6963,  G_loss: 1.5323\n",
      " Epoch [84/300], Batch Step [300/323], D_loss: 0.6905,  G_loss: 1.3898\n",
      " Epoch [84/300], Batch Step [310/323], D_loss: 0.7774,  G_loss: 1.5438\n",
      " Epoch [84/300], Batch Step [320/323], D_loss: 0.6609,  G_loss: 1.5539\n",
      " Epoch [85/300], Batch Step [0/323], D_loss: 0.7473,  G_loss: 1.6073\n",
      " Epoch [85/300], Batch Step [10/323], D_loss: 0.6804,  G_loss: 1.3643\n",
      " Epoch [85/300], Batch Step [20/323], D_loss: 0.7163,  G_loss: 1.5817\n",
      " Epoch [85/300], Batch Step [30/323], D_loss: 0.7950,  G_loss: 1.6579\n",
      " Epoch [85/300], Batch Step [40/323], D_loss: 0.6313,  G_loss: 1.3881\n",
      " Epoch [85/300], Batch Step [50/323], D_loss: 0.9221,  G_loss: 1.4018\n",
      " Epoch [85/300], Batch Step [60/323], D_loss: 0.5539,  G_loss: 1.5291\n",
      " Epoch [85/300], Batch Step [70/323], D_loss: 0.6944,  G_loss: 1.5399\n",
      " Epoch [85/300], Batch Step [80/323], D_loss: 0.7388,  G_loss: 1.3259\n",
      " Epoch [85/300], Batch Step [90/323], D_loss: 0.6145,  G_loss: 1.6496\n",
      " Epoch [85/300], Batch Step [100/323], D_loss: 0.6091,  G_loss: 1.6067\n",
      " Epoch [85/300], Batch Step [110/323], D_loss: 0.4824,  G_loss: 1.5795\n",
      " Epoch [85/300], Batch Step [120/323], D_loss: 0.6565,  G_loss: 1.5036\n",
      " Epoch [85/300], Batch Step [130/323], D_loss: 0.7549,  G_loss: 1.4073\n",
      " Epoch [85/300], Batch Step [140/323], D_loss: 0.7327,  G_loss: 1.4968\n",
      " Epoch [85/300], Batch Step [150/323], D_loss: 0.6857,  G_loss: 1.4781\n",
      " Epoch [85/300], Batch Step [160/323], D_loss: 0.7147,  G_loss: 1.5227\n",
      " Epoch [85/300], Batch Step [170/323], D_loss: 0.7850,  G_loss: 1.6632\n",
      " Epoch [85/300], Batch Step [180/323], D_loss: 0.7266,  G_loss: 1.4310\n",
      " Epoch [85/300], Batch Step [190/323], D_loss: 0.6724,  G_loss: 1.6393\n",
      " Epoch [85/300], Batch Step [200/323], D_loss: 0.7401,  G_loss: 1.4632\n",
      " Epoch [85/300], Batch Step [210/323], D_loss: 0.6656,  G_loss: 1.4869\n",
      " Epoch [85/300], Batch Step [220/323], D_loss: 0.7965,  G_loss: 1.5468\n",
      " Epoch [85/300], Batch Step [230/323], D_loss: 0.8530,  G_loss: 1.4407\n",
      " Epoch [85/300], Batch Step [240/323], D_loss: 0.7639,  G_loss: 1.5140\n",
      " Epoch [85/300], Batch Step [250/323], D_loss: 0.8482,  G_loss: 1.5517\n",
      " Epoch [85/300], Batch Step [260/323], D_loss: 0.8265,  G_loss: 1.5289\n",
      " Epoch [85/300], Batch Step [270/323], D_loss: 0.6805,  G_loss: 1.4779\n",
      " Epoch [85/300], Batch Step [280/323], D_loss: 0.6014,  G_loss: 1.5926\n",
      " Epoch [85/300], Batch Step [290/323], D_loss: 0.7876,  G_loss: 1.5404\n",
      " Epoch [85/300], Batch Step [300/323], D_loss: 0.7657,  G_loss: 1.5795\n",
      " Epoch [85/300], Batch Step [310/323], D_loss: 0.6888,  G_loss: 1.4896\n",
      " Epoch [85/300], Batch Step [320/323], D_loss: 0.8985,  G_loss: 1.4039\n",
      " Epoch [86/300], Batch Step [0/323], D_loss: 0.7120,  G_loss: 1.5239\n",
      " Epoch [86/300], Batch Step [10/323], D_loss: 0.7150,  G_loss: 1.4599\n",
      " Epoch [86/300], Batch Step [20/323], D_loss: 0.8820,  G_loss: 1.3068\n",
      " Epoch [86/300], Batch Step [30/323], D_loss: 0.7709,  G_loss: 1.6198\n",
      " Epoch [86/300], Batch Step [40/323], D_loss: 0.5901,  G_loss: 1.4444\n",
      " Epoch [86/300], Batch Step [50/323], D_loss: 0.5790,  G_loss: 1.5295\n",
      " Epoch [86/300], Batch Step [60/323], D_loss: 0.6568,  G_loss: 1.3881\n",
      " Epoch [86/300], Batch Step [70/323], D_loss: 0.7911,  G_loss: 1.6137\n",
      " Epoch [86/300], Batch Step [80/323], D_loss: 0.7008,  G_loss: 1.4398\n",
      " Epoch [86/300], Batch Step [90/323], D_loss: 0.9180,  G_loss: 1.4242\n",
      " Epoch [86/300], Batch Step [100/323], D_loss: 0.6989,  G_loss: 1.4084\n",
      " Epoch [86/300], Batch Step [110/323], D_loss: 0.6378,  G_loss: 1.5238\n",
      " Epoch [86/300], Batch Step [120/323], D_loss: 0.6569,  G_loss: 1.4919\n",
      " Epoch [86/300], Batch Step [130/323], D_loss: 0.9113,  G_loss: 1.5527\n",
      " Epoch [86/300], Batch Step [140/323], D_loss: 0.6863,  G_loss: 1.5540\n",
      " Epoch [86/300], Batch Step [150/323], D_loss: 0.6051,  G_loss: 1.6531\n",
      " Epoch [86/300], Batch Step [160/323], D_loss: 0.7070,  G_loss: 1.3806\n",
      " Epoch [86/300], Batch Step [170/323], D_loss: 0.6128,  G_loss: 1.5343\n",
      " Epoch [86/300], Batch Step [180/323], D_loss: 0.6020,  G_loss: 1.4014\n",
      " Epoch [86/300], Batch Step [190/323], D_loss: 0.7271,  G_loss: 1.5889\n",
      " Epoch [86/300], Batch Step [200/323], D_loss: 0.8224,  G_loss: 1.4004\n",
      " Epoch [86/300], Batch Step [210/323], D_loss: 0.6839,  G_loss: 1.4747\n",
      " Epoch [86/300], Batch Step [220/323], D_loss: 0.5703,  G_loss: 1.5688\n",
      " Epoch [86/300], Batch Step [230/323], D_loss: 0.6958,  G_loss: 1.5404\n",
      " Epoch [86/300], Batch Step [240/323], D_loss: 0.7184,  G_loss: 1.4482\n",
      " Epoch [86/300], Batch Step [250/323], D_loss: 0.6987,  G_loss: 1.4533\n",
      " Epoch [86/300], Batch Step [260/323], D_loss: 0.8643,  G_loss: 1.5364\n",
      " Epoch [86/300], Batch Step [270/323], D_loss: 0.7817,  G_loss: 1.4684\n",
      " Epoch [86/300], Batch Step [280/323], D_loss: 0.7934,  G_loss: 1.4108\n",
      " Epoch [86/300], Batch Step [290/323], D_loss: 0.8573,  G_loss: 1.5088\n",
      " Epoch [86/300], Batch Step [300/323], D_loss: 0.6375,  G_loss: 1.5254\n",
      " Epoch [86/300], Batch Step [310/323], D_loss: 0.5716,  G_loss: 1.5623\n",
      " Epoch [86/300], Batch Step [320/323], D_loss: 0.8066,  G_loss: 1.4153\n",
      " Epoch [87/300], Batch Step [0/323], D_loss: 0.6756,  G_loss: 1.3324\n",
      " Epoch [87/300], Batch Step [10/323], D_loss: 0.6173,  G_loss: 1.5978\n",
      " Epoch [87/300], Batch Step [20/323], D_loss: 0.8495,  G_loss: 1.4454\n",
      " Epoch [87/300], Batch Step [30/323], D_loss: 0.7438,  G_loss: 1.5951\n",
      " Epoch [87/300], Batch Step [40/323], D_loss: 0.7873,  G_loss: 1.4091\n",
      " Epoch [87/300], Batch Step [50/323], D_loss: 0.8216,  G_loss: 1.5233\n",
      " Epoch [87/300], Batch Step [60/323], D_loss: 0.8635,  G_loss: 1.4108\n",
      " Epoch [87/300], Batch Step [70/323], D_loss: 0.9069,  G_loss: 1.6222\n",
      " Epoch [87/300], Batch Step [80/323], D_loss: 0.7694,  G_loss: 1.4304\n",
      " Epoch [87/300], Batch Step [90/323], D_loss: 0.7239,  G_loss: 1.4859\n",
      " Epoch [87/300], Batch Step [100/323], D_loss: 0.7723,  G_loss: 1.4087\n",
      " Epoch [87/300], Batch Step [110/323], D_loss: 0.6372,  G_loss: 1.5090\n",
      " Epoch [87/300], Batch Step [120/323], D_loss: 0.8390,  G_loss: 1.6029\n",
      " Epoch [87/300], Batch Step [130/323], D_loss: 0.6290,  G_loss: 1.4561\n",
      " Epoch [87/300], Batch Step [140/323], D_loss: 0.6558,  G_loss: 1.7302\n",
      " Epoch [87/300], Batch Step [150/323], D_loss: 0.7050,  G_loss: 1.4746\n",
      " Epoch [87/300], Batch Step [160/323], D_loss: 0.9280,  G_loss: 1.4186\n",
      " Epoch [87/300], Batch Step [170/323], D_loss: 0.8065,  G_loss: 1.5218\n",
      " Epoch [87/300], Batch Step [180/323], D_loss: 0.8077,  G_loss: 1.6171\n",
      " Epoch [87/300], Batch Step [190/323], D_loss: 0.7500,  G_loss: 1.3783\n",
      " Epoch [87/300], Batch Step [200/323], D_loss: 0.7354,  G_loss: 1.6011\n",
      " Epoch [87/300], Batch Step [210/323], D_loss: 0.7283,  G_loss: 1.3588\n",
      " Epoch [87/300], Batch Step [220/323], D_loss: 0.6272,  G_loss: 1.4520\n",
      " Epoch [87/300], Batch Step [230/323], D_loss: 0.8003,  G_loss: 1.3969\n",
      " Epoch [87/300], Batch Step [240/323], D_loss: 0.7139,  G_loss: 1.4796\n",
      " Epoch [87/300], Batch Step [250/323], D_loss: 0.5874,  G_loss: 1.5206\n",
      " Epoch [87/300], Batch Step [260/323], D_loss: 0.5939,  G_loss: 1.6729\n",
      " Epoch [87/300], Batch Step [270/323], D_loss: 0.7263,  G_loss: 1.6702\n",
      " Epoch [87/300], Batch Step [280/323], D_loss: 0.6889,  G_loss: 1.5085\n",
      " Epoch [87/300], Batch Step [290/323], D_loss: 0.7541,  G_loss: 1.5516\n",
      " Epoch [87/300], Batch Step [300/323], D_loss: 0.6958,  G_loss: 1.5548\n",
      " Epoch [87/300], Batch Step [310/323], D_loss: 0.8304,  G_loss: 1.3383\n",
      " Epoch [87/300], Batch Step [320/323], D_loss: 0.6548,  G_loss: 1.5301\n",
      " Epoch [88/300], Batch Step [0/323], D_loss: 0.6968,  G_loss: 1.4741\n",
      " Epoch [88/300], Batch Step [10/323], D_loss: 0.7016,  G_loss: 1.3737\n",
      " Epoch [88/300], Batch Step [20/323], D_loss: 0.6965,  G_loss: 1.3337\n",
      " Epoch [88/300], Batch Step [30/323], D_loss: 0.6630,  G_loss: 1.4477\n",
      " Epoch [88/300], Batch Step [40/323], D_loss: 0.5427,  G_loss: 1.5082\n",
      " Epoch [88/300], Batch Step [50/323], D_loss: 0.7555,  G_loss: 1.7202\n",
      " Epoch [88/300], Batch Step [60/323], D_loss: 0.6680,  G_loss: 1.4941\n",
      " Epoch [88/300], Batch Step [70/323], D_loss: 0.7435,  G_loss: 1.5520\n",
      " Epoch [88/300], Batch Step [80/323], D_loss: 0.6196,  G_loss: 1.5389\n",
      " Epoch [88/300], Batch Step [90/323], D_loss: 0.6744,  G_loss: 1.5550\n",
      " Epoch [88/300], Batch Step [100/323], D_loss: 0.7101,  G_loss: 1.5377\n",
      " Epoch [88/300], Batch Step [110/323], D_loss: 0.6982,  G_loss: 1.6163\n",
      " Epoch [88/300], Batch Step [120/323], D_loss: 0.8389,  G_loss: 1.4231\n",
      " Epoch [88/300], Batch Step [130/323], D_loss: 0.7283,  G_loss: 1.5833\n",
      " Epoch [88/300], Batch Step [140/323], D_loss: 0.8229,  G_loss: 1.5591\n",
      " Epoch [88/300], Batch Step [150/323], D_loss: 0.9546,  G_loss: 1.4494\n",
      " Epoch [88/300], Batch Step [160/323], D_loss: 0.7333,  G_loss: 1.4913\n",
      " Epoch [88/300], Batch Step [170/323], D_loss: 0.7223,  G_loss: 1.5297\n",
      " Epoch [88/300], Batch Step [180/323], D_loss: 0.5933,  G_loss: 1.5204\n",
      " Epoch [88/300], Batch Step [190/323], D_loss: 0.5083,  G_loss: 1.5915\n",
      " Epoch [88/300], Batch Step [200/323], D_loss: 0.6375,  G_loss: 1.5948\n",
      " Epoch [88/300], Batch Step [210/323], D_loss: 0.6611,  G_loss: 1.5598\n",
      " Epoch [88/300], Batch Step [220/323], D_loss: 0.7597,  G_loss: 1.4912\n",
      " Epoch [88/300], Batch Step [230/323], D_loss: 0.9916,  G_loss: 1.4214\n",
      " Epoch [88/300], Batch Step [240/323], D_loss: 0.7467,  G_loss: 1.4303\n",
      " Epoch [88/300], Batch Step [250/323], D_loss: 0.8565,  G_loss: 1.4337\n",
      " Epoch [88/300], Batch Step [260/323], D_loss: 0.8105,  G_loss: 1.3060\n",
      " Epoch [88/300], Batch Step [270/323], D_loss: 0.8448,  G_loss: 1.5789\n",
      " Epoch [88/300], Batch Step [280/323], D_loss: 0.7807,  G_loss: 1.3333\n",
      " Epoch [88/300], Batch Step [290/323], D_loss: 0.6676,  G_loss: 1.5425\n",
      " Epoch [88/300], Batch Step [300/323], D_loss: 0.7883,  G_loss: 1.4826\n",
      " Epoch [88/300], Batch Step [310/323], D_loss: 0.6008,  G_loss: 1.5185\n",
      " Epoch [88/300], Batch Step [320/323], D_loss: 0.6955,  G_loss: 1.5617\n",
      " Epoch [89/300], Batch Step [0/323], D_loss: 0.7308,  G_loss: 1.6015\n",
      " Epoch [89/300], Batch Step [10/323], D_loss: 0.6853,  G_loss: 1.4964\n",
      " Epoch [89/300], Batch Step [20/323], D_loss: 0.7323,  G_loss: 1.7178\n",
      " Epoch [89/300], Batch Step [30/323], D_loss: 0.7252,  G_loss: 1.4712\n",
      " Epoch [89/300], Batch Step [40/323], D_loss: 0.6408,  G_loss: 1.4467\n",
      " Epoch [89/300], Batch Step [50/323], D_loss: 0.7651,  G_loss: 1.4825\n",
      " Epoch [89/300], Batch Step [60/323], D_loss: 0.8178,  G_loss: 1.4774\n",
      " Epoch [89/300], Batch Step [70/323], D_loss: 0.6550,  G_loss: 1.4402\n",
      " Epoch [89/300], Batch Step [80/323], D_loss: 0.8334,  G_loss: 1.5152\n",
      " Epoch [89/300], Batch Step [90/323], D_loss: 0.7637,  G_loss: 1.4022\n",
      " Epoch [89/300], Batch Step [100/323], D_loss: 0.6397,  G_loss: 1.5570\n",
      " Epoch [89/300], Batch Step [110/323], D_loss: 0.6195,  G_loss: 1.5305\n",
      " Epoch [89/300], Batch Step [120/323], D_loss: 0.7150,  G_loss: 1.5743\n",
      " Epoch [89/300], Batch Step [130/323], D_loss: 0.7318,  G_loss: 1.6871\n",
      " Epoch [89/300], Batch Step [140/323], D_loss: 0.7367,  G_loss: 1.2804\n",
      " Epoch [89/300], Batch Step [150/323], D_loss: 0.5908,  G_loss: 1.6334\n",
      " Epoch [89/300], Batch Step [160/323], D_loss: 0.6535,  G_loss: 1.4890\n",
      " Epoch [89/300], Batch Step [170/323], D_loss: 0.8334,  G_loss: 1.5718\n",
      " Epoch [89/300], Batch Step [180/323], D_loss: 0.6417,  G_loss: 1.6423\n",
      " Epoch [89/300], Batch Step [190/323], D_loss: 0.5685,  G_loss: 1.5294\n",
      " Epoch [89/300], Batch Step [200/323], D_loss: 0.7763,  G_loss: 1.5164\n",
      " Epoch [89/300], Batch Step [210/323], D_loss: 0.6452,  G_loss: 1.4074\n",
      " Epoch [89/300], Batch Step [220/323], D_loss: 0.7576,  G_loss: 1.5338\n",
      " Epoch [89/300], Batch Step [230/323], D_loss: 0.7296,  G_loss: 1.3447\n",
      " Epoch [89/300], Batch Step [240/323], D_loss: 0.6981,  G_loss: 1.6226\n",
      " Epoch [89/300], Batch Step [250/323], D_loss: 0.7070,  G_loss: 1.4111\n",
      " Epoch [89/300], Batch Step [260/323], D_loss: 0.7235,  G_loss: 1.5332\n",
      " Epoch [89/300], Batch Step [270/323], D_loss: 0.5793,  G_loss: 1.4467\n",
      " Epoch [89/300], Batch Step [280/323], D_loss: 0.7128,  G_loss: 1.5512\n",
      " Epoch [89/300], Batch Step [290/323], D_loss: 0.8702,  G_loss: 1.5229\n",
      " Epoch [89/300], Batch Step [300/323], D_loss: 0.7711,  G_loss: 1.3728\n",
      " Epoch [89/300], Batch Step [310/323], D_loss: 0.6427,  G_loss: 1.5860\n",
      " Epoch [89/300], Batch Step [320/323], D_loss: 0.7438,  G_loss: 1.3711\n",
      " Epoch [90/300], Batch Step [0/323], D_loss: 0.8280,  G_loss: 1.4084\n",
      " Epoch [90/300], Batch Step [10/323], D_loss: 0.8007,  G_loss: 1.6227\n",
      " Epoch [90/300], Batch Step [20/323], D_loss: 0.6820,  G_loss: 1.4045\n",
      " Epoch [90/300], Batch Step [30/323], D_loss: 0.7246,  G_loss: 1.4257\n",
      " Epoch [90/300], Batch Step [40/323], D_loss: 0.7934,  G_loss: 1.4941\n",
      " Epoch [90/300], Batch Step [50/323], D_loss: 0.6644,  G_loss: 1.4894\n",
      " Epoch [90/300], Batch Step [60/323], D_loss: 0.6638,  G_loss: 1.6072\n",
      " Epoch [90/300], Batch Step [70/323], D_loss: 0.5451,  G_loss: 1.4538\n",
      " Epoch [90/300], Batch Step [80/323], D_loss: 0.7961,  G_loss: 1.4394\n",
      " Epoch [90/300], Batch Step [90/323], D_loss: 0.8109,  G_loss: 1.5568\n",
      " Epoch [90/300], Batch Step [100/323], D_loss: 0.6380,  G_loss: 1.6247\n",
      " Epoch [90/300], Batch Step [110/323], D_loss: 0.7186,  G_loss: 1.5551\n",
      " Epoch [90/300], Batch Step [120/323], D_loss: 0.7731,  G_loss: 1.4840\n",
      " Epoch [90/300], Batch Step [130/323], D_loss: 0.7937,  G_loss: 1.4676\n",
      " Epoch [90/300], Batch Step [140/323], D_loss: 0.7845,  G_loss: 1.6222\n",
      " Epoch [90/300], Batch Step [150/323], D_loss: 0.6389,  G_loss: 1.4337\n",
      " Epoch [90/300], Batch Step [160/323], D_loss: 0.7112,  G_loss: 1.5384\n",
      " Epoch [90/300], Batch Step [170/323], D_loss: 0.7697,  G_loss: 1.4711\n",
      " Epoch [90/300], Batch Step [180/323], D_loss: 0.5907,  G_loss: 1.4445\n",
      " Epoch [90/300], Batch Step [190/323], D_loss: 0.6633,  G_loss: 1.5426\n",
      " Epoch [90/300], Batch Step [200/323], D_loss: 0.6678,  G_loss: 1.2933\n",
      " Epoch [90/300], Batch Step [210/323], D_loss: 0.6745,  G_loss: 1.4900\n",
      " Epoch [90/300], Batch Step [220/323], D_loss: 0.6133,  G_loss: 1.6050\n",
      " Epoch [90/300], Batch Step [230/323], D_loss: 0.8670,  G_loss: 1.6450\n",
      " Epoch [90/300], Batch Step [240/323], D_loss: 0.7695,  G_loss: 1.4320\n",
      " Epoch [90/300], Batch Step [250/323], D_loss: 0.6274,  G_loss: 1.4730\n",
      " Epoch [90/300], Batch Step [260/323], D_loss: 0.6449,  G_loss: 1.4611\n",
      " Epoch [90/300], Batch Step [270/323], D_loss: 0.6906,  G_loss: 1.3995\n",
      " Epoch [90/300], Batch Step [280/323], D_loss: 0.6552,  G_loss: 1.4378\n",
      " Epoch [90/300], Batch Step [290/323], D_loss: 0.7453,  G_loss: 1.5257\n",
      " Epoch [90/300], Batch Step [300/323], D_loss: 0.5998,  G_loss: 1.6269\n",
      " Epoch [90/300], Batch Step [310/323], D_loss: 0.6150,  G_loss: 1.6224\n",
      " Epoch [90/300], Batch Step [320/323], D_loss: 0.5908,  G_loss: 1.4383\n",
      " Epoch [91/300], Batch Step [0/323], D_loss: 0.6490,  G_loss: 1.3682\n",
      " Epoch [91/300], Batch Step [10/323], D_loss: 0.6148,  G_loss: 1.4931\n",
      " Epoch [91/300], Batch Step [20/323], D_loss: 0.7839,  G_loss: 1.4151\n",
      " Epoch [91/300], Batch Step [30/323], D_loss: 0.7752,  G_loss: 1.6789\n",
      " Epoch [91/300], Batch Step [40/323], D_loss: 0.6199,  G_loss: 1.3053\n",
      " Epoch [91/300], Batch Step [50/323], D_loss: 0.7176,  G_loss: 1.4895\n",
      " Epoch [91/300], Batch Step [60/323], D_loss: 0.6931,  G_loss: 1.5411\n",
      " Epoch [91/300], Batch Step [70/323], D_loss: 0.7698,  G_loss: 1.5425\n",
      " Epoch [91/300], Batch Step [80/323], D_loss: 0.7575,  G_loss: 1.5520\n",
      " Epoch [91/300], Batch Step [90/323], D_loss: 0.9515,  G_loss: 1.3488\n",
      " Epoch [91/300], Batch Step [100/323], D_loss: 0.6885,  G_loss: 1.4951\n",
      " Epoch [91/300], Batch Step [110/323], D_loss: 0.6175,  G_loss: 1.4974\n",
      " Epoch [91/300], Batch Step [120/323], D_loss: 0.6229,  G_loss: 1.4070\n",
      " Epoch [91/300], Batch Step [130/323], D_loss: 0.6567,  G_loss: 1.5188\n",
      " Epoch [91/300], Batch Step [140/323], D_loss: 0.5211,  G_loss: 1.7061\n",
      " Epoch [91/300], Batch Step [150/323], D_loss: 0.7294,  G_loss: 1.5716\n",
      " Epoch [91/300], Batch Step [160/323], D_loss: 0.7526,  G_loss: 1.4312\n",
      " Epoch [91/300], Batch Step [170/323], D_loss: 0.8017,  G_loss: 1.4808\n",
      " Epoch [91/300], Batch Step [180/323], D_loss: 0.6818,  G_loss: 1.4212\n",
      " Epoch [91/300], Batch Step [190/323], D_loss: 0.6575,  G_loss: 1.5286\n",
      " Epoch [91/300], Batch Step [200/323], D_loss: 0.8093,  G_loss: 1.5370\n",
      " Epoch [91/300], Batch Step [210/323], D_loss: 0.8055,  G_loss: 1.5432\n",
      " Epoch [91/300], Batch Step [220/323], D_loss: 0.8450,  G_loss: 1.5139\n",
      " Epoch [91/300], Batch Step [230/323], D_loss: 0.6267,  G_loss: 1.4584\n",
      " Epoch [91/300], Batch Step [240/323], D_loss: 0.9057,  G_loss: 1.5651\n",
      " Epoch [91/300], Batch Step [250/323], D_loss: 0.6440,  G_loss: 1.4371\n",
      " Epoch [91/300], Batch Step [260/323], D_loss: 0.7894,  G_loss: 1.6122\n",
      " Epoch [91/300], Batch Step [270/323], D_loss: 0.7567,  G_loss: 1.4680\n",
      " Epoch [91/300], Batch Step [280/323], D_loss: 0.6527,  G_loss: 1.5360\n",
      " Epoch [91/300], Batch Step [290/323], D_loss: 0.7227,  G_loss: 1.5846\n",
      " Epoch [91/300], Batch Step [300/323], D_loss: 0.6075,  G_loss: 1.5671\n",
      " Epoch [91/300], Batch Step [310/323], D_loss: 0.5943,  G_loss: 1.5178\n",
      " Epoch [91/300], Batch Step [320/323], D_loss: 0.8505,  G_loss: 1.5800\n",
      " Epoch [92/300], Batch Step [0/323], D_loss: 0.7569,  G_loss: 1.6119\n",
      " Epoch [92/300], Batch Step [10/323], D_loss: 0.5828,  G_loss: 1.5366\n",
      " Epoch [92/300], Batch Step [20/323], D_loss: 0.7121,  G_loss: 1.5760\n",
      " Epoch [92/300], Batch Step [30/323], D_loss: 0.8097,  G_loss: 1.3862\n",
      " Epoch [92/300], Batch Step [40/323], D_loss: 0.6477,  G_loss: 1.6160\n",
      " Epoch [92/300], Batch Step [50/323], D_loss: 0.7646,  G_loss: 1.5041\n",
      " Epoch [92/300], Batch Step [60/323], D_loss: 0.6830,  G_loss: 1.5266\n",
      " Epoch [92/300], Batch Step [70/323], D_loss: 0.6990,  G_loss: 1.6971\n",
      " Epoch [92/300], Batch Step [80/323], D_loss: 0.6389,  G_loss: 1.4160\n",
      " Epoch [92/300], Batch Step [90/323], D_loss: 0.5356,  G_loss: 1.5353\n",
      " Epoch [92/300], Batch Step [100/323], D_loss: 0.7069,  G_loss: 1.6790\n",
      " Epoch [92/300], Batch Step [110/323], D_loss: 0.8933,  G_loss: 1.3291\n",
      " Epoch [92/300], Batch Step [120/323], D_loss: 0.6780,  G_loss: 1.5620\n",
      " Epoch [92/300], Batch Step [130/323], D_loss: 0.6590,  G_loss: 1.4752\n",
      " Epoch [92/300], Batch Step [140/323], D_loss: 0.7446,  G_loss: 1.3817\n",
      " Epoch [92/300], Batch Step [150/323], D_loss: 0.7748,  G_loss: 1.5383\n",
      " Epoch [92/300], Batch Step [160/323], D_loss: 0.6871,  G_loss: 1.3986\n",
      " Epoch [92/300], Batch Step [170/323], D_loss: 0.6389,  G_loss: 1.7130\n",
      " Epoch [92/300], Batch Step [180/323], D_loss: 0.7594,  G_loss: 1.2355\n",
      " Epoch [92/300], Batch Step [190/323], D_loss: 0.6781,  G_loss: 1.5965\n",
      " Epoch [92/300], Batch Step [200/323], D_loss: 0.7734,  G_loss: 1.6008\n",
      " Epoch [92/300], Batch Step [210/323], D_loss: 0.6970,  G_loss: 1.4139\n",
      " Epoch [92/300], Batch Step [220/323], D_loss: 0.7956,  G_loss: 1.4363\n",
      " Epoch [92/300], Batch Step [230/323], D_loss: 0.6810,  G_loss: 1.6254\n",
      " Epoch [92/300], Batch Step [240/323], D_loss: 0.7345,  G_loss: 1.4902\n",
      " Epoch [92/300], Batch Step [250/323], D_loss: 0.7668,  G_loss: 1.5309\n",
      " Epoch [92/300], Batch Step [260/323], D_loss: 0.6261,  G_loss: 1.3994\n",
      " Epoch [92/300], Batch Step [270/323], D_loss: 0.4821,  G_loss: 1.6090\n",
      " Epoch [92/300], Batch Step [280/323], D_loss: 0.9208,  G_loss: 1.4800\n",
      " Epoch [92/300], Batch Step [290/323], D_loss: 0.7731,  G_loss: 1.5725\n",
      " Epoch [92/300], Batch Step [300/323], D_loss: 0.6741,  G_loss: 1.6458\n",
      " Epoch [92/300], Batch Step [310/323], D_loss: 0.6770,  G_loss: 1.4582\n",
      " Epoch [92/300], Batch Step [320/323], D_loss: 0.6522,  G_loss: 1.6212\n",
      " Epoch [93/300], Batch Step [0/323], D_loss: 0.6565,  G_loss: 1.5204\n",
      " Epoch [93/300], Batch Step [10/323], D_loss: 0.6384,  G_loss: 1.5602\n",
      " Epoch [93/300], Batch Step [20/323], D_loss: 0.8063,  G_loss: 1.4436\n",
      " Epoch [93/300], Batch Step [30/323], D_loss: 0.6924,  G_loss: 1.4931\n",
      " Epoch [93/300], Batch Step [40/323], D_loss: 0.7640,  G_loss: 1.4887\n",
      " Epoch [93/300], Batch Step [50/323], D_loss: 0.6747,  G_loss: 1.4191\n",
      " Epoch [93/300], Batch Step [60/323], D_loss: 0.6237,  G_loss: 1.5106\n",
      " Epoch [93/300], Batch Step [70/323], D_loss: 0.7264,  G_loss: 1.4736\n",
      " Epoch [93/300], Batch Step [80/323], D_loss: 0.7405,  G_loss: 1.5488\n",
      " Epoch [93/300], Batch Step [90/323], D_loss: 1.0045,  G_loss: 1.6283\n",
      " Epoch [93/300], Batch Step [100/323], D_loss: 0.6671,  G_loss: 1.4256\n",
      " Epoch [93/300], Batch Step [110/323], D_loss: 0.7612,  G_loss: 1.4416\n",
      " Epoch [93/300], Batch Step [120/323], D_loss: 0.7295,  G_loss: 1.5730\n",
      " Epoch [93/300], Batch Step [130/323], D_loss: 0.7793,  G_loss: 1.5612\n",
      " Epoch [93/300], Batch Step [140/323], D_loss: 0.6990,  G_loss: 1.5988\n",
      " Epoch [93/300], Batch Step [150/323], D_loss: 0.7988,  G_loss: 1.6228\n",
      " Epoch [93/300], Batch Step [160/323], D_loss: 0.9348,  G_loss: 1.4703\n",
      " Epoch [93/300], Batch Step [170/323], D_loss: 0.6904,  G_loss: 1.5820\n",
      " Epoch [93/300], Batch Step [180/323], D_loss: 0.6552,  G_loss: 1.4981\n",
      " Epoch [93/300], Batch Step [190/323], D_loss: 0.7414,  G_loss: 1.4277\n",
      " Epoch [93/300], Batch Step [200/323], D_loss: 0.6008,  G_loss: 1.4810\n",
      " Epoch [93/300], Batch Step [210/323], D_loss: 0.8326,  G_loss: 1.5996\n",
      " Epoch [93/300], Batch Step [220/323], D_loss: 0.8052,  G_loss: 1.4518\n",
      " Epoch [93/300], Batch Step [230/323], D_loss: 0.7619,  G_loss: 1.5280\n",
      " Epoch [93/300], Batch Step [240/323], D_loss: 0.7087,  G_loss: 1.6147\n",
      " Epoch [93/300], Batch Step [250/323], D_loss: 0.7044,  G_loss: 1.4226\n",
      " Epoch [93/300], Batch Step [260/323], D_loss: 0.6483,  G_loss: 1.4455\n",
      " Epoch [93/300], Batch Step [270/323], D_loss: 0.8172,  G_loss: 1.6197\n",
      " Epoch [93/300], Batch Step [280/323], D_loss: 0.7391,  G_loss: 1.4012\n",
      " Epoch [93/300], Batch Step [290/323], D_loss: 0.7655,  G_loss: 1.5488\n",
      " Epoch [93/300], Batch Step [300/323], D_loss: 0.6594,  G_loss: 1.5348\n",
      " Epoch [93/300], Batch Step [310/323], D_loss: 0.5829,  G_loss: 1.5375\n",
      " Epoch [93/300], Batch Step [320/323], D_loss: 0.7406,  G_loss: 1.4892\n",
      " Epoch [94/300], Batch Step [0/323], D_loss: 0.7960,  G_loss: 1.4543\n",
      " Epoch [94/300], Batch Step [10/323], D_loss: 0.6567,  G_loss: 1.4334\n",
      " Epoch [94/300], Batch Step [20/323], D_loss: 0.6642,  G_loss: 1.6136\n",
      " Epoch [94/300], Batch Step [30/323], D_loss: 0.7243,  G_loss: 1.5189\n",
      " Epoch [94/300], Batch Step [40/323], D_loss: 0.6821,  G_loss: 1.4916\n",
      " Epoch [94/300], Batch Step [50/323], D_loss: 0.5184,  G_loss: 1.5898\n",
      " Epoch [94/300], Batch Step [60/323], D_loss: 0.6947,  G_loss: 1.5742\n",
      " Epoch [94/300], Batch Step [70/323], D_loss: 0.7878,  G_loss: 1.4859\n",
      " Epoch [94/300], Batch Step [80/323], D_loss: 0.7361,  G_loss: 1.4059\n",
      " Epoch [94/300], Batch Step [90/323], D_loss: 0.7908,  G_loss: 1.5033\n",
      " Epoch [94/300], Batch Step [100/323], D_loss: 0.9027,  G_loss: 1.4823\n",
      " Epoch [94/300], Batch Step [110/323], D_loss: 0.6037,  G_loss: 1.5324\n",
      " Epoch [94/300], Batch Step [120/323], D_loss: 0.6160,  G_loss: 1.5619\n",
      " Epoch [94/300], Batch Step [130/323], D_loss: 0.7234,  G_loss: 1.5903\n",
      " Epoch [94/300], Batch Step [140/323], D_loss: 0.7709,  G_loss: 1.5358\n",
      " Epoch [94/300], Batch Step [150/323], D_loss: 0.7360,  G_loss: 1.5364\n",
      " Epoch [94/300], Batch Step [160/323], D_loss: 0.7307,  G_loss: 1.5612\n",
      " Epoch [94/300], Batch Step [170/323], D_loss: 0.7438,  G_loss: 1.5768\n",
      " Epoch [94/300], Batch Step [180/323], D_loss: 0.6985,  G_loss: 1.4636\n",
      " Epoch [94/300], Batch Step [190/323], D_loss: 0.7394,  G_loss: 1.4912\n",
      " Epoch [94/300], Batch Step [200/323], D_loss: 0.6766,  G_loss: 1.4220\n",
      " Epoch [94/300], Batch Step [210/323], D_loss: 0.7942,  G_loss: 1.6194\n",
      " Epoch [94/300], Batch Step [220/323], D_loss: 0.7936,  G_loss: 1.3405\n",
      " Epoch [94/300], Batch Step [230/323], D_loss: 0.7514,  G_loss: 1.5649\n",
      " Epoch [94/300], Batch Step [240/323], D_loss: 0.6874,  G_loss: 1.4139\n",
      " Epoch [94/300], Batch Step [250/323], D_loss: 0.6368,  G_loss: 1.5543\n",
      " Epoch [94/300], Batch Step [260/323], D_loss: 0.6707,  G_loss: 1.5812\n",
      " Epoch [94/300], Batch Step [270/323], D_loss: 0.6492,  G_loss: 1.6608\n",
      " Epoch [94/300], Batch Step [280/323], D_loss: 0.6840,  G_loss: 1.5801\n",
      " Epoch [94/300], Batch Step [290/323], D_loss: 0.8128,  G_loss: 1.3519\n",
      " Epoch [94/300], Batch Step [300/323], D_loss: 0.8380,  G_loss: 1.5427\n",
      " Epoch [94/300], Batch Step [310/323], D_loss: 0.8272,  G_loss: 1.4301\n",
      " Epoch [94/300], Batch Step [320/323], D_loss: 0.7419,  G_loss: 1.4340\n",
      " Epoch [95/300], Batch Step [0/323], D_loss: 0.7702,  G_loss: 1.4442\n",
      " Epoch [95/300], Batch Step [10/323], D_loss: 0.8014,  G_loss: 1.5638\n",
      " Epoch [95/300], Batch Step [20/323], D_loss: 0.8984,  G_loss: 1.4323\n",
      " Epoch [95/300], Batch Step [30/323], D_loss: 0.5739,  G_loss: 1.6014\n",
      " Epoch [95/300], Batch Step [40/323], D_loss: 0.7620,  G_loss: 1.4221\n",
      " Epoch [95/300], Batch Step [50/323], D_loss: 0.6540,  G_loss: 1.5482\n",
      " Epoch [95/300], Batch Step [60/323], D_loss: 0.6870,  G_loss: 1.6834\n",
      " Epoch [95/300], Batch Step [70/323], D_loss: 0.8053,  G_loss: 1.4338\n",
      " Epoch [95/300], Batch Step [80/323], D_loss: 0.5685,  G_loss: 1.5373\n",
      " Epoch [95/300], Batch Step [90/323], D_loss: 0.8266,  G_loss: 1.6369\n",
      " Epoch [95/300], Batch Step [100/323], D_loss: 0.7189,  G_loss: 1.2664\n",
      " Epoch [95/300], Batch Step [110/323], D_loss: 0.7420,  G_loss: 1.5274\n",
      " Epoch [95/300], Batch Step [120/323], D_loss: 0.7636,  G_loss: 1.4544\n",
      " Epoch [95/300], Batch Step [130/323], D_loss: 0.7480,  G_loss: 1.4529\n",
      " Epoch [95/300], Batch Step [140/323], D_loss: 0.6642,  G_loss: 1.5424\n",
      " Epoch [95/300], Batch Step [150/323], D_loss: 0.7764,  G_loss: 1.6966\n",
      " Epoch [95/300], Batch Step [160/323], D_loss: 0.5970,  G_loss: 1.4511\n",
      " Epoch [95/300], Batch Step [170/323], D_loss: 0.8599,  G_loss: 1.4576\n",
      " Epoch [95/300], Batch Step [180/323], D_loss: 0.5988,  G_loss: 1.4592\n",
      " Epoch [95/300], Batch Step [190/323], D_loss: 0.5950,  G_loss: 1.4697\n",
      " Epoch [95/300], Batch Step [200/323], D_loss: 0.6907,  G_loss: 1.5730\n",
      " Epoch [95/300], Batch Step [210/323], D_loss: 0.8455,  G_loss: 1.5253\n",
      " Epoch [95/300], Batch Step [220/323], D_loss: 0.6749,  G_loss: 1.5747\n",
      " Epoch [95/300], Batch Step [230/323], D_loss: 0.6344,  G_loss: 1.5731\n",
      " Epoch [95/300], Batch Step [240/323], D_loss: 0.9277,  G_loss: 1.4989\n",
      " Epoch [95/300], Batch Step [250/323], D_loss: 0.6979,  G_loss: 1.3667\n",
      " Epoch [95/300], Batch Step [260/323], D_loss: 0.6819,  G_loss: 1.5188\n",
      " Epoch [95/300], Batch Step [270/323], D_loss: 0.5580,  G_loss: 1.5325\n",
      " Epoch [95/300], Batch Step [280/323], D_loss: 0.8945,  G_loss: 1.5263\n",
      " Epoch [95/300], Batch Step [290/323], D_loss: 0.6424,  G_loss: 1.5886\n",
      " Epoch [95/300], Batch Step [300/323], D_loss: 0.6529,  G_loss: 1.6845\n",
      " Epoch [95/300], Batch Step [310/323], D_loss: 0.7356,  G_loss: 1.4507\n",
      " Epoch [95/300], Batch Step [320/323], D_loss: 0.7724,  G_loss: 1.5071\n",
      " Epoch [96/300], Batch Step [0/323], D_loss: 0.7202,  G_loss: 1.5122\n",
      " Epoch [96/300], Batch Step [10/323], D_loss: 0.7976,  G_loss: 1.4390\n",
      " Epoch [96/300], Batch Step [20/323], D_loss: 0.7047,  G_loss: 1.4172\n",
      " Epoch [96/300], Batch Step [30/323], D_loss: 0.8178,  G_loss: 1.5494\n",
      " Epoch [96/300], Batch Step [40/323], D_loss: 0.7561,  G_loss: 1.5121\n",
      " Epoch [96/300], Batch Step [50/323], D_loss: 0.7108,  G_loss: 1.5153\n",
      " Epoch [96/300], Batch Step [60/323], D_loss: 0.7436,  G_loss: 1.4334\n",
      " Epoch [96/300], Batch Step [70/323], D_loss: 0.6463,  G_loss: 1.5960\n",
      " Epoch [96/300], Batch Step [80/323], D_loss: 0.7757,  G_loss: 1.4040\n",
      " Epoch [96/300], Batch Step [90/323], D_loss: 0.6680,  G_loss: 1.5556\n",
      " Epoch [96/300], Batch Step [100/323], D_loss: 0.8212,  G_loss: 1.5308\n",
      " Epoch [96/300], Batch Step [110/323], D_loss: 0.7125,  G_loss: 1.4472\n",
      " Epoch [96/300], Batch Step [120/323], D_loss: 0.7151,  G_loss: 1.4591\n",
      " Epoch [96/300], Batch Step [130/323], D_loss: 0.8323,  G_loss: 1.4458\n",
      " Epoch [96/300], Batch Step [140/323], D_loss: 0.8228,  G_loss: 1.5233\n",
      " Epoch [96/300], Batch Step [150/323], D_loss: 0.6918,  G_loss: 1.3886\n",
      " Epoch [96/300], Batch Step [160/323], D_loss: 0.6378,  G_loss: 1.6679\n",
      " Epoch [96/300], Batch Step [170/323], D_loss: 0.6718,  G_loss: 1.7325\n",
      " Epoch [96/300], Batch Step [180/323], D_loss: 0.7609,  G_loss: 1.3388\n",
      " Epoch [96/300], Batch Step [190/323], D_loss: 0.8468,  G_loss: 1.4750\n",
      " Epoch [96/300], Batch Step [200/323], D_loss: 0.7657,  G_loss: 1.4952\n",
      " Epoch [96/300], Batch Step [210/323], D_loss: 0.8301,  G_loss: 1.4799\n",
      " Epoch [96/300], Batch Step [220/323], D_loss: 0.6968,  G_loss: 1.4014\n",
      " Epoch [96/300], Batch Step [230/323], D_loss: 0.5863,  G_loss: 1.6640\n",
      " Epoch [96/300], Batch Step [240/323], D_loss: 0.6227,  G_loss: 1.4520\n",
      " Epoch [96/300], Batch Step [250/323], D_loss: 0.7293,  G_loss: 1.5580\n",
      " Epoch [96/300], Batch Step [260/323], D_loss: 0.6972,  G_loss: 1.4857\n",
      " Epoch [96/300], Batch Step [270/323], D_loss: 0.8553,  G_loss: 1.4790\n",
      " Epoch [96/300], Batch Step [280/323], D_loss: 0.6951,  G_loss: 1.4224\n",
      " Epoch [96/300], Batch Step [290/323], D_loss: 0.5764,  G_loss: 1.6035\n",
      " Epoch [96/300], Batch Step [300/323], D_loss: 0.7044,  G_loss: 1.6209\n",
      " Epoch [96/300], Batch Step [310/323], D_loss: 0.6540,  G_loss: 1.5378\n",
      " Epoch [96/300], Batch Step [320/323], D_loss: 0.6836,  G_loss: 1.5914\n",
      " Epoch [97/300], Batch Step [0/323], D_loss: 0.8357,  G_loss: 1.5329\n",
      " Epoch [97/300], Batch Step [10/323], D_loss: 0.6079,  G_loss: 1.4397\n",
      " Epoch [97/300], Batch Step [20/323], D_loss: 0.7927,  G_loss: 1.5410\n",
      " Epoch [97/300], Batch Step [30/323], D_loss: 0.6260,  G_loss: 1.6054\n",
      " Epoch [97/300], Batch Step [40/323], D_loss: 0.8787,  G_loss: 1.4470\n",
      " Epoch [97/300], Batch Step [50/323], D_loss: 0.7836,  G_loss: 1.3607\n",
      " Epoch [97/300], Batch Step [60/323], D_loss: 0.4835,  G_loss: 1.5713\n",
      " Epoch [97/300], Batch Step [70/323], D_loss: 0.7833,  G_loss: 1.5451\n",
      " Epoch [97/300], Batch Step [80/323], D_loss: 0.5485,  G_loss: 1.3889\n",
      " Epoch [97/300], Batch Step [90/323], D_loss: 0.8655,  G_loss: 1.8079\n",
      " Epoch [97/300], Batch Step [100/323], D_loss: 0.6439,  G_loss: 1.4211\n",
      " Epoch [97/300], Batch Step [110/323], D_loss: 0.7569,  G_loss: 1.5973\n",
      " Epoch [97/300], Batch Step [120/323], D_loss: 0.6496,  G_loss: 1.5649\n",
      " Epoch [97/300], Batch Step [130/323], D_loss: 0.5451,  G_loss: 1.4185\n",
      " Epoch [97/300], Batch Step [140/323], D_loss: 0.7002,  G_loss: 1.4875\n",
      " Epoch [97/300], Batch Step [150/323], D_loss: 0.7279,  G_loss: 1.4282\n",
      " Epoch [97/300], Batch Step [160/323], D_loss: 0.6657,  G_loss: 1.5295\n",
      " Epoch [97/300], Batch Step [170/323], D_loss: 0.7005,  G_loss: 1.4443\n",
      " Epoch [97/300], Batch Step [180/323], D_loss: 0.7499,  G_loss: 1.4696\n",
      " Epoch [97/300], Batch Step [190/323], D_loss: 0.7534,  G_loss: 1.6280\n",
      " Epoch [97/300], Batch Step [200/323], D_loss: 0.5935,  G_loss: 1.4036\n",
      " Epoch [97/300], Batch Step [210/323], D_loss: 0.5936,  G_loss: 1.5663\n",
      " Epoch [97/300], Batch Step [220/323], D_loss: 0.4866,  G_loss: 1.4664\n",
      " Epoch [97/300], Batch Step [230/323], D_loss: 0.7037,  G_loss: 1.4425\n",
      " Epoch [97/300], Batch Step [240/323], D_loss: 0.6671,  G_loss: 1.4328\n",
      " Epoch [97/300], Batch Step [250/323], D_loss: 0.6112,  G_loss: 1.6189\n",
      " Epoch [97/300], Batch Step [260/323], D_loss: 0.7131,  G_loss: 1.6247\n",
      " Epoch [97/300], Batch Step [270/323], D_loss: 0.6742,  G_loss: 1.4994\n",
      " Epoch [97/300], Batch Step [280/323], D_loss: 0.7943,  G_loss: 1.5660\n",
      " Epoch [97/300], Batch Step [290/323], D_loss: 0.8240,  G_loss: 1.5874\n",
      " Epoch [97/300], Batch Step [300/323], D_loss: 0.6153,  G_loss: 1.5513\n",
      " Epoch [97/300], Batch Step [310/323], D_loss: 0.8031,  G_loss: 1.4916\n",
      " Epoch [97/300], Batch Step [320/323], D_loss: 0.7042,  G_loss: 1.6321\n",
      " Epoch [98/300], Batch Step [0/323], D_loss: 0.6426,  G_loss: 1.5731\n",
      " Epoch [98/300], Batch Step [10/323], D_loss: 0.6945,  G_loss: 1.4741\n",
      " Epoch [98/300], Batch Step [20/323], D_loss: 0.6584,  G_loss: 1.5555\n",
      " Epoch [98/300], Batch Step [30/323], D_loss: 0.5956,  G_loss: 1.4707\n",
      " Epoch [98/300], Batch Step [40/323], D_loss: 0.7304,  G_loss: 1.5566\n",
      " Epoch [98/300], Batch Step [50/323], D_loss: 0.5883,  G_loss: 1.5662\n",
      " Epoch [98/300], Batch Step [60/323], D_loss: 0.7685,  G_loss: 1.5479\n",
      " Epoch [98/300], Batch Step [70/323], D_loss: 0.7774,  G_loss: 1.5199\n",
      " Epoch [98/300], Batch Step [80/323], D_loss: 0.5354,  G_loss: 1.4879\n",
      " Epoch [98/300], Batch Step [90/323], D_loss: 0.6722,  G_loss: 1.5176\n",
      " Epoch [98/300], Batch Step [100/323], D_loss: 0.7279,  G_loss: 1.5097\n",
      " Epoch [98/300], Batch Step [110/323], D_loss: 0.7660,  G_loss: 1.6509\n",
      " Epoch [98/300], Batch Step [120/323], D_loss: 0.7203,  G_loss: 1.4577\n",
      " Epoch [98/300], Batch Step [130/323], D_loss: 0.7394,  G_loss: 1.5935\n",
      " Epoch [98/300], Batch Step [140/323], D_loss: 0.6722,  G_loss: 1.4696\n",
      " Epoch [98/300], Batch Step [150/323], D_loss: 0.5924,  G_loss: 1.5347\n",
      " Epoch [98/300], Batch Step [160/323], D_loss: 0.5743,  G_loss: 1.4596\n",
      " Epoch [98/300], Batch Step [170/323], D_loss: 0.7212,  G_loss: 1.3624\n",
      " Epoch [98/300], Batch Step [180/323], D_loss: 0.7943,  G_loss: 1.7290\n",
      " Epoch [98/300], Batch Step [190/323], D_loss: 0.5951,  G_loss: 1.3849\n",
      " Epoch [98/300], Batch Step [200/323], D_loss: 0.5637,  G_loss: 1.6449\n",
      " Epoch [98/300], Batch Step [210/323], D_loss: 0.8090,  G_loss: 1.3986\n",
      " Epoch [98/300], Batch Step [220/323], D_loss: 0.9277,  G_loss: 1.5336\n",
      " Epoch [98/300], Batch Step [230/323], D_loss: 0.7018,  G_loss: 1.4390\n",
      " Epoch [98/300], Batch Step [240/323], D_loss: 0.8952,  G_loss: 1.4924\n",
      " Epoch [98/300], Batch Step [250/323], D_loss: 0.5661,  G_loss: 1.6109\n",
      " Epoch [98/300], Batch Step [260/323], D_loss: 0.8414,  G_loss: 1.4938\n",
      " Epoch [98/300], Batch Step [270/323], D_loss: 0.6345,  G_loss: 1.4592\n",
      " Epoch [98/300], Batch Step [280/323], D_loss: 0.7332,  G_loss: 1.6129\n",
      " Epoch [98/300], Batch Step [290/323], D_loss: 0.7953,  G_loss: 1.5816\n",
      " Epoch [98/300], Batch Step [300/323], D_loss: 0.7218,  G_loss: 1.4627\n",
      " Epoch [98/300], Batch Step [310/323], D_loss: 0.8943,  G_loss: 1.4077\n",
      " Epoch [98/300], Batch Step [320/323], D_loss: 0.6344,  G_loss: 1.6478\n",
      " Epoch [99/300], Batch Step [0/323], D_loss: 0.7430,  G_loss: 1.5381\n",
      " Epoch [99/300], Batch Step [10/323], D_loss: 0.5997,  G_loss: 1.4601\n",
      " Epoch [99/300], Batch Step [20/323], D_loss: 0.6435,  G_loss: 1.5571\n",
      " Epoch [99/300], Batch Step [30/323], D_loss: 0.6557,  G_loss: 1.4346\n",
      " Epoch [99/300], Batch Step [40/323], D_loss: 0.7379,  G_loss: 1.5820\n",
      " Epoch [99/300], Batch Step [50/323], D_loss: 0.6345,  G_loss: 1.5012\n",
      " Epoch [99/300], Batch Step [60/323], D_loss: 0.7088,  G_loss: 1.5597\n",
      " Epoch [99/300], Batch Step [70/323], D_loss: 0.7799,  G_loss: 1.5879\n",
      " Epoch [99/300], Batch Step [80/323], D_loss: 0.7472,  G_loss: 1.2317\n",
      " Epoch [99/300], Batch Step [90/323], D_loss: 0.5875,  G_loss: 1.5916\n",
      " Epoch [99/300], Batch Step [100/323], D_loss: 0.7455,  G_loss: 1.4157\n",
      " Epoch [99/300], Batch Step [110/323], D_loss: 0.7090,  G_loss: 1.4915\n",
      " Epoch [99/300], Batch Step [120/323], D_loss: 0.8872,  G_loss: 1.6316\n",
      " Epoch [99/300], Batch Step [130/323], D_loss: 0.6692,  G_loss: 1.3608\n",
      " Epoch [99/300], Batch Step [140/323], D_loss: 0.6111,  G_loss: 1.5322\n",
      " Epoch [99/300], Batch Step [150/323], D_loss: 0.5664,  G_loss: 1.5805\n",
      " Epoch [99/300], Batch Step [160/323], D_loss: 0.7132,  G_loss: 1.4411\n",
      " Epoch [99/300], Batch Step [170/323], D_loss: 0.7055,  G_loss: 1.6022\n",
      " Epoch [99/300], Batch Step [180/323], D_loss: 0.7065,  G_loss: 1.4232\n",
      " Epoch [99/300], Batch Step [190/323], D_loss: 0.5978,  G_loss: 1.7708\n",
      " Epoch [99/300], Batch Step [200/323], D_loss: 0.8156,  G_loss: 1.5469\n",
      " Epoch [99/300], Batch Step [210/323], D_loss: 0.7552,  G_loss: 1.4718\n",
      " Epoch [99/300], Batch Step [220/323], D_loss: 0.6979,  G_loss: 1.5568\n",
      " Epoch [99/300], Batch Step [230/323], D_loss: 0.7777,  G_loss: 1.5509\n",
      " Epoch [99/300], Batch Step [240/323], D_loss: 0.5788,  G_loss: 1.3884\n",
      " Epoch [99/300], Batch Step [250/323], D_loss: 0.7647,  G_loss: 1.7386\n",
      " Epoch [99/300], Batch Step [260/323], D_loss: 0.8004,  G_loss: 1.5311\n",
      " Epoch [99/300], Batch Step [270/323], D_loss: 0.7923,  G_loss: 1.4285\n",
      " Epoch [99/300], Batch Step [280/323], D_loss: 0.6979,  G_loss: 1.4903\n",
      " Epoch [99/300], Batch Step [290/323], D_loss: 0.7447,  G_loss: 1.5388\n",
      " Epoch [99/300], Batch Step [300/323], D_loss: 0.6082,  G_loss: 1.4387\n",
      " Epoch [99/300], Batch Step [310/323], D_loss: 0.6027,  G_loss: 1.6238\n",
      " Epoch [99/300], Batch Step [320/323], D_loss: 0.7896,  G_loss: 1.5668\n",
      " Epoch [100/300], Batch Step [0/323], D_loss: 0.6400,  G_loss: 1.4708\n",
      " Epoch [100/300], Batch Step [10/323], D_loss: 0.7828,  G_loss: 1.4493\n",
      " Epoch [100/300], Batch Step [20/323], D_loss: 0.6894,  G_loss: 1.4978\n",
      " Epoch [100/300], Batch Step [30/323], D_loss: 0.5878,  G_loss: 1.5270\n",
      " Epoch [100/300], Batch Step [40/323], D_loss: 0.6805,  G_loss: 1.4087\n",
      " Epoch [100/300], Batch Step [50/323], D_loss: 0.7650,  G_loss: 1.5939\n",
      " Epoch [100/300], Batch Step [60/323], D_loss: 0.7753,  G_loss: 1.5090\n",
      " Epoch [100/300], Batch Step [70/323], D_loss: 0.6851,  G_loss: 1.5050\n",
      " Epoch [100/300], Batch Step [80/323], D_loss: 0.7290,  G_loss: 1.5981\n",
      " Epoch [100/300], Batch Step [90/323], D_loss: 0.7538,  G_loss: 1.5312\n",
      " Epoch [100/300], Batch Step [100/323], D_loss: 0.5229,  G_loss: 1.6525\n",
      " Epoch [100/300], Batch Step [110/323], D_loss: 0.6764,  G_loss: 1.4978\n",
      " Epoch [100/300], Batch Step [120/323], D_loss: 0.5979,  G_loss: 1.5309\n",
      " Epoch [100/300], Batch Step [130/323], D_loss: 0.6026,  G_loss: 1.5959\n",
      " Epoch [100/300], Batch Step [140/323], D_loss: 0.7293,  G_loss: 1.4871\n",
      " Epoch [100/300], Batch Step [150/323], D_loss: 0.7423,  G_loss: 1.4050\n",
      " Epoch [100/300], Batch Step [160/323], D_loss: 0.5623,  G_loss: 1.6698\n",
      " Epoch [100/300], Batch Step [170/323], D_loss: 0.6506,  G_loss: 1.5863\n",
      " Epoch [100/300], Batch Step [180/323], D_loss: 0.6109,  G_loss: 1.3676\n",
      " Epoch [100/300], Batch Step [190/323], D_loss: 0.6605,  G_loss: 1.4220\n",
      " Epoch [100/300], Batch Step [200/323], D_loss: 0.6901,  G_loss: 1.5812\n",
      " Epoch [100/300], Batch Step [210/323], D_loss: 0.8384,  G_loss: 1.5384\n",
      " Epoch [100/300], Batch Step [220/323], D_loss: 0.7879,  G_loss: 1.5385\n",
      " Epoch [100/300], Batch Step [230/323], D_loss: 0.5646,  G_loss: 1.4709\n",
      " Epoch [100/300], Batch Step [240/323], D_loss: 0.6414,  G_loss: 1.5182\n",
      " Epoch [100/300], Batch Step [250/323], D_loss: 0.7065,  G_loss: 1.4843\n",
      " Epoch [100/300], Batch Step [260/323], D_loss: 0.8109,  G_loss: 1.5155\n",
      " Epoch [100/300], Batch Step [270/323], D_loss: 0.6930,  G_loss: 1.4445\n",
      " Epoch [100/300], Batch Step [280/323], D_loss: 0.6913,  G_loss: 1.4908\n",
      " Epoch [100/300], Batch Step [290/323], D_loss: 0.7920,  G_loss: 1.4737\n",
      " Epoch [100/300], Batch Step [300/323], D_loss: 0.5981,  G_loss: 1.5507\n",
      " Epoch [100/300], Batch Step [310/323], D_loss: 0.7667,  G_loss: 1.6104\n",
      " Epoch [100/300], Batch Step [320/323], D_loss: 0.6442,  G_loss: 1.4422\n",
      " Epoch [101/300], Batch Step [0/323], D_loss: 0.7260,  G_loss: 1.5662\n",
      " Epoch [101/300], Batch Step [10/323], D_loss: 0.6763,  G_loss: 1.5146\n",
      " Epoch [101/300], Batch Step [20/323], D_loss: 0.7662,  G_loss: 1.5663\n",
      " Epoch [101/300], Batch Step [30/323], D_loss: 0.5883,  G_loss: 1.5081\n",
      " Epoch [101/300], Batch Step [40/323], D_loss: 0.7173,  G_loss: 1.5535\n",
      " Epoch [101/300], Batch Step [50/323], D_loss: 0.6614,  G_loss: 1.4875\n",
      " Epoch [101/300], Batch Step [60/323], D_loss: 0.7728,  G_loss: 1.4443\n",
      " Epoch [101/300], Batch Step [70/323], D_loss: 0.6508,  G_loss: 1.5616\n",
      " Epoch [101/300], Batch Step [80/323], D_loss: 0.7104,  G_loss: 1.6674\n",
      " Epoch [101/300], Batch Step [90/323], D_loss: 0.5702,  G_loss: 1.5453\n",
      " Epoch [101/300], Batch Step [100/323], D_loss: 0.5862,  G_loss: 1.4991\n",
      " Epoch [101/300], Batch Step [110/323], D_loss: 0.7125,  G_loss: 1.5707\n",
      " Epoch [101/300], Batch Step [120/323], D_loss: 0.6371,  G_loss: 1.5181\n",
      " Epoch [101/300], Batch Step [130/323], D_loss: 0.7752,  G_loss: 1.4388\n",
      " Epoch [101/300], Batch Step [140/323], D_loss: 0.8176,  G_loss: 1.4402\n",
      " Epoch [101/300], Batch Step [150/323], D_loss: 0.7565,  G_loss: 1.5144\n",
      " Epoch [101/300], Batch Step [160/323], D_loss: 0.7307,  G_loss: 1.3749\n",
      " Epoch [101/300], Batch Step [170/323], D_loss: 0.7191,  G_loss: 1.5546\n",
      " Epoch [101/300], Batch Step [180/323], D_loss: 0.5555,  G_loss: 1.4745\n",
      " Epoch [101/300], Batch Step [190/323], D_loss: 0.7388,  G_loss: 1.4723\n",
      " Epoch [101/300], Batch Step [200/323], D_loss: 0.5525,  G_loss: 1.4533\n",
      " Epoch [101/300], Batch Step [210/323], D_loss: 0.6708,  G_loss: 1.6531\n",
      " Epoch [101/300], Batch Step [220/323], D_loss: 0.6492,  G_loss: 1.3472\n",
      " Epoch [101/300], Batch Step [230/323], D_loss: 0.6878,  G_loss: 1.6361\n",
      " Epoch [101/300], Batch Step [240/323], D_loss: 0.7723,  G_loss: 1.4310\n",
      " Epoch [101/300], Batch Step [250/323], D_loss: 0.6798,  G_loss: 1.5704\n",
      " Epoch [101/300], Batch Step [260/323], D_loss: 0.6956,  G_loss: 1.4974\n",
      " Epoch [101/300], Batch Step [270/323], D_loss: 0.7952,  G_loss: 1.3832\n",
      " Epoch [101/300], Batch Step [280/323], D_loss: 0.6147,  G_loss: 1.4818\n",
      " Epoch [101/300], Batch Step [290/323], D_loss: 0.6177,  G_loss: 1.5517\n",
      " Epoch [101/300], Batch Step [300/323], D_loss: 0.6498,  G_loss: 1.5566\n",
      " Epoch [101/300], Batch Step [310/323], D_loss: 0.5394,  G_loss: 1.5709\n",
      " Epoch [101/300], Batch Step [320/323], D_loss: 0.7023,  G_loss: 1.5755\n",
      " Epoch [102/300], Batch Step [0/323], D_loss: 0.5498,  G_loss: 1.5552\n",
      " Epoch [102/300], Batch Step [10/323], D_loss: 0.6349,  G_loss: 1.5018\n",
      " Epoch [102/300], Batch Step [20/323], D_loss: 0.7574,  G_loss: 1.5158\n",
      " Epoch [102/300], Batch Step [30/323], D_loss: 0.7664,  G_loss: 1.5891\n",
      " Epoch [102/300], Batch Step [40/323], D_loss: 0.6870,  G_loss: 1.4405\n",
      " Epoch [102/300], Batch Step [50/323], D_loss: 0.7458,  G_loss: 1.4938\n",
      " Epoch [102/300], Batch Step [60/323], D_loss: 0.7263,  G_loss: 1.4648\n",
      " Epoch [102/300], Batch Step [70/323], D_loss: 0.6722,  G_loss: 1.6134\n",
      " Epoch [102/300], Batch Step [80/323], D_loss: 0.6306,  G_loss: 1.5630\n",
      " Epoch [102/300], Batch Step [90/323], D_loss: 0.5684,  G_loss: 1.6759\n",
      " Epoch [102/300], Batch Step [100/323], D_loss: 0.8099,  G_loss: 1.3263\n",
      " Epoch [102/300], Batch Step [110/323], D_loss: 0.6765,  G_loss: 1.6164\n",
      " Epoch [102/300], Batch Step [120/323], D_loss: 0.6073,  G_loss: 1.5744\n",
      " Epoch [102/300], Batch Step [130/323], D_loss: 0.7463,  G_loss: 1.4226\n",
      " Epoch [102/300], Batch Step [140/323], D_loss: 0.8296,  G_loss: 1.6637\n",
      " Epoch [102/300], Batch Step [150/323], D_loss: 0.6607,  G_loss: 1.5000\n",
      " Epoch [102/300], Batch Step [160/323], D_loss: 0.7321,  G_loss: 1.5546\n",
      " Epoch [102/300], Batch Step [170/323], D_loss: 0.8203,  G_loss: 1.4055\n",
      " Epoch [102/300], Batch Step [180/323], D_loss: 0.6696,  G_loss: 1.6766\n",
      " Epoch [102/300], Batch Step [190/323], D_loss: 0.5096,  G_loss: 1.5388\n",
      " Epoch [102/300], Batch Step [200/323], D_loss: 0.9039,  G_loss: 1.4984\n",
      " Epoch [102/300], Batch Step [210/323], D_loss: 0.7040,  G_loss: 1.5458\n",
      " Epoch [102/300], Batch Step [220/323], D_loss: 0.6667,  G_loss: 1.4983\n",
      " Epoch [102/300], Batch Step [230/323], D_loss: 0.6842,  G_loss: 1.6740\n",
      " Epoch [102/300], Batch Step [240/323], D_loss: 0.9427,  G_loss: 1.4011\n",
      " Epoch [102/300], Batch Step [250/323], D_loss: 0.7220,  G_loss: 1.5210\n",
      " Epoch [102/300], Batch Step [260/323], D_loss: 0.7816,  G_loss: 1.5650\n",
      " Epoch [102/300], Batch Step [270/323], D_loss: 0.6030,  G_loss: 1.2929\n",
      " Epoch [102/300], Batch Step [280/323], D_loss: 0.6807,  G_loss: 1.6306\n",
      " Epoch [102/300], Batch Step [290/323], D_loss: 0.7123,  G_loss: 1.5584\n",
      " Epoch [102/300], Batch Step [300/323], D_loss: 0.4697,  G_loss: 1.5269\n",
      " Epoch [102/300], Batch Step [310/323], D_loss: 0.6671,  G_loss: 1.6234\n",
      " Epoch [102/300], Batch Step [320/323], D_loss: 0.6961,  G_loss: 1.4902\n",
      " Epoch [103/300], Batch Step [0/323], D_loss: 0.7182,  G_loss: 1.5598\n",
      " Epoch [103/300], Batch Step [10/323], D_loss: 0.5581,  G_loss: 1.5899\n",
      " Epoch [103/300], Batch Step [20/323], D_loss: 0.6564,  G_loss: 1.5404\n",
      " Epoch [103/300], Batch Step [30/323], D_loss: 0.7154,  G_loss: 1.4854\n",
      " Epoch [103/300], Batch Step [40/323], D_loss: 0.6598,  G_loss: 1.4651\n",
      " Epoch [103/300], Batch Step [50/323], D_loss: 0.7901,  G_loss: 1.6209\n",
      " Epoch [103/300], Batch Step [60/323], D_loss: 0.7392,  G_loss: 1.4583\n",
      " Epoch [103/300], Batch Step [70/323], D_loss: 0.7210,  G_loss: 1.4732\n",
      " Epoch [103/300], Batch Step [80/323], D_loss: 0.6650,  G_loss: 1.4970\n",
      " Epoch [103/300], Batch Step [90/323], D_loss: 0.7010,  G_loss: 1.3544\n",
      " Epoch [103/300], Batch Step [100/323], D_loss: 0.6009,  G_loss: 1.8385\n",
      " Epoch [103/300], Batch Step [110/323], D_loss: 0.5419,  G_loss: 1.5664\n",
      " Epoch [103/300], Batch Step [120/323], D_loss: 0.6959,  G_loss: 1.5534\n",
      " Epoch [103/300], Batch Step [130/323], D_loss: 0.7554,  G_loss: 1.5610\n",
      " Epoch [103/300], Batch Step [140/323], D_loss: 0.6281,  G_loss: 1.5578\n",
      " Epoch [103/300], Batch Step [150/323], D_loss: 0.4936,  G_loss: 1.5085\n",
      " Epoch [103/300], Batch Step [160/323], D_loss: 0.7373,  G_loss: 1.3913\n",
      " Epoch [103/300], Batch Step [170/323], D_loss: 0.7328,  G_loss: 1.5177\n",
      " Epoch [103/300], Batch Step [180/323], D_loss: 0.7531,  G_loss: 1.4114\n",
      " Epoch [103/300], Batch Step [190/323], D_loss: 0.6711,  G_loss: 1.6504\n",
      " Epoch [103/300], Batch Step [200/323], D_loss: 0.6500,  G_loss: 1.4054\n",
      " Epoch [103/300], Batch Step [210/323], D_loss: 0.6673,  G_loss: 1.6877\n",
      " Epoch [103/300], Batch Step [220/323], D_loss: 0.5231,  G_loss: 1.5497\n",
      " Epoch [103/300], Batch Step [230/323], D_loss: 0.6519,  G_loss: 1.7018\n",
      " Epoch [103/300], Batch Step [240/323], D_loss: 0.5643,  G_loss: 1.5277\n",
      " Epoch [103/300], Batch Step [250/323], D_loss: 0.6290,  G_loss: 1.5048\n",
      " Epoch [103/300], Batch Step [260/323], D_loss: 0.6346,  G_loss: 1.6059\n",
      " Epoch [103/300], Batch Step [270/323], D_loss: 0.8435,  G_loss: 1.5306\n",
      " Epoch [103/300], Batch Step [280/323], D_loss: 0.6407,  G_loss: 1.6800\n",
      " Epoch [103/300], Batch Step [290/323], D_loss: 0.7919,  G_loss: 1.4600\n",
      " Epoch [103/300], Batch Step [300/323], D_loss: 0.8064,  G_loss: 1.6513\n",
      " Epoch [103/300], Batch Step [310/323], D_loss: 0.7454,  G_loss: 1.3227\n",
      " Epoch [103/300], Batch Step [320/323], D_loss: 0.6397,  G_loss: 1.7762\n",
      " Epoch [104/300], Batch Step [0/323], D_loss: 0.9502,  G_loss: 1.6117\n",
      " Epoch [104/300], Batch Step [10/323], D_loss: 0.6615,  G_loss: 1.5343\n",
      " Epoch [104/300], Batch Step [20/323], D_loss: 0.5625,  G_loss: 1.5533\n",
      " Epoch [104/300], Batch Step [30/323], D_loss: 0.6710,  G_loss: 1.5321\n",
      " Epoch [104/300], Batch Step [40/323], D_loss: 0.5917,  G_loss: 1.4209\n",
      " Epoch [104/300], Batch Step [50/323], D_loss: 0.5949,  G_loss: 1.7119\n",
      " Epoch [104/300], Batch Step [60/323], D_loss: 0.5939,  G_loss: 1.6122\n",
      " Epoch [104/300], Batch Step [70/323], D_loss: 0.7033,  G_loss: 1.4047\n",
      " Epoch [104/300], Batch Step [80/323], D_loss: 0.7404,  G_loss: 1.7436\n",
      " Epoch [104/300], Batch Step [90/323], D_loss: 0.7228,  G_loss: 1.4055\n",
      " Epoch [104/300], Batch Step [100/323], D_loss: 0.6166,  G_loss: 1.5437\n",
      " Epoch [104/300], Batch Step [110/323], D_loss: 0.8138,  G_loss: 1.6268\n",
      " Epoch [104/300], Batch Step [120/323], D_loss: 0.6377,  G_loss: 1.5242\n",
      " Epoch [104/300], Batch Step [130/323], D_loss: 0.7317,  G_loss: 1.5913\n",
      " Epoch [104/300], Batch Step [140/323], D_loss: 0.6478,  G_loss: 1.4336\n",
      " Epoch [104/300], Batch Step [150/323], D_loss: 0.7727,  G_loss: 1.7381\n",
      " Epoch [104/300], Batch Step [160/323], D_loss: 0.5824,  G_loss: 1.5057\n",
      " Epoch [104/300], Batch Step [170/323], D_loss: 0.7093,  G_loss: 1.5846\n",
      " Epoch [104/300], Batch Step [180/323], D_loss: 0.5976,  G_loss: 1.6780\n",
      " Epoch [104/300], Batch Step [190/323], D_loss: 0.6848,  G_loss: 1.5976\n",
      " Epoch [104/300], Batch Step [200/323], D_loss: 0.7956,  G_loss: 1.6122\n",
      " Epoch [104/300], Batch Step [210/323], D_loss: 0.6560,  G_loss: 1.6809\n",
      " Epoch [104/300], Batch Step [220/323], D_loss: 0.7337,  G_loss: 1.5888\n",
      " Epoch [104/300], Batch Step [230/323], D_loss: 0.8432,  G_loss: 1.6815\n",
      " Epoch [104/300], Batch Step [240/323], D_loss: 0.7570,  G_loss: 1.5486\n",
      " Epoch [104/300], Batch Step [250/323], D_loss: 0.7491,  G_loss: 1.4510\n",
      " Epoch [104/300], Batch Step [260/323], D_loss: 0.6606,  G_loss: 1.5399\n",
      " Epoch [104/300], Batch Step [270/323], D_loss: 0.7226,  G_loss: 1.6405\n",
      " Epoch [104/300], Batch Step [280/323], D_loss: 0.6410,  G_loss: 1.6451\n",
      " Epoch [104/300], Batch Step [290/323], D_loss: 0.6315,  G_loss: 1.6121\n",
      " Epoch [104/300], Batch Step [300/323], D_loss: 0.6326,  G_loss: 1.6367\n",
      " Epoch [104/300], Batch Step [310/323], D_loss: 0.7549,  G_loss: 1.4688\n",
      " Epoch [104/300], Batch Step [320/323], D_loss: 0.5624,  G_loss: 1.6962\n",
      " Epoch [105/300], Batch Step [0/323], D_loss: 0.6370,  G_loss: 1.6821\n",
      " Epoch [105/300], Batch Step [10/323], D_loss: 0.7940,  G_loss: 1.3981\n",
      " Epoch [105/300], Batch Step [20/323], D_loss: 0.6590,  G_loss: 1.6352\n",
      " Epoch [105/300], Batch Step [30/323], D_loss: 0.6459,  G_loss: 1.5716\n",
      " Epoch [105/300], Batch Step [40/323], D_loss: 0.7246,  G_loss: 1.4905\n",
      " Epoch [105/300], Batch Step [50/323], D_loss: 0.4979,  G_loss: 1.6492\n",
      " Epoch [105/300], Batch Step [60/323], D_loss: 0.6315,  G_loss: 1.4900\n",
      " Epoch [105/300], Batch Step [70/323], D_loss: 0.8194,  G_loss: 1.4600\n",
      " Epoch [105/300], Batch Step [80/323], D_loss: 0.6820,  G_loss: 1.6505\n",
      " Epoch [105/300], Batch Step [90/323], D_loss: 0.8711,  G_loss: 1.5167\n",
      " Epoch [105/300], Batch Step [100/323], D_loss: 0.6744,  G_loss: 1.5237\n",
      " Epoch [105/300], Batch Step [110/323], D_loss: 0.7755,  G_loss: 1.6320\n",
      " Epoch [105/300], Batch Step [120/323], D_loss: 0.7290,  G_loss: 1.6657\n",
      " Epoch [105/300], Batch Step [130/323], D_loss: 0.5637,  G_loss: 1.4914\n",
      " Epoch [105/300], Batch Step [140/323], D_loss: 0.5888,  G_loss: 1.6006\n",
      " Epoch [105/300], Batch Step [150/323], D_loss: 0.6472,  G_loss: 1.5842\n",
      " Epoch [105/300], Batch Step [160/323], D_loss: 0.8054,  G_loss: 1.4103\n",
      " Epoch [105/300], Batch Step [170/323], D_loss: 0.6796,  G_loss: 1.4528\n",
      " Epoch [105/300], Batch Step [180/323], D_loss: 0.8912,  G_loss: 1.6817\n",
      " Epoch [105/300], Batch Step [190/323], D_loss: 0.7912,  G_loss: 1.3421\n",
      " Epoch [105/300], Batch Step [200/323], D_loss: 0.8714,  G_loss: 1.5350\n",
      " Epoch [105/300], Batch Step [210/323], D_loss: 0.8102,  G_loss: 1.6371\n",
      " Epoch [105/300], Batch Step [220/323], D_loss: 0.5231,  G_loss: 1.4682\n",
      " Epoch [105/300], Batch Step [230/323], D_loss: 0.7990,  G_loss: 1.5933\n",
      " Epoch [105/300], Batch Step [240/323], D_loss: 0.6605,  G_loss: 1.4217\n",
      " Epoch [105/300], Batch Step [250/323], D_loss: 0.6426,  G_loss: 1.5156\n",
      " Epoch [105/300], Batch Step [260/323], D_loss: 0.6376,  G_loss: 1.5029\n",
      " Epoch [105/300], Batch Step [270/323], D_loss: 0.6797,  G_loss: 1.4629\n",
      " Epoch [105/300], Batch Step [280/323], D_loss: 0.7649,  G_loss: 1.6133\n",
      " Epoch [105/300], Batch Step [290/323], D_loss: 0.7886,  G_loss: 1.5347\n",
      " Epoch [105/300], Batch Step [300/323], D_loss: 0.6281,  G_loss: 1.5068\n",
      " Epoch [105/300], Batch Step [310/323], D_loss: 0.6771,  G_loss: 1.5827\n",
      " Epoch [105/300], Batch Step [320/323], D_loss: 0.5575,  G_loss: 1.5371\n",
      " Epoch [106/300], Batch Step [0/323], D_loss: 0.6238,  G_loss: 1.5451\n",
      " Epoch [106/300], Batch Step [10/323], D_loss: 0.7525,  G_loss: 1.5423\n",
      " Epoch [106/300], Batch Step [20/323], D_loss: 0.7546,  G_loss: 1.5811\n",
      " Epoch [106/300], Batch Step [30/323], D_loss: 0.7404,  G_loss: 1.5477\n",
      " Epoch [106/300], Batch Step [40/323], D_loss: 0.6518,  G_loss: 1.4443\n",
      " Epoch [106/300], Batch Step [50/323], D_loss: 0.6538,  G_loss: 1.5940\n",
      " Epoch [106/300], Batch Step [60/323], D_loss: 0.5994,  G_loss: 1.5152\n",
      " Epoch [106/300], Batch Step [70/323], D_loss: 0.5917,  G_loss: 1.7033\n",
      " Epoch [106/300], Batch Step [80/323], D_loss: 0.6979,  G_loss: 1.4391\n",
      " Epoch [106/300], Batch Step [90/323], D_loss: 0.8293,  G_loss: 1.5445\n",
      " Epoch [106/300], Batch Step [100/323], D_loss: 0.5867,  G_loss: 1.5357\n",
      " Epoch [106/300], Batch Step [110/323], D_loss: 0.6971,  G_loss: 1.5660\n",
      " Epoch [106/300], Batch Step [120/323], D_loss: 0.7377,  G_loss: 1.4083\n",
      " Epoch [106/300], Batch Step [130/323], D_loss: 0.6503,  G_loss: 1.5885\n",
      " Epoch [106/300], Batch Step [140/323], D_loss: 0.6185,  G_loss: 1.5076\n",
      " Epoch [106/300], Batch Step [150/323], D_loss: 0.8329,  G_loss: 1.5717\n",
      " Epoch [106/300], Batch Step [160/323], D_loss: 0.5909,  G_loss: 1.5253\n",
      " Epoch [106/300], Batch Step [170/323], D_loss: 0.7254,  G_loss: 1.5456\n",
      " Epoch [106/300], Batch Step [180/323], D_loss: 0.7112,  G_loss: 1.4358\n",
      " Epoch [106/300], Batch Step [190/323], D_loss: 0.7112,  G_loss: 1.5175\n",
      " Epoch [106/300], Batch Step [200/323], D_loss: 0.6713,  G_loss: 1.3965\n",
      " Epoch [106/300], Batch Step [210/323], D_loss: 0.6094,  G_loss: 1.6201\n",
      " Epoch [106/300], Batch Step [220/323], D_loss: 0.7701,  G_loss: 1.5065\n",
      " Epoch [106/300], Batch Step [230/323], D_loss: 0.6000,  G_loss: 1.4713\n",
      " Epoch [106/300], Batch Step [240/323], D_loss: 0.6762,  G_loss: 1.5946\n",
      " Epoch [106/300], Batch Step [250/323], D_loss: 0.6134,  G_loss: 1.4096\n",
      " Epoch [106/300], Batch Step [260/323], D_loss: 0.7717,  G_loss: 1.5541\n",
      " Epoch [106/300], Batch Step [270/323], D_loss: 0.6256,  G_loss: 1.5793\n",
      " Epoch [106/300], Batch Step [280/323], D_loss: 0.6303,  G_loss: 1.5645\n",
      " Epoch [106/300], Batch Step [290/323], D_loss: 0.7614,  G_loss: 1.5213\n",
      " Epoch [106/300], Batch Step [300/323], D_loss: 0.6689,  G_loss: 1.4618\n",
      " Epoch [106/300], Batch Step [310/323], D_loss: 0.6061,  G_loss: 1.6481\n",
      " Epoch [106/300], Batch Step [320/323], D_loss: 0.5613,  G_loss: 1.5699\n",
      " Epoch [107/300], Batch Step [0/323], D_loss: 0.6896,  G_loss: 1.4481\n",
      " Epoch [107/300], Batch Step [10/323], D_loss: 0.7445,  G_loss: 1.6092\n",
      " Epoch [107/300], Batch Step [20/323], D_loss: 0.7748,  G_loss: 1.3898\n",
      " Epoch [107/300], Batch Step [30/323], D_loss: 0.7774,  G_loss: 1.4702\n",
      " Epoch [107/300], Batch Step [40/323], D_loss: 0.6291,  G_loss: 1.6394\n",
      " Epoch [107/300], Batch Step [50/323], D_loss: 0.7357,  G_loss: 1.5926\n",
      " Epoch [107/300], Batch Step [60/323], D_loss: 0.6589,  G_loss: 1.5234\n",
      " Epoch [107/300], Batch Step [70/323], D_loss: 0.7043,  G_loss: 1.6003\n",
      " Epoch [107/300], Batch Step [80/323], D_loss: 0.9164,  G_loss: 1.4749\n",
      " Epoch [107/300], Batch Step [90/323], D_loss: 0.6801,  G_loss: 1.4811\n",
      " Epoch [107/300], Batch Step [100/323], D_loss: 0.6357,  G_loss: 1.7194\n",
      " Epoch [107/300], Batch Step [110/323], D_loss: 0.6821,  G_loss: 1.3597\n",
      " Epoch [107/300], Batch Step [120/323], D_loss: 0.6721,  G_loss: 1.4748\n",
      " Epoch [107/300], Batch Step [130/323], D_loss: 0.7431,  G_loss: 1.4535\n",
      " Epoch [107/300], Batch Step [140/323], D_loss: 0.6123,  G_loss: 1.5365\n",
      " Epoch [107/300], Batch Step [150/323], D_loss: 0.6498,  G_loss: 1.3594\n",
      " Epoch [107/300], Batch Step [160/323], D_loss: 0.6390,  G_loss: 1.5947\n",
      " Epoch [107/300], Batch Step [170/323], D_loss: 0.7812,  G_loss: 1.6152\n",
      " Epoch [107/300], Batch Step [180/323], D_loss: 0.7870,  G_loss: 1.4987\n",
      " Epoch [107/300], Batch Step [190/323], D_loss: 0.7248,  G_loss: 1.4282\n",
      " Epoch [107/300], Batch Step [200/323], D_loss: 0.6848,  G_loss: 1.5546\n",
      " Epoch [107/300], Batch Step [210/323], D_loss: 0.5241,  G_loss: 1.4862\n",
      " Epoch [107/300], Batch Step [220/323], D_loss: 0.6186,  G_loss: 1.5530\n",
      " Epoch [107/300], Batch Step [230/323], D_loss: 0.7228,  G_loss: 1.4997\n",
      " Epoch [107/300], Batch Step [240/323], D_loss: 0.6384,  G_loss: 1.5758\n",
      " Epoch [107/300], Batch Step [250/323], D_loss: 0.6148,  G_loss: 1.6516\n",
      " Epoch [107/300], Batch Step [260/323], D_loss: 0.6293,  G_loss: 1.3516\n",
      " Epoch [107/300], Batch Step [270/323], D_loss: 0.6508,  G_loss: 1.7024\n",
      " Epoch [107/300], Batch Step [280/323], D_loss: 0.6481,  G_loss: 1.5256\n",
      " Epoch [107/300], Batch Step [290/323], D_loss: 0.8353,  G_loss: 1.5073\n",
      " Epoch [107/300], Batch Step [300/323], D_loss: 0.7249,  G_loss: 1.4993\n",
      " Epoch [107/300], Batch Step [310/323], D_loss: 0.6823,  G_loss: 1.5766\n",
      " Epoch [107/300], Batch Step [320/323], D_loss: 0.7258,  G_loss: 1.3705\n",
      " Epoch [108/300], Batch Step [0/323], D_loss: 0.7011,  G_loss: 1.3824\n",
      " Epoch [108/300], Batch Step [10/323], D_loss: 0.7535,  G_loss: 1.5991\n",
      " Epoch [108/300], Batch Step [20/323], D_loss: 0.6054,  G_loss: 1.4794\n",
      " Epoch [108/300], Batch Step [30/323], D_loss: 0.6537,  G_loss: 1.5108\n",
      " Epoch [108/300], Batch Step [40/323], D_loss: 0.5985,  G_loss: 1.5174\n",
      " Epoch [108/300], Batch Step [50/323], D_loss: 0.6874,  G_loss: 1.4654\n",
      " Epoch [108/300], Batch Step [60/323], D_loss: 0.6937,  G_loss: 1.5245\n",
      " Epoch [108/300], Batch Step [70/323], D_loss: 0.7403,  G_loss: 1.5568\n",
      " Epoch [108/300], Batch Step [80/323], D_loss: 0.6550,  G_loss: 1.5020\n",
      " Epoch [108/300], Batch Step [90/323], D_loss: 0.8839,  G_loss: 1.4245\n",
      " Epoch [108/300], Batch Step [100/323], D_loss: 0.6827,  G_loss: 1.4994\n",
      " Epoch [108/300], Batch Step [110/323], D_loss: 0.7225,  G_loss: 1.4823\n",
      " Epoch [108/300], Batch Step [120/323], D_loss: 0.5675,  G_loss: 1.5262\n",
      " Epoch [108/300], Batch Step [130/323], D_loss: 0.6956,  G_loss: 1.6311\n",
      " Epoch [108/300], Batch Step [140/323], D_loss: 0.6494,  G_loss: 1.4156\n",
      " Epoch [108/300], Batch Step [150/323], D_loss: 0.7432,  G_loss: 1.5982\n",
      " Epoch [108/300], Batch Step [160/323], D_loss: 0.7372,  G_loss: 1.5811\n",
      " Epoch [108/300], Batch Step [170/323], D_loss: 0.7752,  G_loss: 1.5808\n",
      " Epoch [108/300], Batch Step [180/323], D_loss: 0.5595,  G_loss: 1.5434\n",
      " Epoch [108/300], Batch Step [190/323], D_loss: 0.6123,  G_loss: 1.4933\n",
      " Epoch [108/300], Batch Step [200/323], D_loss: 0.7463,  G_loss: 1.4531\n",
      " Epoch [108/300], Batch Step [210/323], D_loss: 0.6948,  G_loss: 1.5256\n",
      " Epoch [108/300], Batch Step [220/323], D_loss: 0.6064,  G_loss: 1.5492\n",
      " Epoch [108/300], Batch Step [230/323], D_loss: 0.7879,  G_loss: 1.5332\n",
      " Epoch [108/300], Batch Step [240/323], D_loss: 0.7373,  G_loss: 1.5570\n",
      " Epoch [108/300], Batch Step [250/323], D_loss: 0.7619,  G_loss: 1.6112\n",
      " Epoch [108/300], Batch Step [260/323], D_loss: 0.5954,  G_loss: 1.5465\n",
      " Epoch [108/300], Batch Step [270/323], D_loss: 0.6286,  G_loss: 1.5520\n",
      " Epoch [108/300], Batch Step [280/323], D_loss: 0.5441,  G_loss: 1.6118\n",
      " Epoch [108/300], Batch Step [290/323], D_loss: 0.7665,  G_loss: 1.4745\n",
      " Epoch [108/300], Batch Step [300/323], D_loss: 0.7359,  G_loss: 1.4605\n",
      " Epoch [108/300], Batch Step [310/323], D_loss: 0.6466,  G_loss: 1.6782\n",
      " Epoch [108/300], Batch Step [320/323], D_loss: 0.6701,  G_loss: 1.5586\n",
      " Epoch [109/300], Batch Step [0/323], D_loss: 0.6607,  G_loss: 1.4619\n",
      " Epoch [109/300], Batch Step [10/323], D_loss: 0.6196,  G_loss: 1.6303\n",
      " Epoch [109/300], Batch Step [20/323], D_loss: 0.5312,  G_loss: 1.5957\n",
      " Epoch [109/300], Batch Step [30/323], D_loss: 0.6413,  G_loss: 1.5388\n",
      " Epoch [109/300], Batch Step [40/323], D_loss: 0.7291,  G_loss: 1.4407\n",
      " Epoch [109/300], Batch Step [50/323], D_loss: 0.7519,  G_loss: 1.6018\n",
      " Epoch [109/300], Batch Step [60/323], D_loss: 0.4934,  G_loss: 1.5650\n",
      " Epoch [109/300], Batch Step [70/323], D_loss: 0.7483,  G_loss: 1.6258\n",
      " Epoch [109/300], Batch Step [80/323], D_loss: 0.6334,  G_loss: 1.5119\n",
      " Epoch [109/300], Batch Step [90/323], D_loss: 0.6049,  G_loss: 1.5537\n",
      " Epoch [109/300], Batch Step [100/323], D_loss: 0.7089,  G_loss: 1.3672\n",
      " Epoch [109/300], Batch Step [110/323], D_loss: 0.5680,  G_loss: 1.5904\n",
      " Epoch [109/300], Batch Step [120/323], D_loss: 0.6965,  G_loss: 1.6340\n",
      " Epoch [109/300], Batch Step [130/323], D_loss: 0.5798,  G_loss: 1.4013\n",
      " Epoch [109/300], Batch Step [140/323], D_loss: 0.6685,  G_loss: 1.6222\n",
      " Epoch [109/300], Batch Step [150/323], D_loss: 0.7598,  G_loss: 1.6013\n",
      " Epoch [109/300], Batch Step [160/323], D_loss: 0.7833,  G_loss: 1.4634\n",
      " Epoch [109/300], Batch Step [170/323], D_loss: 0.6410,  G_loss: 1.4937\n",
      " Epoch [109/300], Batch Step [180/323], D_loss: 0.6731,  G_loss: 1.5836\n",
      " Epoch [109/300], Batch Step [190/323], D_loss: 0.6408,  G_loss: 1.4033\n",
      " Epoch [109/300], Batch Step [200/323], D_loss: 0.5315,  G_loss: 1.5612\n",
      " Epoch [109/300], Batch Step [210/323], D_loss: 0.6368,  G_loss: 1.5114\n",
      " Epoch [109/300], Batch Step [220/323], D_loss: 0.5216,  G_loss: 1.5876\n",
      " Epoch [109/300], Batch Step [230/323], D_loss: 0.7903,  G_loss: 1.4783\n",
      " Epoch [109/300], Batch Step [240/323], D_loss: 0.6518,  G_loss: 1.4891\n",
      " Epoch [109/300], Batch Step [250/323], D_loss: 0.6934,  G_loss: 1.3000\n",
      " Epoch [109/300], Batch Step [260/323], D_loss: 0.6189,  G_loss: 1.5759\n",
      " Epoch [109/300], Batch Step [270/323], D_loss: 0.8245,  G_loss: 1.6021\n",
      " Epoch [109/300], Batch Step [280/323], D_loss: 0.7752,  G_loss: 1.3680\n",
      " Epoch [109/300], Batch Step [290/323], D_loss: 0.7784,  G_loss: 1.5588\n",
      " Epoch [109/300], Batch Step [300/323], D_loss: 0.7295,  G_loss: 1.6188\n",
      " Epoch [109/300], Batch Step [310/323], D_loss: 0.7335,  G_loss: 1.3993\n",
      " Epoch [109/300], Batch Step [320/323], D_loss: 0.7170,  G_loss: 1.4800\n",
      " Epoch [110/300], Batch Step [0/323], D_loss: 0.8240,  G_loss: 1.5352\n",
      " Epoch [110/300], Batch Step [10/323], D_loss: 0.6896,  G_loss: 1.4769\n",
      " Epoch [110/300], Batch Step [20/323], D_loss: 0.5163,  G_loss: 1.6604\n",
      " Epoch [110/300], Batch Step [30/323], D_loss: 0.7147,  G_loss: 1.6538\n",
      " Epoch [110/300], Batch Step [40/323], D_loss: 0.7095,  G_loss: 1.4244\n",
      " Epoch [110/300], Batch Step [50/323], D_loss: 0.6578,  G_loss: 1.4984\n",
      " Epoch [110/300], Batch Step [60/323], D_loss: 0.6602,  G_loss: 1.5154\n",
      " Epoch [110/300], Batch Step [70/323], D_loss: 0.6925,  G_loss: 1.4912\n",
      " Epoch [110/300], Batch Step [80/323], D_loss: 0.7440,  G_loss: 1.6624\n",
      " Epoch [110/300], Batch Step [90/323], D_loss: 0.6666,  G_loss: 1.6132\n",
      " Epoch [110/300], Batch Step [100/323], D_loss: 0.6327,  G_loss: 1.5143\n",
      " Epoch [110/300], Batch Step [110/323], D_loss: 0.6360,  G_loss: 1.6128\n",
      " Epoch [110/300], Batch Step [120/323], D_loss: 0.7560,  G_loss: 1.4975\n",
      " Epoch [110/300], Batch Step [130/323], D_loss: 0.7317,  G_loss: 1.5365\n",
      " Epoch [110/300], Batch Step [140/323], D_loss: 0.8193,  G_loss: 1.3857\n",
      " Epoch [110/300], Batch Step [150/323], D_loss: 0.7155,  G_loss: 1.4270\n",
      " Epoch [110/300], Batch Step [160/323], D_loss: 0.6592,  G_loss: 1.5591\n",
      " Epoch [110/300], Batch Step [170/323], D_loss: 0.6657,  G_loss: 1.4242\n",
      " Epoch [110/300], Batch Step [180/323], D_loss: 0.6789,  G_loss: 1.5856\n",
      " Epoch [110/300], Batch Step [190/323], D_loss: 0.5654,  G_loss: 1.6055\n",
      " Epoch [110/300], Batch Step [200/323], D_loss: 0.6714,  G_loss: 1.5755\n",
      " Epoch [110/300], Batch Step [210/323], D_loss: 0.7025,  G_loss: 1.3513\n",
      " Epoch [110/300], Batch Step [220/323], D_loss: 0.5397,  G_loss: 1.6078\n",
      " Epoch [110/300], Batch Step [230/323], D_loss: 0.9376,  G_loss: 1.5229\n",
      " Epoch [110/300], Batch Step [240/323], D_loss: 0.7211,  G_loss: 1.4884\n",
      " Epoch [110/300], Batch Step [250/323], D_loss: 0.6686,  G_loss: 1.6494\n",
      " Epoch [110/300], Batch Step [260/323], D_loss: 0.7760,  G_loss: 1.3285\n",
      " Epoch [110/300], Batch Step [270/323], D_loss: 0.6351,  G_loss: 1.5943\n",
      " Epoch [110/300], Batch Step [280/323], D_loss: 0.5514,  G_loss: 1.6467\n",
      " Epoch [110/300], Batch Step [290/323], D_loss: 0.5075,  G_loss: 1.5693\n",
      " Epoch [110/300], Batch Step [300/323], D_loss: 0.6127,  G_loss: 1.5801\n",
      " Epoch [110/300], Batch Step [310/323], D_loss: 0.6905,  G_loss: 1.4644\n",
      " Epoch [110/300], Batch Step [320/323], D_loss: 0.7891,  G_loss: 1.4901\n",
      " Epoch [111/300], Batch Step [0/323], D_loss: 0.8066,  G_loss: 1.4989\n",
      " Epoch [111/300], Batch Step [10/323], D_loss: 0.6136,  G_loss: 1.6746\n",
      " Epoch [111/300], Batch Step [20/323], D_loss: 0.7148,  G_loss: 1.5011\n",
      " Epoch [111/300], Batch Step [30/323], D_loss: 0.7136,  G_loss: 1.5926\n",
      " Epoch [111/300], Batch Step [40/323], D_loss: 0.7468,  G_loss: 1.4861\n",
      " Epoch [111/300], Batch Step [50/323], D_loss: 0.6692,  G_loss: 1.6536\n",
      " Epoch [111/300], Batch Step [60/323], D_loss: 0.7456,  G_loss: 1.5026\n",
      " Epoch [111/300], Batch Step [70/323], D_loss: 0.8199,  G_loss: 1.4182\n",
      " Epoch [111/300], Batch Step [80/323], D_loss: 0.5469,  G_loss: 1.4598\n",
      " Epoch [111/300], Batch Step [90/323], D_loss: 0.7110,  G_loss: 1.5798\n",
      " Epoch [111/300], Batch Step [100/323], D_loss: 0.6813,  G_loss: 1.5200\n",
      " Epoch [111/300], Batch Step [110/323], D_loss: 0.7537,  G_loss: 1.5288\n",
      " Epoch [111/300], Batch Step [120/323], D_loss: 0.5630,  G_loss: 1.5161\n",
      " Epoch [111/300], Batch Step [130/323], D_loss: 0.7068,  G_loss: 1.6122\n",
      " Epoch [111/300], Batch Step [140/323], D_loss: 0.5688,  G_loss: 1.4275\n",
      " Epoch [111/300], Batch Step [150/323], D_loss: 0.6144,  G_loss: 1.5254\n",
      " Epoch [111/300], Batch Step [160/323], D_loss: 0.6631,  G_loss: 1.4674\n",
      " Epoch [111/300], Batch Step [170/323], D_loss: 0.6465,  G_loss: 1.5131\n",
      " Epoch [111/300], Batch Step [180/323], D_loss: 0.6309,  G_loss: 1.7217\n",
      " Epoch [111/300], Batch Step [190/323], D_loss: 0.6118,  G_loss: 1.5360\n",
      " Epoch [111/300], Batch Step [200/323], D_loss: 0.6381,  G_loss: 1.4965\n",
      " Epoch [111/300], Batch Step [210/323], D_loss: 0.8119,  G_loss: 1.4628\n",
      " Epoch [111/300], Batch Step [220/323], D_loss: 0.7299,  G_loss: 1.4954\n",
      " Epoch [111/300], Batch Step [230/323], D_loss: 0.8205,  G_loss: 1.5644\n",
      " Epoch [111/300], Batch Step [240/323], D_loss: 0.6851,  G_loss: 1.5870\n",
      " Epoch [111/300], Batch Step [250/323], D_loss: 0.6219,  G_loss: 1.6203\n",
      " Epoch [111/300], Batch Step [260/323], D_loss: 0.6150,  G_loss: 1.6168\n",
      " Epoch [111/300], Batch Step [270/323], D_loss: 0.6535,  G_loss: 1.6662\n",
      " Epoch [111/300], Batch Step [280/323], D_loss: 0.5895,  G_loss: 1.6100\n",
      " Epoch [111/300], Batch Step [290/323], D_loss: 0.6596,  G_loss: 1.4428\n",
      " Epoch [111/300], Batch Step [300/323], D_loss: 0.6760,  G_loss: 1.6090\n",
      " Epoch [111/300], Batch Step [310/323], D_loss: 0.6812,  G_loss: 1.4567\n",
      " Epoch [111/300], Batch Step [320/323], D_loss: 0.6578,  G_loss: 1.3826\n",
      " Epoch [112/300], Batch Step [0/323], D_loss: 0.6865,  G_loss: 1.4527\n",
      " Epoch [112/300], Batch Step [10/323], D_loss: 0.6531,  G_loss: 1.5200\n",
      " Epoch [112/300], Batch Step [20/323], D_loss: 0.6680,  G_loss: 1.5414\n",
      " Epoch [112/300], Batch Step [30/323], D_loss: 0.6680,  G_loss: 1.3381\n",
      " Epoch [112/300], Batch Step [40/323], D_loss: 0.5572,  G_loss: 1.6371\n",
      " Epoch [112/300], Batch Step [50/323], D_loss: 0.7438,  G_loss: 1.5041\n",
      " Epoch [112/300], Batch Step [60/323], D_loss: 0.7220,  G_loss: 1.4364\n",
      " Epoch [112/300], Batch Step [70/323], D_loss: 0.6107,  G_loss: 1.5526\n",
      " Epoch [112/300], Batch Step [80/323], D_loss: 0.5998,  G_loss: 1.5106\n",
      " Epoch [112/300], Batch Step [90/323], D_loss: 0.5771,  G_loss: 1.3417\n",
      " Epoch [112/300], Batch Step [100/323], D_loss: 0.6168,  G_loss: 1.6755\n",
      " Epoch [112/300], Batch Step [110/323], D_loss: 0.7335,  G_loss: 1.3561\n",
      " Epoch [112/300], Batch Step [120/323], D_loss: 0.6011,  G_loss: 1.5344\n",
      " Epoch [112/300], Batch Step [130/323], D_loss: 0.7036,  G_loss: 1.6987\n",
      " Epoch [112/300], Batch Step [140/323], D_loss: 0.6735,  G_loss: 1.3800\n",
      " Epoch [112/300], Batch Step [150/323], D_loss: 0.5005,  G_loss: 1.6767\n",
      " Epoch [112/300], Batch Step [160/323], D_loss: 0.7242,  G_loss: 1.4900\n",
      " Epoch [112/300], Batch Step [170/323], D_loss: 0.6347,  G_loss: 1.5444\n",
      " Epoch [112/300], Batch Step [180/323], D_loss: 0.6410,  G_loss: 1.5807\n",
      " Epoch [112/300], Batch Step [190/323], D_loss: 0.8482,  G_loss: 1.4666\n",
      " Epoch [112/300], Batch Step [200/323], D_loss: 0.5558,  G_loss: 1.6768\n",
      " Epoch [112/300], Batch Step [210/323], D_loss: 0.7075,  G_loss: 1.5269\n",
      " Epoch [112/300], Batch Step [220/323], D_loss: 0.6688,  G_loss: 1.4718\n",
      " Epoch [112/300], Batch Step [230/323], D_loss: 0.7003,  G_loss: 1.5184\n",
      " Epoch [112/300], Batch Step [240/323], D_loss: 0.6103,  G_loss: 1.5275\n",
      " Epoch [112/300], Batch Step [250/323], D_loss: 0.7521,  G_loss: 1.4761\n",
      " Epoch [112/300], Batch Step [260/323], D_loss: 0.5423,  G_loss: 1.5013\n",
      " Epoch [112/300], Batch Step [270/323], D_loss: 0.6749,  G_loss: 1.5503\n",
      " Epoch [112/300], Batch Step [280/323], D_loss: 0.7944,  G_loss: 1.6962\n",
      " Epoch [112/300], Batch Step [290/323], D_loss: 0.5600,  G_loss: 1.5139\n",
      " Epoch [112/300], Batch Step [300/323], D_loss: 0.8002,  G_loss: 1.4955\n",
      " Epoch [112/300], Batch Step [310/323], D_loss: 0.5282,  G_loss: 1.4537\n",
      " Epoch [112/300], Batch Step [320/323], D_loss: 0.7665,  G_loss: 1.5535\n",
      " Epoch [113/300], Batch Step [0/323], D_loss: 0.6588,  G_loss: 1.4366\n",
      " Epoch [113/300], Batch Step [10/323], D_loss: 0.7142,  G_loss: 1.5566\n",
      " Epoch [113/300], Batch Step [20/323], D_loss: 0.7001,  G_loss: 1.5795\n",
      " Epoch [113/300], Batch Step [30/323], D_loss: 0.6694,  G_loss: 1.6217\n",
      " Epoch [113/300], Batch Step [40/323], D_loss: 0.5894,  G_loss: 1.4266\n",
      " Epoch [113/300], Batch Step [50/323], D_loss: 0.7619,  G_loss: 1.4724\n",
      " Epoch [113/300], Batch Step [60/323], D_loss: 0.6234,  G_loss: 1.4805\n",
      " Epoch [113/300], Batch Step [70/323], D_loss: 0.5741,  G_loss: 1.5856\n",
      " Epoch [113/300], Batch Step [80/323], D_loss: 0.6502,  G_loss: 1.5501\n",
      " Epoch [113/300], Batch Step [90/323], D_loss: 0.6706,  G_loss: 1.4729\n",
      " Epoch [113/300], Batch Step [100/323], D_loss: 0.7036,  G_loss: 1.4973\n",
      " Epoch [113/300], Batch Step [110/323], D_loss: 0.6524,  G_loss: 1.5489\n",
      " Epoch [113/300], Batch Step [120/323], D_loss: 0.7237,  G_loss: 1.5340\n",
      " Epoch [113/300], Batch Step [130/323], D_loss: 0.4733,  G_loss: 1.5970\n",
      " Epoch [113/300], Batch Step [140/323], D_loss: 0.6277,  G_loss: 1.4673\n",
      " Epoch [113/300], Batch Step [150/323], D_loss: 0.9025,  G_loss: 1.4827\n",
      " Epoch [113/300], Batch Step [160/323], D_loss: 0.6839,  G_loss: 1.4377\n",
      " Epoch [113/300], Batch Step [170/323], D_loss: 0.7074,  G_loss: 1.5933\n",
      " Epoch [113/300], Batch Step [180/323], D_loss: 0.6137,  G_loss: 1.5445\n",
      " Epoch [113/300], Batch Step [190/323], D_loss: 0.7485,  G_loss: 1.5936\n",
      " Epoch [113/300], Batch Step [200/323], D_loss: 0.5602,  G_loss: 1.4695\n",
      " Epoch [113/300], Batch Step [210/323], D_loss: 0.6288,  G_loss: 1.6588\n",
      " Epoch [113/300], Batch Step [220/323], D_loss: 0.6324,  G_loss: 1.4587\n",
      " Epoch [113/300], Batch Step [230/323], D_loss: 0.7016,  G_loss: 1.6045\n",
      " Epoch [113/300], Batch Step [240/323], D_loss: 0.7168,  G_loss: 1.6188\n",
      " Epoch [113/300], Batch Step [250/323], D_loss: 0.7923,  G_loss: 1.5371\n",
      " Epoch [113/300], Batch Step [260/323], D_loss: 0.6948,  G_loss: 1.6082\n",
      " Epoch [113/300], Batch Step [270/323], D_loss: 0.6571,  G_loss: 1.4159\n",
      " Epoch [113/300], Batch Step [280/323], D_loss: 0.6683,  G_loss: 1.6172\n",
      " Epoch [113/300], Batch Step [290/323], D_loss: 0.7002,  G_loss: 1.5059\n",
      " Epoch [113/300], Batch Step [300/323], D_loss: 0.6778,  G_loss: 1.6479\n",
      " Epoch [113/300], Batch Step [310/323], D_loss: 0.6156,  G_loss: 1.4627\n",
      " Epoch [113/300], Batch Step [320/323], D_loss: 0.8661,  G_loss: 1.6463\n",
      " Epoch [114/300], Batch Step [0/323], D_loss: 0.6573,  G_loss: 1.5586\n",
      " Epoch [114/300], Batch Step [10/323], D_loss: 0.7786,  G_loss: 1.5219\n",
      " Epoch [114/300], Batch Step [20/323], D_loss: 0.6520,  G_loss: 1.5498\n",
      " Epoch [114/300], Batch Step [30/323], D_loss: 0.8099,  G_loss: 1.4532\n",
      " Epoch [114/300], Batch Step [40/323], D_loss: 0.6328,  G_loss: 1.6144\n",
      " Epoch [114/300], Batch Step [50/323], D_loss: 0.8258,  G_loss: 1.4578\n",
      " Epoch [114/300], Batch Step [60/323], D_loss: 0.6929,  G_loss: 1.5296\n",
      " Epoch [114/300], Batch Step [70/323], D_loss: 0.7686,  G_loss: 1.6033\n",
      " Epoch [114/300], Batch Step [80/323], D_loss: 0.6891,  G_loss: 1.4914\n",
      " Epoch [114/300], Batch Step [90/323], D_loss: 0.7457,  G_loss: 1.5351\n",
      " Epoch [114/300], Batch Step [100/323], D_loss: 0.5436,  G_loss: 1.4773\n",
      " Epoch [114/300], Batch Step [110/323], D_loss: 0.7222,  G_loss: 1.5144\n",
      " Epoch [114/300], Batch Step [120/323], D_loss: 0.6581,  G_loss: 1.4670\n",
      " Epoch [114/300], Batch Step [130/323], D_loss: 0.7875,  G_loss: 1.5989\n",
      " Epoch [114/300], Batch Step [140/323], D_loss: 0.6792,  G_loss: 1.4744\n",
      " Epoch [114/300], Batch Step [150/323], D_loss: 0.6437,  G_loss: 1.5737\n",
      " Epoch [114/300], Batch Step [160/323], D_loss: 0.6702,  G_loss: 1.6176\n",
      " Epoch [114/300], Batch Step [170/323], D_loss: 0.6530,  G_loss: 1.5876\n",
      " Epoch [114/300], Batch Step [180/323], D_loss: 0.5965,  G_loss: 1.4173\n",
      " Epoch [114/300], Batch Step [190/323], D_loss: 0.7134,  G_loss: 1.4562\n",
      " Epoch [114/300], Batch Step [200/323], D_loss: 0.6221,  G_loss: 1.4836\n",
      " Epoch [114/300], Batch Step [210/323], D_loss: 0.7099,  G_loss: 1.6097\n",
      " Epoch [114/300], Batch Step [220/323], D_loss: 0.4242,  G_loss: 1.6437\n",
      " Epoch [114/300], Batch Step [230/323], D_loss: 0.6334,  G_loss: 1.5327\n",
      " Epoch [114/300], Batch Step [240/323], D_loss: 0.4503,  G_loss: 1.7100\n",
      " Epoch [114/300], Batch Step [250/323], D_loss: 0.6713,  G_loss: 1.4984\n",
      " Epoch [114/300], Batch Step [260/323], D_loss: 0.5495,  G_loss: 1.5884\n",
      " Epoch [114/300], Batch Step [270/323], D_loss: 0.6186,  G_loss: 1.5429\n",
      " Epoch [114/300], Batch Step [280/323], D_loss: 0.7090,  G_loss: 1.3866\n",
      " Epoch [114/300], Batch Step [290/323], D_loss: 0.7363,  G_loss: 1.5473\n",
      " Epoch [114/300], Batch Step [300/323], D_loss: 0.6892,  G_loss: 1.6496\n",
      " Epoch [114/300], Batch Step [310/323], D_loss: 0.6437,  G_loss: 1.6459\n",
      " Epoch [114/300], Batch Step [320/323], D_loss: 0.6321,  G_loss: 1.5518\n",
      " Epoch [115/300], Batch Step [0/323], D_loss: 0.6327,  G_loss: 1.5269\n",
      " Epoch [115/300], Batch Step [10/323], D_loss: 0.6346,  G_loss: 1.6399\n",
      " Epoch [115/300], Batch Step [20/323], D_loss: 0.7209,  G_loss: 1.5734\n",
      " Epoch [115/300], Batch Step [30/323], D_loss: 0.8132,  G_loss: 1.5779\n",
      " Epoch [115/300], Batch Step [40/323], D_loss: 0.7547,  G_loss: 1.4532\n",
      " Epoch [115/300], Batch Step [50/323], D_loss: 0.7414,  G_loss: 1.6639\n",
      " Epoch [115/300], Batch Step [60/323], D_loss: 0.5080,  G_loss: 1.4659\n",
      " Epoch [115/300], Batch Step [70/323], D_loss: 0.9206,  G_loss: 1.6044\n",
      " Epoch [115/300], Batch Step [80/323], D_loss: 0.7916,  G_loss: 1.4753\n",
      " Epoch [115/300], Batch Step [90/323], D_loss: 0.7432,  G_loss: 1.4585\n",
      " Epoch [115/300], Batch Step [100/323], D_loss: 0.8063,  G_loss: 1.7365\n",
      " Epoch [115/300], Batch Step [110/323], D_loss: 0.5331,  G_loss: 1.5565\n",
      " Epoch [115/300], Batch Step [120/323], D_loss: 0.5840,  G_loss: 1.5946\n",
      " Epoch [115/300], Batch Step [130/323], D_loss: 0.7552,  G_loss: 1.6502\n",
      " Epoch [115/300], Batch Step [140/323], D_loss: 0.6593,  G_loss: 1.5961\n",
      " Epoch [115/300], Batch Step [150/323], D_loss: 0.7297,  G_loss: 1.5796\n",
      " Epoch [115/300], Batch Step [160/323], D_loss: 0.6996,  G_loss: 1.5942\n",
      " Epoch [115/300], Batch Step [170/323], D_loss: 0.7442,  G_loss: 1.4420\n",
      " Epoch [115/300], Batch Step [180/323], D_loss: 0.6807,  G_loss: 1.4211\n",
      " Epoch [115/300], Batch Step [190/323], D_loss: 0.6499,  G_loss: 1.5646\n",
      " Epoch [115/300], Batch Step [200/323], D_loss: 0.7630,  G_loss: 1.5444\n",
      " Epoch [115/300], Batch Step [210/323], D_loss: 0.7190,  G_loss: 1.3939\n",
      " Epoch [115/300], Batch Step [220/323], D_loss: 0.6743,  G_loss: 1.5740\n",
      " Epoch [115/300], Batch Step [230/323], D_loss: 0.6149,  G_loss: 1.5120\n",
      " Epoch [115/300], Batch Step [240/323], D_loss: 0.7607,  G_loss: 1.5760\n",
      " Epoch [115/300], Batch Step [250/323], D_loss: 0.6504,  G_loss: 1.4831\n",
      " Epoch [115/300], Batch Step [260/323], D_loss: 0.5707,  G_loss: 1.7340\n",
      " Epoch [115/300], Batch Step [270/323], D_loss: 0.7821,  G_loss: 1.6123\n",
      " Epoch [115/300], Batch Step [280/323], D_loss: 0.5968,  G_loss: 1.5818\n",
      " Epoch [115/300], Batch Step [290/323], D_loss: 0.8148,  G_loss: 1.6134\n",
      " Epoch [115/300], Batch Step [300/323], D_loss: 0.7340,  G_loss: 1.4373\n",
      " Epoch [115/300], Batch Step [310/323], D_loss: 0.6910,  G_loss: 1.6371\n",
      " Epoch [115/300], Batch Step [320/323], D_loss: 0.7075,  G_loss: 1.4669\n",
      " Epoch [116/300], Batch Step [0/323], D_loss: 0.6257,  G_loss: 1.4680\n",
      " Epoch [116/300], Batch Step [10/323], D_loss: 0.6236,  G_loss: 1.6469\n",
      " Epoch [116/300], Batch Step [20/323], D_loss: 0.6251,  G_loss: 1.4298\n",
      " Epoch [116/300], Batch Step [30/323], D_loss: 0.6052,  G_loss: 1.5921\n",
      " Epoch [116/300], Batch Step [40/323], D_loss: 0.6591,  G_loss: 1.5437\n",
      " Epoch [116/300], Batch Step [50/323], D_loss: 0.6282,  G_loss: 1.4850\n",
      " Epoch [116/300], Batch Step [60/323], D_loss: 0.6293,  G_loss: 1.5269\n",
      " Epoch [116/300], Batch Step [70/323], D_loss: 0.7311,  G_loss: 1.5855\n",
      " Epoch [116/300], Batch Step [80/323], D_loss: 0.5787,  G_loss: 1.5480\n",
      " Epoch [116/300], Batch Step [90/323], D_loss: 0.7048,  G_loss: 1.4610\n",
      " Epoch [116/300], Batch Step [100/323], D_loss: 0.6699,  G_loss: 1.6532\n",
      " Epoch [116/300], Batch Step [110/323], D_loss: 0.6532,  G_loss: 1.4514\n",
      " Epoch [116/300], Batch Step [120/323], D_loss: 0.8253,  G_loss: 1.5312\n",
      " Epoch [116/300], Batch Step [130/323], D_loss: 0.5567,  G_loss: 1.4804\n",
      " Epoch [116/300], Batch Step [140/323], D_loss: 0.7452,  G_loss: 1.6995\n",
      " Epoch [116/300], Batch Step [150/323], D_loss: 0.6458,  G_loss: 1.5252\n",
      " Epoch [116/300], Batch Step [160/323], D_loss: 0.6577,  G_loss: 1.4018\n",
      " Epoch [116/300], Batch Step [170/323], D_loss: 0.6186,  G_loss: 1.7778\n",
      " Epoch [116/300], Batch Step [180/323], D_loss: 0.6165,  G_loss: 1.4984\n",
      " Epoch [116/300], Batch Step [190/323], D_loss: 0.6352,  G_loss: 1.6093\n",
      " Epoch [116/300], Batch Step [200/323], D_loss: 0.5805,  G_loss: 1.5013\n",
      " Epoch [116/300], Batch Step [210/323], D_loss: 0.6059,  G_loss: 1.3617\n",
      " Epoch [116/300], Batch Step [220/323], D_loss: 0.5594,  G_loss: 1.6674\n",
      " Epoch [116/300], Batch Step [230/323], D_loss: 0.7178,  G_loss: 1.5790\n",
      " Epoch [116/300], Batch Step [240/323], D_loss: 0.7183,  G_loss: 1.4781\n",
      " Epoch [116/300], Batch Step [250/323], D_loss: 0.5998,  G_loss: 1.5081\n",
      " Epoch [116/300], Batch Step [260/323], D_loss: 0.6599,  G_loss: 1.5145\n",
      " Epoch [116/300], Batch Step [270/323], D_loss: 0.7003,  G_loss: 1.5240\n",
      " Epoch [116/300], Batch Step [280/323], D_loss: 0.6788,  G_loss: 1.4311\n",
      " Epoch [116/300], Batch Step [290/323], D_loss: 0.6470,  G_loss: 1.4326\n",
      " Epoch [116/300], Batch Step [300/323], D_loss: 0.7347,  G_loss: 1.6391\n",
      " Epoch [116/300], Batch Step [310/323], D_loss: 0.5515,  G_loss: 1.5880\n",
      " Epoch [116/300], Batch Step [320/323], D_loss: 0.7090,  G_loss: 1.4047\n",
      " Epoch [117/300], Batch Step [0/323], D_loss: 0.5403,  G_loss: 1.4892\n",
      " Epoch [117/300], Batch Step [10/323], D_loss: 0.6520,  G_loss: 1.4737\n",
      " Epoch [117/300], Batch Step [20/323], D_loss: 0.7747,  G_loss: 1.4514\n",
      " Epoch [117/300], Batch Step [30/323], D_loss: 0.6712,  G_loss: 1.5405\n",
      " Epoch [117/300], Batch Step [40/323], D_loss: 0.6972,  G_loss: 1.5339\n",
      " Epoch [117/300], Batch Step [50/323], D_loss: 0.6065,  G_loss: 1.3944\n",
      " Epoch [117/300], Batch Step [60/323], D_loss: 0.6701,  G_loss: 1.6419\n",
      " Epoch [117/300], Batch Step [70/323], D_loss: 0.5999,  G_loss: 1.5426\n",
      " Epoch [117/300], Batch Step [80/323], D_loss: 0.5457,  G_loss: 1.6106\n",
      " Epoch [117/300], Batch Step [90/323], D_loss: 0.6342,  G_loss: 1.6834\n",
      " Epoch [117/300], Batch Step [100/323], D_loss: 0.5414,  G_loss: 1.3746\n",
      " Epoch [117/300], Batch Step [110/323], D_loss: 0.7362,  G_loss: 1.4817\n",
      " Epoch [117/300], Batch Step [120/323], D_loss: 0.8346,  G_loss: 1.6269\n",
      " Epoch [117/300], Batch Step [130/323], D_loss: 0.6690,  G_loss: 1.4915\n",
      " Epoch [117/300], Batch Step [140/323], D_loss: 0.6927,  G_loss: 1.4242\n",
      " Epoch [117/300], Batch Step [150/323], D_loss: 0.6165,  G_loss: 1.5781\n",
      " Epoch [117/300], Batch Step [160/323], D_loss: 0.6209,  G_loss: 1.5733\n",
      " Epoch [117/300], Batch Step [170/323], D_loss: 0.8213,  G_loss: 1.4257\n",
      " Epoch [117/300], Batch Step [180/323], D_loss: 0.6795,  G_loss: 1.6342\n",
      " Epoch [117/300], Batch Step [190/323], D_loss: 0.7197,  G_loss: 1.4502\n",
      " Epoch [117/300], Batch Step [200/323], D_loss: 0.7900,  G_loss: 1.5111\n",
      " Epoch [117/300], Batch Step [210/323], D_loss: 0.6893,  G_loss: 1.5849\n",
      " Epoch [117/300], Batch Step [220/323], D_loss: 0.6767,  G_loss: 1.5647\n",
      " Epoch [117/300], Batch Step [230/323], D_loss: 0.6789,  G_loss: 1.5775\n",
      " Epoch [117/300], Batch Step [240/323], D_loss: 0.7019,  G_loss: 1.3109\n",
      " Epoch [117/300], Batch Step [250/323], D_loss: 0.6646,  G_loss: 1.5190\n",
      " Epoch [117/300], Batch Step [260/323], D_loss: 0.4910,  G_loss: 1.5204\n",
      " Epoch [117/300], Batch Step [270/323], D_loss: 0.7664,  G_loss: 1.4927\n",
      " Epoch [117/300], Batch Step [280/323], D_loss: 0.6690,  G_loss: 1.4488\n",
      " Epoch [117/300], Batch Step [290/323], D_loss: 0.5318,  G_loss: 1.5934\n",
      " Epoch [117/300], Batch Step [300/323], D_loss: 0.5858,  G_loss: 1.4983\n",
      " Epoch [117/300], Batch Step [310/323], D_loss: 0.6569,  G_loss: 1.5353\n",
      " Epoch [117/300], Batch Step [320/323], D_loss: 0.6008,  G_loss: 1.5472\n",
      " Epoch [118/300], Batch Step [0/323], D_loss: 0.6647,  G_loss: 1.4873\n",
      " Epoch [118/300], Batch Step [10/323], D_loss: 0.5967,  G_loss: 1.5365\n",
      " Epoch [118/300], Batch Step [20/323], D_loss: 0.7845,  G_loss: 1.6566\n",
      " Epoch [118/300], Batch Step [30/323], D_loss: 0.6364,  G_loss: 1.3700\n",
      " Epoch [118/300], Batch Step [40/323], D_loss: 0.6506,  G_loss: 1.6036\n",
      " Epoch [118/300], Batch Step [50/323], D_loss: 0.7836,  G_loss: 1.4033\n",
      " Epoch [118/300], Batch Step [60/323], D_loss: 0.6555,  G_loss: 1.4882\n",
      " Epoch [118/300], Batch Step [70/323], D_loss: 0.8030,  G_loss: 1.6249\n",
      " Epoch [118/300], Batch Step [80/323], D_loss: 0.8917,  G_loss: 1.5355\n",
      " Epoch [118/300], Batch Step [90/323], D_loss: 0.7598,  G_loss: 1.5859\n",
      " Epoch [118/300], Batch Step [100/323], D_loss: 0.6338,  G_loss: 1.4694\n",
      " Epoch [118/300], Batch Step [110/323], D_loss: 0.7689,  G_loss: 1.5715\n",
      " Epoch [118/300], Batch Step [120/323], D_loss: 0.7109,  G_loss: 1.7051\n",
      " Epoch [118/300], Batch Step [130/323], D_loss: 0.7366,  G_loss: 1.5940\n",
      " Epoch [118/300], Batch Step [140/323], D_loss: 0.6000,  G_loss: 1.5250\n",
      " Epoch [118/300], Batch Step [150/323], D_loss: 0.8024,  G_loss: 1.7018\n",
      " Epoch [118/300], Batch Step [160/323], D_loss: 0.6493,  G_loss: 1.5613\n",
      " Epoch [118/300], Batch Step [170/323], D_loss: 0.7636,  G_loss: 1.5804\n",
      " Epoch [118/300], Batch Step [180/323], D_loss: 0.5082,  G_loss: 1.5210\n",
      " Epoch [118/300], Batch Step [190/323], D_loss: 0.5971,  G_loss: 1.5732\n",
      " Epoch [118/300], Batch Step [200/323], D_loss: 0.6721,  G_loss: 1.7020\n",
      " Epoch [118/300], Batch Step [210/323], D_loss: 0.6362,  G_loss: 1.4663\n",
      " Epoch [118/300], Batch Step [220/323], D_loss: 0.8030,  G_loss: 1.6020\n",
      " Epoch [118/300], Batch Step [230/323], D_loss: 0.6281,  G_loss: 1.5770\n",
      " Epoch [118/300], Batch Step [240/323], D_loss: 0.6441,  G_loss: 1.4595\n",
      " Epoch [118/300], Batch Step [250/323], D_loss: 0.7163,  G_loss: 1.6051\n",
      " Epoch [118/300], Batch Step [260/323], D_loss: 0.7123,  G_loss: 1.4679\n",
      " Epoch [118/300], Batch Step [270/323], D_loss: 0.7414,  G_loss: 1.4093\n",
      " Epoch [118/300], Batch Step [280/323], D_loss: 0.6599,  G_loss: 1.5953\n",
      " Epoch [118/300], Batch Step [290/323], D_loss: 0.8855,  G_loss: 1.4299\n",
      " Epoch [118/300], Batch Step [300/323], D_loss: 0.7530,  G_loss: 1.4440\n",
      " Epoch [118/300], Batch Step [310/323], D_loss: 0.7248,  G_loss: 1.4740\n",
      " Epoch [118/300], Batch Step [320/323], D_loss: 0.8497,  G_loss: 1.6493\n",
      " Epoch [119/300], Batch Step [0/323], D_loss: 0.7024,  G_loss: 1.5704\n",
      " Epoch [119/300], Batch Step [10/323], D_loss: 0.6021,  G_loss: 1.4600\n",
      " Epoch [119/300], Batch Step [20/323], D_loss: 0.5100,  G_loss: 1.6222\n",
      " Epoch [119/300], Batch Step [30/323], D_loss: 0.6209,  G_loss: 1.4608\n",
      " Epoch [119/300], Batch Step [40/323], D_loss: 0.6684,  G_loss: 1.4333\n",
      " Epoch [119/300], Batch Step [50/323], D_loss: 0.5192,  G_loss: 1.4767\n",
      " Epoch [119/300], Batch Step [60/323], D_loss: 0.6386,  G_loss: 1.6261\n",
      " Epoch [119/300], Batch Step [70/323], D_loss: 0.6247,  G_loss: 1.4855\n",
      " Epoch [119/300], Batch Step [80/323], D_loss: 0.7637,  G_loss: 1.5659\n",
      " Epoch [119/300], Batch Step [90/323], D_loss: 0.7382,  G_loss: 1.5474\n",
      " Epoch [119/300], Batch Step [100/323], D_loss: 0.7714,  G_loss: 1.6118\n",
      " Epoch [119/300], Batch Step [110/323], D_loss: 0.5913,  G_loss: 1.4654\n",
      " Epoch [119/300], Batch Step [120/323], D_loss: 0.7689,  G_loss: 1.4484\n",
      " Epoch [119/300], Batch Step [130/323], D_loss: 0.8487,  G_loss: 1.5604\n",
      " Epoch [119/300], Batch Step [140/323], D_loss: 0.6495,  G_loss: 1.4034\n",
      " Epoch [119/300], Batch Step [150/323], D_loss: 0.5774,  G_loss: 1.6039\n",
      " Epoch [119/300], Batch Step [160/323], D_loss: 0.5261,  G_loss: 1.6312\n",
      " Epoch [119/300], Batch Step [170/323], D_loss: 0.6967,  G_loss: 1.4982\n",
      " Epoch [119/300], Batch Step [180/323], D_loss: 0.6985,  G_loss: 1.5188\n",
      " Epoch [119/300], Batch Step [190/323], D_loss: 0.5152,  G_loss: 1.7467\n",
      " Epoch [119/300], Batch Step [200/323], D_loss: 0.6375,  G_loss: 1.5062\n",
      " Epoch [119/300], Batch Step [210/323], D_loss: 0.7407,  G_loss: 1.5081\n",
      " Epoch [119/300], Batch Step [220/323], D_loss: 0.7717,  G_loss: 1.4102\n",
      " Epoch [119/300], Batch Step [230/323], D_loss: 0.7617,  G_loss: 1.4949\n",
      " Epoch [119/300], Batch Step [240/323], D_loss: 0.7881,  G_loss: 1.4106\n",
      " Epoch [119/300], Batch Step [250/323], D_loss: 0.4735,  G_loss: 1.6694\n",
      " Epoch [119/300], Batch Step [260/323], D_loss: 0.7994,  G_loss: 1.5736\n",
      " Epoch [119/300], Batch Step [270/323], D_loss: 0.6427,  G_loss: 1.4145\n",
      " Epoch [119/300], Batch Step [280/323], D_loss: 0.7139,  G_loss: 1.6492\n",
      " Epoch [119/300], Batch Step [290/323], D_loss: 0.6130,  G_loss: 1.5250\n",
      " Epoch [119/300], Batch Step [300/323], D_loss: 0.7190,  G_loss: 1.5514\n",
      " Epoch [119/300], Batch Step [310/323], D_loss: 0.6265,  G_loss: 1.5515\n",
      " Epoch [119/300], Batch Step [320/323], D_loss: 0.6715,  G_loss: 1.4815\n",
      " Epoch [120/300], Batch Step [0/323], D_loss: 0.5011,  G_loss: 1.5506\n",
      " Epoch [120/300], Batch Step [10/323], D_loss: 0.4068,  G_loss: 1.5600\n",
      " Epoch [120/300], Batch Step [20/323], D_loss: 0.7440,  G_loss: 1.5994\n",
      " Epoch [120/300], Batch Step [30/323], D_loss: 0.5532,  G_loss: 1.4750\n",
      " Epoch [120/300], Batch Step [40/323], D_loss: 0.6844,  G_loss: 1.6264\n",
      " Epoch [120/300], Batch Step [50/323], D_loss: 0.6067,  G_loss: 1.5227\n",
      " Epoch [120/300], Batch Step [60/323], D_loss: 0.7148,  G_loss: 1.4869\n",
      " Epoch [120/300], Batch Step [70/323], D_loss: 0.5785,  G_loss: 1.6472\n",
      " Epoch [120/300], Batch Step [80/323], D_loss: 0.7180,  G_loss: 1.5851\n",
      " Epoch [120/300], Batch Step [90/323], D_loss: 0.6722,  G_loss: 1.4852\n",
      " Epoch [120/300], Batch Step [100/323], D_loss: 0.5982,  G_loss: 1.7247\n",
      " Epoch [120/300], Batch Step [110/323], D_loss: 0.6572,  G_loss: 1.3905\n",
      " Epoch [120/300], Batch Step [120/323], D_loss: 0.8859,  G_loss: 1.4302\n",
      " Epoch [120/300], Batch Step [130/323], D_loss: 0.7046,  G_loss: 1.4636\n",
      " Epoch [120/300], Batch Step [140/323], D_loss: 0.6117,  G_loss: 1.6129\n",
      " Epoch [120/300], Batch Step [150/323], D_loss: 0.7894,  G_loss: 1.4805\n",
      " Epoch [120/300], Batch Step [160/323], D_loss: 0.5525,  G_loss: 1.4930\n",
      " Epoch [120/300], Batch Step [170/323], D_loss: 0.6549,  G_loss: 1.6896\n",
      " Epoch [120/300], Batch Step [180/323], D_loss: 0.6291,  G_loss: 1.5756\n",
      " Epoch [120/300], Batch Step [190/323], D_loss: 0.5939,  G_loss: 1.5460\n",
      " Epoch [120/300], Batch Step [200/323], D_loss: 0.5898,  G_loss: 1.6258\n",
      " Epoch [120/300], Batch Step [210/323], D_loss: 0.5225,  G_loss: 1.6521\n",
      " Epoch [120/300], Batch Step [220/323], D_loss: 0.6344,  G_loss: 1.5780\n",
      " Epoch [120/300], Batch Step [230/323], D_loss: 0.6666,  G_loss: 1.5379\n",
      " Epoch [120/300], Batch Step [240/323], D_loss: 0.7451,  G_loss: 1.6030\n",
      " Epoch [120/300], Batch Step [250/323], D_loss: 0.8404,  G_loss: 1.6480\n",
      " Epoch [120/300], Batch Step [260/323], D_loss: 0.5963,  G_loss: 1.3542\n",
      " Epoch [120/300], Batch Step [270/323], D_loss: 0.6992,  G_loss: 1.8666\n",
      " Epoch [120/300], Batch Step [280/323], D_loss: 0.5711,  G_loss: 1.5192\n",
      " Epoch [120/300], Batch Step [290/323], D_loss: 0.7588,  G_loss: 1.5785\n",
      " Epoch [120/300], Batch Step [300/323], D_loss: 0.6273,  G_loss: 1.4880\n",
      " Epoch [120/300], Batch Step [310/323], D_loss: 0.6643,  G_loss: 1.5400\n",
      " Epoch [120/300], Batch Step [320/323], D_loss: 0.7145,  G_loss: 1.6762\n",
      " Epoch [121/300], Batch Step [0/323], D_loss: 0.8940,  G_loss: 1.5972\n",
      " Epoch [121/300], Batch Step [10/323], D_loss: 0.6850,  G_loss: 1.5703\n",
      " Epoch [121/300], Batch Step [20/323], D_loss: 0.8417,  G_loss: 1.4616\n",
      " Epoch [121/300], Batch Step [30/323], D_loss: 0.6733,  G_loss: 1.4792\n",
      " Epoch [121/300], Batch Step [40/323], D_loss: 0.6772,  G_loss: 1.5438\n",
      " Epoch [121/300], Batch Step [50/323], D_loss: 0.6538,  G_loss: 1.5752\n",
      " Epoch [121/300], Batch Step [60/323], D_loss: 0.7877,  G_loss: 1.6213\n",
      " Epoch [121/300], Batch Step [70/323], D_loss: 0.5562,  G_loss: 1.4093\n",
      " Epoch [121/300], Batch Step [80/323], D_loss: 0.5941,  G_loss: 1.5796\n",
      " Epoch [121/300], Batch Step [90/323], D_loss: 0.5987,  G_loss: 1.5040\n",
      " Epoch [121/300], Batch Step [100/323], D_loss: 0.8926,  G_loss: 1.5708\n",
      " Epoch [121/300], Batch Step [110/323], D_loss: 0.7484,  G_loss: 1.6412\n",
      " Epoch [121/300], Batch Step [120/323], D_loss: 0.6392,  G_loss: 1.5996\n",
      " Epoch [121/300], Batch Step [130/323], D_loss: 0.6121,  G_loss: 1.5309\n",
      " Epoch [121/300], Batch Step [140/323], D_loss: 0.6824,  G_loss: 1.6509\n",
      " Epoch [121/300], Batch Step [150/323], D_loss: 0.6698,  G_loss: 1.4069\n",
      " Epoch [121/300], Batch Step [160/323], D_loss: 0.4891,  G_loss: 1.6303\n",
      " Epoch [121/300], Batch Step [170/323], D_loss: 0.7598,  G_loss: 1.4828\n",
      " Epoch [121/300], Batch Step [180/323], D_loss: 0.7156,  G_loss: 1.6136\n",
      " Epoch [121/300], Batch Step [190/323], D_loss: 0.8448,  G_loss: 1.4992\n",
      " Epoch [121/300], Batch Step [200/323], D_loss: 0.6400,  G_loss: 1.4639\n",
      " Epoch [121/300], Batch Step [210/323], D_loss: 0.6716,  G_loss: 1.6374\n",
      " Epoch [121/300], Batch Step [220/323], D_loss: 0.6140,  G_loss: 1.5116\n",
      " Epoch [121/300], Batch Step [230/323], D_loss: 0.6820,  G_loss: 1.5566\n",
      " Epoch [121/300], Batch Step [240/323], D_loss: 0.6875,  G_loss: 1.5544\n",
      " Epoch [121/300], Batch Step [250/323], D_loss: 0.5881,  G_loss: 1.5977\n",
      " Epoch [121/300], Batch Step [260/323], D_loss: 0.6231,  G_loss: 1.4427\n",
      " Epoch [121/300], Batch Step [270/323], D_loss: 0.8487,  G_loss: 1.5471\n",
      " Epoch [121/300], Batch Step [280/323], D_loss: 0.5886,  G_loss: 1.4494\n",
      " Epoch [121/300], Batch Step [290/323], D_loss: 0.6913,  G_loss: 1.6893\n",
      " Epoch [121/300], Batch Step [300/323], D_loss: 0.5394,  G_loss: 1.5668\n",
      " Epoch [121/300], Batch Step [310/323], D_loss: 0.6097,  G_loss: 1.5045\n",
      " Epoch [121/300], Batch Step [320/323], D_loss: 0.6495,  G_loss: 1.5892\n",
      " Epoch [122/300], Batch Step [0/323], D_loss: 0.7679,  G_loss: 1.6159\n",
      " Epoch [122/300], Batch Step [10/323], D_loss: 0.7613,  G_loss: 1.4835\n",
      " Epoch [122/300], Batch Step [20/323], D_loss: 0.6204,  G_loss: 1.6716\n",
      " Epoch [122/300], Batch Step [30/323], D_loss: 0.7077,  G_loss: 1.5155\n",
      " Epoch [122/300], Batch Step [40/323], D_loss: 0.6987,  G_loss: 1.4473\n",
      " Epoch [122/300], Batch Step [50/323], D_loss: 0.6500,  G_loss: 1.5791\n",
      " Epoch [122/300], Batch Step [60/323], D_loss: 0.5752,  G_loss: 1.6131\n",
      " Epoch [122/300], Batch Step [70/323], D_loss: 0.7157,  G_loss: 1.5594\n",
      " Epoch [122/300], Batch Step [80/323], D_loss: 0.6635,  G_loss: 1.5837\n",
      " Epoch [122/300], Batch Step [90/323], D_loss: 0.8070,  G_loss: 1.5072\n",
      " Epoch [122/300], Batch Step [100/323], D_loss: 0.6483,  G_loss: 1.4844\n",
      " Epoch [122/300], Batch Step [110/323], D_loss: 0.6783,  G_loss: 1.5413\n",
      " Epoch [122/300], Batch Step [120/323], D_loss: 0.7367,  G_loss: 1.4151\n",
      " Epoch [122/300], Batch Step [130/323], D_loss: 0.6647,  G_loss: 1.6157\n",
      " Epoch [122/300], Batch Step [140/323], D_loss: 0.5887,  G_loss: 1.3681\n",
      " Epoch [122/300], Batch Step [150/323], D_loss: 0.7670,  G_loss: 1.6761\n",
      " Epoch [122/300], Batch Step [160/323], D_loss: 0.6073,  G_loss: 1.3391\n",
      " Epoch [122/300], Batch Step [170/323], D_loss: 0.7254,  G_loss: 1.5189\n",
      " Epoch [122/300], Batch Step [180/323], D_loss: 0.6270,  G_loss: 1.6078\n",
      " Epoch [122/300], Batch Step [190/323], D_loss: 0.5789,  G_loss: 1.5372\n",
      " Epoch [122/300], Batch Step [200/323], D_loss: 0.6932,  G_loss: 1.5078\n",
      " Epoch [122/300], Batch Step [210/323], D_loss: 0.5650,  G_loss: 1.5498\n",
      " Epoch [122/300], Batch Step [220/323], D_loss: 0.6293,  G_loss: 1.6940\n",
      " Epoch [122/300], Batch Step [230/323], D_loss: 0.6046,  G_loss: 1.4206\n",
      " Epoch [122/300], Batch Step [240/323], D_loss: 0.5073,  G_loss: 1.5991\n",
      " Epoch [122/300], Batch Step [250/323], D_loss: 0.6933,  G_loss: 1.7490\n",
      " Epoch [122/300], Batch Step [260/323], D_loss: 0.7585,  G_loss: 1.3222\n",
      " Epoch [122/300], Batch Step [270/323], D_loss: 0.6786,  G_loss: 1.6355\n",
      " Epoch [122/300], Batch Step [280/323], D_loss: 0.5360,  G_loss: 1.5746\n",
      " Epoch [122/300], Batch Step [290/323], D_loss: 0.8360,  G_loss: 1.6117\n",
      " Epoch [122/300], Batch Step [300/323], D_loss: 0.7418,  G_loss: 1.6474\n",
      " Epoch [122/300], Batch Step [310/323], D_loss: 0.6249,  G_loss: 1.5870\n",
      " Epoch [122/300], Batch Step [320/323], D_loss: 0.6105,  G_loss: 1.5371\n",
      " Epoch [123/300], Batch Step [0/323], D_loss: 0.8328,  G_loss: 1.5158\n",
      " Epoch [123/300], Batch Step [10/323], D_loss: 0.7315,  G_loss: 1.5127\n",
      " Epoch [123/300], Batch Step [20/323], D_loss: 0.7809,  G_loss: 1.6566\n",
      " Epoch [123/300], Batch Step [30/323], D_loss: 0.7027,  G_loss: 1.3746\n",
      " Epoch [123/300], Batch Step [40/323], D_loss: 0.8577,  G_loss: 1.6140\n",
      " Epoch [123/300], Batch Step [50/323], D_loss: 0.7921,  G_loss: 1.5133\n",
      " Epoch [123/300], Batch Step [60/323], D_loss: 0.6826,  G_loss: 1.5133\n",
      " Epoch [123/300], Batch Step [70/323], D_loss: 0.7661,  G_loss: 1.5345\n",
      " Epoch [123/300], Batch Step [80/323], D_loss: 0.5144,  G_loss: 1.5759\n",
      " Epoch [123/300], Batch Step [90/323], D_loss: 0.6571,  G_loss: 1.4992\n",
      " Epoch [123/300], Batch Step [100/323], D_loss: 0.5080,  G_loss: 1.5961\n",
      " Epoch [123/300], Batch Step [110/323], D_loss: 0.8181,  G_loss: 1.3598\n",
      " Epoch [123/300], Batch Step [120/323], D_loss: 0.7363,  G_loss: 1.4537\n",
      " Epoch [123/300], Batch Step [130/323], D_loss: 0.7705,  G_loss: 1.5627\n",
      " Epoch [123/300], Batch Step [140/323], D_loss: 0.6434,  G_loss: 1.4264\n",
      " Epoch [123/300], Batch Step [150/323], D_loss: 0.6576,  G_loss: 1.5485\n",
      " Epoch [123/300], Batch Step [160/323], D_loss: 0.5772,  G_loss: 1.5403\n",
      " Epoch [123/300], Batch Step [170/323], D_loss: 0.6632,  G_loss: 1.5915\n",
      " Epoch [123/300], Batch Step [180/323], D_loss: 0.7200,  G_loss: 1.6085\n",
      " Epoch [123/300], Batch Step [190/323], D_loss: 0.6828,  G_loss: 1.5197\n",
      " Epoch [123/300], Batch Step [200/323], D_loss: 0.8055,  G_loss: 1.5324\n",
      " Epoch [123/300], Batch Step [210/323], D_loss: 0.4974,  G_loss: 1.5358\n",
      " Epoch [123/300], Batch Step [220/323], D_loss: 0.5741,  G_loss: 1.6486\n",
      " Epoch [123/300], Batch Step [230/323], D_loss: 0.7323,  G_loss: 1.5945\n",
      " Epoch [123/300], Batch Step [240/323], D_loss: 0.8183,  G_loss: 1.5205\n",
      " Epoch [123/300], Batch Step [250/323], D_loss: 0.7124,  G_loss: 1.4916\n",
      " Epoch [123/300], Batch Step [260/323], D_loss: 0.7704,  G_loss: 1.5785\n",
      " Epoch [123/300], Batch Step [270/323], D_loss: 0.6175,  G_loss: 1.4159\n",
      " Epoch [123/300], Batch Step [280/323], D_loss: 0.6116,  G_loss: 1.6334\n",
      " Epoch [123/300], Batch Step [290/323], D_loss: 0.7099,  G_loss: 1.5500\n",
      " Epoch [123/300], Batch Step [300/323], D_loss: 0.5769,  G_loss: 1.5272\n",
      " Epoch [123/300], Batch Step [310/323], D_loss: 0.5247,  G_loss: 1.5989\n",
      " Epoch [123/300], Batch Step [320/323], D_loss: 0.6917,  G_loss: 1.6838\n",
      " Epoch [124/300], Batch Step [0/323], D_loss: 0.6320,  G_loss: 1.5814\n",
      " Epoch [124/300], Batch Step [10/323], D_loss: 0.7788,  G_loss: 1.5217\n",
      " Epoch [124/300], Batch Step [20/323], D_loss: 0.6671,  G_loss: 1.5289\n",
      " Epoch [124/300], Batch Step [30/323], D_loss: 0.6896,  G_loss: 1.5500\n",
      " Epoch [124/300], Batch Step [40/323], D_loss: 0.6751,  G_loss: 1.5755\n",
      " Epoch [124/300], Batch Step [50/323], D_loss: 0.6850,  G_loss: 1.5321\n",
      " Epoch [124/300], Batch Step [60/323], D_loss: 0.5949,  G_loss: 1.5073\n",
      " Epoch [124/300], Batch Step [70/323], D_loss: 0.5196,  G_loss: 1.5679\n",
      " Epoch [124/300], Batch Step [80/323], D_loss: 0.8528,  G_loss: 1.3904\n",
      " Epoch [124/300], Batch Step [90/323], D_loss: 0.6277,  G_loss: 1.6823\n",
      " Epoch [124/300], Batch Step [100/323], D_loss: 0.6605,  G_loss: 1.5537\n",
      " Epoch [124/300], Batch Step [110/323], D_loss: 0.5947,  G_loss: 1.5019\n",
      " Epoch [124/300], Batch Step [120/323], D_loss: 0.7401,  G_loss: 1.5420\n",
      " Epoch [124/300], Batch Step [130/323], D_loss: 0.6798,  G_loss: 1.7452\n",
      " Epoch [124/300], Batch Step [140/323], D_loss: 0.7583,  G_loss: 1.5264\n",
      " Epoch [124/300], Batch Step [150/323], D_loss: 0.6958,  G_loss: 1.5897\n",
      " Epoch [124/300], Batch Step [160/323], D_loss: 0.7699,  G_loss: 1.4242\n",
      " Epoch [124/300], Batch Step [170/323], D_loss: 0.5127,  G_loss: 1.5355\n",
      " Epoch [124/300], Batch Step [180/323], D_loss: 0.6146,  G_loss: 1.5547\n",
      " Epoch [124/300], Batch Step [190/323], D_loss: 0.6728,  G_loss: 1.4146\n",
      " Epoch [124/300], Batch Step [200/323], D_loss: 0.7487,  G_loss: 1.7049\n",
      " Epoch [124/300], Batch Step [210/323], D_loss: 0.6830,  G_loss: 1.3340\n",
      " Epoch [124/300], Batch Step [220/323], D_loss: 0.5618,  G_loss: 1.5796\n",
      " Epoch [124/300], Batch Step [230/323], D_loss: 0.7083,  G_loss: 1.5082\n",
      " Epoch [124/300], Batch Step [240/323], D_loss: 0.5851,  G_loss: 1.4174\n",
      " Epoch [124/300], Batch Step [250/323], D_loss: 0.6177,  G_loss: 1.3938\n",
      " Epoch [124/300], Batch Step [260/323], D_loss: 0.7825,  G_loss: 1.5782\n",
      " Epoch [124/300], Batch Step [270/323], D_loss: 0.6415,  G_loss: 1.7560\n",
      " Epoch [124/300], Batch Step [280/323], D_loss: 0.6801,  G_loss: 1.4648\n",
      " Epoch [124/300], Batch Step [290/323], D_loss: 0.7295,  G_loss: 1.4181\n",
      " Epoch [124/300], Batch Step [300/323], D_loss: 0.6679,  G_loss: 1.5536\n",
      " Epoch [124/300], Batch Step [310/323], D_loss: 0.7219,  G_loss: 1.4627\n",
      " Epoch [124/300], Batch Step [320/323], D_loss: 0.8050,  G_loss: 1.4777\n",
      " Epoch [125/300], Batch Step [0/323], D_loss: 0.5320,  G_loss: 1.5675\n",
      " Epoch [125/300], Batch Step [10/323], D_loss: 0.6840,  G_loss: 1.6200\n",
      " Epoch [125/300], Batch Step [20/323], D_loss: 0.7082,  G_loss: 1.4148\n",
      " Epoch [125/300], Batch Step [30/323], D_loss: 0.8840,  G_loss: 1.5405\n",
      " Epoch [125/300], Batch Step [40/323], D_loss: 0.8014,  G_loss: 1.4431\n",
      " Epoch [125/300], Batch Step [50/323], D_loss: 0.6238,  G_loss: 1.6279\n",
      " Epoch [125/300], Batch Step [60/323], D_loss: 0.6600,  G_loss: 1.4903\n",
      " Epoch [125/300], Batch Step [70/323], D_loss: 0.6328,  G_loss: 1.6507\n",
      " Epoch [125/300], Batch Step [80/323], D_loss: 0.7445,  G_loss: 1.5591\n",
      " Epoch [125/300], Batch Step [90/323], D_loss: 0.6256,  G_loss: 1.4365\n",
      " Epoch [125/300], Batch Step [100/323], D_loss: 0.6193,  G_loss: 1.6756\n",
      " Epoch [125/300], Batch Step [110/323], D_loss: 0.6018,  G_loss: 1.4192\n",
      " Epoch [125/300], Batch Step [120/323], D_loss: 0.6482,  G_loss: 1.6140\n",
      " Epoch [125/300], Batch Step [130/323], D_loss: 0.6220,  G_loss: 1.6168\n",
      " Epoch [125/300], Batch Step [140/323], D_loss: 0.6392,  G_loss: 1.4851\n",
      " Epoch [125/300], Batch Step [150/323], D_loss: 0.6108,  G_loss: 1.6247\n",
      " Epoch [125/300], Batch Step [160/323], D_loss: 0.7282,  G_loss: 1.5237\n",
      " Epoch [125/300], Batch Step [170/323], D_loss: 0.5457,  G_loss: 1.5641\n",
      " Epoch [125/300], Batch Step [180/323], D_loss: 0.7166,  G_loss: 1.6338\n",
      " Epoch [125/300], Batch Step [190/323], D_loss: 0.7819,  G_loss: 1.4300\n",
      " Epoch [125/300], Batch Step [200/323], D_loss: 0.5915,  G_loss: 1.6322\n",
      " Epoch [125/300], Batch Step [210/323], D_loss: 0.8008,  G_loss: 1.4783\n",
      " Epoch [125/300], Batch Step [220/323], D_loss: 0.6488,  G_loss: 1.4485\n",
      " Epoch [125/300], Batch Step [230/323], D_loss: 0.7699,  G_loss: 1.5661\n",
      " Epoch [125/300], Batch Step [240/323], D_loss: 0.7558,  G_loss: 1.5752\n",
      " Epoch [125/300], Batch Step [250/323], D_loss: 0.6139,  G_loss: 1.6148\n",
      " Epoch [125/300], Batch Step [260/323], D_loss: 0.6753,  G_loss: 1.5477\n",
      " Epoch [125/300], Batch Step [270/323], D_loss: 0.8012,  G_loss: 1.4310\n",
      " Epoch [125/300], Batch Step [280/323], D_loss: 0.6571,  G_loss: 1.6611\n",
      " Epoch [125/300], Batch Step [290/323], D_loss: 0.5817,  G_loss: 1.6187\n",
      " Epoch [125/300], Batch Step [300/323], D_loss: 0.6169,  G_loss: 1.3852\n",
      " Epoch [125/300], Batch Step [310/323], D_loss: 0.6524,  G_loss: 1.6978\n",
      " Epoch [125/300], Batch Step [320/323], D_loss: 0.7658,  G_loss: 1.5199\n",
      " Epoch [126/300], Batch Step [0/323], D_loss: 0.6854,  G_loss: 1.4497\n",
      " Epoch [126/300], Batch Step [10/323], D_loss: 0.6163,  G_loss: 1.7199\n",
      " Epoch [126/300], Batch Step [20/323], D_loss: 0.7922,  G_loss: 1.5562\n",
      " Epoch [126/300], Batch Step [30/323], D_loss: 0.8662,  G_loss: 1.5951\n",
      " Epoch [126/300], Batch Step [40/323], D_loss: 0.6820,  G_loss: 1.4246\n",
      " Epoch [126/300], Batch Step [50/323], D_loss: 0.7643,  G_loss: 1.5175\n",
      " Epoch [126/300], Batch Step [60/323], D_loss: 0.7185,  G_loss: 1.4911\n",
      " Epoch [126/300], Batch Step [70/323], D_loss: 0.6396,  G_loss: 1.5912\n",
      " Epoch [126/300], Batch Step [80/323], D_loss: 0.6713,  G_loss: 1.5090\n",
      " Epoch [126/300], Batch Step [90/323], D_loss: 0.8147,  G_loss: 1.6442\n",
      " Epoch [126/300], Batch Step [100/323], D_loss: 0.6455,  G_loss: 1.5460\n",
      " Epoch [126/300], Batch Step [110/323], D_loss: 0.4969,  G_loss: 1.6491\n",
      " Epoch [126/300], Batch Step [120/323], D_loss: 0.5242,  G_loss: 1.5921\n",
      " Epoch [126/300], Batch Step [130/323], D_loss: 0.6769,  G_loss: 1.5118\n",
      " Epoch [126/300], Batch Step [140/323], D_loss: 0.6178,  G_loss: 1.5872\n",
      " Epoch [126/300], Batch Step [150/323], D_loss: 0.7860,  G_loss: 1.5008\n",
      " Epoch [126/300], Batch Step [160/323], D_loss: 0.6287,  G_loss: 1.5016\n",
      " Epoch [126/300], Batch Step [170/323], D_loss: 0.6580,  G_loss: 1.6180\n",
      " Epoch [126/300], Batch Step [180/323], D_loss: 0.6768,  G_loss: 1.4536\n",
      " Epoch [126/300], Batch Step [190/323], D_loss: 0.6264,  G_loss: 1.8135\n",
      " Epoch [126/300], Batch Step [200/323], D_loss: 0.6533,  G_loss: 1.6074\n",
      " Epoch [126/300], Batch Step [210/323], D_loss: 0.7646,  G_loss: 1.4765\n",
      " Epoch [126/300], Batch Step [220/323], D_loss: 0.7627,  G_loss: 1.5446\n",
      " Epoch [126/300], Batch Step [230/323], D_loss: 0.6338,  G_loss: 1.5445\n",
      " Epoch [126/300], Batch Step [240/323], D_loss: 0.7035,  G_loss: 1.6630\n",
      " Epoch [126/300], Batch Step [250/323], D_loss: 0.6306,  G_loss: 1.5786\n",
      " Epoch [126/300], Batch Step [260/323], D_loss: 0.6412,  G_loss: 1.5930\n",
      " Epoch [126/300], Batch Step [270/323], D_loss: 0.6798,  G_loss: 1.5589\n",
      " Epoch [126/300], Batch Step [280/323], D_loss: 0.6517,  G_loss: 1.4530\n",
      " Epoch [126/300], Batch Step [290/323], D_loss: 0.6145,  G_loss: 1.6511\n",
      " Epoch [126/300], Batch Step [300/323], D_loss: 0.7496,  G_loss: 1.4189\n",
      " Epoch [126/300], Batch Step [310/323], D_loss: 0.6129,  G_loss: 1.5510\n",
      " Epoch [126/300], Batch Step [320/323], D_loss: 0.5361,  G_loss: 1.6389\n",
      " Epoch [127/300], Batch Step [0/323], D_loss: 0.7541,  G_loss: 1.6306\n",
      " Epoch [127/300], Batch Step [10/323], D_loss: 0.5946,  G_loss: 1.4302\n",
      " Epoch [127/300], Batch Step [20/323], D_loss: 0.7636,  G_loss: 1.5193\n",
      " Epoch [127/300], Batch Step [30/323], D_loss: 0.8402,  G_loss: 1.5892\n",
      " Epoch [127/300], Batch Step [40/323], D_loss: 0.7276,  G_loss: 1.4470\n",
      " Epoch [127/300], Batch Step [50/323], D_loss: 0.6130,  G_loss: 1.5670\n",
      " Epoch [127/300], Batch Step [60/323], D_loss: 0.6289,  G_loss: 1.7441\n",
      " Epoch [127/300], Batch Step [70/323], D_loss: 0.5881,  G_loss: 1.5412\n",
      " Epoch [127/300], Batch Step [80/323], D_loss: 0.8237,  G_loss: 1.5466\n",
      " Epoch [127/300], Batch Step [90/323], D_loss: 0.6960,  G_loss: 1.5143\n",
      " Epoch [127/300], Batch Step [100/323], D_loss: 0.6997,  G_loss: 1.5847\n",
      " Epoch [127/300], Batch Step [110/323], D_loss: 0.6303,  G_loss: 1.5161\n",
      " Epoch [127/300], Batch Step [120/323], D_loss: 0.6858,  G_loss: 1.5038\n",
      " Epoch [127/300], Batch Step [130/323], D_loss: 0.6077,  G_loss: 1.5721\n",
      " Epoch [127/300], Batch Step [140/323], D_loss: 0.6396,  G_loss: 1.4868\n",
      " Epoch [127/300], Batch Step [150/323], D_loss: 0.7064,  G_loss: 1.6529\n",
      " Epoch [127/300], Batch Step [160/323], D_loss: 0.6652,  G_loss: 1.5420\n",
      " Epoch [127/300], Batch Step [170/323], D_loss: 0.6522,  G_loss: 1.5926\n",
      " Epoch [127/300], Batch Step [180/323], D_loss: 0.6765,  G_loss: 1.5992\n",
      " Epoch [127/300], Batch Step [190/323], D_loss: 0.6378,  G_loss: 1.4814\n",
      " Epoch [127/300], Batch Step [200/323], D_loss: 0.5315,  G_loss: 1.6829\n",
      " Epoch [127/300], Batch Step [210/323], D_loss: 0.6429,  G_loss: 1.4581\n",
      " Epoch [127/300], Batch Step [220/323], D_loss: 0.6661,  G_loss: 1.4795\n",
      " Epoch [127/300], Batch Step [230/323], D_loss: 0.5735,  G_loss: 1.8818\n",
      " Epoch [127/300], Batch Step [240/323], D_loss: 0.6970,  G_loss: 1.5043\n",
      " Epoch [127/300], Batch Step [250/323], D_loss: 0.6479,  G_loss: 1.6385\n",
      " Epoch [127/300], Batch Step [260/323], D_loss: 0.5964,  G_loss: 1.5618\n",
      " Epoch [127/300], Batch Step [270/323], D_loss: 0.6201,  G_loss: 1.4766\n",
      " Epoch [127/300], Batch Step [280/323], D_loss: 0.4513,  G_loss: 1.6711\n",
      " Epoch [127/300], Batch Step [290/323], D_loss: 0.5066,  G_loss: 1.5682\n",
      " Epoch [127/300], Batch Step [300/323], D_loss: 0.6574,  G_loss: 1.6309\n",
      " Epoch [127/300], Batch Step [310/323], D_loss: 0.5247,  G_loss: 1.5723\n",
      " Epoch [127/300], Batch Step [320/323], D_loss: 0.6214,  G_loss: 1.5510\n",
      " Epoch [128/300], Batch Step [0/323], D_loss: 0.6895,  G_loss: 1.5679\n",
      " Epoch [128/300], Batch Step [10/323], D_loss: 0.5553,  G_loss: 1.5222\n",
      " Epoch [128/300], Batch Step [20/323], D_loss: 0.8063,  G_loss: 1.6115\n",
      " Epoch [128/300], Batch Step [30/323], D_loss: 0.6508,  G_loss: 1.5470\n",
      " Epoch [128/300], Batch Step [40/323], D_loss: 0.6945,  G_loss: 1.5893\n",
      " Epoch [128/300], Batch Step [50/323], D_loss: 0.7541,  G_loss: 1.4312\n",
      " Epoch [128/300], Batch Step [60/323], D_loss: 0.6016,  G_loss: 1.6572\n",
      " Epoch [128/300], Batch Step [70/323], D_loss: 0.8033,  G_loss: 1.4659\n",
      " Epoch [128/300], Batch Step [80/323], D_loss: 0.8421,  G_loss: 1.5683\n",
      " Epoch [128/300], Batch Step [90/323], D_loss: 0.5714,  G_loss: 1.6756\n",
      " Epoch [128/300], Batch Step [100/323], D_loss: 0.6207,  G_loss: 1.6190\n",
      " Epoch [128/300], Batch Step [110/323], D_loss: 0.5458,  G_loss: 1.5962\n",
      " Epoch [128/300], Batch Step [120/323], D_loss: 0.6746,  G_loss: 1.4964\n",
      " Epoch [128/300], Batch Step [130/323], D_loss: 0.6688,  G_loss: 1.5962\n",
      " Epoch [128/300], Batch Step [140/323], D_loss: 0.8675,  G_loss: 1.4757\n",
      " Epoch [128/300], Batch Step [150/323], D_loss: 0.7073,  G_loss: 1.4764\n",
      " Epoch [128/300], Batch Step [160/323], D_loss: 0.6088,  G_loss: 1.4281\n",
      " Epoch [128/300], Batch Step [170/323], D_loss: 0.6202,  G_loss: 1.6718\n",
      " Epoch [128/300], Batch Step [180/323], D_loss: 0.5443,  G_loss: 1.5647\n",
      " Epoch [128/300], Batch Step [190/323], D_loss: 0.5837,  G_loss: 1.5411\n",
      " Epoch [128/300], Batch Step [200/323], D_loss: 0.4961,  G_loss: 1.5845\n",
      " Epoch [128/300], Batch Step [210/323], D_loss: 0.6388,  G_loss: 1.4851\n",
      " Epoch [128/300], Batch Step [220/323], D_loss: 0.7353,  G_loss: 1.5573\n",
      " Epoch [128/300], Batch Step [230/323], D_loss: 0.7955,  G_loss: 1.6257\n",
      " Epoch [128/300], Batch Step [240/323], D_loss: 0.5905,  G_loss: 1.6117\n",
      " Epoch [128/300], Batch Step [250/323], D_loss: 0.7662,  G_loss: 1.4635\n",
      " Epoch [128/300], Batch Step [260/323], D_loss: 0.5922,  G_loss: 1.4907\n",
      " Epoch [128/300], Batch Step [270/323], D_loss: 0.6612,  G_loss: 1.4872\n",
      " Epoch [128/300], Batch Step [280/323], D_loss: 0.8068,  G_loss: 1.6082\n",
      " Epoch [128/300], Batch Step [290/323], D_loss: 0.8083,  G_loss: 1.4327\n",
      " Epoch [128/300], Batch Step [300/323], D_loss: 0.6268,  G_loss: 1.4614\n",
      " Epoch [128/300], Batch Step [310/323], D_loss: 0.6436,  G_loss: 1.7619\n",
      " Epoch [128/300], Batch Step [320/323], D_loss: 0.6220,  G_loss: 1.6594\n",
      " Epoch [129/300], Batch Step [0/323], D_loss: 1.0363,  G_loss: 1.5453\n",
      " Epoch [129/300], Batch Step [10/323], D_loss: 0.6713,  G_loss: 1.5064\n",
      " Epoch [129/300], Batch Step [20/323], D_loss: 0.6226,  G_loss: 1.5758\n",
      " Epoch [129/300], Batch Step [30/323], D_loss: 0.7346,  G_loss: 1.5220\n",
      " Epoch [129/300], Batch Step [40/323], D_loss: 0.5594,  G_loss: 1.7550\n",
      " Epoch [129/300], Batch Step [50/323], D_loss: 0.7201,  G_loss: 1.4457\n",
      " Epoch [129/300], Batch Step [60/323], D_loss: 0.7011,  G_loss: 1.6614\n",
      " Epoch [129/300], Batch Step [70/323], D_loss: 0.8330,  G_loss: 1.6378\n",
      " Epoch [129/300], Batch Step [80/323], D_loss: 0.6790,  G_loss: 1.4083\n",
      " Epoch [129/300], Batch Step [90/323], D_loss: 0.6351,  G_loss: 1.5388\n",
      " Epoch [129/300], Batch Step [100/323], D_loss: 0.8104,  G_loss: 1.4867\n",
      " Epoch [129/300], Batch Step [110/323], D_loss: 0.7315,  G_loss: 1.5508\n",
      " Epoch [129/300], Batch Step [120/323], D_loss: 0.7248,  G_loss: 1.5297\n",
      " Epoch [129/300], Batch Step [130/323], D_loss: 0.7046,  G_loss: 1.3997\n",
      " Epoch [129/300], Batch Step [140/323], D_loss: 0.7069,  G_loss: 1.6910\n",
      " Epoch [129/300], Batch Step [150/323], D_loss: 0.6562,  G_loss: 1.5289\n",
      " Epoch [129/300], Batch Step [160/323], D_loss: 0.6597,  G_loss: 1.6038\n",
      " Epoch [129/300], Batch Step [170/323], D_loss: 0.6888,  G_loss: 1.5017\n",
      " Epoch [129/300], Batch Step [180/323], D_loss: 0.8153,  G_loss: 1.4476\n",
      " Epoch [129/300], Batch Step [190/323], D_loss: 0.5946,  G_loss: 1.4394\n",
      " Epoch [129/300], Batch Step [200/323], D_loss: 0.5838,  G_loss: 1.6191\n",
      " Epoch [129/300], Batch Step [210/323], D_loss: 0.6995,  G_loss: 1.4669\n",
      " Epoch [129/300], Batch Step [220/323], D_loss: 0.7051,  G_loss: 1.5233\n",
      " Epoch [129/300], Batch Step [230/323], D_loss: 0.7272,  G_loss: 1.5220\n",
      " Epoch [129/300], Batch Step [240/323], D_loss: 0.6211,  G_loss: 1.4838\n",
      " Epoch [129/300], Batch Step [250/323], D_loss: 0.6972,  G_loss: 1.5240\n",
      " Epoch [129/300], Batch Step [260/323], D_loss: 0.7683,  G_loss: 1.5405\n",
      " Epoch [129/300], Batch Step [270/323], D_loss: 0.6877,  G_loss: 1.5958\n",
      " Epoch [129/300], Batch Step [280/323], D_loss: 0.7825,  G_loss: 1.4265\n",
      " Epoch [129/300], Batch Step [290/323], D_loss: 0.7198,  G_loss: 1.6777\n",
      " Epoch [129/300], Batch Step [300/323], D_loss: 0.6823,  G_loss: 1.4194\n",
      " Epoch [129/300], Batch Step [310/323], D_loss: 0.5791,  G_loss: 1.5096\n",
      " Epoch [129/300], Batch Step [320/323], D_loss: 0.5222,  G_loss: 1.7686\n",
      " Epoch [130/300], Batch Step [0/323], D_loss: 0.7087,  G_loss: 1.6825\n",
      " Epoch [130/300], Batch Step [10/323], D_loss: 0.5663,  G_loss: 1.4018\n",
      " Epoch [130/300], Batch Step [20/323], D_loss: 0.6482,  G_loss: 1.6761\n",
      " Epoch [130/300], Batch Step [30/323], D_loss: 0.6878,  G_loss: 1.6198\n",
      " Epoch [130/300], Batch Step [40/323], D_loss: 0.9184,  G_loss: 1.6104\n",
      " Epoch [130/300], Batch Step [50/323], D_loss: 0.7275,  G_loss: 1.4135\n",
      " Epoch [130/300], Batch Step [60/323], D_loss: 0.4781,  G_loss: 1.7309\n",
      " Epoch [130/300], Batch Step [70/323], D_loss: 0.6916,  G_loss: 1.4606\n",
      " Epoch [130/300], Batch Step [80/323], D_loss: 0.6818,  G_loss: 1.5426\n",
      " Epoch [130/300], Batch Step [90/323], D_loss: 0.6910,  G_loss: 1.5627\n",
      " Epoch [130/300], Batch Step [100/323], D_loss: 0.7438,  G_loss: 1.4599\n",
      " Epoch [130/300], Batch Step [110/323], D_loss: 0.7312,  G_loss: 1.5781\n",
      " Epoch [130/300], Batch Step [120/323], D_loss: 0.6761,  G_loss: 1.5817\n",
      " Epoch [130/300], Batch Step [130/323], D_loss: 0.7414,  G_loss: 1.3756\n",
      " Epoch [130/300], Batch Step [140/323], D_loss: 0.5700,  G_loss: 1.5924\n",
      " Epoch [130/300], Batch Step [150/323], D_loss: 0.4763,  G_loss: 1.4984\n",
      " Epoch [130/300], Batch Step [160/323], D_loss: 0.6128,  G_loss: 1.5890\n",
      " Epoch [130/300], Batch Step [170/323], D_loss: 0.6765,  G_loss: 1.5895\n",
      " Epoch [130/300], Batch Step [180/323], D_loss: 0.6301,  G_loss: 1.5070\n",
      " Epoch [130/300], Batch Step [190/323], D_loss: 0.7107,  G_loss: 1.3783\n",
      " Epoch [130/300], Batch Step [200/323], D_loss: 0.7445,  G_loss: 1.5996\n",
      " Epoch [130/300], Batch Step [210/323], D_loss: 0.6574,  G_loss: 1.3162\n",
      " Epoch [130/300], Batch Step [220/323], D_loss: 0.5574,  G_loss: 1.7714\n",
      " Epoch [130/300], Batch Step [230/323], D_loss: 0.6570,  G_loss: 1.3852\n",
      " Epoch [130/300], Batch Step [240/323], D_loss: 0.6766,  G_loss: 1.7232\n",
      " Epoch [130/300], Batch Step [250/323], D_loss: 0.6083,  G_loss: 1.6585\n",
      " Epoch [130/300], Batch Step [260/323], D_loss: 0.6005,  G_loss: 1.5881\n",
      " Epoch [130/300], Batch Step [270/323], D_loss: 0.6182,  G_loss: 1.6761\n",
      " Epoch [130/300], Batch Step [280/323], D_loss: 0.8879,  G_loss: 1.4695\n",
      " Epoch [130/300], Batch Step [290/323], D_loss: 0.6008,  G_loss: 1.6821\n",
      " Epoch [130/300], Batch Step [300/323], D_loss: 0.7630,  G_loss: 1.7282\n",
      " Epoch [130/300], Batch Step [310/323], D_loss: 0.8930,  G_loss: 1.3632\n",
      " Epoch [130/300], Batch Step [320/323], D_loss: 0.6529,  G_loss: 1.7681\n",
      " Epoch [131/300], Batch Step [0/323], D_loss: 0.5841,  G_loss: 1.7931\n",
      " Epoch [131/300], Batch Step [10/323], D_loss: 0.5296,  G_loss: 1.5209\n",
      " Epoch [131/300], Batch Step [20/323], D_loss: 0.6529,  G_loss: 1.5317\n",
      " Epoch [131/300], Batch Step [30/323], D_loss: 0.5721,  G_loss: 1.5389\n",
      " Epoch [131/300], Batch Step [40/323], D_loss: 0.6057,  G_loss: 1.6428\n",
      " Epoch [131/300], Batch Step [50/323], D_loss: 0.7880,  G_loss: 1.5289\n",
      " Epoch [131/300], Batch Step [60/323], D_loss: 0.7694,  G_loss: 1.4857\n",
      " Epoch [131/300], Batch Step [70/323], D_loss: 0.8511,  G_loss: 1.5884\n",
      " Epoch [131/300], Batch Step [80/323], D_loss: 0.6782,  G_loss: 1.4116\n",
      " Epoch [131/300], Batch Step [90/323], D_loss: 0.8393,  G_loss: 1.5417\n",
      " Epoch [131/300], Batch Step [100/323], D_loss: 0.4926,  G_loss: 1.5892\n",
      " Epoch [131/300], Batch Step [110/323], D_loss: 0.6266,  G_loss: 1.4930\n",
      " Epoch [131/300], Batch Step [120/323], D_loss: 0.6482,  G_loss: 1.6189\n",
      " Epoch [131/300], Batch Step [130/323], D_loss: 0.5770,  G_loss: 1.5619\n",
      " Epoch [131/300], Batch Step [140/323], D_loss: 0.7290,  G_loss: 1.6445\n",
      " Epoch [131/300], Batch Step [150/323], D_loss: 0.5940,  G_loss: 1.7338\n",
      " Epoch [131/300], Batch Step [160/323], D_loss: 0.6175,  G_loss: 1.6935\n",
      " Epoch [131/300], Batch Step [170/323], D_loss: 0.5903,  G_loss: 1.5101\n",
      " Epoch [131/300], Batch Step [180/323], D_loss: 0.8114,  G_loss: 1.4998\n",
      " Epoch [131/300], Batch Step [190/323], D_loss: 0.6260,  G_loss: 1.6293\n",
      " Epoch [131/300], Batch Step [200/323], D_loss: 0.7398,  G_loss: 1.4142\n",
      " Epoch [131/300], Batch Step [210/323], D_loss: 0.6639,  G_loss: 1.5650\n",
      " Epoch [131/300], Batch Step [220/323], D_loss: 0.6622,  G_loss: 1.4522\n",
      " Epoch [131/300], Batch Step [230/323], D_loss: 0.6378,  G_loss: 1.5406\n",
      " Epoch [131/300], Batch Step [240/323], D_loss: 0.7600,  G_loss: 1.5986\n",
      " Epoch [131/300], Batch Step [250/323], D_loss: 0.7197,  G_loss: 1.6666\n",
      " Epoch [131/300], Batch Step [260/323], D_loss: 0.5635,  G_loss: 1.5355\n",
      " Epoch [131/300], Batch Step [270/323], D_loss: 0.5687,  G_loss: 1.7537\n",
      " Epoch [131/300], Batch Step [280/323], D_loss: 0.7710,  G_loss: 1.3770\n",
      " Epoch [131/300], Batch Step [290/323], D_loss: 0.6349,  G_loss: 1.7938\n",
      " Epoch [131/300], Batch Step [300/323], D_loss: 0.5977,  G_loss: 1.4838\n",
      " Epoch [131/300], Batch Step [310/323], D_loss: 0.6215,  G_loss: 1.5487\n",
      " Epoch [131/300], Batch Step [320/323], D_loss: 0.6071,  G_loss: 1.6786\n",
      " Epoch [132/300], Batch Step [0/323], D_loss: 0.6510,  G_loss: 1.5987\n",
      " Epoch [132/300], Batch Step [10/323], D_loss: 0.7837,  G_loss: 1.6126\n",
      " Epoch [132/300], Batch Step [20/323], D_loss: 0.6149,  G_loss: 1.5190\n",
      " Epoch [132/300], Batch Step [30/323], D_loss: 0.6961,  G_loss: 1.6903\n",
      " Epoch [132/300], Batch Step [40/323], D_loss: 0.7163,  G_loss: 1.5112\n",
      " Epoch [132/300], Batch Step [50/323], D_loss: 0.8103,  G_loss: 1.5870\n",
      " Epoch [132/300], Batch Step [60/323], D_loss: 0.6153,  G_loss: 1.7059\n",
      " Epoch [132/300], Batch Step [70/323], D_loss: 0.6140,  G_loss: 1.4678\n",
      " Epoch [132/300], Batch Step [80/323], D_loss: 0.6442,  G_loss: 1.6739\n",
      " Epoch [132/300], Batch Step [90/323], D_loss: 0.6973,  G_loss: 1.5546\n",
      " Epoch [132/300], Batch Step [100/323], D_loss: 0.6486,  G_loss: 1.5710\n",
      " Epoch [132/300], Batch Step [110/323], D_loss: 0.5774,  G_loss: 1.5742\n",
      " Epoch [132/300], Batch Step [120/323], D_loss: 0.5610,  G_loss: 1.6070\n",
      " Epoch [132/300], Batch Step [130/323], D_loss: 0.6939,  G_loss: 1.6561\n",
      " Epoch [132/300], Batch Step [140/323], D_loss: 0.7135,  G_loss: 1.5325\n",
      " Epoch [132/300], Batch Step [150/323], D_loss: 0.5744,  G_loss: 1.4920\n",
      " Epoch [132/300], Batch Step [160/323], D_loss: 0.7158,  G_loss: 1.6864\n",
      " Epoch [132/300], Batch Step [170/323], D_loss: 0.7347,  G_loss: 1.4396\n",
      " Epoch [132/300], Batch Step [180/323], D_loss: 0.5964,  G_loss: 1.5492\n",
      " Epoch [132/300], Batch Step [190/323], D_loss: 0.7621,  G_loss: 1.5572\n",
      " Epoch [132/300], Batch Step [200/323], D_loss: 0.7610,  G_loss: 1.4913\n",
      " Epoch [132/300], Batch Step [210/323], D_loss: 0.7871,  G_loss: 1.5102\n",
      " Epoch [132/300], Batch Step [220/323], D_loss: 0.7499,  G_loss: 1.4645\n",
      " Epoch [132/300], Batch Step [230/323], D_loss: 0.4313,  G_loss: 1.4882\n",
      " Epoch [132/300], Batch Step [240/323], D_loss: 0.7602,  G_loss: 1.6106\n",
      " Epoch [132/300], Batch Step [250/323], D_loss: 0.6473,  G_loss: 1.5684\n",
      " Epoch [132/300], Batch Step [260/323], D_loss: 0.7674,  G_loss: 1.5857\n",
      " Epoch [132/300], Batch Step [270/323], D_loss: 0.6816,  G_loss: 1.5366\n",
      " Epoch [132/300], Batch Step [280/323], D_loss: 0.6501,  G_loss: 1.4375\n",
      " Epoch [132/300], Batch Step [290/323], D_loss: 0.8229,  G_loss: 1.7119\n",
      " Epoch [132/300], Batch Step [300/323], D_loss: 0.6665,  G_loss: 1.5970\n",
      " Epoch [132/300], Batch Step [310/323], D_loss: 0.6436,  G_loss: 1.4769\n",
      " Epoch [132/300], Batch Step [320/323], D_loss: 0.6662,  G_loss: 1.6035\n",
      " Epoch [133/300], Batch Step [0/323], D_loss: 0.7766,  G_loss: 1.6214\n",
      " Epoch [133/300], Batch Step [10/323], D_loss: 0.6996,  G_loss: 1.5090\n",
      " Epoch [133/300], Batch Step [20/323], D_loss: 0.8155,  G_loss: 1.5819\n",
      " Epoch [133/300], Batch Step [30/323], D_loss: 0.7216,  G_loss: 1.5247\n",
      " Epoch [133/300], Batch Step [40/323], D_loss: 0.7967,  G_loss: 1.4959\n",
      " Epoch [133/300], Batch Step [50/323], D_loss: 0.5378,  G_loss: 1.5018\n",
      " Epoch [133/300], Batch Step [60/323], D_loss: 0.6917,  G_loss: 1.5774\n",
      " Epoch [133/300], Batch Step [70/323], D_loss: 0.6187,  G_loss: 1.5325\n",
      " Epoch [133/300], Batch Step [80/323], D_loss: 0.7182,  G_loss: 1.5068\n",
      " Epoch [133/300], Batch Step [90/323], D_loss: 0.6417,  G_loss: 1.5024\n",
      " Epoch [133/300], Batch Step [100/323], D_loss: 0.7138,  G_loss: 1.6916\n",
      " Epoch [133/300], Batch Step [110/323], D_loss: 0.7201,  G_loss: 1.5712\n",
      " Epoch [133/300], Batch Step [120/323], D_loss: 0.6215,  G_loss: 1.5625\n",
      " Epoch [133/300], Batch Step [130/323], D_loss: 0.8086,  G_loss: 1.6164\n",
      " Epoch [133/300], Batch Step [140/323], D_loss: 0.6852,  G_loss: 1.4818\n",
      " Epoch [133/300], Batch Step [150/323], D_loss: 0.5732,  G_loss: 1.6289\n",
      " Epoch [133/300], Batch Step [160/323], D_loss: 0.8233,  G_loss: 1.6746\n",
      " Epoch [133/300], Batch Step [170/323], D_loss: 0.6541,  G_loss: 1.4896\n",
      " Epoch [133/300], Batch Step [180/323], D_loss: 0.6092,  G_loss: 1.6629\n",
      " Epoch [133/300], Batch Step [190/323], D_loss: 0.6790,  G_loss: 1.5561\n",
      " Epoch [133/300], Batch Step [200/323], D_loss: 0.5679,  G_loss: 1.3978\n",
      " Epoch [133/300], Batch Step [210/323], D_loss: 0.5951,  G_loss: 1.7447\n",
      " Epoch [133/300], Batch Step [220/323], D_loss: 0.5332,  G_loss: 1.5804\n",
      " Epoch [133/300], Batch Step [230/323], D_loss: 0.7287,  G_loss: 1.5074\n",
      " Epoch [133/300], Batch Step [240/323], D_loss: 0.8168,  G_loss: 1.5683\n",
      " Epoch [133/300], Batch Step [250/323], D_loss: 0.7687,  G_loss: 1.5855\n",
      " Epoch [133/300], Batch Step [260/323], D_loss: 0.6360,  G_loss: 1.5150\n",
      " Epoch [133/300], Batch Step [270/323], D_loss: 0.6680,  G_loss: 1.6181\n",
      " Epoch [133/300], Batch Step [280/323], D_loss: 0.6938,  G_loss: 1.4988\n",
      " Epoch [133/300], Batch Step [290/323], D_loss: 0.7257,  G_loss: 1.6551\n",
      " Epoch [133/300], Batch Step [300/323], D_loss: 0.5804,  G_loss: 1.4813\n",
      " Epoch [133/300], Batch Step [310/323], D_loss: 0.6525,  G_loss: 1.4660\n",
      " Epoch [133/300], Batch Step [320/323], D_loss: 0.6844,  G_loss: 1.4536\n",
      " Epoch [134/300], Batch Step [0/323], D_loss: 0.7827,  G_loss: 1.4271\n",
      " Epoch [134/300], Batch Step [10/323], D_loss: 0.6996,  G_loss: 1.3783\n",
      " Epoch [134/300], Batch Step [20/323], D_loss: 0.7227,  G_loss: 1.6126\n",
      " Epoch [134/300], Batch Step [30/323], D_loss: 0.7364,  G_loss: 1.4956\n",
      " Epoch [134/300], Batch Step [40/323], D_loss: 0.5999,  G_loss: 1.5956\n",
      " Epoch [134/300], Batch Step [50/323], D_loss: 0.7108,  G_loss: 1.5134\n",
      " Epoch [134/300], Batch Step [60/323], D_loss: 0.7939,  G_loss: 1.4883\n",
      " Epoch [134/300], Batch Step [70/323], D_loss: 0.6566,  G_loss: 1.6490\n",
      " Epoch [134/300], Batch Step [80/323], D_loss: 0.4656,  G_loss: 1.5247\n",
      " Epoch [134/300], Batch Step [90/323], D_loss: 0.7032,  G_loss: 1.4669\n",
      " Epoch [134/300], Batch Step [100/323], D_loss: 0.6899,  G_loss: 1.4423\n",
      " Epoch [134/300], Batch Step [110/323], D_loss: 0.5557,  G_loss: 1.6232\n",
      " Epoch [134/300], Batch Step [120/323], D_loss: 0.5394,  G_loss: 1.6340\n",
      " Epoch [134/300], Batch Step [130/323], D_loss: 0.7757,  G_loss: 1.6508\n",
      " Epoch [134/300], Batch Step [140/323], D_loss: 0.5441,  G_loss: 1.6067\n",
      " Epoch [134/300], Batch Step [150/323], D_loss: 0.7496,  G_loss: 1.5665\n",
      " Epoch [134/300], Batch Step [160/323], D_loss: 0.7371,  G_loss: 1.6430\n",
      " Epoch [134/300], Batch Step [170/323], D_loss: 0.6726,  G_loss: 1.4864\n",
      " Epoch [134/300], Batch Step [180/323], D_loss: 0.7366,  G_loss: 1.4509\n",
      " Epoch [134/300], Batch Step [190/323], D_loss: 0.6244,  G_loss: 1.6534\n",
      " Epoch [134/300], Batch Step [200/323], D_loss: 0.6096,  G_loss: 1.5621\n",
      " Epoch [134/300], Batch Step [210/323], D_loss: 0.7421,  G_loss: 1.5429\n",
      " Epoch [134/300], Batch Step [220/323], D_loss: 0.6407,  G_loss: 1.6313\n",
      " Epoch [134/300], Batch Step [230/323], D_loss: 0.6389,  G_loss: 1.5541\n",
      " Epoch [134/300], Batch Step [240/323], D_loss: 0.7416,  G_loss: 1.4052\n",
      " Epoch [134/300], Batch Step [250/323], D_loss: 0.6280,  G_loss: 1.5441\n",
      " Epoch [134/300], Batch Step [260/323], D_loss: 0.5601,  G_loss: 1.6246\n",
      " Epoch [134/300], Batch Step [270/323], D_loss: 0.5534,  G_loss: 1.6517\n",
      " Epoch [134/300], Batch Step [280/323], D_loss: 0.7566,  G_loss: 1.5372\n",
      " Epoch [134/300], Batch Step [290/323], D_loss: 0.6382,  G_loss: 1.5716\n",
      " Epoch [134/300], Batch Step [300/323], D_loss: 0.5921,  G_loss: 1.5599\n",
      " Epoch [134/300], Batch Step [310/323], D_loss: 0.6214,  G_loss: 1.5236\n",
      " Epoch [134/300], Batch Step [320/323], D_loss: 0.5902,  G_loss: 1.6155\n",
      " Epoch [135/300], Batch Step [0/323], D_loss: 0.6281,  G_loss: 1.6528\n",
      " Epoch [135/300], Batch Step [10/323], D_loss: 0.5651,  G_loss: 1.5630\n",
      " Epoch [135/300], Batch Step [20/323], D_loss: 0.7765,  G_loss: 1.6014\n",
      " Epoch [135/300], Batch Step [30/323], D_loss: 0.7303,  G_loss: 1.6085\n",
      " Epoch [135/300], Batch Step [40/323], D_loss: 0.6957,  G_loss: 1.4310\n",
      " Epoch [135/300], Batch Step [50/323], D_loss: 0.6346,  G_loss: 1.5173\n",
      " Epoch [135/300], Batch Step [60/323], D_loss: 0.6382,  G_loss: 1.5354\n",
      " Epoch [135/300], Batch Step [70/323], D_loss: 0.7138,  G_loss: 1.4950\n",
      " Epoch [135/300], Batch Step [80/323], D_loss: 0.7731,  G_loss: 1.6487\n",
      " Epoch [135/300], Batch Step [90/323], D_loss: 0.6575,  G_loss: 1.5791\n",
      " Epoch [135/300], Batch Step [100/323], D_loss: 0.7215,  G_loss: 1.4731\n",
      " Epoch [135/300], Batch Step [110/323], D_loss: 0.6445,  G_loss: 1.5994\n",
      " Epoch [135/300], Batch Step [120/323], D_loss: 0.6732,  G_loss: 1.5101\n",
      " Epoch [135/300], Batch Step [130/323], D_loss: 0.7000,  G_loss: 1.4813\n",
      " Epoch [135/300], Batch Step [140/323], D_loss: 0.4983,  G_loss: 1.6356\n",
      " Epoch [135/300], Batch Step [150/323], D_loss: 0.7367,  G_loss: 1.5960\n",
      " Epoch [135/300], Batch Step [160/323], D_loss: 0.6494,  G_loss: 1.5426\n",
      " Epoch [135/300], Batch Step [170/323], D_loss: 0.7531,  G_loss: 1.6335\n",
      " Epoch [135/300], Batch Step [180/323], D_loss: 0.5535,  G_loss: 1.5680\n",
      " Epoch [135/300], Batch Step [190/323], D_loss: 0.6761,  G_loss: 1.5248\n",
      " Epoch [135/300], Batch Step [200/323], D_loss: 0.5998,  G_loss: 1.4990\n",
      " Epoch [135/300], Batch Step [210/323], D_loss: 0.6131,  G_loss: 1.5673\n",
      " Epoch [135/300], Batch Step [220/323], D_loss: 0.5927,  G_loss: 1.5452\n",
      " Epoch [135/300], Batch Step [230/323], D_loss: 0.4473,  G_loss: 1.5038\n",
      " Epoch [135/300], Batch Step [240/323], D_loss: 0.6505,  G_loss: 1.5839\n",
      " Epoch [135/300], Batch Step [250/323], D_loss: 0.6016,  G_loss: 1.5281\n",
      " Epoch [135/300], Batch Step [260/323], D_loss: 0.6996,  G_loss: 1.6093\n",
      " Epoch [135/300], Batch Step [270/323], D_loss: 0.7184,  G_loss: 1.4141\n",
      " Epoch [135/300], Batch Step [280/323], D_loss: 0.5506,  G_loss: 1.7463\n",
      " Epoch [135/300], Batch Step [290/323], D_loss: 0.7671,  G_loss: 1.5064\n",
      " Epoch [135/300], Batch Step [300/323], D_loss: 0.7306,  G_loss: 1.4787\n",
      " Epoch [135/300], Batch Step [310/323], D_loss: 0.7697,  G_loss: 1.5560\n",
      " Epoch [135/300], Batch Step [320/323], D_loss: 0.5827,  G_loss: 1.4805\n",
      " Epoch [136/300], Batch Step [0/323], D_loss: 0.6175,  G_loss: 1.4854\n",
      " Epoch [136/300], Batch Step [10/323], D_loss: 0.5801,  G_loss: 1.6601\n",
      " Epoch [136/300], Batch Step [20/323], D_loss: 0.7617,  G_loss: 1.4656\n",
      " Epoch [136/300], Batch Step [30/323], D_loss: 0.5874,  G_loss: 1.5555\n",
      " Epoch [136/300], Batch Step [40/323], D_loss: 0.6498,  G_loss: 1.6328\n",
      " Epoch [136/300], Batch Step [50/323], D_loss: 0.7908,  G_loss: 1.6263\n",
      " Epoch [136/300], Batch Step [60/323], D_loss: 0.6548,  G_loss: 1.5285\n",
      " Epoch [136/300], Batch Step [70/323], D_loss: 0.8400,  G_loss: 1.4857\n",
      " Epoch [136/300], Batch Step [80/323], D_loss: 0.6624,  G_loss: 1.5703\n",
      " Epoch [136/300], Batch Step [90/323], D_loss: 0.7509,  G_loss: 1.5984\n",
      " Epoch [136/300], Batch Step [100/323], D_loss: 0.6161,  G_loss: 1.4954\n",
      " Epoch [136/300], Batch Step [110/323], D_loss: 0.6197,  G_loss: 1.6458\n",
      " Epoch [136/300], Batch Step [120/323], D_loss: 0.8921,  G_loss: 1.6569\n",
      " Epoch [136/300], Batch Step [130/323], D_loss: 0.6831,  G_loss: 1.4723\n",
      " Epoch [136/300], Batch Step [140/323], D_loss: 0.7260,  G_loss: 1.6955\n",
      " Epoch [136/300], Batch Step [150/323], D_loss: 0.6465,  G_loss: 1.5289\n",
      " Epoch [136/300], Batch Step [160/323], D_loss: 0.7044,  G_loss: 1.5223\n",
      " Epoch [136/300], Batch Step [170/323], D_loss: 0.5933,  G_loss: 1.6393\n",
      " Epoch [136/300], Batch Step [180/323], D_loss: 0.6797,  G_loss: 1.4003\n",
      " Epoch [136/300], Batch Step [190/323], D_loss: 0.7300,  G_loss: 1.4488\n",
      " Epoch [136/300], Batch Step [200/323], D_loss: 0.6434,  G_loss: 1.6784\n",
      " Epoch [136/300], Batch Step [210/323], D_loss: 0.6915,  G_loss: 1.5898\n",
      " Epoch [136/300], Batch Step [220/323], D_loss: 0.7278,  G_loss: 1.6254\n",
      " Epoch [136/300], Batch Step [230/323], D_loss: 0.5558,  G_loss: 1.5643\n",
      " Epoch [136/300], Batch Step [240/323], D_loss: 0.6440,  G_loss: 1.6813\n",
      " Epoch [136/300], Batch Step [250/323], D_loss: 0.7505,  G_loss: 1.5262\n",
      " Epoch [136/300], Batch Step [260/323], D_loss: 0.7400,  G_loss: 1.4221\n",
      " Epoch [136/300], Batch Step [270/323], D_loss: 0.5427,  G_loss: 1.6525\n",
      " Epoch [136/300], Batch Step [280/323], D_loss: 0.5976,  G_loss: 1.4692\n",
      " Epoch [136/300], Batch Step [290/323], D_loss: 0.7372,  G_loss: 1.4331\n",
      " Epoch [136/300], Batch Step [300/323], D_loss: 0.6623,  G_loss: 1.6382\n",
      " Epoch [136/300], Batch Step [310/323], D_loss: 0.5984,  G_loss: 1.4844\n",
      " Epoch [136/300], Batch Step [320/323], D_loss: 0.6619,  G_loss: 1.6317\n",
      " Epoch [137/300], Batch Step [0/323], D_loss: 0.6738,  G_loss: 1.7032\n",
      " Epoch [137/300], Batch Step [10/323], D_loss: 0.6317,  G_loss: 1.6540\n",
      " Epoch [137/300], Batch Step [20/323], D_loss: 0.6344,  G_loss: 1.4744\n",
      " Epoch [137/300], Batch Step [30/323], D_loss: 0.6839,  G_loss: 1.5592\n",
      " Epoch [137/300], Batch Step [40/323], D_loss: 0.6801,  G_loss: 1.5734\n",
      " Epoch [137/300], Batch Step [50/323], D_loss: 0.7129,  G_loss: 1.5156\n",
      " Epoch [137/300], Batch Step [60/323], D_loss: 0.7822,  G_loss: 1.6675\n",
      " Epoch [137/300], Batch Step [70/323], D_loss: 0.8688,  G_loss: 1.5432\n",
      " Epoch [137/300], Batch Step [80/323], D_loss: 0.5353,  G_loss: 1.4624\n",
      " Epoch [137/300], Batch Step [90/323], D_loss: 0.6026,  G_loss: 1.7417\n",
      " Epoch [137/300], Batch Step [100/323], D_loss: 0.6718,  G_loss: 1.5773\n",
      " Epoch [137/300], Batch Step [110/323], D_loss: 0.7511,  G_loss: 1.3768\n",
      " Epoch [137/300], Batch Step [120/323], D_loss: 0.7410,  G_loss: 1.5671\n",
      " Epoch [137/300], Batch Step [130/323], D_loss: 0.6804,  G_loss: 1.4627\n",
      " Epoch [137/300], Batch Step [140/323], D_loss: 0.5469,  G_loss: 1.5313\n",
      " Epoch [137/300], Batch Step [150/323], D_loss: 0.5804,  G_loss: 1.4536\n",
      " Epoch [137/300], Batch Step [160/323], D_loss: 0.5288,  G_loss: 1.5086\n",
      " Epoch [137/300], Batch Step [170/323], D_loss: 0.7239,  G_loss: 1.6185\n",
      " Epoch [137/300], Batch Step [180/323], D_loss: 0.7000,  G_loss: 1.5717\n",
      " Epoch [137/300], Batch Step [190/323], D_loss: 0.7662,  G_loss: 1.7287\n",
      " Epoch [137/300], Batch Step [200/323], D_loss: 0.8239,  G_loss: 1.5581\n",
      " Epoch [137/300], Batch Step [210/323], D_loss: 0.8238,  G_loss: 1.5253\n",
      " Epoch [137/300], Batch Step [220/323], D_loss: 0.6876,  G_loss: 1.6700\n",
      " Epoch [137/300], Batch Step [230/323], D_loss: 0.7766,  G_loss: 1.4036\n",
      " Epoch [137/300], Batch Step [240/323], D_loss: 0.6793,  G_loss: 1.6851\n",
      " Epoch [137/300], Batch Step [250/323], D_loss: 0.4144,  G_loss: 1.5273\n",
      " Epoch [137/300], Batch Step [260/323], D_loss: 0.6465,  G_loss: 1.5682\n",
      " Epoch [137/300], Batch Step [270/323], D_loss: 0.6670,  G_loss: 1.5182\n",
      " Epoch [137/300], Batch Step [280/323], D_loss: 0.6749,  G_loss: 1.5210\n",
      " Epoch [137/300], Batch Step [290/323], D_loss: 0.6036,  G_loss: 1.7062\n",
      " Epoch [137/300], Batch Step [300/323], D_loss: 0.5435,  G_loss: 1.5177\n",
      " Epoch [137/300], Batch Step [310/323], D_loss: 0.6158,  G_loss: 1.6279\n",
      " Epoch [137/300], Batch Step [320/323], D_loss: 0.6929,  G_loss: 1.6169\n",
      " Epoch [138/300], Batch Step [0/323], D_loss: 0.6241,  G_loss: 1.4770\n",
      " Epoch [138/300], Batch Step [10/323], D_loss: 0.7097,  G_loss: 1.6335\n",
      " Epoch [138/300], Batch Step [20/323], D_loss: 0.8413,  G_loss: 1.7257\n",
      " Epoch [138/300], Batch Step [30/323], D_loss: 0.6730,  G_loss: 1.3678\n",
      " Epoch [138/300], Batch Step [40/323], D_loss: 0.7047,  G_loss: 1.6020\n",
      " Epoch [138/300], Batch Step [50/323], D_loss: 0.5880,  G_loss: 1.5856\n",
      " Epoch [138/300], Batch Step [60/323], D_loss: 0.5745,  G_loss: 1.4939\n",
      " Epoch [138/300], Batch Step [70/323], D_loss: 0.6123,  G_loss: 1.6519\n",
      " Epoch [138/300], Batch Step [80/323], D_loss: 0.7174,  G_loss: 1.5846\n",
      " Epoch [138/300], Batch Step [90/323], D_loss: 0.6776,  G_loss: 1.5399\n",
      " Epoch [138/300], Batch Step [100/323], D_loss: 0.6125,  G_loss: 1.7140\n",
      " Epoch [138/300], Batch Step [110/323], D_loss: 0.6037,  G_loss: 1.5366\n",
      " Epoch [138/300], Batch Step [120/323], D_loss: 0.5758,  G_loss: 1.6019\n",
      " Epoch [138/300], Batch Step [130/323], D_loss: 0.8042,  G_loss: 1.6178\n",
      " Epoch [138/300], Batch Step [140/323], D_loss: 0.6019,  G_loss: 1.5395\n",
      " Epoch [138/300], Batch Step [150/323], D_loss: 0.9006,  G_loss: 1.5276\n",
      " Epoch [138/300], Batch Step [160/323], D_loss: 0.6265,  G_loss: 1.6268\n",
      " Epoch [138/300], Batch Step [170/323], D_loss: 0.6364,  G_loss: 1.5294\n",
      " Epoch [138/300], Batch Step [180/323], D_loss: 0.7482,  G_loss: 1.6080\n",
      " Epoch [138/300], Batch Step [190/323], D_loss: 0.5971,  G_loss: 1.6929\n",
      " Epoch [138/300], Batch Step [200/323], D_loss: 0.6971,  G_loss: 1.4981\n",
      " Epoch [138/300], Batch Step [210/323], D_loss: 0.6516,  G_loss: 1.6116\n",
      " Epoch [138/300], Batch Step [220/323], D_loss: 0.4868,  G_loss: 1.6624\n",
      " Epoch [138/300], Batch Step [230/323], D_loss: 0.6746,  G_loss: 1.6456\n",
      " Epoch [138/300], Batch Step [240/323], D_loss: 0.6800,  G_loss: 1.4751\n",
      " Epoch [138/300], Batch Step [250/323], D_loss: 0.8726,  G_loss: 1.5638\n",
      " Epoch [138/300], Batch Step [260/323], D_loss: 0.7685,  G_loss: 1.6442\n",
      " Epoch [138/300], Batch Step [270/323], D_loss: 0.5403,  G_loss: 1.3725\n",
      " Epoch [138/300], Batch Step [280/323], D_loss: 0.6130,  G_loss: 1.6770\n",
      " Epoch [138/300], Batch Step [290/323], D_loss: 0.6427,  G_loss: 1.6840\n",
      " Epoch [138/300], Batch Step [300/323], D_loss: 0.6518,  G_loss: 1.3537\n",
      " Epoch [138/300], Batch Step [310/323], D_loss: 0.6136,  G_loss: 1.6760\n",
      " Epoch [138/300], Batch Step [320/323], D_loss: 0.6613,  G_loss: 1.5046\n",
      " Epoch [139/300], Batch Step [0/323], D_loss: 0.6826,  G_loss: 1.5554\n",
      " Epoch [139/300], Batch Step [10/323], D_loss: 0.7040,  G_loss: 1.5636\n",
      " Epoch [139/300], Batch Step [20/323], D_loss: 0.6429,  G_loss: 1.6252\n",
      " Epoch [139/300], Batch Step [30/323], D_loss: 0.7342,  G_loss: 1.6638\n",
      " Epoch [139/300], Batch Step [40/323], D_loss: 0.5378,  G_loss: 1.6451\n",
      " Epoch [139/300], Batch Step [50/323], D_loss: 0.6245,  G_loss: 1.5267\n",
      " Epoch [139/300], Batch Step [60/323], D_loss: 0.6959,  G_loss: 1.6155\n",
      " Epoch [139/300], Batch Step [70/323], D_loss: 0.6901,  G_loss: 1.6345\n",
      " Epoch [139/300], Batch Step [80/323], D_loss: 0.7312,  G_loss: 1.6091\n",
      " Epoch [139/300], Batch Step [90/323], D_loss: 0.7394,  G_loss: 1.6058\n",
      " Epoch [139/300], Batch Step [100/323], D_loss: 0.7430,  G_loss: 1.3326\n",
      " Epoch [139/300], Batch Step [110/323], D_loss: 0.6531,  G_loss: 1.5378\n",
      " Epoch [139/300], Batch Step [120/323], D_loss: 0.7711,  G_loss: 1.5314\n",
      " Epoch [139/300], Batch Step [130/323], D_loss: 0.5960,  G_loss: 1.4788\n",
      " Epoch [139/300], Batch Step [140/323], D_loss: 0.6267,  G_loss: 1.5340\n",
      " Epoch [139/300], Batch Step [150/323], D_loss: 0.6352,  G_loss: 1.6477\n",
      " Epoch [139/300], Batch Step [160/323], D_loss: 0.7292,  G_loss: 1.5341\n",
      " Epoch [139/300], Batch Step [170/323], D_loss: 0.6293,  G_loss: 1.4784\n",
      " Epoch [139/300], Batch Step [180/323], D_loss: 0.7566,  G_loss: 1.6739\n",
      " Epoch [139/300], Batch Step [190/323], D_loss: 0.7023,  G_loss: 1.5914\n",
      " Epoch [139/300], Batch Step [200/323], D_loss: 0.7598,  G_loss: 1.5547\n",
      " Epoch [139/300], Batch Step [210/323], D_loss: 0.7531,  G_loss: 1.6007\n",
      " Epoch [139/300], Batch Step [220/323], D_loss: 0.6240,  G_loss: 1.4338\n",
      " Epoch [139/300], Batch Step [230/323], D_loss: 0.6930,  G_loss: 1.6960\n",
      " Epoch [139/300], Batch Step [240/323], D_loss: 0.6511,  G_loss: 1.4195\n",
      " Epoch [139/300], Batch Step [250/323], D_loss: 0.7536,  G_loss: 1.5799\n",
      " Epoch [139/300], Batch Step [260/323], D_loss: 0.7451,  G_loss: 1.6435\n",
      " Epoch [139/300], Batch Step [270/323], D_loss: 0.8192,  G_loss: 1.5408\n",
      " Epoch [139/300], Batch Step [280/323], D_loss: 0.7395,  G_loss: 1.7012\n",
      " Epoch [139/300], Batch Step [290/323], D_loss: 0.6598,  G_loss: 1.5554\n",
      " Epoch [139/300], Batch Step [300/323], D_loss: 0.6592,  G_loss: 1.6088\n",
      " Epoch [139/300], Batch Step [310/323], D_loss: 0.6239,  G_loss: 1.5400\n",
      " Epoch [139/300], Batch Step [320/323], D_loss: 0.6528,  G_loss: 1.7226\n",
      " Epoch [140/300], Batch Step [0/323], D_loss: 0.5518,  G_loss: 1.7746\n",
      " Epoch [140/300], Batch Step [10/323], D_loss: 0.6736,  G_loss: 1.5450\n",
      " Epoch [140/300], Batch Step [20/323], D_loss: 0.7346,  G_loss: 1.6156\n",
      " Epoch [140/300], Batch Step [30/323], D_loss: 0.8674,  G_loss: 1.6189\n",
      " Epoch [140/300], Batch Step [40/323], D_loss: 0.6018,  G_loss: 1.4640\n",
      " Epoch [140/300], Batch Step [50/323], D_loss: 0.7677,  G_loss: 1.6250\n",
      " Epoch [140/300], Batch Step [60/323], D_loss: 0.6843,  G_loss: 1.4397\n",
      " Epoch [140/300], Batch Step [70/323], D_loss: 0.6883,  G_loss: 1.5648\n",
      " Epoch [140/300], Batch Step [80/323], D_loss: 0.5814,  G_loss: 1.6017\n",
      " Epoch [140/300], Batch Step [90/323], D_loss: 0.6907,  G_loss: 1.3987\n",
      " Epoch [140/300], Batch Step [100/323], D_loss: 0.5763,  G_loss: 1.6431\n",
      " Epoch [140/300], Batch Step [110/323], D_loss: 0.5089,  G_loss: 1.6052\n",
      " Epoch [140/300], Batch Step [120/323], D_loss: 0.7624,  G_loss: 1.4313\n",
      " Epoch [140/300], Batch Step [130/323], D_loss: 0.6385,  G_loss: 1.5968\n",
      " Epoch [140/300], Batch Step [140/323], D_loss: 0.7629,  G_loss: 1.5841\n",
      " Epoch [140/300], Batch Step [150/323], D_loss: 0.6657,  G_loss: 1.7341\n",
      " Epoch [140/300], Batch Step [160/323], D_loss: 0.6653,  G_loss: 1.4725\n",
      " Epoch [140/300], Batch Step [170/323], D_loss: 0.5591,  G_loss: 1.5581\n",
      " Epoch [140/300], Batch Step [180/323], D_loss: 0.8352,  G_loss: 1.6103\n",
      " Epoch [140/300], Batch Step [190/323], D_loss: 0.6171,  G_loss: 1.5479\n",
      " Epoch [140/300], Batch Step [200/323], D_loss: 0.6750,  G_loss: 1.6575\n",
      " Epoch [140/300], Batch Step [210/323], D_loss: 0.6499,  G_loss: 1.5245\n",
      " Epoch [140/300], Batch Step [220/323], D_loss: 0.6003,  G_loss: 1.5810\n",
      " Epoch [140/300], Batch Step [230/323], D_loss: 0.5853,  G_loss: 1.4951\n",
      " Epoch [140/300], Batch Step [240/323], D_loss: 0.7943,  G_loss: 1.4899\n",
      " Epoch [140/300], Batch Step [250/323], D_loss: 0.6705,  G_loss: 1.5811\n",
      " Epoch [140/300], Batch Step [260/323], D_loss: 0.6942,  G_loss: 1.4843\n",
      " Epoch [140/300], Batch Step [270/323], D_loss: 0.6788,  G_loss: 1.4684\n",
      " Epoch [140/300], Batch Step [280/323], D_loss: 0.6188,  G_loss: 1.5849\n",
      " Epoch [140/300], Batch Step [290/323], D_loss: 0.7122,  G_loss: 1.6109\n",
      " Epoch [140/300], Batch Step [300/323], D_loss: 0.7217,  G_loss: 1.5053\n",
      " Epoch [140/300], Batch Step [310/323], D_loss: 0.6387,  G_loss: 1.6040\n",
      " Epoch [140/300], Batch Step [320/323], D_loss: 0.5498,  G_loss: 1.7083\n",
      " Epoch [141/300], Batch Step [0/323], D_loss: 0.8018,  G_loss: 1.6814\n",
      " Epoch [141/300], Batch Step [10/323], D_loss: 0.6852,  G_loss: 1.4548\n",
      " Epoch [141/300], Batch Step [20/323], D_loss: 0.7830,  G_loss: 1.5785\n",
      " Epoch [141/300], Batch Step [30/323], D_loss: 0.6731,  G_loss: 1.5885\n",
      " Epoch [141/300], Batch Step [40/323], D_loss: 0.7083,  G_loss: 1.5778\n",
      " Epoch [141/300], Batch Step [50/323], D_loss: 0.5854,  G_loss: 1.5828\n",
      " Epoch [141/300], Batch Step [60/323], D_loss: 0.6182,  G_loss: 1.7638\n",
      " Epoch [141/300], Batch Step [70/323], D_loss: 0.6287,  G_loss: 1.3618\n",
      " Epoch [141/300], Batch Step [80/323], D_loss: 0.6607,  G_loss: 1.5341\n",
      " Epoch [141/300], Batch Step [90/323], D_loss: 0.4929,  G_loss: 1.5922\n",
      " Epoch [141/300], Batch Step [100/323], D_loss: 0.7195,  G_loss: 1.4819\n",
      " Epoch [141/300], Batch Step [110/323], D_loss: 0.5229,  G_loss: 1.5023\n",
      " Epoch [141/300], Batch Step [120/323], D_loss: 0.6305,  G_loss: 1.5096\n",
      " Epoch [141/300], Batch Step [130/323], D_loss: 0.6030,  G_loss: 1.5838\n",
      " Epoch [141/300], Batch Step [140/323], D_loss: 0.6135,  G_loss: 1.5413\n",
      " Epoch [141/300], Batch Step [150/323], D_loss: 0.6401,  G_loss: 1.5398\n",
      " Epoch [141/300], Batch Step [160/323], D_loss: 0.6598,  G_loss: 1.4833\n",
      " Epoch [141/300], Batch Step [170/323], D_loss: 0.5814,  G_loss: 1.4853\n",
      " Epoch [141/300], Batch Step [180/323], D_loss: 0.8159,  G_loss: 1.6029\n",
      " Epoch [141/300], Batch Step [190/323], D_loss: 0.5566,  G_loss: 1.6063\n",
      " Epoch [141/300], Batch Step [200/323], D_loss: 0.6275,  G_loss: 1.5280\n",
      " Epoch [141/300], Batch Step [210/323], D_loss: 0.7346,  G_loss: 1.5577\n",
      " Epoch [141/300], Batch Step [220/323], D_loss: 0.7375,  G_loss: 1.5489\n",
      " Epoch [141/300], Batch Step [230/323], D_loss: 0.7130,  G_loss: 1.5825\n",
      " Epoch [141/300], Batch Step [240/323], D_loss: 0.4819,  G_loss: 1.5583\n",
      " Epoch [141/300], Batch Step [250/323], D_loss: 0.7338,  G_loss: 1.6203\n",
      " Epoch [141/300], Batch Step [260/323], D_loss: 0.7475,  G_loss: 1.4893\n",
      " Epoch [141/300], Batch Step [270/323], D_loss: 0.8704,  G_loss: 1.6538\n",
      " Epoch [141/300], Batch Step [280/323], D_loss: 0.7202,  G_loss: 1.5418\n",
      " Epoch [141/300], Batch Step [290/323], D_loss: 0.6805,  G_loss: 1.5273\n",
      " Epoch [141/300], Batch Step [300/323], D_loss: 0.6073,  G_loss: 1.5399\n",
      " Epoch [141/300], Batch Step [310/323], D_loss: 0.6496,  G_loss: 1.7551\n",
      " Epoch [141/300], Batch Step [320/323], D_loss: 0.5625,  G_loss: 1.6469\n",
      " Epoch [142/300], Batch Step [0/323], D_loss: 0.7217,  G_loss: 1.5916\n",
      " Epoch [142/300], Batch Step [10/323], D_loss: 0.7010,  G_loss: 1.5469\n",
      " Epoch [142/300], Batch Step [20/323], D_loss: 0.9264,  G_loss: 1.6304\n",
      " Epoch [142/300], Batch Step [30/323], D_loss: 0.6631,  G_loss: 1.4637\n",
      " Epoch [142/300], Batch Step [40/323], D_loss: 0.6416,  G_loss: 1.6574\n",
      " Epoch [142/300], Batch Step [50/323], D_loss: 0.6871,  G_loss: 1.5587\n",
      " Epoch [142/300], Batch Step [60/323], D_loss: 0.6705,  G_loss: 1.4864\n",
      " Epoch [142/300], Batch Step [70/323], D_loss: 0.8313,  G_loss: 1.6200\n",
      " Epoch [142/300], Batch Step [80/323], D_loss: 0.5903,  G_loss: 1.4120\n",
      " Epoch [142/300], Batch Step [90/323], D_loss: 0.6620,  G_loss: 1.5607\n",
      " Epoch [142/300], Batch Step [100/323], D_loss: 0.4477,  G_loss: 1.7272\n",
      " Epoch [142/300], Batch Step [110/323], D_loss: 0.5727,  G_loss: 1.5088\n",
      " Epoch [142/300], Batch Step [120/323], D_loss: 0.7089,  G_loss: 1.5508\n",
      " Epoch [142/300], Batch Step [130/323], D_loss: 0.5633,  G_loss: 1.5386\n",
      " Epoch [142/300], Batch Step [140/323], D_loss: 0.7465,  G_loss: 1.6255\n",
      " Epoch [142/300], Batch Step [150/323], D_loss: 0.6171,  G_loss: 1.5670\n",
      " Epoch [142/300], Batch Step [160/323], D_loss: 0.5994,  G_loss: 1.5322\n",
      " Epoch [142/300], Batch Step [170/323], D_loss: 0.5735,  G_loss: 1.6575\n",
      " Epoch [142/300], Batch Step [180/323], D_loss: 0.6045,  G_loss: 1.6812\n",
      " Epoch [142/300], Batch Step [190/323], D_loss: 0.7076,  G_loss: 1.5647\n",
      " Epoch [142/300], Batch Step [200/323], D_loss: 0.6019,  G_loss: 1.5564\n",
      " Epoch [142/300], Batch Step [210/323], D_loss: 0.7935,  G_loss: 1.5676\n",
      " Epoch [142/300], Batch Step [220/323], D_loss: 0.6653,  G_loss: 1.4756\n",
      " Epoch [142/300], Batch Step [230/323], D_loss: 0.7417,  G_loss: 1.6489\n",
      " Epoch [142/300], Batch Step [240/323], D_loss: 0.6232,  G_loss: 1.5279\n",
      " Epoch [142/300], Batch Step [250/323], D_loss: 0.6756,  G_loss: 1.5060\n",
      " Epoch [142/300], Batch Step [260/323], D_loss: 0.7358,  G_loss: 1.4452\n",
      " Epoch [142/300], Batch Step [270/323], D_loss: 0.7349,  G_loss: 1.5600\n",
      " Epoch [142/300], Batch Step [280/323], D_loss: 0.5623,  G_loss: 1.6810\n",
      " Epoch [142/300], Batch Step [290/323], D_loss: 0.5314,  G_loss: 1.5420\n",
      " Epoch [142/300], Batch Step [300/323], D_loss: 0.7265,  G_loss: 1.5994\n",
      " Epoch [142/300], Batch Step [310/323], D_loss: 0.7095,  G_loss: 1.4414\n",
      " Epoch [142/300], Batch Step [320/323], D_loss: 0.6109,  G_loss: 1.7632\n",
      " Epoch [143/300], Batch Step [0/323], D_loss: 0.6723,  G_loss: 1.7945\n",
      " Epoch [143/300], Batch Step [10/323], D_loss: 0.6240,  G_loss: 1.4739\n",
      " Epoch [143/300], Batch Step [20/323], D_loss: 0.5886,  G_loss: 1.6637\n",
      " Epoch [143/300], Batch Step [30/323], D_loss: 0.6485,  G_loss: 1.4531\n",
      " Epoch [143/300], Batch Step [40/323], D_loss: 0.7444,  G_loss: 1.5621\n",
      " Epoch [143/300], Batch Step [50/323], D_loss: 0.5895,  G_loss: 1.5740\n",
      " Epoch [143/300], Batch Step [60/323], D_loss: 0.6143,  G_loss: 1.4761\n",
      " Epoch [143/300], Batch Step [70/323], D_loss: 0.6179,  G_loss: 1.6842\n",
      " Epoch [143/300], Batch Step [80/323], D_loss: 0.4184,  G_loss: 1.7985\n",
      " Epoch [143/300], Batch Step [90/323], D_loss: 0.7105,  G_loss: 1.6189\n",
      " Epoch [143/300], Batch Step [100/323], D_loss: 0.6725,  G_loss: 1.6222\n",
      " Epoch [143/300], Batch Step [110/323], D_loss: 0.5719,  G_loss: 1.5795\n",
      " Epoch [143/300], Batch Step [120/323], D_loss: 0.6725,  G_loss: 1.5377\n",
      " Epoch [143/300], Batch Step [130/323], D_loss: 0.5549,  G_loss: 1.5980\n",
      " Epoch [143/300], Batch Step [140/323], D_loss: 0.6530,  G_loss: 1.5570\n",
      " Epoch [143/300], Batch Step [150/323], D_loss: 0.7758,  G_loss: 1.5307\n",
      " Epoch [143/300], Batch Step [160/323], D_loss: 0.6387,  G_loss: 1.5990\n",
      " Epoch [143/300], Batch Step [170/323], D_loss: 0.7480,  G_loss: 1.4854\n",
      " Epoch [143/300], Batch Step [180/323], D_loss: 0.7061,  G_loss: 1.6091\n",
      " Epoch [143/300], Batch Step [190/323], D_loss: 0.5955,  G_loss: 1.5629\n",
      " Epoch [143/300], Batch Step [200/323], D_loss: 0.6188,  G_loss: 1.5645\n",
      " Epoch [143/300], Batch Step [210/323], D_loss: 0.6909,  G_loss: 1.4979\n",
      " Epoch [143/300], Batch Step [220/323], D_loss: 0.6192,  G_loss: 1.5761\n",
      " Epoch [143/300], Batch Step [230/323], D_loss: 0.7403,  G_loss: 1.6290\n",
      " Epoch [143/300], Batch Step [240/323], D_loss: 0.7125,  G_loss: 1.4888\n",
      " Epoch [143/300], Batch Step [250/323], D_loss: 0.5661,  G_loss: 1.5217\n",
      " Epoch [143/300], Batch Step [260/323], D_loss: 0.5805,  G_loss: 1.5858\n",
      " Epoch [143/300], Batch Step [270/323], D_loss: 0.4814,  G_loss: 1.7058\n",
      " Epoch [143/300], Batch Step [280/323], D_loss: 0.6883,  G_loss: 1.5903\n",
      " Epoch [143/300], Batch Step [290/323], D_loss: 0.5076,  G_loss: 1.6061\n",
      " Epoch [143/300], Batch Step [300/323], D_loss: 0.7345,  G_loss: 1.6244\n",
      " Epoch [143/300], Batch Step [310/323], D_loss: 0.5122,  G_loss: 1.5542\n",
      " Epoch [143/300], Batch Step [320/323], D_loss: 0.8921,  G_loss: 1.5815\n",
      " Epoch [144/300], Batch Step [0/323], D_loss: 0.6489,  G_loss: 1.5818\n",
      " Epoch [144/300], Batch Step [10/323], D_loss: 0.7736,  G_loss: 1.5315\n",
      " Epoch [144/300], Batch Step [20/323], D_loss: 0.6066,  G_loss: 1.8120\n",
      " Epoch [144/300], Batch Step [30/323], D_loss: 0.5625,  G_loss: 1.5976\n",
      " Epoch [144/300], Batch Step [40/323], D_loss: 0.6476,  G_loss: 1.4647\n",
      " Epoch [144/300], Batch Step [50/323], D_loss: 0.7394,  G_loss: 1.6576\n",
      " Epoch [144/300], Batch Step [60/323], D_loss: 0.5458,  G_loss: 1.5108\n",
      " Epoch [144/300], Batch Step [70/323], D_loss: 0.6604,  G_loss: 1.5529\n",
      " Epoch [144/300], Batch Step [80/323], D_loss: 0.6685,  G_loss: 1.5246\n",
      " Epoch [144/300], Batch Step [90/323], D_loss: 0.8143,  G_loss: 1.5066\n",
      " Epoch [144/300], Batch Step [100/323], D_loss: 0.6961,  G_loss: 1.6205\n",
      " Epoch [144/300], Batch Step [110/323], D_loss: 0.5200,  G_loss: 1.5749\n",
      " Epoch [144/300], Batch Step [120/323], D_loss: 0.5762,  G_loss: 1.5179\n",
      " Epoch [144/300], Batch Step [130/323], D_loss: 0.7145,  G_loss: 1.6543\n",
      " Epoch [144/300], Batch Step [140/323], D_loss: 0.7154,  G_loss: 1.5442\n",
      " Epoch [144/300], Batch Step [150/323], D_loss: 0.6313,  G_loss: 1.4985\n",
      " Epoch [144/300], Batch Step [160/323], D_loss: 0.6131,  G_loss: 1.7219\n",
      " Epoch [144/300], Batch Step [170/323], D_loss: 0.7727,  G_loss: 1.4772\n",
      " Epoch [144/300], Batch Step [180/323], D_loss: 0.5405,  G_loss: 1.5995\n",
      " Epoch [144/300], Batch Step [190/323], D_loss: 0.7486,  G_loss: 1.5512\n",
      " Epoch [144/300], Batch Step [200/323], D_loss: 0.6160,  G_loss: 1.4861\n",
      " Epoch [144/300], Batch Step [210/323], D_loss: 0.6878,  G_loss: 1.6971\n",
      " Epoch [144/300], Batch Step [220/323], D_loss: 0.6086,  G_loss: 1.5729\n",
      " Epoch [144/300], Batch Step [230/323], D_loss: 0.7560,  G_loss: 1.6107\n",
      " Epoch [144/300], Batch Step [240/323], D_loss: 0.7160,  G_loss: 1.4399\n",
      " Epoch [144/300], Batch Step [250/323], D_loss: 0.5831,  G_loss: 1.7079\n",
      " Epoch [144/300], Batch Step [260/323], D_loss: 0.6603,  G_loss: 1.7418\n",
      " Epoch [144/300], Batch Step [270/323], D_loss: 0.5870,  G_loss: 1.5860\n",
      " Epoch [144/300], Batch Step [280/323], D_loss: 0.7569,  G_loss: 1.5905\n",
      " Epoch [144/300], Batch Step [290/323], D_loss: 0.5693,  G_loss: 1.6387\n",
      " Epoch [144/300], Batch Step [300/323], D_loss: 0.6499,  G_loss: 1.5489\n",
      " Epoch [144/300], Batch Step [310/323], D_loss: 0.6759,  G_loss: 1.5677\n",
      " Epoch [144/300], Batch Step [320/323], D_loss: 0.6592,  G_loss: 1.6205\n",
      " Epoch [145/300], Batch Step [0/323], D_loss: 0.5173,  G_loss: 1.6550\n",
      " Epoch [145/300], Batch Step [10/323], D_loss: 0.6595,  G_loss: 1.5375\n",
      " Epoch [145/300], Batch Step [20/323], D_loss: 0.7582,  G_loss: 1.5792\n",
      " Epoch [145/300], Batch Step [30/323], D_loss: 0.7729,  G_loss: 1.3762\n",
      " Epoch [145/300], Batch Step [40/323], D_loss: 0.7883,  G_loss: 1.5368\n",
      " Epoch [145/300], Batch Step [50/323], D_loss: 0.7297,  G_loss: 1.4708\n",
      " Epoch [145/300], Batch Step [60/323], D_loss: 0.7127,  G_loss: 1.6649\n",
      " Epoch [145/300], Batch Step [70/323], D_loss: 0.6375,  G_loss: 1.5930\n",
      " Epoch [145/300], Batch Step [80/323], D_loss: 0.7747,  G_loss: 1.4933\n",
      " Epoch [145/300], Batch Step [90/323], D_loss: 0.5597,  G_loss: 1.7067\n",
      " Epoch [145/300], Batch Step [100/323], D_loss: 0.6293,  G_loss: 1.5660\n",
      " Epoch [145/300], Batch Step [110/323], D_loss: 0.6433,  G_loss: 1.5300\n",
      " Epoch [145/300], Batch Step [120/323], D_loss: 0.7591,  G_loss: 1.5920\n",
      " Epoch [145/300], Batch Step [130/323], D_loss: 0.7117,  G_loss: 1.4555\n",
      " Epoch [145/300], Batch Step [140/323], D_loss: 0.6255,  G_loss: 1.6378\n",
      " Epoch [145/300], Batch Step [150/323], D_loss: 0.6762,  G_loss: 1.6021\n",
      " Epoch [145/300], Batch Step [160/323], D_loss: 0.8052,  G_loss: 1.5152\n",
      " Epoch [145/300], Batch Step [170/323], D_loss: 0.5569,  G_loss: 1.5141\n",
      " Epoch [145/300], Batch Step [180/323], D_loss: 0.5045,  G_loss: 1.5372\n",
      " Epoch [145/300], Batch Step [190/323], D_loss: 0.7281,  G_loss: 1.4315\n",
      " Epoch [145/300], Batch Step [200/323], D_loss: 0.5675,  G_loss: 1.8391\n",
      " Epoch [145/300], Batch Step [210/323], D_loss: 0.6785,  G_loss: 1.6614\n",
      " Epoch [145/300], Batch Step [220/323], D_loss: 0.6488,  G_loss: 1.5765\n",
      " Epoch [145/300], Batch Step [230/323], D_loss: 0.5233,  G_loss: 1.6015\n",
      " Epoch [145/300], Batch Step [240/323], D_loss: 0.6391,  G_loss: 1.6601\n",
      " Epoch [145/300], Batch Step [250/323], D_loss: 0.7222,  G_loss: 1.4273\n",
      " Epoch [145/300], Batch Step [260/323], D_loss: 0.5244,  G_loss: 1.6235\n",
      " Epoch [145/300], Batch Step [270/323], D_loss: 0.6188,  G_loss: 1.6869\n",
      " Epoch [145/300], Batch Step [280/323], D_loss: 0.7037,  G_loss: 1.5398\n",
      " Epoch [145/300], Batch Step [290/323], D_loss: 0.6823,  G_loss: 1.6122\n",
      " Epoch [145/300], Batch Step [300/323], D_loss: 0.7210,  G_loss: 1.4415\n",
      " Epoch [145/300], Batch Step [310/323], D_loss: 0.7150,  G_loss: 1.6381\n",
      " Epoch [145/300], Batch Step [320/323], D_loss: 0.6723,  G_loss: 1.5146\n",
      " Epoch [146/300], Batch Step [0/323], D_loss: 0.6735,  G_loss: 1.5399\n",
      " Epoch [146/300], Batch Step [10/323], D_loss: 0.5457,  G_loss: 1.8019\n",
      " Epoch [146/300], Batch Step [20/323], D_loss: 0.5932,  G_loss: 1.4929\n",
      " Epoch [146/300], Batch Step [30/323], D_loss: 0.5367,  G_loss: 1.7565\n",
      " Epoch [146/300], Batch Step [40/323], D_loss: 0.6130,  G_loss: 1.5963\n",
      " Epoch [146/300], Batch Step [50/323], D_loss: 0.6920,  G_loss: 1.5208\n",
      " Epoch [146/300], Batch Step [60/323], D_loss: 0.6718,  G_loss: 1.5573\n",
      " Epoch [146/300], Batch Step [70/323], D_loss: 0.7451,  G_loss: 1.6316\n",
      " Epoch [146/300], Batch Step [80/323], D_loss: 0.6817,  G_loss: 1.4658\n",
      " Epoch [146/300], Batch Step [90/323], D_loss: 0.6992,  G_loss: 1.7717\n",
      " Epoch [146/300], Batch Step [100/323], D_loss: 0.5918,  G_loss: 1.5158\n",
      " Epoch [146/300], Batch Step [110/323], D_loss: 0.5308,  G_loss: 1.5699\n",
      " Epoch [146/300], Batch Step [120/323], D_loss: 0.6415,  G_loss: 1.5609\n",
      " Epoch [146/300], Batch Step [130/323], D_loss: 0.6503,  G_loss: 1.4803\n",
      " Epoch [146/300], Batch Step [140/323], D_loss: 0.7868,  G_loss: 1.6025\n",
      " Epoch [146/300], Batch Step [150/323], D_loss: 0.5779,  G_loss: 1.6295\n",
      " Epoch [146/300], Batch Step [160/323], D_loss: 0.5598,  G_loss: 1.7377\n",
      " Epoch [146/300], Batch Step [170/323], D_loss: 0.6173,  G_loss: 1.6985\n",
      " Epoch [146/300], Batch Step [180/323], D_loss: 0.6797,  G_loss: 1.5959\n",
      " Epoch [146/300], Batch Step [190/323], D_loss: 0.6364,  G_loss: 1.6451\n",
      " Epoch [146/300], Batch Step [200/323], D_loss: 0.6243,  G_loss: 1.5743\n",
      " Epoch [146/300], Batch Step [210/323], D_loss: 0.6383,  G_loss: 1.4518\n",
      " Epoch [146/300], Batch Step [220/323], D_loss: 0.7016,  G_loss: 1.7702\n",
      " Epoch [146/300], Batch Step [230/323], D_loss: 0.5727,  G_loss: 1.4977\n",
      " Epoch [146/300], Batch Step [240/323], D_loss: 0.5353,  G_loss: 1.5805\n",
      " Epoch [146/300], Batch Step [250/323], D_loss: 0.5077,  G_loss: 1.6282\n",
      " Epoch [146/300], Batch Step [260/323], D_loss: 0.7316,  G_loss: 1.5742\n",
      " Epoch [146/300], Batch Step [270/323], D_loss: 0.5577,  G_loss: 1.4319\n",
      " Epoch [146/300], Batch Step [280/323], D_loss: 0.5976,  G_loss: 1.8872\n",
      " Epoch [146/300], Batch Step [290/323], D_loss: 0.6091,  G_loss: 1.5880\n",
      " Epoch [146/300], Batch Step [300/323], D_loss: 0.7379,  G_loss: 1.4430\n",
      " Epoch [146/300], Batch Step [310/323], D_loss: 0.6870,  G_loss: 1.5233\n",
      " Epoch [146/300], Batch Step [320/323], D_loss: 0.6233,  G_loss: 1.4445\n",
      " Epoch [147/300], Batch Step [0/323], D_loss: 0.7527,  G_loss: 1.5989\n",
      " Epoch [147/300], Batch Step [10/323], D_loss: 0.6013,  G_loss: 1.5697\n",
      " Epoch [147/300], Batch Step [20/323], D_loss: 0.6828,  G_loss: 1.5510\n",
      " Epoch [147/300], Batch Step [30/323], D_loss: 0.7337,  G_loss: 1.5133\n",
      " Epoch [147/300], Batch Step [40/323], D_loss: 0.7141,  G_loss: 1.4859\n",
      " Epoch [147/300], Batch Step [50/323], D_loss: 0.5890,  G_loss: 1.5621\n",
      " Epoch [147/300], Batch Step [60/323], D_loss: 0.7329,  G_loss: 1.7352\n",
      " Epoch [147/300], Batch Step [70/323], D_loss: 0.6328,  G_loss: 1.4653\n",
      " Epoch [147/300], Batch Step [80/323], D_loss: 0.6565,  G_loss: 1.5972\n",
      " Epoch [147/300], Batch Step [90/323], D_loss: 0.7654,  G_loss: 1.6431\n",
      " Epoch [147/300], Batch Step [100/323], D_loss: 0.6395,  G_loss: 1.5884\n",
      " Epoch [147/300], Batch Step [110/323], D_loss: 0.5401,  G_loss: 1.6026\n",
      " Epoch [147/300], Batch Step [120/323], D_loss: 0.5523,  G_loss: 1.6033\n",
      " Epoch [147/300], Batch Step [130/323], D_loss: 0.6560,  G_loss: 1.5628\n",
      " Epoch [147/300], Batch Step [140/323], D_loss: 0.6595,  G_loss: 1.5876\n",
      " Epoch [147/300], Batch Step [150/323], D_loss: 0.8218,  G_loss: 1.7315\n",
      " Epoch [147/300], Batch Step [160/323], D_loss: 0.7476,  G_loss: 1.4484\n",
      " Epoch [147/300], Batch Step [170/323], D_loss: 0.6542,  G_loss: 1.7350\n",
      " Epoch [147/300], Batch Step [180/323], D_loss: 0.5832,  G_loss: 1.4766\n",
      " Epoch [147/300], Batch Step [190/323], D_loss: 0.6258,  G_loss: 1.5147\n",
      " Epoch [147/300], Batch Step [200/323], D_loss: 0.8478,  G_loss: 1.6527\n",
      " Epoch [147/300], Batch Step [210/323], D_loss: 0.7042,  G_loss: 1.5134\n",
      " Epoch [147/300], Batch Step [220/323], D_loss: 0.7356,  G_loss: 1.6030\n",
      " Epoch [147/300], Batch Step [230/323], D_loss: 0.6172,  G_loss: 1.4999\n",
      " Epoch [147/300], Batch Step [240/323], D_loss: 0.5803,  G_loss: 1.5758\n",
      " Epoch [147/300], Batch Step [250/323], D_loss: 0.6240,  G_loss: 1.6988\n",
      " Epoch [147/300], Batch Step [260/323], D_loss: 0.7467,  G_loss: 1.4703\n",
      " Epoch [147/300], Batch Step [270/323], D_loss: 0.6200,  G_loss: 1.5452\n",
      " Epoch [147/300], Batch Step [280/323], D_loss: 0.6341,  G_loss: 1.6445\n",
      " Epoch [147/300], Batch Step [290/323], D_loss: 0.7025,  G_loss: 1.5957\n",
      " Epoch [147/300], Batch Step [300/323], D_loss: 0.6702,  G_loss: 1.5157\n",
      " Epoch [147/300], Batch Step [310/323], D_loss: 0.6285,  G_loss: 1.5983\n",
      " Epoch [147/300], Batch Step [320/323], D_loss: 0.6977,  G_loss: 1.4924\n",
      " Epoch [148/300], Batch Step [0/323], D_loss: 0.5652,  G_loss: 1.5761\n",
      " Epoch [148/300], Batch Step [10/323], D_loss: 0.6663,  G_loss: 1.5868\n",
      " Epoch [148/300], Batch Step [20/323], D_loss: 0.6295,  G_loss: 1.4233\n",
      " Epoch [148/300], Batch Step [30/323], D_loss: 0.5704,  G_loss: 1.6468\n",
      " Epoch [148/300], Batch Step [40/323], D_loss: 0.6792,  G_loss: 1.5154\n",
      " Epoch [148/300], Batch Step [50/323], D_loss: 0.6363,  G_loss: 1.6294\n",
      " Epoch [148/300], Batch Step [60/323], D_loss: 0.5676,  G_loss: 1.7121\n",
      " Epoch [148/300], Batch Step [70/323], D_loss: 0.5986,  G_loss: 1.6368\n",
      " Epoch [148/300], Batch Step [80/323], D_loss: 0.7346,  G_loss: 1.5821\n",
      " Epoch [148/300], Batch Step [90/323], D_loss: 0.6792,  G_loss: 1.6651\n",
      " Epoch [148/300], Batch Step [100/323], D_loss: 0.7737,  G_loss: 1.6516\n",
      " Epoch [148/300], Batch Step [110/323], D_loss: 0.7191,  G_loss: 1.4950\n",
      " Epoch [148/300], Batch Step [120/323], D_loss: 0.5363,  G_loss: 1.6134\n",
      " Epoch [148/300], Batch Step [130/323], D_loss: 0.7985,  G_loss: 1.5133\n",
      " Epoch [148/300], Batch Step [140/323], D_loss: 0.7121,  G_loss: 1.5045\n",
      " Epoch [148/300], Batch Step [150/323], D_loss: 0.6637,  G_loss: 1.5883\n",
      " Epoch [148/300], Batch Step [160/323], D_loss: 0.7386,  G_loss: 1.5813\n",
      " Epoch [148/300], Batch Step [170/323], D_loss: 0.6700,  G_loss: 1.5872\n",
      " Epoch [148/300], Batch Step [180/323], D_loss: 0.5855,  G_loss: 1.6684\n",
      " Epoch [148/300], Batch Step [190/323], D_loss: 0.7707,  G_loss: 1.6377\n",
      " Epoch [148/300], Batch Step [200/323], D_loss: 0.6300,  G_loss: 1.4174\n",
      " Epoch [148/300], Batch Step [210/323], D_loss: 0.6282,  G_loss: 1.6588\n",
      " Epoch [148/300], Batch Step [220/323], D_loss: 0.6462,  G_loss: 1.5960\n",
      " Epoch [148/300], Batch Step [230/323], D_loss: 0.6549,  G_loss: 1.5698\n",
      " Epoch [148/300], Batch Step [240/323], D_loss: 0.8570,  G_loss: 1.5377\n",
      " Epoch [148/300], Batch Step [250/323], D_loss: 0.8253,  G_loss: 1.4777\n",
      " Epoch [148/300], Batch Step [260/323], D_loss: 0.6507,  G_loss: 1.6373\n",
      " Epoch [148/300], Batch Step [270/323], D_loss: 0.6946,  G_loss: 1.5067\n",
      " Epoch [148/300], Batch Step [280/323], D_loss: 0.7949,  G_loss: 1.5475\n",
      " Epoch [148/300], Batch Step [290/323], D_loss: 0.5423,  G_loss: 1.8592\n",
      " Epoch [148/300], Batch Step [300/323], D_loss: 0.6909,  G_loss: 1.6034\n",
      " Epoch [148/300], Batch Step [310/323], D_loss: 0.6805,  G_loss: 1.4378\n",
      " Epoch [148/300], Batch Step [320/323], D_loss: 0.5634,  G_loss: 1.6265\n",
      " Epoch [149/300], Batch Step [0/323], D_loss: 0.8386,  G_loss: 1.6414\n",
      " Epoch [149/300], Batch Step [10/323], D_loss: 0.6685,  G_loss: 1.5516\n",
      " Epoch [149/300], Batch Step [20/323], D_loss: 0.5336,  G_loss: 1.6507\n",
      " Epoch [149/300], Batch Step [30/323], D_loss: 0.6717,  G_loss: 1.5919\n",
      " Epoch [149/300], Batch Step [40/323], D_loss: 0.7508,  G_loss: 1.4994\n",
      " Epoch [149/300], Batch Step [50/323], D_loss: 0.6554,  G_loss: 1.6564\n",
      " Epoch [149/300], Batch Step [60/323], D_loss: 0.5534,  G_loss: 1.5992\n",
      " Epoch [149/300], Batch Step [70/323], D_loss: 0.6607,  G_loss: 1.6457\n",
      " Epoch [149/300], Batch Step [80/323], D_loss: 0.6439,  G_loss: 1.4748\n",
      " Epoch [149/300], Batch Step [90/323], D_loss: 0.8060,  G_loss: 1.5876\n",
      " Epoch [149/300], Batch Step [100/323], D_loss: 0.7794,  G_loss: 1.4831\n",
      " Epoch [149/300], Batch Step [110/323], D_loss: 0.5481,  G_loss: 1.4998\n",
      " Epoch [149/300], Batch Step [120/323], D_loss: 0.4616,  G_loss: 1.7200\n",
      " Epoch [149/300], Batch Step [130/323], D_loss: 0.5256,  G_loss: 1.5375\n",
      " Epoch [149/300], Batch Step [140/323], D_loss: 0.6082,  G_loss: 1.4298\n",
      " Epoch [149/300], Batch Step [150/323], D_loss: 0.6205,  G_loss: 1.5751\n",
      " Epoch [149/300], Batch Step [160/323], D_loss: 0.7371,  G_loss: 1.4241\n",
      " Epoch [149/300], Batch Step [170/323], D_loss: 0.6642,  G_loss: 1.5756\n",
      " Epoch [149/300], Batch Step [180/323], D_loss: 0.6820,  G_loss: 1.5743\n",
      " Epoch [149/300], Batch Step [190/323], D_loss: 0.5945,  G_loss: 1.5898\n",
      " Epoch [149/300], Batch Step [200/323], D_loss: 0.5974,  G_loss: 1.6368\n",
      " Epoch [149/300], Batch Step [210/323], D_loss: 0.5723,  G_loss: 1.5639\n",
      " Epoch [149/300], Batch Step [220/323], D_loss: 0.6605,  G_loss: 1.5626\n",
      " Epoch [149/300], Batch Step [230/323], D_loss: 0.6365,  G_loss: 1.4710\n",
      " Epoch [149/300], Batch Step [240/323], D_loss: 0.5758,  G_loss: 1.7234\n",
      " Epoch [149/300], Batch Step [250/323], D_loss: 0.7653,  G_loss: 1.4462\n",
      " Epoch [149/300], Batch Step [260/323], D_loss: 0.6697,  G_loss: 1.5024\n",
      " Epoch [149/300], Batch Step [270/323], D_loss: 0.7020,  G_loss: 1.6664\n",
      " Epoch [149/300], Batch Step [280/323], D_loss: 0.5544,  G_loss: 1.4677\n",
      " Epoch [149/300], Batch Step [290/323], D_loss: 0.6770,  G_loss: 1.6072\n",
      " Epoch [149/300], Batch Step [300/323], D_loss: 0.5444,  G_loss: 1.5441\n",
      " Epoch [149/300], Batch Step [310/323], D_loss: 0.6411,  G_loss: 1.7115\n",
      " Epoch [149/300], Batch Step [320/323], D_loss: 0.7317,  G_loss: 1.6179\n",
      " Epoch [150/300], Batch Step [0/323], D_loss: 0.7098,  G_loss: 1.5089\n",
      " Epoch [150/300], Batch Step [10/323], D_loss: 0.5951,  G_loss: 1.6061\n",
      " Epoch [150/300], Batch Step [20/323], D_loss: 0.5905,  G_loss: 1.5744\n",
      " Epoch [150/300], Batch Step [30/323], D_loss: 0.7378,  G_loss: 1.5681\n",
      " Epoch [150/300], Batch Step [40/323], D_loss: 0.7650,  G_loss: 1.5604\n",
      " Epoch [150/300], Batch Step [50/323], D_loss: 0.6006,  G_loss: 1.5202\n",
      " Epoch [150/300], Batch Step [60/323], D_loss: 0.5238,  G_loss: 1.6270\n",
      " Epoch [150/300], Batch Step [70/323], D_loss: 0.7348,  G_loss: 1.6214\n",
      " Epoch [150/300], Batch Step [80/323], D_loss: 0.6101,  G_loss: 1.5353\n",
      " Epoch [150/300], Batch Step [90/323], D_loss: 0.6027,  G_loss: 1.4953\n",
      " Epoch [150/300], Batch Step [100/323], D_loss: 0.7029,  G_loss: 1.5404\n",
      " Epoch [150/300], Batch Step [110/323], D_loss: 0.6578,  G_loss: 1.5925\n",
      " Epoch [150/300], Batch Step [120/323], D_loss: 0.7273,  G_loss: 1.7232\n",
      " Epoch [150/300], Batch Step [130/323], D_loss: 0.6699,  G_loss: 1.5612\n",
      " Epoch [150/300], Batch Step [140/323], D_loss: 0.5946,  G_loss: 1.7357\n",
      " Epoch [150/300], Batch Step [150/323], D_loss: 0.6453,  G_loss: 1.4337\n",
      " Epoch [150/300], Batch Step [160/323], D_loss: 0.7195,  G_loss: 1.6017\n",
      " Epoch [150/300], Batch Step [170/323], D_loss: 0.6316,  G_loss: 1.5457\n",
      " Epoch [150/300], Batch Step [180/323], D_loss: 0.5524,  G_loss: 1.5215\n",
      " Epoch [150/300], Batch Step [190/323], D_loss: 0.6575,  G_loss: 1.5394\n",
      " Epoch [150/300], Batch Step [200/323], D_loss: 0.8106,  G_loss: 1.5360\n",
      " Epoch [150/300], Batch Step [210/323], D_loss: 0.5712,  G_loss: 1.6351\n",
      " Epoch [150/300], Batch Step [220/323], D_loss: 0.5750,  G_loss: 1.5272\n",
      " Epoch [150/300], Batch Step [230/323], D_loss: 0.4545,  G_loss: 1.4807\n",
      " Epoch [150/300], Batch Step [240/323], D_loss: 0.6941,  G_loss: 1.5359\n",
      " Epoch [150/300], Batch Step [250/323], D_loss: 0.6647,  G_loss: 1.5427\n",
      " Epoch [150/300], Batch Step [260/323], D_loss: 0.6562,  G_loss: 1.5728\n",
      " Epoch [150/300], Batch Step [270/323], D_loss: 0.8111,  G_loss: 1.5090\n",
      " Epoch [150/300], Batch Step [280/323], D_loss: 0.6555,  G_loss: 1.5990\n",
      " Epoch [150/300], Batch Step [290/323], D_loss: 0.7337,  G_loss: 1.4599\n",
      " Epoch [150/300], Batch Step [300/323], D_loss: 0.6797,  G_loss: 1.5520\n",
      " Epoch [150/300], Batch Step [310/323], D_loss: 0.7401,  G_loss: 1.4490\n",
      " Epoch [150/300], Batch Step [320/323], D_loss: 0.6975,  G_loss: 1.5615\n",
      " Epoch [151/300], Batch Step [0/323], D_loss: 0.6716,  G_loss: 1.5988\n",
      " Epoch [151/300], Batch Step [10/323], D_loss: 0.7832,  G_loss: 1.6386\n",
      " Epoch [151/300], Batch Step [20/323], D_loss: 0.6404,  G_loss: 1.4402\n",
      " Epoch [151/300], Batch Step [30/323], D_loss: 0.6669,  G_loss: 1.6150\n",
      " Epoch [151/300], Batch Step [40/323], D_loss: 0.4944,  G_loss: 1.6482\n",
      " Epoch [151/300], Batch Step [50/323], D_loss: 0.7872,  G_loss: 1.3509\n",
      " Epoch [151/300], Batch Step [60/323], D_loss: 0.6213,  G_loss: 1.5607\n",
      " Epoch [151/300], Batch Step [70/323], D_loss: 0.6518,  G_loss: 1.5877\n",
      " Epoch [151/300], Batch Step [80/323], D_loss: 0.7731,  G_loss: 1.5947\n",
      " Epoch [151/300], Batch Step [90/323], D_loss: 0.5043,  G_loss: 1.6380\n",
      " Epoch [151/300], Batch Step [100/323], D_loss: 0.7243,  G_loss: 1.4647\n",
      " Epoch [151/300], Batch Step [110/323], D_loss: 0.6460,  G_loss: 1.5697\n",
      " Epoch [151/300], Batch Step [120/323], D_loss: 0.7502,  G_loss: 1.5978\n",
      " Epoch [151/300], Batch Step [130/323], D_loss: 0.6013,  G_loss: 1.4717\n",
      " Epoch [151/300], Batch Step [140/323], D_loss: 0.6793,  G_loss: 1.6299\n",
      " Epoch [151/300], Batch Step [150/323], D_loss: 0.6908,  G_loss: 1.5245\n",
      " Epoch [151/300], Batch Step [160/323], D_loss: 0.5944,  G_loss: 1.6056\n",
      " Epoch [151/300], Batch Step [170/323], D_loss: 0.7048,  G_loss: 1.6633\n",
      " Epoch [151/300], Batch Step [180/323], D_loss: 0.6141,  G_loss: 1.5827\n",
      " Epoch [151/300], Batch Step [190/323], D_loss: 0.8548,  G_loss: 1.5694\n",
      " Epoch [151/300], Batch Step [200/323], D_loss: 0.7534,  G_loss: 1.5464\n",
      " Epoch [151/300], Batch Step [210/323], D_loss: 0.6840,  G_loss: 1.6790\n",
      " Epoch [151/300], Batch Step [220/323], D_loss: 0.7618,  G_loss: 1.4636\n",
      " Epoch [151/300], Batch Step [230/323], D_loss: 0.6194,  G_loss: 1.5822\n",
      " Epoch [151/300], Batch Step [240/323], D_loss: 0.6321,  G_loss: 1.5614\n",
      " Epoch [151/300], Batch Step [250/323], D_loss: 0.8500,  G_loss: 1.7175\n",
      " Epoch [151/300], Batch Step [260/323], D_loss: 0.6085,  G_loss: 1.7272\n",
      " Epoch [151/300], Batch Step [270/323], D_loss: 0.6399,  G_loss: 1.4612\n",
      " Epoch [151/300], Batch Step [280/323], D_loss: 0.5920,  G_loss: 1.4937\n",
      " Epoch [151/300], Batch Step [290/323], D_loss: 0.5881,  G_loss: 1.6744\n",
      " Epoch [151/300], Batch Step [300/323], D_loss: 0.6055,  G_loss: 1.5775\n",
      " Epoch [151/300], Batch Step [310/323], D_loss: 0.6712,  G_loss: 1.5937\n",
      " Epoch [151/300], Batch Step [320/323], D_loss: 0.7878,  G_loss: 1.6186\n",
      " Epoch [152/300], Batch Step [0/323], D_loss: 0.7207,  G_loss: 1.4325\n",
      " Epoch [152/300], Batch Step [10/323], D_loss: 0.5528,  G_loss: 1.6344\n",
      " Epoch [152/300], Batch Step [20/323], D_loss: 0.7350,  G_loss: 1.7827\n",
      " Epoch [152/300], Batch Step [30/323], D_loss: 0.6132,  G_loss: 1.5516\n",
      " Epoch [152/300], Batch Step [40/323], D_loss: 0.8111,  G_loss: 1.5532\n",
      " Epoch [152/300], Batch Step [50/323], D_loss: 0.6544,  G_loss: 1.6065\n",
      " Epoch [152/300], Batch Step [60/323], D_loss: 0.6025,  G_loss: 1.4413\n",
      " Epoch [152/300], Batch Step [70/323], D_loss: 0.7427,  G_loss: 1.5944\n",
      " Epoch [152/300], Batch Step [80/323], D_loss: 0.6285,  G_loss: 1.4798\n",
      " Epoch [152/300], Batch Step [90/323], D_loss: 0.5565,  G_loss: 1.7271\n",
      " Epoch [152/300], Batch Step [100/323], D_loss: 0.6099,  G_loss: 1.4643\n",
      " Epoch [152/300], Batch Step [110/323], D_loss: 0.5845,  G_loss: 1.5942\n",
      " Epoch [152/300], Batch Step [120/323], D_loss: 0.4548,  G_loss: 1.6729\n",
      " Epoch [152/300], Batch Step [130/323], D_loss: 0.7637,  G_loss: 1.6272\n",
      " Epoch [152/300], Batch Step [140/323], D_loss: 0.5750,  G_loss: 1.4948\n",
      " Epoch [152/300], Batch Step [150/323], D_loss: 0.5515,  G_loss: 1.5122\n",
      " Epoch [152/300], Batch Step [160/323], D_loss: 0.7311,  G_loss: 1.5739\n",
      " Epoch [152/300], Batch Step [170/323], D_loss: 0.6270,  G_loss: 1.6702\n",
      " Epoch [152/300], Batch Step [180/323], D_loss: 0.6231,  G_loss: 1.5940\n",
      " Epoch [152/300], Batch Step [190/323], D_loss: 0.5906,  G_loss: 1.5917\n",
      " Epoch [152/300], Batch Step [200/323], D_loss: 0.7269,  G_loss: 1.4401\n",
      " Epoch [152/300], Batch Step [210/323], D_loss: 0.6390,  G_loss: 1.4730\n",
      " Epoch [152/300], Batch Step [220/323], D_loss: 0.6551,  G_loss: 1.5933\n",
      " Epoch [152/300], Batch Step [230/323], D_loss: 0.6666,  G_loss: 1.4572\n",
      " Epoch [152/300], Batch Step [240/323], D_loss: 0.7065,  G_loss: 1.6009\n",
      " Epoch [152/300], Batch Step [250/323], D_loss: 0.6614,  G_loss: 1.6482\n",
      " Epoch [152/300], Batch Step [260/323], D_loss: 0.5617,  G_loss: 1.5545\n",
      " Epoch [152/300], Batch Step [270/323], D_loss: 0.6173,  G_loss: 1.5282\n",
      " Epoch [152/300], Batch Step [280/323], D_loss: 0.5993,  G_loss: 1.5374\n",
      " Epoch [152/300], Batch Step [290/323], D_loss: 0.8350,  G_loss: 1.5377\n",
      " Epoch [152/300], Batch Step [300/323], D_loss: 0.6823,  G_loss: 1.4734\n",
      " Epoch [152/300], Batch Step [310/323], D_loss: 0.7616,  G_loss: 1.7099\n",
      " Epoch [152/300], Batch Step [320/323], D_loss: 0.6393,  G_loss: 1.6284\n",
      " Epoch [153/300], Batch Step [0/323], D_loss: 0.6794,  G_loss: 1.5402\n",
      " Epoch [153/300], Batch Step [10/323], D_loss: 0.6293,  G_loss: 1.5660\n",
      " Epoch [153/300], Batch Step [20/323], D_loss: 0.4758,  G_loss: 1.5391\n",
      " Epoch [153/300], Batch Step [30/323], D_loss: 0.6311,  G_loss: 1.6705\n",
      " Epoch [153/300], Batch Step [40/323], D_loss: 0.4988,  G_loss: 1.6417\n",
      " Epoch [153/300], Batch Step [50/323], D_loss: 0.6354,  G_loss: 1.6114\n",
      " Epoch [153/300], Batch Step [60/323], D_loss: 0.6862,  G_loss: 1.5554\n",
      " Epoch [153/300], Batch Step [70/323], D_loss: 0.5937,  G_loss: 1.6172\n",
      " Epoch [153/300], Batch Step [80/323], D_loss: 0.4557,  G_loss: 1.6676\n",
      " Epoch [153/300], Batch Step [90/323], D_loss: 0.8593,  G_loss: 1.5164\n",
      " Epoch [153/300], Batch Step [100/323], D_loss: 0.6143,  G_loss: 1.4556\n",
      " Epoch [153/300], Batch Step [110/323], D_loss: 0.7111,  G_loss: 1.6754\n",
      " Epoch [153/300], Batch Step [120/323], D_loss: 0.7205,  G_loss: 1.5111\n",
      " Epoch [153/300], Batch Step [130/323], D_loss: 0.6023,  G_loss: 1.5984\n",
      " Epoch [153/300], Batch Step [140/323], D_loss: 0.7158,  G_loss: 1.4415\n",
      " Epoch [153/300], Batch Step [150/323], D_loss: 0.5938,  G_loss: 1.5247\n",
      " Epoch [153/300], Batch Step [160/323], D_loss: 0.6018,  G_loss: 1.4938\n",
      " Epoch [153/300], Batch Step [170/323], D_loss: 0.6203,  G_loss: 1.6317\n",
      " Epoch [153/300], Batch Step [180/323], D_loss: 0.6326,  G_loss: 1.6601\n",
      " Epoch [153/300], Batch Step [190/323], D_loss: 0.6281,  G_loss: 1.4942\n",
      " Epoch [153/300], Batch Step [200/323], D_loss: 0.6938,  G_loss: 1.5657\n",
      " Epoch [153/300], Batch Step [210/323], D_loss: 0.4878,  G_loss: 1.5837\n",
      " Epoch [153/300], Batch Step [220/323], D_loss: 0.8404,  G_loss: 1.6834\n",
      " Epoch [153/300], Batch Step [230/323], D_loss: 0.5879,  G_loss: 1.5191\n",
      " Epoch [153/300], Batch Step [240/323], D_loss: 0.7350,  G_loss: 1.5347\n",
      " Epoch [153/300], Batch Step [250/323], D_loss: 0.7071,  G_loss: 1.6436\n",
      " Epoch [153/300], Batch Step [260/323], D_loss: 0.6814,  G_loss: 1.5715\n",
      " Epoch [153/300], Batch Step [270/323], D_loss: 0.6362,  G_loss: 1.5657\n",
      " Epoch [153/300], Batch Step [280/323], D_loss: 0.5663,  G_loss: 1.5814\n",
      " Epoch [153/300], Batch Step [290/323], D_loss: 0.5694,  G_loss: 1.5612\n",
      " Epoch [153/300], Batch Step [300/323], D_loss: 0.4632,  G_loss: 1.6407\n",
      " Epoch [153/300], Batch Step [310/323], D_loss: 0.6608,  G_loss: 1.5648\n",
      " Epoch [153/300], Batch Step [320/323], D_loss: 0.6583,  G_loss: 1.6817\n",
      " Epoch [154/300], Batch Step [0/323], D_loss: 0.5631,  G_loss: 1.6943\n",
      " Epoch [154/300], Batch Step [10/323], D_loss: 0.6323,  G_loss: 1.3830\n",
      " Epoch [154/300], Batch Step [20/323], D_loss: 0.6205,  G_loss: 1.5993\n",
      " Epoch [154/300], Batch Step [30/323], D_loss: 0.8547,  G_loss: 1.5897\n",
      " Epoch [154/300], Batch Step [40/323], D_loss: 0.6236,  G_loss: 1.4725\n",
      " Epoch [154/300], Batch Step [50/323], D_loss: 0.7185,  G_loss: 1.6969\n",
      " Epoch [154/300], Batch Step [60/323], D_loss: 0.7243,  G_loss: 1.5284\n",
      " Epoch [154/300], Batch Step [70/323], D_loss: 0.8271,  G_loss: 1.6865\n",
      " Epoch [154/300], Batch Step [80/323], D_loss: 0.7657,  G_loss: 1.5238\n",
      " Epoch [154/300], Batch Step [90/323], D_loss: 0.6769,  G_loss: 1.5750\n",
      " Epoch [154/300], Batch Step [100/323], D_loss: 0.5726,  G_loss: 1.6272\n",
      " Epoch [154/300], Batch Step [110/323], D_loss: 0.5896,  G_loss: 1.5173\n",
      " Epoch [154/300], Batch Step [120/323], D_loss: 0.6618,  G_loss: 1.5791\n",
      " Epoch [154/300], Batch Step [130/323], D_loss: 0.7418,  G_loss: 1.6398\n",
      " Epoch [154/300], Batch Step [140/323], D_loss: 0.6976,  G_loss: 1.4221\n",
      " Epoch [154/300], Batch Step [150/323], D_loss: 0.6946,  G_loss: 1.6794\n",
      " Epoch [154/300], Batch Step [160/323], D_loss: 0.8123,  G_loss: 1.4132\n",
      " Epoch [154/300], Batch Step [170/323], D_loss: 0.6348,  G_loss: 1.6830\n",
      " Epoch [154/300], Batch Step [180/323], D_loss: 0.9861,  G_loss: 1.7218\n",
      " Epoch [154/300], Batch Step [190/323], D_loss: 0.6754,  G_loss: 1.5038\n",
      " Epoch [154/300], Batch Step [200/323], D_loss: 0.6059,  G_loss: 1.5579\n",
      " Epoch [154/300], Batch Step [210/323], D_loss: 0.6745,  G_loss: 1.5173\n",
      " Epoch [154/300], Batch Step [220/323], D_loss: 0.6457,  G_loss: 1.6111\n",
      " Epoch [154/300], Batch Step [230/323], D_loss: 0.5578,  G_loss: 1.6173\n",
      " Epoch [154/300], Batch Step [240/323], D_loss: 0.5019,  G_loss: 1.6911\n",
      " Epoch [154/300], Batch Step [250/323], D_loss: 0.6463,  G_loss: 1.6947\n",
      " Epoch [154/300], Batch Step [260/323], D_loss: 0.6806,  G_loss: 1.5891\n",
      " Epoch [154/300], Batch Step [270/323], D_loss: 0.6251,  G_loss: 1.7135\n",
      " Epoch [154/300], Batch Step [280/323], D_loss: 0.7175,  G_loss: 1.4033\n",
      " Epoch [154/300], Batch Step [290/323], D_loss: 0.7357,  G_loss: 1.7220\n",
      " Epoch [154/300], Batch Step [300/323], D_loss: 0.7274,  G_loss: 1.4873\n",
      " Epoch [154/300], Batch Step [310/323], D_loss: 0.5444,  G_loss: 1.4172\n",
      " Epoch [154/300], Batch Step [320/323], D_loss: 0.6730,  G_loss: 1.6471\n",
      " Epoch [155/300], Batch Step [0/323], D_loss: 0.7409,  G_loss: 1.5891\n",
      " Epoch [155/300], Batch Step [10/323], D_loss: 0.5633,  G_loss: 1.4841\n",
      " Epoch [155/300], Batch Step [20/323], D_loss: 0.7504,  G_loss: 1.6417\n",
      " Epoch [155/300], Batch Step [30/323], D_loss: 0.6536,  G_loss: 1.5183\n",
      " Epoch [155/300], Batch Step [40/323], D_loss: 0.7121,  G_loss: 1.6798\n",
      " Epoch [155/300], Batch Step [50/323], D_loss: 0.7361,  G_loss: 1.5479\n",
      " Epoch [155/300], Batch Step [60/323], D_loss: 0.7087,  G_loss: 1.5418\n",
      " Epoch [155/300], Batch Step [70/323], D_loss: 0.5902,  G_loss: 1.5488\n",
      " Epoch [155/300], Batch Step [80/323], D_loss: 0.7319,  G_loss: 1.5383\n",
      " Epoch [155/300], Batch Step [90/323], D_loss: 0.6051,  G_loss: 1.6323\n",
      " Epoch [155/300], Batch Step [100/323], D_loss: 0.6762,  G_loss: 1.6161\n",
      " Epoch [155/300], Batch Step [110/323], D_loss: 0.8005,  G_loss: 1.4263\n",
      " Epoch [155/300], Batch Step [120/323], D_loss: 0.5639,  G_loss: 1.6886\n",
      " Epoch [155/300], Batch Step [130/323], D_loss: 0.6523,  G_loss: 1.5690\n",
      " Epoch [155/300], Batch Step [140/323], D_loss: 0.7386,  G_loss: 1.6700\n",
      " Epoch [155/300], Batch Step [150/323], D_loss: 0.8086,  G_loss: 1.5261\n",
      " Epoch [155/300], Batch Step [160/323], D_loss: 0.6700,  G_loss: 1.6213\n",
      " Epoch [155/300], Batch Step [170/323], D_loss: 0.4582,  G_loss: 1.5727\n",
      " Epoch [155/300], Batch Step [180/323], D_loss: 0.6630,  G_loss: 1.5223\n",
      " Epoch [155/300], Batch Step [190/323], D_loss: 0.6209,  G_loss: 1.4610\n",
      " Epoch [155/300], Batch Step [200/323], D_loss: 0.7427,  G_loss: 1.4747\n",
      " Epoch [155/300], Batch Step [210/323], D_loss: 0.5244,  G_loss: 1.6118\n",
      " Epoch [155/300], Batch Step [220/323], D_loss: 0.5717,  G_loss: 1.6531\n",
      " Epoch [155/300], Batch Step [230/323], D_loss: 0.6674,  G_loss: 1.4837\n",
      " Epoch [155/300], Batch Step [240/323], D_loss: 0.6185,  G_loss: 1.5225\n",
      " Epoch [155/300], Batch Step [250/323], D_loss: 0.6615,  G_loss: 1.5392\n",
      " Epoch [155/300], Batch Step [260/323], D_loss: 0.5697,  G_loss: 1.6670\n",
      " Epoch [155/300], Batch Step [270/323], D_loss: 0.7688,  G_loss: 1.5953\n",
      " Epoch [155/300], Batch Step [280/323], D_loss: 0.6989,  G_loss: 1.6156\n",
      " Epoch [155/300], Batch Step [290/323], D_loss: 0.5465,  G_loss: 1.6206\n",
      " Epoch [155/300], Batch Step [300/323], D_loss: 0.6467,  G_loss: 1.5835\n",
      " Epoch [155/300], Batch Step [310/323], D_loss: 0.7647,  G_loss: 1.4684\n",
      " Epoch [155/300], Batch Step [320/323], D_loss: 0.6803,  G_loss: 1.5373\n",
      " Epoch [156/300], Batch Step [0/323], D_loss: 0.7441,  G_loss: 1.5783\n",
      " Epoch [156/300], Batch Step [10/323], D_loss: 0.8063,  G_loss: 1.4176\n",
      " Epoch [156/300], Batch Step [20/323], D_loss: 0.7500,  G_loss: 1.5535\n",
      " Epoch [156/300], Batch Step [30/323], D_loss: 0.7510,  G_loss: 1.4328\n",
      " Epoch [156/300], Batch Step [40/323], D_loss: 0.6156,  G_loss: 1.5749\n",
      " Epoch [156/300], Batch Step [50/323], D_loss: 0.6342,  G_loss: 1.6735\n",
      " Epoch [156/300], Batch Step [60/323], D_loss: 0.5502,  G_loss: 1.6497\n",
      " Epoch [156/300], Batch Step [70/323], D_loss: 0.6867,  G_loss: 1.4803\n",
      " Epoch [156/300], Batch Step [80/323], D_loss: 0.5889,  G_loss: 1.7956\n",
      " Epoch [156/300], Batch Step [90/323], D_loss: 0.7873,  G_loss: 1.5998\n",
      " Epoch [156/300], Batch Step [100/323], D_loss: 0.6296,  G_loss: 1.6336\n",
      " Epoch [156/300], Batch Step [110/323], D_loss: 0.5853,  G_loss: 1.6024\n",
      " Epoch [156/300], Batch Step [120/323], D_loss: 0.6622,  G_loss: 1.4881\n",
      " Epoch [156/300], Batch Step [130/323], D_loss: 0.7933,  G_loss: 1.6314\n",
      " Epoch [156/300], Batch Step [140/323], D_loss: 0.6505,  G_loss: 1.5137\n",
      " Epoch [156/300], Batch Step [150/323], D_loss: 0.7588,  G_loss: 1.6435\n",
      " Epoch [156/300], Batch Step [160/323], D_loss: 0.6009,  G_loss: 1.4258\n",
      " Epoch [156/300], Batch Step [170/323], D_loss: 0.5486,  G_loss: 1.7130\n",
      " Epoch [156/300], Batch Step [180/323], D_loss: 0.5389,  G_loss: 1.4946\n",
      " Epoch [156/300], Batch Step [190/323], D_loss: 0.6733,  G_loss: 1.5828\n",
      " Epoch [156/300], Batch Step [200/323], D_loss: 0.5364,  G_loss: 1.5575\n",
      " Epoch [156/300], Batch Step [210/323], D_loss: 0.5855,  G_loss: 1.7768\n",
      " Epoch [156/300], Batch Step [220/323], D_loss: 0.6395,  G_loss: 1.5123\n",
      " Epoch [156/300], Batch Step [230/323], D_loss: 0.7253,  G_loss: 1.5617\n",
      " Epoch [156/300], Batch Step [240/323], D_loss: 0.6835,  G_loss: 1.5530\n",
      " Epoch [156/300], Batch Step [250/323], D_loss: 0.6337,  G_loss: 1.7357\n",
      " Epoch [156/300], Batch Step [260/323], D_loss: 0.6604,  G_loss: 1.5756\n",
      " Epoch [156/300], Batch Step [270/323], D_loss: 0.6850,  G_loss: 1.5153\n",
      " Epoch [156/300], Batch Step [280/323], D_loss: 0.8008,  G_loss: 1.5176\n",
      " Epoch [156/300], Batch Step [290/323], D_loss: 0.6707,  G_loss: 1.6161\n",
      " Epoch [156/300], Batch Step [300/323], D_loss: 0.6025,  G_loss: 1.5433\n",
      " Epoch [156/300], Batch Step [310/323], D_loss: 0.4543,  G_loss: 1.7509\n",
      " Epoch [156/300], Batch Step [320/323], D_loss: 0.6380,  G_loss: 1.5001\n",
      " Epoch [157/300], Batch Step [0/323], D_loss: 0.5393,  G_loss: 1.5086\n",
      " Epoch [157/300], Batch Step [10/323], D_loss: 0.6517,  G_loss: 1.5795\n",
      " Epoch [157/300], Batch Step [20/323], D_loss: 0.5432,  G_loss: 1.6769\n",
      " Epoch [157/300], Batch Step [30/323], D_loss: 0.7500,  G_loss: 1.5331\n",
      " Epoch [157/300], Batch Step [40/323], D_loss: 0.5692,  G_loss: 1.5894\n",
      " Epoch [157/300], Batch Step [50/323], D_loss: 0.6040,  G_loss: 1.4761\n",
      " Epoch [157/300], Batch Step [60/323], D_loss: 0.7217,  G_loss: 1.7021\n",
      " Epoch [157/300], Batch Step [70/323], D_loss: 0.7526,  G_loss: 1.7359\n",
      " Epoch [157/300], Batch Step [80/323], D_loss: 0.6272,  G_loss: 1.5226\n",
      " Epoch [157/300], Batch Step [90/323], D_loss: 0.7556,  G_loss: 1.5623\n",
      " Epoch [157/300], Batch Step [100/323], D_loss: 0.6079,  G_loss: 1.5689\n",
      " Epoch [157/300], Batch Step [110/323], D_loss: 0.5655,  G_loss: 1.5610\n",
      " Epoch [157/300], Batch Step [120/323], D_loss: 0.5519,  G_loss: 1.5109\n",
      " Epoch [157/300], Batch Step [130/323], D_loss: 0.6727,  G_loss: 1.5893\n",
      " Epoch [157/300], Batch Step [140/323], D_loss: 0.4684,  G_loss: 1.6252\n",
      " Epoch [157/300], Batch Step [150/323], D_loss: 0.5511,  G_loss: 1.6349\n",
      " Epoch [157/300], Batch Step [160/323], D_loss: 0.6232,  G_loss: 1.5757\n",
      " Epoch [157/300], Batch Step [170/323], D_loss: 0.7061,  G_loss: 1.4739\n",
      " Epoch [157/300], Batch Step [180/323], D_loss: 0.5844,  G_loss: 1.5406\n",
      " Epoch [157/300], Batch Step [190/323], D_loss: 0.6797,  G_loss: 1.6041\n",
      " Epoch [157/300], Batch Step [200/323], D_loss: 0.6897,  G_loss: 1.4501\n",
      " Epoch [157/300], Batch Step [210/323], D_loss: 0.5722,  G_loss: 1.6724\n",
      " Epoch [157/300], Batch Step [220/323], D_loss: 0.6557,  G_loss: 1.6713\n",
      " Epoch [157/300], Batch Step [230/323], D_loss: 0.6585,  G_loss: 1.5105\n",
      " Epoch [157/300], Batch Step [240/323], D_loss: 0.5394,  G_loss: 1.6451\n",
      " Epoch [157/300], Batch Step [250/323], D_loss: 0.6542,  G_loss: 1.5937\n",
      " Epoch [157/300], Batch Step [260/323], D_loss: 0.4529,  G_loss: 1.4742\n",
      " Epoch [157/300], Batch Step [270/323], D_loss: 0.6329,  G_loss: 1.6377\n",
      " Epoch [157/300], Batch Step [280/323], D_loss: 0.6816,  G_loss: 1.5674\n",
      " Epoch [157/300], Batch Step [290/323], D_loss: 0.8130,  G_loss: 1.4790\n",
      " Epoch [157/300], Batch Step [300/323], D_loss: 0.6690,  G_loss: 1.5603\n",
      " Epoch [157/300], Batch Step [310/323], D_loss: 0.6598,  G_loss: 1.5423\n",
      " Epoch [157/300], Batch Step [320/323], D_loss: 0.7094,  G_loss: 1.3875\n",
      " Epoch [158/300], Batch Step [0/323], D_loss: 0.7217,  G_loss: 1.4349\n",
      " Epoch [158/300], Batch Step [10/323], D_loss: 0.6673,  G_loss: 1.5304\n",
      " Epoch [158/300], Batch Step [20/323], D_loss: 0.5941,  G_loss: 1.4781\n",
      " Epoch [158/300], Batch Step [30/323], D_loss: 0.6187,  G_loss: 1.6478\n",
      " Epoch [158/300], Batch Step [40/323], D_loss: 0.6245,  G_loss: 1.4861\n",
      " Epoch [158/300], Batch Step [50/323], D_loss: 0.6713,  G_loss: 1.6380\n",
      " Epoch [158/300], Batch Step [60/323], D_loss: 0.7995,  G_loss: 1.5953\n",
      " Epoch [158/300], Batch Step [70/323], D_loss: 0.6159,  G_loss: 1.4553\n",
      " Epoch [158/300], Batch Step [80/323], D_loss: 0.7304,  G_loss: 1.7354\n",
      " Epoch [158/300], Batch Step [90/323], D_loss: 0.7420,  G_loss: 1.5539\n",
      " Epoch [158/300], Batch Step [100/323], D_loss: 0.6027,  G_loss: 1.5867\n",
      " Epoch [158/300], Batch Step [110/323], D_loss: 0.5675,  G_loss: 1.6505\n",
      " Epoch [158/300], Batch Step [120/323], D_loss: 0.5817,  G_loss: 1.4893\n",
      " Epoch [158/300], Batch Step [130/323], D_loss: 0.5870,  G_loss: 1.6165\n",
      " Epoch [158/300], Batch Step [140/323], D_loss: 0.6771,  G_loss: 1.5556\n",
      " Epoch [158/300], Batch Step [150/323], D_loss: 0.8755,  G_loss: 1.5230\n",
      " Epoch [158/300], Batch Step [160/323], D_loss: 0.7128,  G_loss: 1.6435\n",
      " Epoch [158/300], Batch Step [170/323], D_loss: 0.6065,  G_loss: 1.6289\n",
      " Epoch [158/300], Batch Step [180/323], D_loss: 0.5220,  G_loss: 1.5117\n",
      " Epoch [158/300], Batch Step [190/323], D_loss: 0.6291,  G_loss: 1.7793\n",
      " Epoch [158/300], Batch Step [200/323], D_loss: 0.6357,  G_loss: 1.5474\n",
      " Epoch [158/300], Batch Step [210/323], D_loss: 0.6189,  G_loss: 1.6251\n",
      " Epoch [158/300], Batch Step [220/323], D_loss: 0.6059,  G_loss: 1.6101\n",
      " Epoch [158/300], Batch Step [230/323], D_loss: 0.7527,  G_loss: 1.5531\n",
      " Epoch [158/300], Batch Step [240/323], D_loss: 0.5268,  G_loss: 1.7871\n",
      " Epoch [158/300], Batch Step [250/323], D_loss: 0.6880,  G_loss: 1.5598\n",
      " Epoch [158/300], Batch Step [260/323], D_loss: 0.7241,  G_loss: 1.5937\n",
      " Epoch [158/300], Batch Step [270/323], D_loss: 0.6012,  G_loss: 1.4863\n",
      " Epoch [158/300], Batch Step [280/323], D_loss: 0.7880,  G_loss: 1.5937\n",
      " Epoch [158/300], Batch Step [290/323], D_loss: 0.6034,  G_loss: 1.5791\n",
      " Epoch [158/300], Batch Step [300/323], D_loss: 0.7992,  G_loss: 1.5491\n",
      " Epoch [158/300], Batch Step [310/323], D_loss: 0.7573,  G_loss: 1.5939\n",
      " Epoch [158/300], Batch Step [320/323], D_loss: 0.6384,  G_loss: 1.6095\n",
      " Epoch [159/300], Batch Step [0/323], D_loss: 0.5742,  G_loss: 1.6912\n",
      " Epoch [159/300], Batch Step [10/323], D_loss: 0.7288,  G_loss: 1.6213\n",
      " Epoch [159/300], Batch Step [20/323], D_loss: 0.6734,  G_loss: 1.4614\n",
      " Epoch [159/300], Batch Step [30/323], D_loss: 0.4811,  G_loss: 1.7505\n",
      " Epoch [159/300], Batch Step [40/323], D_loss: 0.6699,  G_loss: 1.5806\n",
      " Epoch [159/300], Batch Step [50/323], D_loss: 0.6652,  G_loss: 1.5852\n",
      " Epoch [159/300], Batch Step [60/323], D_loss: 0.8572,  G_loss: 1.4955\n",
      " Epoch [159/300], Batch Step [70/323], D_loss: 0.6563,  G_loss: 1.5572\n",
      " Epoch [159/300], Batch Step [80/323], D_loss: 0.7867,  G_loss: 1.5054\n",
      " Epoch [159/300], Batch Step [90/323], D_loss: 0.6052,  G_loss: 1.5493\n",
      " Epoch [159/300], Batch Step [100/323], D_loss: 0.7395,  G_loss: 1.4950\n",
      " Epoch [159/300], Batch Step [110/323], D_loss: 0.8839,  G_loss: 1.5963\n",
      " Epoch [159/300], Batch Step [120/323], D_loss: 0.6558,  G_loss: 1.6414\n",
      " Epoch [159/300], Batch Step [130/323], D_loss: 0.5307,  G_loss: 1.6301\n",
      " Epoch [159/300], Batch Step [140/323], D_loss: 0.7364,  G_loss: 1.4449\n",
      " Epoch [159/300], Batch Step [150/323], D_loss: 0.6492,  G_loss: 1.7024\n",
      " Epoch [159/300], Batch Step [160/323], D_loss: 0.6076,  G_loss: 1.6242\n",
      " Epoch [159/300], Batch Step [170/323], D_loss: 0.6730,  G_loss: 1.5453\n",
      " Epoch [159/300], Batch Step [180/323], D_loss: 0.7389,  G_loss: 1.5760\n",
      " Epoch [159/300], Batch Step [190/323], D_loss: 0.6135,  G_loss: 1.6052\n",
      " Epoch [159/300], Batch Step [200/323], D_loss: 0.6592,  G_loss: 1.5226\n",
      " Epoch [159/300], Batch Step [210/323], D_loss: 0.7685,  G_loss: 1.4008\n",
      " Epoch [159/300], Batch Step [220/323], D_loss: 0.5483,  G_loss: 1.7129\n",
      " Epoch [159/300], Batch Step [230/323], D_loss: 0.8228,  G_loss: 1.6774\n",
      " Epoch [159/300], Batch Step [240/323], D_loss: 0.6322,  G_loss: 1.5393\n",
      " Epoch [159/300], Batch Step [250/323], D_loss: 0.6303,  G_loss: 1.6681\n",
      " Epoch [159/300], Batch Step [260/323], D_loss: 0.7286,  G_loss: 1.5712\n",
      " Epoch [159/300], Batch Step [270/323], D_loss: 0.7452,  G_loss: 1.5568\n",
      " Epoch [159/300], Batch Step [280/323], D_loss: 0.7068,  G_loss: 1.5099\n",
      " Epoch [159/300], Batch Step [290/323], D_loss: 0.6093,  G_loss: 1.5993\n",
      " Epoch [159/300], Batch Step [300/323], D_loss: 0.6538,  G_loss: 1.6419\n",
      " Epoch [159/300], Batch Step [310/323], D_loss: 0.6282,  G_loss: 1.5717\n",
      " Epoch [159/300], Batch Step [320/323], D_loss: 0.6317,  G_loss: 1.6526\n",
      " Epoch [160/300], Batch Step [0/323], D_loss: 0.7024,  G_loss: 1.5753\n",
      " Epoch [160/300], Batch Step [10/323], D_loss: 0.6297,  G_loss: 1.5273\n",
      " Epoch [160/300], Batch Step [20/323], D_loss: 0.6859,  G_loss: 1.6532\n",
      " Epoch [160/300], Batch Step [30/323], D_loss: 0.6451,  G_loss: 1.4585\n",
      " Epoch [160/300], Batch Step [40/323], D_loss: 0.6029,  G_loss: 1.6290\n",
      " Epoch [160/300], Batch Step [50/323], D_loss: 0.6691,  G_loss: 1.5214\n",
      " Epoch [160/300], Batch Step [60/323], D_loss: 0.7459,  G_loss: 1.5128\n",
      " Epoch [160/300], Batch Step [70/323], D_loss: 0.5482,  G_loss: 1.6492\n",
      " Epoch [160/300], Batch Step [80/323], D_loss: 0.6381,  G_loss: 1.4085\n",
      " Epoch [160/300], Batch Step [90/323], D_loss: 0.5848,  G_loss: 1.5759\n",
      " Epoch [160/300], Batch Step [100/323], D_loss: 0.6551,  G_loss: 1.5657\n",
      " Epoch [160/300], Batch Step [110/323], D_loss: 0.6462,  G_loss: 1.5431\n",
      " Epoch [160/300], Batch Step [120/323], D_loss: 0.5807,  G_loss: 1.6374\n",
      " Epoch [160/300], Batch Step [130/323], D_loss: 0.7641,  G_loss: 1.6818\n",
      " Epoch [160/300], Batch Step [140/323], D_loss: 0.6262,  G_loss: 1.6859\n",
      " Epoch [160/300], Batch Step [150/323], D_loss: 0.6552,  G_loss: 1.6889\n",
      " Epoch [160/300], Batch Step [160/323], D_loss: 0.6341,  G_loss: 1.4789\n",
      " Epoch [160/300], Batch Step [170/323], D_loss: 0.6925,  G_loss: 1.6461\n",
      " Epoch [160/300], Batch Step [180/323], D_loss: 0.5445,  G_loss: 1.4760\n",
      " Epoch [160/300], Batch Step [190/323], D_loss: 0.6108,  G_loss: 1.7867\n",
      " Epoch [160/300], Batch Step [200/323], D_loss: 0.7257,  G_loss: 1.6156\n",
      " Epoch [160/300], Batch Step [210/323], D_loss: 0.6123,  G_loss: 1.6219\n",
      " Epoch [160/300], Batch Step [220/323], D_loss: 0.7397,  G_loss: 1.4481\n",
      " Epoch [160/300], Batch Step [230/323], D_loss: 0.6406,  G_loss: 1.5448\n",
      " Epoch [160/300], Batch Step [240/323], D_loss: 0.5373,  G_loss: 1.6510\n",
      " Epoch [160/300], Batch Step [250/323], D_loss: 0.6016,  G_loss: 1.6358\n",
      " Epoch [160/300], Batch Step [260/323], D_loss: 0.5343,  G_loss: 1.6104\n",
      " Epoch [160/300], Batch Step [270/323], D_loss: 0.6179,  G_loss: 1.5421\n",
      " Epoch [160/300], Batch Step [280/323], D_loss: 0.5890,  G_loss: 1.6030\n",
      " Epoch [160/300], Batch Step [290/323], D_loss: 0.6751,  G_loss: 1.4705\n",
      " Epoch [160/300], Batch Step [300/323], D_loss: 0.6126,  G_loss: 1.7208\n",
      " Epoch [160/300], Batch Step [310/323], D_loss: 0.6055,  G_loss: 1.5559\n",
      " Epoch [160/300], Batch Step [320/323], D_loss: 0.6427,  G_loss: 1.7034\n",
      " Epoch [161/300], Batch Step [0/323], D_loss: 0.7698,  G_loss: 1.7004\n",
      " Epoch [161/300], Batch Step [10/323], D_loss: 0.7145,  G_loss: 1.5493\n",
      " Epoch [161/300], Batch Step [20/323], D_loss: 0.8470,  G_loss: 1.6638\n",
      " Epoch [161/300], Batch Step [30/323], D_loss: 0.6721,  G_loss: 1.5258\n",
      " Epoch [161/300], Batch Step [40/323], D_loss: 0.6048,  G_loss: 1.6850\n",
      " Epoch [161/300], Batch Step [50/323], D_loss: 0.6797,  G_loss: 1.7180\n",
      " Epoch [161/300], Batch Step [60/323], D_loss: 0.6809,  G_loss: 1.4385\n",
      " Epoch [161/300], Batch Step [70/323], D_loss: 0.7815,  G_loss: 1.6796\n",
      " Epoch [161/300], Batch Step [80/323], D_loss: 0.6358,  G_loss: 1.6455\n",
      " Epoch [161/300], Batch Step [90/323], D_loss: 0.7470,  G_loss: 1.4886\n",
      " Epoch [161/300], Batch Step [100/323], D_loss: 0.7043,  G_loss: 1.6164\n",
      " Epoch [161/300], Batch Step [110/323], D_loss: 0.7069,  G_loss: 1.6075\n",
      " Epoch [161/300], Batch Step [120/323], D_loss: 0.6942,  G_loss: 1.6218\n",
      " Epoch [161/300], Batch Step [130/323], D_loss: 0.7523,  G_loss: 1.3890\n",
      " Epoch [161/300], Batch Step [140/323], D_loss: 0.7509,  G_loss: 1.5933\n",
      " Epoch [161/300], Batch Step [150/323], D_loss: 0.5588,  G_loss: 1.4601\n",
      " Epoch [161/300], Batch Step [160/323], D_loss: 0.5779,  G_loss: 1.5804\n",
      " Epoch [161/300], Batch Step [170/323], D_loss: 0.7929,  G_loss: 1.7278\n",
      " Epoch [161/300], Batch Step [180/323], D_loss: 0.5491,  G_loss: 1.5027\n",
      " Epoch [161/300], Batch Step [190/323], D_loss: 0.6479,  G_loss: 1.7036\n",
      " Epoch [161/300], Batch Step [200/323], D_loss: 0.7113,  G_loss: 1.6260\n",
      " Epoch [161/300], Batch Step [210/323], D_loss: 0.6636,  G_loss: 1.5759\n",
      " Epoch [161/300], Batch Step [220/323], D_loss: 0.6670,  G_loss: 1.6059\n",
      " Epoch [161/300], Batch Step [230/323], D_loss: 0.7170,  G_loss: 1.5578\n",
      " Epoch [161/300], Batch Step [240/323], D_loss: 0.8872,  G_loss: 1.4940\n",
      " Epoch [161/300], Batch Step [250/323], D_loss: 0.5725,  G_loss: 1.6724\n",
      " Epoch [161/300], Batch Step [260/323], D_loss: 0.7384,  G_loss: 1.4183\n",
      " Epoch [161/300], Batch Step [270/323], D_loss: 0.6427,  G_loss: 1.5821\n",
      " Epoch [161/300], Batch Step [280/323], D_loss: 0.6382,  G_loss: 1.7520\n",
      " Epoch [161/300], Batch Step [290/323], D_loss: 0.5992,  G_loss: 1.6968\n",
      " Epoch [161/300], Batch Step [300/323], D_loss: 0.6917,  G_loss: 1.5491\n",
      " Epoch [161/300], Batch Step [310/323], D_loss: 0.5265,  G_loss: 1.6964\n",
      " Epoch [161/300], Batch Step [320/323], D_loss: 0.7015,  G_loss: 1.4392\n",
      " Epoch [162/300], Batch Step [0/323], D_loss: 0.6821,  G_loss: 1.4815\n",
      " Epoch [162/300], Batch Step [10/323], D_loss: 0.4994,  G_loss: 1.7971\n",
      " Epoch [162/300], Batch Step [20/323], D_loss: 0.7429,  G_loss: 1.5792\n",
      " Epoch [162/300], Batch Step [30/323], D_loss: 0.6840,  G_loss: 1.4233\n",
      " Epoch [162/300], Batch Step [40/323], D_loss: 0.6182,  G_loss: 1.5596\n",
      " Epoch [162/300], Batch Step [50/323], D_loss: 0.6011,  G_loss: 1.5575\n",
      " Epoch [162/300], Batch Step [60/323], D_loss: 0.6372,  G_loss: 1.5748\n",
      " Epoch [162/300], Batch Step [70/323], D_loss: 0.6900,  G_loss: 1.5753\n",
      " Epoch [162/300], Batch Step [80/323], D_loss: 0.7175,  G_loss: 1.4665\n",
      " Epoch [162/300], Batch Step [90/323], D_loss: 0.5879,  G_loss: 1.5772\n",
      " Epoch [162/300], Batch Step [100/323], D_loss: 0.5522,  G_loss: 1.5149\n",
      " Epoch [162/300], Batch Step [110/323], D_loss: 0.5801,  G_loss: 1.4453\n",
      " Epoch [162/300], Batch Step [120/323], D_loss: 0.7862,  G_loss: 1.7695\n",
      " Epoch [162/300], Batch Step [130/323], D_loss: 0.4494,  G_loss: 1.4778\n",
      " Epoch [162/300], Batch Step [140/323], D_loss: 0.6083,  G_loss: 1.5952\n",
      " Epoch [162/300], Batch Step [150/323], D_loss: 0.6510,  G_loss: 1.5723\n",
      " Epoch [162/300], Batch Step [160/323], D_loss: 0.5578,  G_loss: 1.6904\n",
      " Epoch [162/300], Batch Step [170/323], D_loss: 0.6531,  G_loss: 1.5970\n",
      " Epoch [162/300], Batch Step [180/323], D_loss: 0.6582,  G_loss: 1.4828\n",
      " Epoch [162/300], Batch Step [190/323], D_loss: 0.6315,  G_loss: 1.6793\n",
      " Epoch [162/300], Batch Step [200/323], D_loss: 0.5107,  G_loss: 1.6722\n",
      " Epoch [162/300], Batch Step [210/323], D_loss: 0.6672,  G_loss: 1.5948\n",
      " Epoch [162/300], Batch Step [220/323], D_loss: 0.7821,  G_loss: 1.5226\n",
      " Epoch [162/300], Batch Step [230/323], D_loss: 0.6725,  G_loss: 1.5198\n",
      " Epoch [162/300], Batch Step [240/323], D_loss: 0.6873,  G_loss: 1.7003\n",
      " Epoch [162/300], Batch Step [250/323], D_loss: 0.5985,  G_loss: 1.5416\n",
      " Epoch [162/300], Batch Step [260/323], D_loss: 0.6619,  G_loss: 1.6698\n",
      " Epoch [162/300], Batch Step [270/323], D_loss: 0.7986,  G_loss: 1.4703\n",
      " Epoch [162/300], Batch Step [280/323], D_loss: 0.6685,  G_loss: 1.5321\n",
      " Epoch [162/300], Batch Step [290/323], D_loss: 0.6534,  G_loss: 1.6746\n",
      " Epoch [162/300], Batch Step [300/323], D_loss: 0.6400,  G_loss: 1.5090\n",
      " Epoch [162/300], Batch Step [310/323], D_loss: 0.5004,  G_loss: 1.7418\n",
      " Epoch [162/300], Batch Step [320/323], D_loss: 0.6058,  G_loss: 1.5124\n",
      " Epoch [163/300], Batch Step [0/323], D_loss: 0.7118,  G_loss: 1.4697\n",
      " Epoch [163/300], Batch Step [10/323], D_loss: 0.7453,  G_loss: 1.7926\n",
      " Epoch [163/300], Batch Step [20/323], D_loss: 0.6170,  G_loss: 1.5101\n",
      " Epoch [163/300], Batch Step [30/323], D_loss: 0.6888,  G_loss: 1.6638\n",
      " Epoch [163/300], Batch Step [40/323], D_loss: 0.8355,  G_loss: 1.5704\n",
      " Epoch [163/300], Batch Step [50/323], D_loss: 0.6523,  G_loss: 1.5502\n",
      " Epoch [163/300], Batch Step [60/323], D_loss: 0.8631,  G_loss: 1.5061\n",
      " Epoch [163/300], Batch Step [70/323], D_loss: 0.6434,  G_loss: 1.5705\n",
      " Epoch [163/300], Batch Step [80/323], D_loss: 0.8792,  G_loss: 1.5704\n",
      " Epoch [163/300], Batch Step [90/323], D_loss: 0.7084,  G_loss: 1.5514\n",
      " Epoch [163/300], Batch Step [100/323], D_loss: 0.5372,  G_loss: 1.6342\n",
      " Epoch [163/300], Batch Step [110/323], D_loss: 0.6317,  G_loss: 1.6572\n",
      " Epoch [163/300], Batch Step [120/323], D_loss: 0.6916,  G_loss: 1.6057\n",
      " Epoch [163/300], Batch Step [130/323], D_loss: 0.6618,  G_loss: 1.5926\n",
      " Epoch [163/300], Batch Step [140/323], D_loss: 0.6469,  G_loss: 1.5390\n",
      " Epoch [163/300], Batch Step [150/323], D_loss: 0.7388,  G_loss: 1.5346\n",
      " Epoch [163/300], Batch Step [160/323], D_loss: 0.6118,  G_loss: 1.5250\n",
      " Epoch [163/300], Batch Step [170/323], D_loss: 0.6702,  G_loss: 1.7493\n",
      " Epoch [163/300], Batch Step [180/323], D_loss: 0.6317,  G_loss: 1.7196\n",
      " Epoch [163/300], Batch Step [190/323], D_loss: 0.6594,  G_loss: 1.6072\n",
      " Epoch [163/300], Batch Step [200/323], D_loss: 0.6600,  G_loss: 1.5223\n",
      " Epoch [163/300], Batch Step [210/323], D_loss: 0.6272,  G_loss: 1.5529\n",
      " Epoch [163/300], Batch Step [220/323], D_loss: 0.6576,  G_loss: 1.6113\n",
      " Epoch [163/300], Batch Step [230/323], D_loss: 0.8018,  G_loss: 1.4478\n",
      " Epoch [163/300], Batch Step [240/323], D_loss: 0.7730,  G_loss: 1.5601\n",
      " Epoch [163/300], Batch Step [250/323], D_loss: 0.6463,  G_loss: 1.6350\n",
      " Epoch [163/300], Batch Step [260/323], D_loss: 0.6364,  G_loss: 1.7007\n",
      " Epoch [163/300], Batch Step [270/323], D_loss: 0.8061,  G_loss: 1.5471\n",
      " Epoch [163/300], Batch Step [280/323], D_loss: 0.6170,  G_loss: 1.5402\n",
      " Epoch [163/300], Batch Step [290/323], D_loss: 0.7628,  G_loss: 1.5271\n",
      " Epoch [163/300], Batch Step [300/323], D_loss: 0.6569,  G_loss: 1.5296\n",
      " Epoch [163/300], Batch Step [310/323], D_loss: 0.6596,  G_loss: 1.5940\n",
      " Epoch [163/300], Batch Step [320/323], D_loss: 0.6872,  G_loss: 1.5669\n",
      " Epoch [164/300], Batch Step [0/323], D_loss: 0.4803,  G_loss: 1.7460\n",
      " Epoch [164/300], Batch Step [10/323], D_loss: 0.6761,  G_loss: 1.8823\n",
      " Epoch [164/300], Batch Step [20/323], D_loss: 0.6229,  G_loss: 1.4747\n",
      " Epoch [164/300], Batch Step [30/323], D_loss: 0.6864,  G_loss: 1.5794\n",
      " Epoch [164/300], Batch Step [40/323], D_loss: 0.5604,  G_loss: 1.6528\n",
      " Epoch [164/300], Batch Step [50/323], D_loss: 0.5029,  G_loss: 1.7766\n",
      " Epoch [164/300], Batch Step [60/323], D_loss: 0.7208,  G_loss: 1.6728\n",
      " Epoch [164/300], Batch Step [70/323], D_loss: 0.6000,  G_loss: 1.4612\n",
      " Epoch [164/300], Batch Step [80/323], D_loss: 0.7695,  G_loss: 1.5174\n",
      " Epoch [164/300], Batch Step [90/323], D_loss: 0.6896,  G_loss: 1.7414\n",
      " Epoch [164/300], Batch Step [100/323], D_loss: 0.6724,  G_loss: 1.6172\n",
      " Epoch [164/300], Batch Step [110/323], D_loss: 0.7814,  G_loss: 1.5457\n",
      " Epoch [164/300], Batch Step [120/323], D_loss: 0.6224,  G_loss: 1.6269\n",
      " Epoch [164/300], Batch Step [130/323], D_loss: 0.7949,  G_loss: 1.5949\n",
      " Epoch [164/300], Batch Step [140/323], D_loss: 0.8232,  G_loss: 1.4800\n",
      " Epoch [164/300], Batch Step [150/323], D_loss: 0.6803,  G_loss: 1.4866\n",
      " Epoch [164/300], Batch Step [160/323], D_loss: 0.5496,  G_loss: 1.7629\n",
      " Epoch [164/300], Batch Step [170/323], D_loss: 0.6383,  G_loss: 1.5164\n",
      " Epoch [164/300], Batch Step [180/323], D_loss: 0.7033,  G_loss: 1.6623\n",
      " Epoch [164/300], Batch Step [190/323], D_loss: 0.5908,  G_loss: 1.6828\n",
      " Epoch [164/300], Batch Step [200/323], D_loss: 0.6373,  G_loss: 1.4717\n",
      " Epoch [164/300], Batch Step [210/323], D_loss: 0.6196,  G_loss: 1.7538\n",
      " Epoch [164/300], Batch Step [220/323], D_loss: 0.7014,  G_loss: 1.5360\n",
      " Epoch [164/300], Batch Step [230/323], D_loss: 0.7457,  G_loss: 1.3481\n",
      " Epoch [164/300], Batch Step [240/323], D_loss: 0.6849,  G_loss: 1.7211\n",
      " Epoch [164/300], Batch Step [250/323], D_loss: 0.5750,  G_loss: 1.6721\n",
      " Epoch [164/300], Batch Step [260/323], D_loss: 0.5895,  G_loss: 1.2882\n",
      " Epoch [164/300], Batch Step [270/323], D_loss: 0.7248,  G_loss: 1.7498\n",
      " Epoch [164/300], Batch Step [280/323], D_loss: 0.6177,  G_loss: 1.5473\n",
      " Epoch [164/300], Batch Step [290/323], D_loss: 0.7210,  G_loss: 1.5751\n",
      " Epoch [164/300], Batch Step [300/323], D_loss: 0.7379,  G_loss: 1.4635\n",
      " Epoch [164/300], Batch Step [310/323], D_loss: 0.6324,  G_loss: 1.4921\n",
      " Epoch [164/300], Batch Step [320/323], D_loss: 0.5828,  G_loss: 1.4923\n",
      " Epoch [165/300], Batch Step [0/323], D_loss: 0.6304,  G_loss: 1.5262\n",
      " Epoch [165/300], Batch Step [10/323], D_loss: 0.5191,  G_loss: 1.5915\n",
      " Epoch [165/300], Batch Step [20/323], D_loss: 0.6304,  G_loss: 1.6943\n",
      " Epoch [165/300], Batch Step [30/323], D_loss: 0.6606,  G_loss: 1.6735\n",
      " Epoch [165/300], Batch Step [40/323], D_loss: 0.6194,  G_loss: 1.4756\n",
      " Epoch [165/300], Batch Step [50/323], D_loss: 0.7069,  G_loss: 1.6279\n",
      " Epoch [165/300], Batch Step [60/323], D_loss: 0.5826,  G_loss: 1.4493\n",
      " Epoch [165/300], Batch Step [70/323], D_loss: 0.6992,  G_loss: 1.5773\n",
      " Epoch [165/300], Batch Step [80/323], D_loss: 0.7291,  G_loss: 1.5466\n",
      " Epoch [165/300], Batch Step [90/323], D_loss: 0.5840,  G_loss: 1.6162\n",
      " Epoch [165/300], Batch Step [100/323], D_loss: 0.6727,  G_loss: 1.5758\n",
      " Epoch [165/300], Batch Step [110/323], D_loss: 0.5820,  G_loss: 1.4611\n",
      " Epoch [165/300], Batch Step [120/323], D_loss: 0.5143,  G_loss: 1.7512\n",
      " Epoch [165/300], Batch Step [130/323], D_loss: 0.6841,  G_loss: 1.4504\n",
      " Epoch [165/300], Batch Step [140/323], D_loss: 0.5543,  G_loss: 1.4382\n",
      " Epoch [165/300], Batch Step [150/323], D_loss: 0.6668,  G_loss: 1.7082\n",
      " Epoch [165/300], Batch Step [160/323], D_loss: 0.6447,  G_loss: 1.5921\n",
      " Epoch [165/300], Batch Step [170/323], D_loss: 0.7639,  G_loss: 1.6613\n",
      " Epoch [165/300], Batch Step [180/323], D_loss: 0.4627,  G_loss: 1.5691\n",
      " Epoch [165/300], Batch Step [190/323], D_loss: 0.5187,  G_loss: 1.5349\n",
      " Epoch [165/300], Batch Step [200/323], D_loss: 0.5214,  G_loss: 1.7501\n",
      " Epoch [165/300], Batch Step [210/323], D_loss: 0.6091,  G_loss: 1.6556\n",
      " Epoch [165/300], Batch Step [220/323], D_loss: 0.5982,  G_loss: 1.5304\n",
      " Epoch [165/300], Batch Step [230/323], D_loss: 0.5772,  G_loss: 1.7132\n",
      " Epoch [165/300], Batch Step [240/323], D_loss: 0.7112,  G_loss: 1.6480\n",
      " Epoch [165/300], Batch Step [250/323], D_loss: 0.9020,  G_loss: 1.5263\n",
      " Epoch [165/300], Batch Step [260/323], D_loss: 0.6808,  G_loss: 1.5418\n",
      " Epoch [165/300], Batch Step [270/323], D_loss: 0.6963,  G_loss: 1.7669\n",
      " Epoch [165/300], Batch Step [280/323], D_loss: 0.8252,  G_loss: 1.5355\n",
      " Epoch [165/300], Batch Step [290/323], D_loss: 0.7420,  G_loss: 1.6037\n",
      " Epoch [165/300], Batch Step [300/323], D_loss: 0.6348,  G_loss: 1.5333\n",
      " Epoch [165/300], Batch Step [310/323], D_loss: 0.6312,  G_loss: 1.5431\n",
      " Epoch [165/300], Batch Step [320/323], D_loss: 0.6879,  G_loss: 1.6863\n",
      " Epoch [166/300], Batch Step [0/323], D_loss: 0.5371,  G_loss: 1.5629\n",
      " Epoch [166/300], Batch Step [10/323], D_loss: 0.5633,  G_loss: 1.5426\n",
      " Epoch [166/300], Batch Step [20/323], D_loss: 0.5059,  G_loss: 1.6332\n",
      " Epoch [166/300], Batch Step [30/323], D_loss: 0.6975,  G_loss: 1.5067\n",
      " Epoch [166/300], Batch Step [40/323], D_loss: 0.5629,  G_loss: 1.5046\n",
      " Epoch [166/300], Batch Step [50/323], D_loss: 0.5915,  G_loss: 1.6471\n",
      " Epoch [166/300], Batch Step [60/323], D_loss: 0.6320,  G_loss: 1.6529\n",
      " Epoch [166/300], Batch Step [70/323], D_loss: 0.7418,  G_loss: 1.5269\n",
      " Epoch [166/300], Batch Step [80/323], D_loss: 0.6094,  G_loss: 1.5636\n",
      " Epoch [166/300], Batch Step [90/323], D_loss: 0.5590,  G_loss: 1.7695\n",
      " Epoch [166/300], Batch Step [100/323], D_loss: 0.5785,  G_loss: 1.4572\n",
      " Epoch [166/300], Batch Step [110/323], D_loss: 0.5316,  G_loss: 1.6108\n",
      " Epoch [166/300], Batch Step [120/323], D_loss: 0.5259,  G_loss: 1.5488\n",
      " Epoch [166/300], Batch Step [130/323], D_loss: 0.7101,  G_loss: 1.5676\n",
      " Epoch [166/300], Batch Step [140/323], D_loss: 0.6128,  G_loss: 1.7143\n",
      " Epoch [166/300], Batch Step [150/323], D_loss: 0.5840,  G_loss: 1.5951\n",
      " Epoch [166/300], Batch Step [160/323], D_loss: 0.6774,  G_loss: 1.6253\n",
      " Epoch [166/300], Batch Step [170/323], D_loss: 0.5448,  G_loss: 1.6496\n",
      " Epoch [166/300], Batch Step [180/323], D_loss: 0.7250,  G_loss: 1.4678\n",
      " Epoch [166/300], Batch Step [190/323], D_loss: 0.9175,  G_loss: 1.5834\n",
      " Epoch [166/300], Batch Step [200/323], D_loss: 0.6045,  G_loss: 1.5364\n",
      " Epoch [166/300], Batch Step [210/323], D_loss: 0.6919,  G_loss: 1.4805\n",
      " Epoch [166/300], Batch Step [220/323], D_loss: 0.6860,  G_loss: 1.6770\n",
      " Epoch [166/300], Batch Step [230/323], D_loss: 0.5936,  G_loss: 1.5326\n",
      " Epoch [166/300], Batch Step [240/323], D_loss: 0.6276,  G_loss: 1.5460\n",
      " Epoch [166/300], Batch Step [250/323], D_loss: 0.6605,  G_loss: 1.5392\n",
      " Epoch [166/300], Batch Step [260/323], D_loss: 0.7767,  G_loss: 1.5408\n",
      " Epoch [166/300], Batch Step [270/323], D_loss: 0.7505,  G_loss: 1.4942\n",
      " Epoch [166/300], Batch Step [280/323], D_loss: 0.7229,  G_loss: 1.5784\n",
      " Epoch [166/300], Batch Step [290/323], D_loss: 0.5528,  G_loss: 1.6295\n",
      " Epoch [166/300], Batch Step [300/323], D_loss: 0.6149,  G_loss: 1.4379\n",
      " Epoch [166/300], Batch Step [310/323], D_loss: 0.5752,  G_loss: 1.4837\n",
      " Epoch [166/300], Batch Step [320/323], D_loss: 0.7443,  G_loss: 1.5704\n",
      " Epoch [167/300], Batch Step [0/323], D_loss: 0.8137,  G_loss: 1.4237\n",
      " Epoch [167/300], Batch Step [10/323], D_loss: 0.6446,  G_loss: 1.5526\n",
      " Epoch [167/300], Batch Step [20/323], D_loss: 0.7790,  G_loss: 1.5400\n",
      " Epoch [167/300], Batch Step [30/323], D_loss: 0.6342,  G_loss: 1.4091\n",
      " Epoch [167/300], Batch Step [40/323], D_loss: 0.6537,  G_loss: 1.6865\n",
      " Epoch [167/300], Batch Step [50/323], D_loss: 0.6284,  G_loss: 1.4533\n",
      " Epoch [167/300], Batch Step [60/323], D_loss: 0.6584,  G_loss: 1.6226\n",
      " Epoch [167/300], Batch Step [70/323], D_loss: 0.5724,  G_loss: 1.7151\n",
      " Epoch [167/300], Batch Step [80/323], D_loss: 0.6322,  G_loss: 1.5840\n",
      " Epoch [167/300], Batch Step [90/323], D_loss: 0.5826,  G_loss: 1.5415\n",
      " Epoch [167/300], Batch Step [100/323], D_loss: 0.6447,  G_loss: 1.7135\n",
      " Epoch [167/300], Batch Step [110/323], D_loss: 0.5894,  G_loss: 1.6111\n",
      " Epoch [167/300], Batch Step [120/323], D_loss: 0.6720,  G_loss: 1.5710\n",
      " Epoch [167/300], Batch Step [130/323], D_loss: 0.7223,  G_loss: 1.5045\n",
      " Epoch [167/300], Batch Step [140/323], D_loss: 0.4900,  G_loss: 1.6152\n",
      " Epoch [167/300], Batch Step [150/323], D_loss: 0.6685,  G_loss: 1.5804\n",
      " Epoch [167/300], Batch Step [160/323], D_loss: 0.7570,  G_loss: 1.6115\n",
      " Epoch [167/300], Batch Step [170/323], D_loss: 0.6358,  G_loss: 1.5549\n",
      " Epoch [167/300], Batch Step [180/323], D_loss: 0.6915,  G_loss: 1.6335\n",
      " Epoch [167/300], Batch Step [190/323], D_loss: 0.7938,  G_loss: 1.5822\n",
      " Epoch [167/300], Batch Step [200/323], D_loss: 0.5981,  G_loss: 1.5900\n",
      " Epoch [167/300], Batch Step [210/323], D_loss: 0.6744,  G_loss: 1.5235\n",
      " Epoch [167/300], Batch Step [220/323], D_loss: 0.6934,  G_loss: 1.5579\n",
      " Epoch [167/300], Batch Step [230/323], D_loss: 0.5179,  G_loss: 1.4581\n",
      " Epoch [167/300], Batch Step [240/323], D_loss: 0.7745,  G_loss: 1.5870\n",
      " Epoch [167/300], Batch Step [250/323], D_loss: 0.6630,  G_loss: 1.4902\n",
      " Epoch [167/300], Batch Step [260/323], D_loss: 0.6914,  G_loss: 1.6507\n",
      " Epoch [167/300], Batch Step [270/323], D_loss: 0.6309,  G_loss: 1.5500\n",
      " Epoch [167/300], Batch Step [280/323], D_loss: 0.5895,  G_loss: 1.6424\n",
      " Epoch [167/300], Batch Step [290/323], D_loss: 0.6597,  G_loss: 1.5953\n",
      " Epoch [167/300], Batch Step [300/323], D_loss: 0.6908,  G_loss: 1.6909\n",
      " Epoch [167/300], Batch Step [310/323], D_loss: 0.4950,  G_loss: 1.5518\n",
      " Epoch [167/300], Batch Step [320/323], D_loss: 0.5843,  G_loss: 1.6415\n",
      " Epoch [168/300], Batch Step [0/323], D_loss: 0.6845,  G_loss: 1.4759\n",
      " Epoch [168/300], Batch Step [10/323], D_loss: 0.5948,  G_loss: 1.5076\n",
      " Epoch [168/300], Batch Step [20/323], D_loss: 0.6093,  G_loss: 1.5951\n",
      " Epoch [168/300], Batch Step [30/323], D_loss: 0.5289,  G_loss: 1.6725\n",
      " Epoch [168/300], Batch Step [40/323], D_loss: 0.5209,  G_loss: 1.6065\n",
      " Epoch [168/300], Batch Step [50/323], D_loss: 0.6344,  G_loss: 1.6238\n",
      " Epoch [168/300], Batch Step [60/323], D_loss: 0.7221,  G_loss: 1.7093\n",
      " Epoch [168/300], Batch Step [70/323], D_loss: 0.5513,  G_loss: 1.4840\n",
      " Epoch [168/300], Batch Step [80/323], D_loss: 0.8148,  G_loss: 1.5809\n",
      " Epoch [168/300], Batch Step [90/323], D_loss: 0.6438,  G_loss: 1.4164\n",
      " Epoch [168/300], Batch Step [100/323], D_loss: 0.6129,  G_loss: 1.7455\n",
      " Epoch [168/300], Batch Step [110/323], D_loss: 0.6920,  G_loss: 1.6090\n",
      " Epoch [168/300], Batch Step [120/323], D_loss: 0.5684,  G_loss: 1.6354\n",
      " Epoch [168/300], Batch Step [130/323], D_loss: 0.7373,  G_loss: 1.7950\n",
      " Epoch [168/300], Batch Step [140/323], D_loss: 0.5942,  G_loss: 1.5050\n",
      " Epoch [168/300], Batch Step [150/323], D_loss: 0.7005,  G_loss: 1.5733\n",
      " Epoch [168/300], Batch Step [160/323], D_loss: 0.6145,  G_loss: 1.7142\n",
      " Epoch [168/300], Batch Step [170/323], D_loss: 0.6206,  G_loss: 1.5603\n",
      " Epoch [168/300], Batch Step [180/323], D_loss: 0.5631,  G_loss: 1.5405\n",
      " Epoch [168/300], Batch Step [190/323], D_loss: 0.6447,  G_loss: 1.5962\n",
      " Epoch [168/300], Batch Step [200/323], D_loss: 0.8332,  G_loss: 1.6094\n",
      " Epoch [168/300], Batch Step [210/323], D_loss: 0.5946,  G_loss: 1.5675\n",
      " Epoch [168/300], Batch Step [220/323], D_loss: 0.6507,  G_loss: 1.7023\n",
      " Epoch [168/300], Batch Step [230/323], D_loss: 0.5387,  G_loss: 1.3726\n",
      " Epoch [168/300], Batch Step [240/323], D_loss: 0.7765,  G_loss: 1.5789\n",
      " Epoch [168/300], Batch Step [250/323], D_loss: 0.6370,  G_loss: 1.5695\n",
      " Epoch [168/300], Batch Step [260/323], D_loss: 0.5620,  G_loss: 1.5931\n",
      " Epoch [168/300], Batch Step [270/323], D_loss: 0.7181,  G_loss: 1.5337\n",
      " Epoch [168/300], Batch Step [280/323], D_loss: 0.6598,  G_loss: 1.5373\n",
      " Epoch [168/300], Batch Step [290/323], D_loss: 0.6467,  G_loss: 1.7552\n",
      " Epoch [168/300], Batch Step [300/323], D_loss: 0.6295,  G_loss: 1.4280\n",
      " Epoch [168/300], Batch Step [310/323], D_loss: 0.5120,  G_loss: 1.5642\n",
      " Epoch [168/300], Batch Step [320/323], D_loss: 0.5936,  G_loss: 1.6217\n",
      " Epoch [169/300], Batch Step [0/323], D_loss: 0.4808,  G_loss: 1.6276\n",
      " Epoch [169/300], Batch Step [10/323], D_loss: 0.6453,  G_loss: 1.5877\n",
      " Epoch [169/300], Batch Step [20/323], D_loss: 0.6595,  G_loss: 1.3356\n",
      " Epoch [169/300], Batch Step [30/323], D_loss: 0.6785,  G_loss: 1.6897\n",
      " Epoch [169/300], Batch Step [40/323], D_loss: 0.5751,  G_loss: 1.7186\n",
      " Epoch [169/300], Batch Step [50/323], D_loss: 0.5982,  G_loss: 1.5902\n",
      " Epoch [169/300], Batch Step [60/323], D_loss: 0.6050,  G_loss: 1.5769\n",
      " Epoch [169/300], Batch Step [70/323], D_loss: 0.6841,  G_loss: 1.6098\n",
      " Epoch [169/300], Batch Step [80/323], D_loss: 0.6925,  G_loss: 1.6395\n",
      " Epoch [169/300], Batch Step [90/323], D_loss: 0.7111,  G_loss: 1.6621\n",
      " Epoch [169/300], Batch Step [100/323], D_loss: 0.6260,  G_loss: 1.6885\n",
      " Epoch [169/300], Batch Step [110/323], D_loss: 0.6834,  G_loss: 1.6718\n",
      " Epoch [169/300], Batch Step [120/323], D_loss: 0.7045,  G_loss: 1.3671\n",
      " Epoch [169/300], Batch Step [130/323], D_loss: 0.5380,  G_loss: 1.5395\n",
      " Epoch [169/300], Batch Step [140/323], D_loss: 0.6174,  G_loss: 1.5560\n",
      " Epoch [169/300], Batch Step [150/323], D_loss: 0.7327,  G_loss: 1.4404\n",
      " Epoch [169/300], Batch Step [160/323], D_loss: 0.6477,  G_loss: 1.6069\n",
      " Epoch [169/300], Batch Step [170/323], D_loss: 0.4969,  G_loss: 1.5620\n",
      " Epoch [169/300], Batch Step [180/323], D_loss: 0.5072,  G_loss: 1.7035\n",
      " Epoch [169/300], Batch Step [190/323], D_loss: 0.4883,  G_loss: 1.5752\n",
      " Epoch [169/300], Batch Step [200/323], D_loss: 0.6907,  G_loss: 1.5875\n",
      " Epoch [169/300], Batch Step [210/323], D_loss: 0.6007,  G_loss: 1.5981\n",
      " Epoch [169/300], Batch Step [220/323], D_loss: 0.6870,  G_loss: 1.4691\n",
      " Epoch [169/300], Batch Step [230/323], D_loss: 0.6471,  G_loss: 1.7187\n",
      " Epoch [169/300], Batch Step [240/323], D_loss: 0.6860,  G_loss: 1.4926\n",
      " Epoch [169/300], Batch Step [250/323], D_loss: 0.5030,  G_loss: 1.5401\n",
      " Epoch [169/300], Batch Step [260/323], D_loss: 0.5624,  G_loss: 1.6976\n",
      " Epoch [169/300], Batch Step [270/323], D_loss: 0.6439,  G_loss: 1.4579\n",
      " Epoch [169/300], Batch Step [280/323], D_loss: 0.5614,  G_loss: 1.5484\n",
      " Epoch [169/300], Batch Step [290/323], D_loss: 0.5285,  G_loss: 1.5984\n",
      " Epoch [169/300], Batch Step [300/323], D_loss: 0.5298,  G_loss: 1.6230\n",
      " Epoch [169/300], Batch Step [310/323], D_loss: 0.7217,  G_loss: 1.5184\n",
      " Epoch [169/300], Batch Step [320/323], D_loss: 0.7492,  G_loss: 1.6321\n",
      " Epoch [170/300], Batch Step [0/323], D_loss: 0.6862,  G_loss: 1.6977\n",
      " Epoch [170/300], Batch Step [10/323], D_loss: 0.6599,  G_loss: 1.5199\n",
      " Epoch [170/300], Batch Step [20/323], D_loss: 0.6002,  G_loss: 1.6142\n",
      " Epoch [170/300], Batch Step [30/323], D_loss: 0.7695,  G_loss: 1.4625\n",
      " Epoch [170/300], Batch Step [40/323], D_loss: 0.7753,  G_loss: 1.5896\n",
      " Epoch [170/300], Batch Step [50/323], D_loss: 0.7773,  G_loss: 1.5412\n",
      " Epoch [170/300], Batch Step [60/323], D_loss: 0.5850,  G_loss: 1.6484\n",
      " Epoch [170/300], Batch Step [70/323], D_loss: 0.7386,  G_loss: 1.6452\n",
      " Epoch [170/300], Batch Step [80/323], D_loss: 0.5411,  G_loss: 1.5903\n",
      " Epoch [170/300], Batch Step [90/323], D_loss: 0.7876,  G_loss: 1.6138\n",
      " Epoch [170/300], Batch Step [100/323], D_loss: 0.6010,  G_loss: 1.5663\n",
      " Epoch [170/300], Batch Step [110/323], D_loss: 0.5886,  G_loss: 1.6800\n",
      " Epoch [170/300], Batch Step [120/323], D_loss: 0.6117,  G_loss: 1.5952\n",
      " Epoch [170/300], Batch Step [130/323], D_loss: 0.7543,  G_loss: 1.5228\n",
      " Epoch [170/300], Batch Step [140/323], D_loss: 0.7521,  G_loss: 1.6126\n",
      " Epoch [170/300], Batch Step [150/323], D_loss: 0.8258,  G_loss: 1.4642\n",
      " Epoch [170/300], Batch Step [160/323], D_loss: 0.6256,  G_loss: 1.5488\n",
      " Epoch [170/300], Batch Step [170/323], D_loss: 0.7373,  G_loss: 1.6477\n",
      " Epoch [170/300], Batch Step [180/323], D_loss: 0.5506,  G_loss: 1.6006\n",
      " Epoch [170/300], Batch Step [190/323], D_loss: 0.6799,  G_loss: 1.5884\n",
      " Epoch [170/300], Batch Step [200/323], D_loss: 0.7684,  G_loss: 1.4458\n",
      " Epoch [170/300], Batch Step [210/323], D_loss: 0.6604,  G_loss: 1.6331\n",
      " Epoch [170/300], Batch Step [220/323], D_loss: 0.6843,  G_loss: 1.6521\n",
      " Epoch [170/300], Batch Step [230/323], D_loss: 0.6499,  G_loss: 1.5922\n",
      " Epoch [170/300], Batch Step [240/323], D_loss: 0.6477,  G_loss: 1.5452\n",
      " Epoch [170/300], Batch Step [250/323], D_loss: 0.7487,  G_loss: 1.4968\n",
      " Epoch [170/300], Batch Step [260/323], D_loss: 0.5813,  G_loss: 1.5186\n",
      " Epoch [170/300], Batch Step [270/323], D_loss: 0.6086,  G_loss: 1.8336\n",
      " Epoch [170/300], Batch Step [280/323], D_loss: 0.7451,  G_loss: 1.6599\n",
      " Epoch [170/300], Batch Step [290/323], D_loss: 0.7126,  G_loss: 1.5060\n",
      " Epoch [170/300], Batch Step [300/323], D_loss: 0.6044,  G_loss: 1.5827\n",
      " Epoch [170/300], Batch Step [310/323], D_loss: 0.4642,  G_loss: 1.5443\n",
      " Epoch [170/300], Batch Step [320/323], D_loss: 0.3837,  G_loss: 1.5829\n",
      " Epoch [171/300], Batch Step [0/323], D_loss: 0.6308,  G_loss: 1.6374\n",
      " Epoch [171/300], Batch Step [10/323], D_loss: 0.7390,  G_loss: 1.6054\n",
      " Epoch [171/300], Batch Step [20/323], D_loss: 0.6420,  G_loss: 1.5416\n",
      " Epoch [171/300], Batch Step [30/323], D_loss: 0.6233,  G_loss: 1.6384\n",
      " Epoch [171/300], Batch Step [40/323], D_loss: 0.7592,  G_loss: 1.5415\n",
      " Epoch [171/300], Batch Step [50/323], D_loss: 0.6447,  G_loss: 1.4775\n",
      " Epoch [171/300], Batch Step [60/323], D_loss: 0.8169,  G_loss: 1.7085\n",
      " Epoch [171/300], Batch Step [70/323], D_loss: 0.7006,  G_loss: 1.5440\n",
      " Epoch [171/300], Batch Step [80/323], D_loss: 0.7198,  G_loss: 1.5895\n",
      " Epoch [171/300], Batch Step [90/323], D_loss: 0.7097,  G_loss: 1.4005\n",
      " Epoch [171/300], Batch Step [100/323], D_loss: 0.6655,  G_loss: 1.7116\n",
      " Epoch [171/300], Batch Step [110/323], D_loss: 0.8141,  G_loss: 1.5435\n",
      " Epoch [171/300], Batch Step [120/323], D_loss: 0.6637,  G_loss: 1.6284\n",
      " Epoch [171/300], Batch Step [130/323], D_loss: 0.6758,  G_loss: 1.6053\n",
      " Epoch [171/300], Batch Step [140/323], D_loss: 0.8392,  G_loss: 1.6462\n",
      " Epoch [171/300], Batch Step [150/323], D_loss: 0.5786,  G_loss: 1.4560\n",
      " Epoch [171/300], Batch Step [160/323], D_loss: 0.6767,  G_loss: 1.5575\n",
      " Epoch [171/300], Batch Step [170/323], D_loss: 0.8233,  G_loss: 1.5778\n",
      " Epoch [171/300], Batch Step [180/323], D_loss: 0.6668,  G_loss: 1.4148\n",
      " Epoch [171/300], Batch Step [190/323], D_loss: 0.5004,  G_loss: 1.6653\n",
      " Epoch [171/300], Batch Step [200/323], D_loss: 0.5300,  G_loss: 1.7989\n",
      " Epoch [171/300], Batch Step [210/323], D_loss: 0.7847,  G_loss: 1.4752\n",
      " Epoch [171/300], Batch Step [220/323], D_loss: 0.7262,  G_loss: 1.6490\n",
      " Epoch [171/300], Batch Step [230/323], D_loss: 0.6053,  G_loss: 1.6165\n",
      " Epoch [171/300], Batch Step [240/323], D_loss: 0.6170,  G_loss: 1.6639\n",
      " Epoch [171/300], Batch Step [250/323], D_loss: 0.5336,  G_loss: 1.5197\n",
      " Epoch [171/300], Batch Step [260/323], D_loss: 0.6844,  G_loss: 1.7821\n",
      " Epoch [171/300], Batch Step [270/323], D_loss: 0.6068,  G_loss: 1.5083\n",
      " Epoch [171/300], Batch Step [280/323], D_loss: 0.6254,  G_loss: 1.6157\n",
      " Epoch [171/300], Batch Step [290/323], D_loss: 0.5378,  G_loss: 1.5476\n",
      " Epoch [171/300], Batch Step [300/323], D_loss: 0.6854,  G_loss: 1.4402\n",
      " Epoch [171/300], Batch Step [310/323], D_loss: 0.7193,  G_loss: 1.6811\n",
      " Epoch [171/300], Batch Step [320/323], D_loss: 0.7604,  G_loss: 1.5999\n",
      " Epoch [172/300], Batch Step [0/323], D_loss: 0.6166,  G_loss: 1.4889\n",
      " Epoch [172/300], Batch Step [10/323], D_loss: 0.6822,  G_loss: 1.4725\n",
      " Epoch [172/300], Batch Step [20/323], D_loss: 0.5486,  G_loss: 1.7346\n",
      " Epoch [172/300], Batch Step [30/323], D_loss: 0.6966,  G_loss: 1.6455\n",
      " Epoch [172/300], Batch Step [40/323], D_loss: 0.7605,  G_loss: 1.4829\n",
      " Epoch [172/300], Batch Step [50/323], D_loss: 0.5235,  G_loss: 1.6420\n",
      " Epoch [172/300], Batch Step [60/323], D_loss: 0.5988,  G_loss: 1.6057\n",
      " Epoch [172/300], Batch Step [70/323], D_loss: 0.6166,  G_loss: 1.4571\n",
      " Epoch [172/300], Batch Step [80/323], D_loss: 0.7024,  G_loss: 1.5848\n",
      " Epoch [172/300], Batch Step [90/323], D_loss: 0.6816,  G_loss: 1.5573\n",
      " Epoch [172/300], Batch Step [100/323], D_loss: 0.5665,  G_loss: 1.5999\n",
      " Epoch [172/300], Batch Step [110/323], D_loss: 0.5844,  G_loss: 1.5758\n",
      " Epoch [172/300], Batch Step [120/323], D_loss: 0.6747,  G_loss: 1.4841\n",
      " Epoch [172/300], Batch Step [130/323], D_loss: 0.5529,  G_loss: 1.5703\n",
      " Epoch [172/300], Batch Step [140/323], D_loss: 0.6913,  G_loss: 1.5806\n",
      " Epoch [172/300], Batch Step [150/323], D_loss: 0.7346,  G_loss: 1.6564\n",
      " Epoch [172/300], Batch Step [160/323], D_loss: 0.5950,  G_loss: 1.4825\n",
      " Epoch [172/300], Batch Step [170/323], D_loss: 0.5972,  G_loss: 1.6527\n",
      " Epoch [172/300], Batch Step [180/323], D_loss: 0.6767,  G_loss: 1.5561\n",
      " Epoch [172/300], Batch Step [190/323], D_loss: 0.7827,  G_loss: 1.5532\n",
      " Epoch [172/300], Batch Step [200/323], D_loss: 0.6110,  G_loss: 1.6616\n",
      " Epoch [172/300], Batch Step [210/323], D_loss: 0.8672,  G_loss: 1.4831\n",
      " Epoch [172/300], Batch Step [220/323], D_loss: 0.5697,  G_loss: 1.6384\n",
      " Epoch [172/300], Batch Step [230/323], D_loss: 0.5966,  G_loss: 1.4413\n",
      " Epoch [172/300], Batch Step [240/323], D_loss: 0.7289,  G_loss: 1.5626\n",
      " Epoch [172/300], Batch Step [250/323], D_loss: 0.5351,  G_loss: 1.6620\n",
      " Epoch [172/300], Batch Step [260/323], D_loss: 0.5797,  G_loss: 1.4645\n",
      " Epoch [172/300], Batch Step [270/323], D_loss: 0.4540,  G_loss: 1.6417\n",
      " Epoch [172/300], Batch Step [280/323], D_loss: 0.5363,  G_loss: 1.7462\n",
      " Epoch [172/300], Batch Step [290/323], D_loss: 0.6464,  G_loss: 1.5345\n",
      " Epoch [172/300], Batch Step [300/323], D_loss: 0.5697,  G_loss: 1.5945\n",
      " Epoch [172/300], Batch Step [310/323], D_loss: 0.8313,  G_loss: 1.6803\n",
      " Epoch [172/300], Batch Step [320/323], D_loss: 0.7416,  G_loss: 1.5221\n",
      " Epoch [173/300], Batch Step [0/323], D_loss: 0.6575,  G_loss: 1.5838\n",
      " Epoch [173/300], Batch Step [10/323], D_loss: 0.7770,  G_loss: 1.5727\n",
      " Epoch [173/300], Batch Step [20/323], D_loss: 0.7066,  G_loss: 1.5262\n",
      " Epoch [173/300], Batch Step [30/323], D_loss: 0.6367,  G_loss: 1.6989\n",
      " Epoch [173/300], Batch Step [40/323], D_loss: 0.6537,  G_loss: 1.4472\n",
      " Epoch [173/300], Batch Step [50/323], D_loss: 0.5895,  G_loss: 1.7278\n",
      " Epoch [173/300], Batch Step [60/323], D_loss: 0.5563,  G_loss: 1.6115\n",
      " Epoch [173/300], Batch Step [70/323], D_loss: 0.6907,  G_loss: 1.6817\n",
      " Epoch [173/300], Batch Step [80/323], D_loss: 0.6383,  G_loss: 1.6622\n",
      " Epoch [173/300], Batch Step [90/323], D_loss: 0.6553,  G_loss: 1.4749\n",
      " Epoch [173/300], Batch Step [100/323], D_loss: 0.6056,  G_loss: 1.5883\n",
      " Epoch [173/300], Batch Step [110/323], D_loss: 0.6792,  G_loss: 1.6047\n",
      " Epoch [173/300], Batch Step [120/323], D_loss: 0.8612,  G_loss: 1.6634\n",
      " Epoch [173/300], Batch Step [130/323], D_loss: 0.7898,  G_loss: 1.5181\n",
      " Epoch [173/300], Batch Step [140/323], D_loss: 0.6408,  G_loss: 1.6379\n",
      " Epoch [173/300], Batch Step [150/323], D_loss: 0.7363,  G_loss: 1.4477\n",
      " Epoch [173/300], Batch Step [160/323], D_loss: 0.6698,  G_loss: 1.5594\n",
      " Epoch [173/300], Batch Step [170/323], D_loss: 0.6736,  G_loss: 1.5774\n",
      " Epoch [173/300], Batch Step [180/323], D_loss: 0.5973,  G_loss: 1.4644\n",
      " Epoch [173/300], Batch Step [190/323], D_loss: 0.7176,  G_loss: 1.8987\n",
      " Epoch [173/300], Batch Step [200/323], D_loss: 0.7307,  G_loss: 1.5526\n",
      " Epoch [173/300], Batch Step [210/323], D_loss: 0.7996,  G_loss: 1.5320\n",
      " Epoch [173/300], Batch Step [220/323], D_loss: 0.6936,  G_loss: 1.7014\n",
      " Epoch [173/300], Batch Step [230/323], D_loss: 0.6902,  G_loss: 1.5076\n",
      " Epoch [173/300], Batch Step [240/323], D_loss: 0.6636,  G_loss: 1.6156\n",
      " Epoch [173/300], Batch Step [250/323], D_loss: 0.5674,  G_loss: 1.5935\n",
      " Epoch [173/300], Batch Step [260/323], D_loss: 0.5967,  G_loss: 1.4030\n",
      " Epoch [173/300], Batch Step [270/323], D_loss: 0.7994,  G_loss: 1.6432\n",
      " Epoch [173/300], Batch Step [280/323], D_loss: 0.7115,  G_loss: 1.5688\n",
      " Epoch [173/300], Batch Step [290/323], D_loss: 0.6719,  G_loss: 1.6447\n",
      " Epoch [173/300], Batch Step [300/323], D_loss: 0.5384,  G_loss: 1.6585\n",
      " Epoch [173/300], Batch Step [310/323], D_loss: 0.5796,  G_loss: 1.7040\n",
      " Epoch [173/300], Batch Step [320/323], D_loss: 0.6019,  G_loss: 1.6121\n",
      " Epoch [174/300], Batch Step [0/323], D_loss: 0.6486,  G_loss: 1.7281\n",
      " Epoch [174/300], Batch Step [10/323], D_loss: 0.7671,  G_loss: 1.5690\n",
      " Epoch [174/300], Batch Step [20/323], D_loss: 0.6093,  G_loss: 1.5796\n",
      " Epoch [174/300], Batch Step [30/323], D_loss: 0.8775,  G_loss: 1.5855\n",
      " Epoch [174/300], Batch Step [40/323], D_loss: 0.6739,  G_loss: 1.3943\n",
      " Epoch [174/300], Batch Step [50/323], D_loss: 0.6402,  G_loss: 1.6573\n",
      " Epoch [174/300], Batch Step [60/323], D_loss: 0.8434,  G_loss: 1.5244\n",
      " Epoch [174/300], Batch Step [70/323], D_loss: 0.5578,  G_loss: 1.4468\n",
      " Epoch [174/300], Batch Step [80/323], D_loss: 0.7160,  G_loss: 1.8029\n",
      " Epoch [174/300], Batch Step [90/323], D_loss: 0.5461,  G_loss: 1.5344\n",
      " Epoch [174/300], Batch Step [100/323], D_loss: 0.5202,  G_loss: 1.5351\n",
      " Epoch [174/300], Batch Step [110/323], D_loss: 0.6990,  G_loss: 1.5674\n",
      " Epoch [174/300], Batch Step [120/323], D_loss: 0.8373,  G_loss: 1.5915\n",
      " Epoch [174/300], Batch Step [130/323], D_loss: 0.6531,  G_loss: 1.5415\n",
      " Epoch [174/300], Batch Step [140/323], D_loss: 0.7143,  G_loss: 1.5165\n",
      " Epoch [174/300], Batch Step [150/323], D_loss: 0.5887,  G_loss: 1.7539\n",
      " Epoch [174/300], Batch Step [160/323], D_loss: 0.7815,  G_loss: 1.5352\n",
      " Epoch [174/300], Batch Step [170/323], D_loss: 0.6187,  G_loss: 1.6180\n",
      " Epoch [174/300], Batch Step [180/323], D_loss: 0.6723,  G_loss: 1.5737\n",
      " Epoch [174/300], Batch Step [190/323], D_loss: 0.8692,  G_loss: 1.6339\n",
      " Epoch [174/300], Batch Step [200/323], D_loss: 0.5221,  G_loss: 1.6010\n",
      " Epoch [174/300], Batch Step [210/323], D_loss: 0.6424,  G_loss: 1.5651\n",
      " Epoch [174/300], Batch Step [220/323], D_loss: 0.5437,  G_loss: 1.7283\n",
      " Epoch [174/300], Batch Step [230/323], D_loss: 0.6105,  G_loss: 1.6877\n",
      " Epoch [174/300], Batch Step [240/323], D_loss: 0.6782,  G_loss: 1.6789\n",
      " Epoch [174/300], Batch Step [250/323], D_loss: 0.6863,  G_loss: 1.4701\n",
      " Epoch [174/300], Batch Step [260/323], D_loss: 0.7458,  G_loss: 1.6357\n",
      " Epoch [174/300], Batch Step [270/323], D_loss: 0.7687,  G_loss: 1.5830\n",
      " Epoch [174/300], Batch Step [280/323], D_loss: 0.7271,  G_loss: 1.5333\n",
      " Epoch [174/300], Batch Step [290/323], D_loss: 0.8470,  G_loss: 1.7080\n",
      " Epoch [174/300], Batch Step [300/323], D_loss: 0.7131,  G_loss: 1.4412\n",
      " Epoch [174/300], Batch Step [310/323], D_loss: 0.4913,  G_loss: 1.6191\n",
      " Epoch [174/300], Batch Step [320/323], D_loss: 0.7404,  G_loss: 1.5237\n",
      " Epoch [175/300], Batch Step [0/323], D_loss: 0.5142,  G_loss: 1.4923\n",
      " Epoch [175/300], Batch Step [10/323], D_loss: 0.5745,  G_loss: 1.5377\n",
      " Epoch [175/300], Batch Step [20/323], D_loss: 0.6502,  G_loss: 1.5532\n",
      " Epoch [175/300], Batch Step [30/323], D_loss: 0.6148,  G_loss: 1.5603\n",
      " Epoch [175/300], Batch Step [40/323], D_loss: 0.5628,  G_loss: 1.6290\n",
      " Epoch [175/300], Batch Step [50/323], D_loss: 0.5909,  G_loss: 1.5198\n",
      " Epoch [175/300], Batch Step [60/323], D_loss: 0.6240,  G_loss: 1.4995\n",
      " Epoch [175/300], Batch Step [70/323], D_loss: 0.5772,  G_loss: 1.5129\n",
      " Epoch [175/300], Batch Step [80/323], D_loss: 0.6128,  G_loss: 1.6330\n",
      " Epoch [175/300], Batch Step [90/323], D_loss: 0.5876,  G_loss: 1.5756\n",
      " Epoch [175/300], Batch Step [100/323], D_loss: 0.7474,  G_loss: 1.5688\n",
      " Epoch [175/300], Batch Step [110/323], D_loss: 0.5464,  G_loss: 1.6143\n",
      " Epoch [175/300], Batch Step [120/323], D_loss: 0.8395,  G_loss: 1.6220\n",
      " Epoch [175/300], Batch Step [130/323], D_loss: 0.6627,  G_loss: 1.4591\n",
      " Epoch [175/300], Batch Step [140/323], D_loss: 0.6038,  G_loss: 1.7663\n",
      " Epoch [175/300], Batch Step [150/323], D_loss: 0.6742,  G_loss: 1.3483\n",
      " Epoch [175/300], Batch Step [160/323], D_loss: 0.6347,  G_loss: 1.6508\n",
      " Epoch [175/300], Batch Step [170/323], D_loss: 0.5729,  G_loss: 1.6197\n",
      " Epoch [175/300], Batch Step [180/323], D_loss: 0.5116,  G_loss: 1.6408\n",
      " Epoch [175/300], Batch Step [190/323], D_loss: 0.6183,  G_loss: 1.7576\n",
      " Epoch [175/300], Batch Step [200/323], D_loss: 0.6597,  G_loss: 1.6900\n",
      " Epoch [175/300], Batch Step [210/323], D_loss: 0.6703,  G_loss: 1.7307\n",
      " Epoch [175/300], Batch Step [220/323], D_loss: 0.6458,  G_loss: 1.6302\n",
      " Epoch [175/300], Batch Step [230/323], D_loss: 0.6512,  G_loss: 1.6320\n",
      " Epoch [175/300], Batch Step [240/323], D_loss: 0.6392,  G_loss: 1.6251\n",
      " Epoch [175/300], Batch Step [250/323], D_loss: 0.8386,  G_loss: 1.5363\n",
      " Epoch [175/300], Batch Step [260/323], D_loss: 0.8360,  G_loss: 1.3726\n",
      " Epoch [175/300], Batch Step [270/323], D_loss: 0.6583,  G_loss: 1.5659\n",
      " Epoch [175/300], Batch Step [280/323], D_loss: 0.5678,  G_loss: 1.5066\n",
      " Epoch [175/300], Batch Step [290/323], D_loss: 0.5796,  G_loss: 1.6346\n",
      " Epoch [175/300], Batch Step [300/323], D_loss: 0.6689,  G_loss: 1.6377\n",
      " Epoch [175/300], Batch Step [310/323], D_loss: 0.6832,  G_loss: 1.5629\n",
      " Epoch [175/300], Batch Step [320/323], D_loss: 0.8111,  G_loss: 1.6878\n",
      " Epoch [176/300], Batch Step [0/323], D_loss: 0.5992,  G_loss: 1.6447\n",
      " Epoch [176/300], Batch Step [10/323], D_loss: 0.4680,  G_loss: 1.5996\n",
      " Epoch [176/300], Batch Step [20/323], D_loss: 0.6038,  G_loss: 1.6665\n",
      " Epoch [176/300], Batch Step [30/323], D_loss: 0.6669,  G_loss: 1.4858\n",
      " Epoch [176/300], Batch Step [40/323], D_loss: 0.7531,  G_loss: 1.5945\n",
      " Epoch [176/300], Batch Step [50/323], D_loss: 0.6111,  G_loss: 1.5239\n",
      " Epoch [176/300], Batch Step [60/323], D_loss: 0.6059,  G_loss: 1.4876\n",
      " Epoch [176/300], Batch Step [70/323], D_loss: 0.6989,  G_loss: 1.5861\n",
      " Epoch [176/300], Batch Step [80/323], D_loss: 0.5663,  G_loss: 1.5710\n",
      " Epoch [176/300], Batch Step [90/323], D_loss: 0.6019,  G_loss: 1.7353\n",
      " Epoch [176/300], Batch Step [100/323], D_loss: 0.6347,  G_loss: 1.7001\n",
      " Epoch [176/300], Batch Step [110/323], D_loss: 0.6055,  G_loss: 1.6761\n",
      " Epoch [176/300], Batch Step [120/323], D_loss: 0.6602,  G_loss: 1.7616\n",
      " Epoch [176/300], Batch Step [130/323], D_loss: 0.6688,  G_loss: 1.4182\n",
      " Epoch [176/300], Batch Step [140/323], D_loss: 0.6931,  G_loss: 1.7517\n",
      " Epoch [176/300], Batch Step [150/323], D_loss: 0.6494,  G_loss: 1.5312\n",
      " Epoch [176/300], Batch Step [160/323], D_loss: 0.5909,  G_loss: 1.5931\n",
      " Epoch [176/300], Batch Step [170/323], D_loss: 0.7357,  G_loss: 1.5769\n",
      " Epoch [176/300], Batch Step [180/323], D_loss: 0.8701,  G_loss: 1.3833\n",
      " Epoch [176/300], Batch Step [190/323], D_loss: 0.6791,  G_loss: 1.5497\n",
      " Epoch [176/300], Batch Step [200/323], D_loss: 0.6228,  G_loss: 1.7406\n",
      " Epoch [176/300], Batch Step [210/323], D_loss: 0.6521,  G_loss: 1.5712\n",
      " Epoch [176/300], Batch Step [220/323], D_loss: 0.4984,  G_loss: 1.5856\n",
      " Epoch [176/300], Batch Step [230/323], D_loss: 0.5971,  G_loss: 1.5410\n",
      " Epoch [176/300], Batch Step [240/323], D_loss: 0.6482,  G_loss: 1.6537\n",
      " Epoch [176/300], Batch Step [250/323], D_loss: 0.6285,  G_loss: 1.6277\n",
      " Epoch [176/300], Batch Step [260/323], D_loss: 0.6819,  G_loss: 1.5887\n",
      " Epoch [176/300], Batch Step [270/323], D_loss: 0.6749,  G_loss: 1.6126\n",
      " Epoch [176/300], Batch Step [280/323], D_loss: 0.6247,  G_loss: 1.6673\n",
      " Epoch [176/300], Batch Step [290/323], D_loss: 0.7018,  G_loss: 1.6690\n",
      " Epoch [176/300], Batch Step [300/323], D_loss: 0.4292,  G_loss: 1.5699\n",
      " Epoch [176/300], Batch Step [310/323], D_loss: 0.6820,  G_loss: 1.6656\n",
      " Epoch [176/300], Batch Step [320/323], D_loss: 0.6252,  G_loss: 1.6047\n",
      " Epoch [177/300], Batch Step [0/323], D_loss: 0.6520,  G_loss: 1.6201\n",
      " Epoch [177/300], Batch Step [10/323], D_loss: 0.6810,  G_loss: 1.5827\n",
      " Epoch [177/300], Batch Step [20/323], D_loss: 0.5754,  G_loss: 1.5369\n",
      " Epoch [177/300], Batch Step [30/323], D_loss: 0.7527,  G_loss: 1.6401\n",
      " Epoch [177/300], Batch Step [40/323], D_loss: 0.6027,  G_loss: 1.5999\n",
      " Epoch [177/300], Batch Step [50/323], D_loss: 0.6024,  G_loss: 1.5891\n",
      " Epoch [177/300], Batch Step [60/323], D_loss: 0.6331,  G_loss: 1.7843\n",
      " Epoch [177/300], Batch Step [70/323], D_loss: 0.6628,  G_loss: 1.4634\n",
      " Epoch [177/300], Batch Step [80/323], D_loss: 0.7125,  G_loss: 1.7206\n",
      " Epoch [177/300], Batch Step [90/323], D_loss: 0.7566,  G_loss: 1.3826\n",
      " Epoch [177/300], Batch Step [100/323], D_loss: 0.6596,  G_loss: 1.5152\n",
      " Epoch [177/300], Batch Step [110/323], D_loss: 0.6988,  G_loss: 1.5651\n",
      " Epoch [177/300], Batch Step [120/323], D_loss: 0.5883,  G_loss: 1.5167\n",
      " Epoch [177/300], Batch Step [130/323], D_loss: 0.7182,  G_loss: 1.6259\n",
      " Epoch [177/300], Batch Step [140/323], D_loss: 0.4301,  G_loss: 1.5821\n",
      " Epoch [177/300], Batch Step [150/323], D_loss: 0.6724,  G_loss: 1.5397\n",
      " Epoch [177/300], Batch Step [160/323], D_loss: 0.6549,  G_loss: 1.5902\n",
      " Epoch [177/300], Batch Step [170/323], D_loss: 0.6252,  G_loss: 1.7379\n",
      " Epoch [177/300], Batch Step [180/323], D_loss: 0.6705,  G_loss: 1.5493\n",
      " Epoch [177/300], Batch Step [190/323], D_loss: 0.6655,  G_loss: 1.5510\n",
      " Epoch [177/300], Batch Step [200/323], D_loss: 0.8079,  G_loss: 1.4643\n",
      " Epoch [177/300], Batch Step [210/323], D_loss: 0.6914,  G_loss: 1.6306\n",
      " Epoch [177/300], Batch Step [220/323], D_loss: 0.6234,  G_loss: 1.7061\n",
      " Epoch [177/300], Batch Step [230/323], D_loss: 0.7084,  G_loss: 1.6185\n",
      " Epoch [177/300], Batch Step [240/323], D_loss: 0.6989,  G_loss: 1.5979\n",
      " Epoch [177/300], Batch Step [250/323], D_loss: 0.5957,  G_loss: 1.6298\n",
      " Epoch [177/300], Batch Step [260/323], D_loss: 0.5209,  G_loss: 1.8087\n",
      " Epoch [177/300], Batch Step [270/323], D_loss: 0.5655,  G_loss: 1.5080\n",
      " Epoch [177/300], Batch Step [280/323], D_loss: 0.6217,  G_loss: 1.5325\n",
      " Epoch [177/300], Batch Step [290/323], D_loss: 0.5309,  G_loss: 1.6246\n",
      " Epoch [177/300], Batch Step [300/323], D_loss: 0.7158,  G_loss: 1.7067\n",
      " Epoch [177/300], Batch Step [310/323], D_loss: 0.5586,  G_loss: 1.6187\n",
      " Epoch [177/300], Batch Step [320/323], D_loss: 0.7873,  G_loss: 1.7221\n",
      " Epoch [178/300], Batch Step [0/323], D_loss: 0.6163,  G_loss: 1.7572\n",
      " Epoch [178/300], Batch Step [10/323], D_loss: 0.7180,  G_loss: 1.6193\n",
      " Epoch [178/300], Batch Step [20/323], D_loss: 0.6379,  G_loss: 1.8264\n",
      " Epoch [178/300], Batch Step [30/323], D_loss: 0.6193,  G_loss: 1.6377\n",
      " Epoch [178/300], Batch Step [40/323], D_loss: 0.6323,  G_loss: 1.6820\n",
      " Epoch [178/300], Batch Step [50/323], D_loss: 0.5585,  G_loss: 1.6053\n",
      " Epoch [178/300], Batch Step [60/323], D_loss: 0.5763,  G_loss: 1.6635\n",
      " Epoch [178/300], Batch Step [70/323], D_loss: 0.7240,  G_loss: 1.5097\n",
      " Epoch [178/300], Batch Step [80/323], D_loss: 0.6686,  G_loss: 1.5228\n",
      " Epoch [178/300], Batch Step [90/323], D_loss: 0.5274,  G_loss: 1.5704\n",
      " Epoch [178/300], Batch Step [100/323], D_loss: 0.6942,  G_loss: 1.5003\n",
      " Epoch [178/300], Batch Step [110/323], D_loss: 0.5758,  G_loss: 1.5763\n",
      " Epoch [178/300], Batch Step [120/323], D_loss: 0.6960,  G_loss: 1.5695\n",
      " Epoch [178/300], Batch Step [130/323], D_loss: 0.5414,  G_loss: 1.5412\n",
      " Epoch [178/300], Batch Step [140/323], D_loss: 0.6372,  G_loss: 1.6474\n",
      " Epoch [178/300], Batch Step [150/323], D_loss: 0.6494,  G_loss: 1.6052\n",
      " Epoch [178/300], Batch Step [160/323], D_loss: 0.5183,  G_loss: 1.6246\n",
      " Epoch [178/300], Batch Step [170/323], D_loss: 0.6128,  G_loss: 1.6318\n",
      " Epoch [178/300], Batch Step [180/323], D_loss: 0.5168,  G_loss: 1.6261\n",
      " Epoch [178/300], Batch Step [190/323], D_loss: 0.7435,  G_loss: 1.7527\n",
      " Epoch [178/300], Batch Step [200/323], D_loss: 0.6964,  G_loss: 1.5837\n",
      " Epoch [178/300], Batch Step [210/323], D_loss: 0.5683,  G_loss: 1.6221\n",
      " Epoch [178/300], Batch Step [220/323], D_loss: 0.6443,  G_loss: 1.6165\n",
      " Epoch [178/300], Batch Step [230/323], D_loss: 0.6190,  G_loss: 1.5041\n",
      " Epoch [178/300], Batch Step [240/323], D_loss: 0.5959,  G_loss: 1.4757\n",
      " Epoch [178/300], Batch Step [250/323], D_loss: 0.8468,  G_loss: 1.6640\n",
      " Epoch [178/300], Batch Step [260/323], D_loss: 0.6616,  G_loss: 1.5779\n",
      " Epoch [178/300], Batch Step [270/323], D_loss: 0.5795,  G_loss: 1.5128\n",
      " Epoch [178/300], Batch Step [280/323], D_loss: 0.6109,  G_loss: 1.6263\n",
      " Epoch [178/300], Batch Step [290/323], D_loss: 0.5504,  G_loss: 1.5520\n",
      " Epoch [178/300], Batch Step [300/323], D_loss: 0.6500,  G_loss: 1.7184\n",
      " Epoch [178/300], Batch Step [310/323], D_loss: 0.6901,  G_loss: 1.4786\n",
      " Epoch [178/300], Batch Step [320/323], D_loss: 0.5498,  G_loss: 1.7318\n",
      " Epoch [179/300], Batch Step [0/323], D_loss: 0.6469,  G_loss: 1.7394\n",
      " Epoch [179/300], Batch Step [10/323], D_loss: 0.7628,  G_loss: 1.5885\n",
      " Epoch [179/300], Batch Step [20/323], D_loss: 0.9536,  G_loss: 1.5272\n",
      " Epoch [179/300], Batch Step [30/323], D_loss: 0.6373,  G_loss: 1.5407\n",
      " Epoch [179/300], Batch Step [40/323], D_loss: 0.7290,  G_loss: 1.5749\n",
      " Epoch [179/300], Batch Step [50/323], D_loss: 0.7446,  G_loss: 1.6184\n",
      " Epoch [179/300], Batch Step [60/323], D_loss: 0.7437,  G_loss: 1.6509\n",
      " Epoch [179/300], Batch Step [70/323], D_loss: 0.6093,  G_loss: 1.5375\n",
      " Epoch [179/300], Batch Step [80/323], D_loss: 0.5951,  G_loss: 1.6967\n",
      " Epoch [179/300], Batch Step [90/323], D_loss: 0.5742,  G_loss: 1.6044\n",
      " Epoch [179/300], Batch Step [100/323], D_loss: 0.6324,  G_loss: 1.5228\n",
      " Epoch [179/300], Batch Step [110/323], D_loss: 0.7492,  G_loss: 1.5629\n",
      " Epoch [179/300], Batch Step [120/323], D_loss: 0.6147,  G_loss: 1.6145\n",
      " Epoch [179/300], Batch Step [130/323], D_loss: 0.6505,  G_loss: 1.6022\n",
      " Epoch [179/300], Batch Step [140/323], D_loss: 0.5087,  G_loss: 1.5433\n",
      " Epoch [179/300], Batch Step [150/323], D_loss: 0.5024,  G_loss: 1.6171\n",
      " Epoch [179/300], Batch Step [160/323], D_loss: 0.5883,  G_loss: 1.6468\n",
      " Epoch [179/300], Batch Step [170/323], D_loss: 0.6955,  G_loss: 1.5213\n",
      " Epoch [179/300], Batch Step [180/323], D_loss: 0.6969,  G_loss: 1.6201\n",
      " Epoch [179/300], Batch Step [190/323], D_loss: 0.6522,  G_loss: 1.7065\n",
      " Epoch [179/300], Batch Step [200/323], D_loss: 0.6296,  G_loss: 1.6183\n",
      " Epoch [179/300], Batch Step [210/323], D_loss: 0.5102,  G_loss: 1.6690\n",
      " Epoch [179/300], Batch Step [220/323], D_loss: 0.6220,  G_loss: 1.4817\n",
      " Epoch [179/300], Batch Step [230/323], D_loss: 0.6176,  G_loss: 1.5652\n",
      " Epoch [179/300], Batch Step [240/323], D_loss: 0.6833,  G_loss: 1.7362\n",
      " Epoch [179/300], Batch Step [250/323], D_loss: 0.6331,  G_loss: 1.4946\n",
      " Epoch [179/300], Batch Step [260/323], D_loss: 0.6983,  G_loss: 1.5473\n",
      " Epoch [179/300], Batch Step [270/323], D_loss: 0.7544,  G_loss: 1.6477\n",
      " Epoch [179/300], Batch Step [280/323], D_loss: 0.6231,  G_loss: 1.4901\n",
      " Epoch [179/300], Batch Step [290/323], D_loss: 0.7687,  G_loss: 1.5138\n",
      " Epoch [179/300], Batch Step [300/323], D_loss: 0.6362,  G_loss: 1.6419\n",
      " Epoch [179/300], Batch Step [310/323], D_loss: 0.6837,  G_loss: 1.5610\n",
      " Epoch [179/300], Batch Step [320/323], D_loss: 0.7779,  G_loss: 1.5926\n",
      " Epoch [180/300], Batch Step [0/323], D_loss: 0.6966,  G_loss: 1.6270\n",
      " Epoch [180/300], Batch Step [10/323], D_loss: 0.5813,  G_loss: 1.5268\n",
      " Epoch [180/300], Batch Step [20/323], D_loss: 0.7004,  G_loss: 1.5277\n",
      " Epoch [180/300], Batch Step [30/323], D_loss: 0.7444,  G_loss: 1.7409\n",
      " Epoch [180/300], Batch Step [40/323], D_loss: 0.5655,  G_loss: 1.5505\n",
      " Epoch [180/300], Batch Step [50/323], D_loss: 0.6003,  G_loss: 1.6480\n",
      " Epoch [180/300], Batch Step [60/323], D_loss: 0.6100,  G_loss: 1.4610\n",
      " Epoch [180/300], Batch Step [70/323], D_loss: 0.6165,  G_loss: 1.6796\n",
      " Epoch [180/300], Batch Step [80/323], D_loss: 0.6459,  G_loss: 1.7091\n",
      " Epoch [180/300], Batch Step [90/323], D_loss: 0.6079,  G_loss: 1.5962\n",
      " Epoch [180/300], Batch Step [100/323], D_loss: 0.7857,  G_loss: 1.4566\n",
      " Epoch [180/300], Batch Step [110/323], D_loss: 0.5158,  G_loss: 1.6511\n",
      " Epoch [180/300], Batch Step [120/323], D_loss: 0.5901,  G_loss: 1.7691\n",
      " Epoch [180/300], Batch Step [130/323], D_loss: 0.6481,  G_loss: 1.4777\n",
      " Epoch [180/300], Batch Step [140/323], D_loss: 0.6082,  G_loss: 1.4737\n",
      " Epoch [180/300], Batch Step [150/323], D_loss: 0.5922,  G_loss: 1.5833\n",
      " Epoch [180/300], Batch Step [160/323], D_loss: 0.6590,  G_loss: 1.7105\n",
      " Epoch [180/300], Batch Step [170/323], D_loss: 0.5259,  G_loss: 1.5079\n",
      " Epoch [180/300], Batch Step [180/323], D_loss: 0.8246,  G_loss: 1.5986\n",
      " Epoch [180/300], Batch Step [190/323], D_loss: 0.6596,  G_loss: 1.4775\n",
      " Epoch [180/300], Batch Step [200/323], D_loss: 0.5473,  G_loss: 1.7477\n",
      " Epoch [180/300], Batch Step [210/323], D_loss: 0.4711,  G_loss: 1.4892\n",
      " Epoch [180/300], Batch Step [220/323], D_loss: 0.5027,  G_loss: 1.5702\n",
      " Epoch [180/300], Batch Step [230/323], D_loss: 0.4901,  G_loss: 1.8680\n",
      " Epoch [180/300], Batch Step [240/323], D_loss: 0.7090,  G_loss: 1.4772\n",
      " Epoch [180/300], Batch Step [250/323], D_loss: 0.7746,  G_loss: 1.7605\n",
      " Epoch [180/300], Batch Step [260/323], D_loss: 0.5493,  G_loss: 1.5137\n",
      " Epoch [180/300], Batch Step [270/323], D_loss: 0.5776,  G_loss: 1.6770\n",
      " Epoch [180/300], Batch Step [280/323], D_loss: 0.7018,  G_loss: 1.4735\n",
      " Epoch [180/300], Batch Step [290/323], D_loss: 0.5444,  G_loss: 1.7046\n",
      " Epoch [180/300], Batch Step [300/323], D_loss: 0.7563,  G_loss: 1.7909\n",
      " Epoch [180/300], Batch Step [310/323], D_loss: 0.6080,  G_loss: 1.5469\n",
      " Epoch [180/300], Batch Step [320/323], D_loss: 0.5965,  G_loss: 1.6892\n",
      " Epoch [181/300], Batch Step [0/323], D_loss: 0.5976,  G_loss: 1.7125\n",
      " Epoch [181/300], Batch Step [10/323], D_loss: 0.6950,  G_loss: 1.5969\n",
      " Epoch [181/300], Batch Step [20/323], D_loss: 0.6028,  G_loss: 1.5866\n",
      " Epoch [181/300], Batch Step [30/323], D_loss: 0.5766,  G_loss: 1.5062\n",
      " Epoch [181/300], Batch Step [40/323], D_loss: 0.6619,  G_loss: 1.5175\n",
      " Epoch [181/300], Batch Step [50/323], D_loss: 0.7956,  G_loss: 1.4988\n",
      " Epoch [181/300], Batch Step [60/323], D_loss: 0.6742,  G_loss: 1.5576\n",
      " Epoch [181/300], Batch Step [70/323], D_loss: 0.4234,  G_loss: 1.5570\n",
      " Epoch [181/300], Batch Step [80/323], D_loss: 0.5798,  G_loss: 1.5105\n",
      " Epoch [181/300], Batch Step [90/323], D_loss: 0.7117,  G_loss: 1.5912\n",
      " Epoch [181/300], Batch Step [100/323], D_loss: 0.6005,  G_loss: 1.5278\n",
      " Epoch [181/300], Batch Step [110/323], D_loss: 0.6782,  G_loss: 1.6809\n",
      " Epoch [181/300], Batch Step [120/323], D_loss: 0.6497,  G_loss: 1.6167\n",
      " Epoch [181/300], Batch Step [130/323], D_loss: 0.6410,  G_loss: 1.5287\n",
      " Epoch [181/300], Batch Step [140/323], D_loss: 0.5520,  G_loss: 1.6889\n",
      " Epoch [181/300], Batch Step [150/323], D_loss: 0.6759,  G_loss: 1.8461\n",
      " Epoch [181/300], Batch Step [160/323], D_loss: 0.7653,  G_loss: 1.4935\n",
      " Epoch [181/300], Batch Step [170/323], D_loss: 0.6377,  G_loss: 1.6168\n",
      " Epoch [181/300], Batch Step [180/323], D_loss: 0.6101,  G_loss: 1.7838\n",
      " Epoch [181/300], Batch Step [190/323], D_loss: 0.6225,  G_loss: 1.3536\n",
      " Epoch [181/300], Batch Step [200/323], D_loss: 0.5080,  G_loss: 1.6333\n",
      " Epoch [181/300], Batch Step [210/323], D_loss: 0.6266,  G_loss: 1.7697\n",
      " Epoch [181/300], Batch Step [220/323], D_loss: 0.6377,  G_loss: 1.5010\n",
      " Epoch [181/300], Batch Step [230/323], D_loss: 0.5484,  G_loss: 1.6728\n",
      " Epoch [181/300], Batch Step [240/323], D_loss: 0.6292,  G_loss: 1.6780\n",
      " Epoch [181/300], Batch Step [250/323], D_loss: 0.7111,  G_loss: 1.5551\n",
      " Epoch [181/300], Batch Step [260/323], D_loss: 0.6430,  G_loss: 1.4878\n",
      " Epoch [181/300], Batch Step [270/323], D_loss: 0.6414,  G_loss: 1.7038\n",
      " Epoch [181/300], Batch Step [280/323], D_loss: 0.5738,  G_loss: 1.6372\n",
      " Epoch [181/300], Batch Step [290/323], D_loss: 0.7231,  G_loss: 1.4626\n",
      " Epoch [181/300], Batch Step [300/323], D_loss: 0.5621,  G_loss: 1.6070\n",
      " Epoch [181/300], Batch Step [310/323], D_loss: 0.5591,  G_loss: 1.7122\n",
      " Epoch [181/300], Batch Step [320/323], D_loss: 0.5935,  G_loss: 1.5583\n",
      " Epoch [182/300], Batch Step [0/323], D_loss: 0.4486,  G_loss: 1.5304\n",
      " Epoch [182/300], Batch Step [10/323], D_loss: 0.6549,  G_loss: 1.6057\n",
      " Epoch [182/300], Batch Step [20/323], D_loss: 0.6017,  G_loss: 1.6479\n",
      " Epoch [182/300], Batch Step [30/323], D_loss: 0.7071,  G_loss: 1.7083\n",
      " Epoch [182/300], Batch Step [40/323], D_loss: 0.6507,  G_loss: 1.4280\n",
      " Epoch [182/300], Batch Step [50/323], D_loss: 0.4911,  G_loss: 1.6280\n",
      " Epoch [182/300], Batch Step [60/323], D_loss: 0.5527,  G_loss: 1.4444\n",
      " Epoch [182/300], Batch Step [70/323], D_loss: 0.8156,  G_loss: 1.5378\n",
      " Epoch [182/300], Batch Step [80/323], D_loss: 0.6818,  G_loss: 1.6579\n",
      " Epoch [182/300], Batch Step [90/323], D_loss: 0.6445,  G_loss: 1.5964\n",
      " Epoch [182/300], Batch Step [100/323], D_loss: 0.4080,  G_loss: 1.6168\n",
      " Epoch [182/300], Batch Step [110/323], D_loss: 0.6665,  G_loss: 1.6698\n",
      " Epoch [182/300], Batch Step [120/323], D_loss: 0.5841,  G_loss: 1.6245\n",
      " Epoch [182/300], Batch Step [130/323], D_loss: 0.7496,  G_loss: 1.7066\n",
      " Epoch [182/300], Batch Step [140/323], D_loss: 0.6697,  G_loss: 1.4755\n",
      " Epoch [182/300], Batch Step [150/323], D_loss: 0.5242,  G_loss: 1.6178\n",
      " Epoch [182/300], Batch Step [160/323], D_loss: 0.6177,  G_loss: 1.7248\n",
      " Epoch [182/300], Batch Step [170/323], D_loss: 0.5441,  G_loss: 1.4977\n",
      " Epoch [182/300], Batch Step [180/323], D_loss: 0.5330,  G_loss: 1.6588\n",
      " Epoch [182/300], Batch Step [190/323], D_loss: 0.7086,  G_loss: 1.5796\n",
      " Epoch [182/300], Batch Step [200/323], D_loss: 0.6927,  G_loss: 1.5354\n",
      " Epoch [182/300], Batch Step [210/323], D_loss: 0.5200,  G_loss: 1.4406\n",
      " Epoch [182/300], Batch Step [220/323], D_loss: 0.5999,  G_loss: 1.5181\n",
      " Epoch [182/300], Batch Step [230/323], D_loss: 0.7019,  G_loss: 1.6120\n",
      " Epoch [182/300], Batch Step [240/323], D_loss: 0.6040,  G_loss: 1.6151\n",
      " Epoch [182/300], Batch Step [250/323], D_loss: 0.6925,  G_loss: 1.4824\n",
      " Epoch [182/300], Batch Step [260/323], D_loss: 0.6620,  G_loss: 1.5021\n",
      " Epoch [182/300], Batch Step [270/323], D_loss: 0.7693,  G_loss: 1.7066\n",
      " Epoch [182/300], Batch Step [280/323], D_loss: 0.7581,  G_loss: 1.6000\n",
      " Epoch [182/300], Batch Step [290/323], D_loss: 0.5915,  G_loss: 1.6715\n",
      " Epoch [182/300], Batch Step [300/323], D_loss: 0.6701,  G_loss: 1.6782\n",
      " Epoch [182/300], Batch Step [310/323], D_loss: 0.6651,  G_loss: 1.5217\n",
      " Epoch [182/300], Batch Step [320/323], D_loss: 0.7149,  G_loss: 1.6980\n",
      " Epoch [183/300], Batch Step [0/323], D_loss: 0.6890,  G_loss: 1.5786\n",
      " Epoch [183/300], Batch Step [10/323], D_loss: 0.5999,  G_loss: 1.5696\n",
      " Epoch [183/300], Batch Step [20/323], D_loss: 0.7425,  G_loss: 1.7270\n",
      " Epoch [183/300], Batch Step [30/323], D_loss: 0.6149,  G_loss: 1.5500\n",
      " Epoch [183/300], Batch Step [40/323], D_loss: 0.6186,  G_loss: 1.7061\n",
      " Epoch [183/300], Batch Step [50/323], D_loss: 0.7208,  G_loss: 1.5057\n",
      " Epoch [183/300], Batch Step [60/323], D_loss: 0.7647,  G_loss: 1.7258\n",
      " Epoch [183/300], Batch Step [70/323], D_loss: 0.5568,  G_loss: 1.5681\n",
      " Epoch [183/300], Batch Step [80/323], D_loss: 0.5254,  G_loss: 1.6579\n",
      " Epoch [183/300], Batch Step [90/323], D_loss: 0.6712,  G_loss: 1.3726\n",
      " Epoch [183/300], Batch Step [100/323], D_loss: 0.7079,  G_loss: 1.6483\n",
      " Epoch [183/300], Batch Step [110/323], D_loss: 0.6399,  G_loss: 1.4912\n",
      " Epoch [183/300], Batch Step [120/323], D_loss: 0.6032,  G_loss: 1.6027\n",
      " Epoch [183/300], Batch Step [130/323], D_loss: 0.5326,  G_loss: 1.6481\n",
      " Epoch [183/300], Batch Step [140/323], D_loss: 0.6047,  G_loss: 1.7678\n",
      " Epoch [183/300], Batch Step [150/323], D_loss: 0.8968,  G_loss: 1.4923\n",
      " Epoch [183/300], Batch Step [160/323], D_loss: 0.5940,  G_loss: 1.6545\n",
      " Epoch [183/300], Batch Step [170/323], D_loss: 0.6539,  G_loss: 1.5152\n",
      " Epoch [183/300], Batch Step [180/323], D_loss: 0.6325,  G_loss: 1.5598\n",
      " Epoch [183/300], Batch Step [190/323], D_loss: 0.5957,  G_loss: 1.5074\n",
      " Epoch [183/300], Batch Step [200/323], D_loss: 0.6869,  G_loss: 1.5765\n",
      " Epoch [183/300], Batch Step [210/323], D_loss: 0.7626,  G_loss: 1.4616\n",
      " Epoch [183/300], Batch Step [220/323], D_loss: 0.6054,  G_loss: 1.5765\n",
      " Epoch [183/300], Batch Step [230/323], D_loss: 0.5898,  G_loss: 1.7045\n",
      " Epoch [183/300], Batch Step [240/323], D_loss: 0.6687,  G_loss: 1.6310\n",
      " Epoch [183/300], Batch Step [250/323], D_loss: 0.7556,  G_loss: 1.6731\n",
      " Epoch [183/300], Batch Step [260/323], D_loss: 0.6313,  G_loss: 1.5274\n",
      " Epoch [183/300], Batch Step [270/323], D_loss: 0.5988,  G_loss: 1.5244\n",
      " Epoch [183/300], Batch Step [280/323], D_loss: 0.5594,  G_loss: 1.6715\n",
      " Epoch [183/300], Batch Step [290/323], D_loss: 0.5456,  G_loss: 1.5191\n",
      " Epoch [183/300], Batch Step [300/323], D_loss: 0.6517,  G_loss: 1.6626\n",
      " Epoch [183/300], Batch Step [310/323], D_loss: 0.5670,  G_loss: 1.6503\n",
      " Epoch [183/300], Batch Step [320/323], D_loss: 0.5519,  G_loss: 1.5748\n",
      " Epoch [184/300], Batch Step [0/323], D_loss: 0.6600,  G_loss: 1.6235\n",
      " Epoch [184/300], Batch Step [10/323], D_loss: 0.6438,  G_loss: 1.5197\n",
      " Epoch [184/300], Batch Step [20/323], D_loss: 0.6039,  G_loss: 1.4343\n",
      " Epoch [184/300], Batch Step [30/323], D_loss: 0.4854,  G_loss: 1.7395\n",
      " Epoch [184/300], Batch Step [40/323], D_loss: 0.7790,  G_loss: 1.5187\n",
      " Epoch [184/300], Batch Step [50/323], D_loss: 0.6520,  G_loss: 1.5625\n",
      " Epoch [184/300], Batch Step [60/323], D_loss: 0.5934,  G_loss: 1.5988\n",
      " Epoch [184/300], Batch Step [70/323], D_loss: 0.6387,  G_loss: 1.5936\n",
      " Epoch [184/300], Batch Step [80/323], D_loss: 0.4573,  G_loss: 1.5225\n",
      " Epoch [184/300], Batch Step [90/323], D_loss: 0.5145,  G_loss: 1.6833\n",
      " Epoch [184/300], Batch Step [100/323], D_loss: 0.6018,  G_loss: 1.6090\n",
      " Epoch [184/300], Batch Step [110/323], D_loss: 0.7047,  G_loss: 1.6136\n",
      " Epoch [184/300], Batch Step [120/323], D_loss: 0.5959,  G_loss: 1.6077\n",
      " Epoch [184/300], Batch Step [130/323], D_loss: 0.5656,  G_loss: 1.5359\n",
      " Epoch [184/300], Batch Step [140/323], D_loss: 0.6326,  G_loss: 1.6374\n",
      " Epoch [184/300], Batch Step [150/323], D_loss: 0.5959,  G_loss: 1.7438\n",
      " Epoch [184/300], Batch Step [160/323], D_loss: 0.6611,  G_loss: 1.5680\n",
      " Epoch [184/300], Batch Step [170/323], D_loss: 0.6747,  G_loss: 1.5183\n",
      " Epoch [184/300], Batch Step [180/323], D_loss: 0.5747,  G_loss: 1.6887\n",
      " Epoch [184/300], Batch Step [190/323], D_loss: 0.6259,  G_loss: 1.4712\n",
      " Epoch [184/300], Batch Step [200/323], D_loss: 0.5655,  G_loss: 1.6358\n",
      " Epoch [184/300], Batch Step [210/323], D_loss: 0.6388,  G_loss: 1.6056\n",
      " Epoch [184/300], Batch Step [220/323], D_loss: 0.6095,  G_loss: 1.6624\n",
      " Epoch [184/300], Batch Step [230/323], D_loss: 0.5939,  G_loss: 1.7010\n",
      " Epoch [184/300], Batch Step [240/323], D_loss: 0.6127,  G_loss: 1.5537\n",
      " Epoch [184/300], Batch Step [250/323], D_loss: 0.7420,  G_loss: 1.6023\n",
      " Epoch [184/300], Batch Step [260/323], D_loss: 0.7092,  G_loss: 1.5137\n",
      " Epoch [184/300], Batch Step [270/323], D_loss: 0.6425,  G_loss: 1.5393\n",
      " Epoch [184/300], Batch Step [280/323], D_loss: 0.7095,  G_loss: 1.7485\n",
      " Epoch [184/300], Batch Step [290/323], D_loss: 0.7272,  G_loss: 1.5542\n",
      " Epoch [184/300], Batch Step [300/323], D_loss: 0.7394,  G_loss: 1.7390\n",
      " Epoch [184/300], Batch Step [310/323], D_loss: 0.7159,  G_loss: 1.4151\n",
      " Epoch [184/300], Batch Step [320/323], D_loss: 0.5846,  G_loss: 1.6712\n",
      " Epoch [185/300], Batch Step [0/323], D_loss: 0.6133,  G_loss: 1.7641\n",
      " Epoch [185/300], Batch Step [10/323], D_loss: 0.6561,  G_loss: 1.8071\n",
      " Epoch [185/300], Batch Step [20/323], D_loss: 0.6643,  G_loss: 1.5867\n",
      " Epoch [185/300], Batch Step [30/323], D_loss: 0.6501,  G_loss: 1.7522\n",
      " Epoch [185/300], Batch Step [40/323], D_loss: 0.4953,  G_loss: 1.6159\n",
      " Epoch [185/300], Batch Step [50/323], D_loss: 0.6227,  G_loss: 1.5900\n",
      " Epoch [185/300], Batch Step [60/323], D_loss: 0.6691,  G_loss: 1.4747\n",
      " Epoch [185/300], Batch Step [70/323], D_loss: 0.5275,  G_loss: 1.6571\n",
      " Epoch [185/300], Batch Step [80/323], D_loss: 0.5473,  G_loss: 1.6327\n",
      " Epoch [185/300], Batch Step [90/323], D_loss: 0.5880,  G_loss: 1.5122\n",
      " Epoch [185/300], Batch Step [100/323], D_loss: 0.8567,  G_loss: 1.5614\n",
      " Epoch [185/300], Batch Step [110/323], D_loss: 0.6870,  G_loss: 1.4030\n",
      " Epoch [185/300], Batch Step [120/323], D_loss: 0.6509,  G_loss: 1.6420\n",
      " Epoch [185/300], Batch Step [130/323], D_loss: 0.7467,  G_loss: 1.5813\n",
      " Epoch [185/300], Batch Step [140/323], D_loss: 0.6602,  G_loss: 1.5385\n",
      " Epoch [185/300], Batch Step [150/323], D_loss: 0.6720,  G_loss: 1.5906\n",
      " Epoch [185/300], Batch Step [160/323], D_loss: 0.6180,  G_loss: 1.5654\n",
      " Epoch [185/300], Batch Step [170/323], D_loss: 0.7417,  G_loss: 1.5597\n",
      " Epoch [185/300], Batch Step [180/323], D_loss: 0.5237,  G_loss: 1.5961\n",
      " Epoch [185/300], Batch Step [190/323], D_loss: 0.6136,  G_loss: 1.6939\n",
      " Epoch [185/300], Batch Step [200/323], D_loss: 0.6679,  G_loss: 1.6093\n",
      " Epoch [185/300], Batch Step [210/323], D_loss: 0.5956,  G_loss: 1.6502\n",
      " Epoch [185/300], Batch Step [220/323], D_loss: 0.5225,  G_loss: 1.4505\n",
      " Epoch [185/300], Batch Step [230/323], D_loss: 0.6856,  G_loss: 1.6449\n",
      " Epoch [185/300], Batch Step [240/323], D_loss: 0.6241,  G_loss: 1.5905\n",
      " Epoch [185/300], Batch Step [250/323], D_loss: 0.6099,  G_loss: 1.4055\n",
      " Epoch [185/300], Batch Step [260/323], D_loss: 0.6390,  G_loss: 1.7827\n",
      " Epoch [185/300], Batch Step [270/323], D_loss: 0.6737,  G_loss: 1.6789\n",
      " Epoch [185/300], Batch Step [280/323], D_loss: 0.6167,  G_loss: 1.5405\n",
      " Epoch [185/300], Batch Step [290/323], D_loss: 0.6228,  G_loss: 1.5698\n",
      " Epoch [185/300], Batch Step [300/323], D_loss: 0.6976,  G_loss: 1.6329\n",
      " Epoch [185/300], Batch Step [310/323], D_loss: 0.6732,  G_loss: 1.5590\n",
      " Epoch [185/300], Batch Step [320/323], D_loss: 0.7416,  G_loss: 1.6716\n",
      " Epoch [186/300], Batch Step [0/323], D_loss: 0.6468,  G_loss: 1.5504\n",
      " Epoch [186/300], Batch Step [10/323], D_loss: 0.5050,  G_loss: 1.5821\n",
      " Epoch [186/300], Batch Step [20/323], D_loss: 0.6031,  G_loss: 1.6931\n",
      " Epoch [186/300], Batch Step [30/323], D_loss: 0.6226,  G_loss: 1.5959\n",
      " Epoch [186/300], Batch Step [40/323], D_loss: 0.6636,  G_loss: 1.6638\n",
      " Epoch [186/300], Batch Step [50/323], D_loss: 0.7907,  G_loss: 1.5276\n",
      " Epoch [186/300], Batch Step [60/323], D_loss: 0.7354,  G_loss: 1.5627\n",
      " Epoch [186/300], Batch Step [70/323], D_loss: 0.5753,  G_loss: 1.6640\n",
      " Epoch [186/300], Batch Step [80/323], D_loss: 0.6076,  G_loss: 1.5597\n",
      " Epoch [186/300], Batch Step [90/323], D_loss: 0.6766,  G_loss: 1.5504\n",
      " Epoch [186/300], Batch Step [100/323], D_loss: 0.6474,  G_loss: 1.5166\n",
      " Epoch [186/300], Batch Step [110/323], D_loss: 0.6372,  G_loss: 1.6961\n",
      " Epoch [186/300], Batch Step [120/323], D_loss: 0.6310,  G_loss: 1.4847\n",
      " Epoch [186/300], Batch Step [130/323], D_loss: 0.8700,  G_loss: 1.6316\n",
      " Epoch [186/300], Batch Step [140/323], D_loss: 0.5535,  G_loss: 1.5658\n",
      " Epoch [186/300], Batch Step [150/323], D_loss: 0.5550,  G_loss: 1.5832\n",
      " Epoch [186/300], Batch Step [160/323], D_loss: 0.5013,  G_loss: 1.5953\n",
      " Epoch [186/300], Batch Step [170/323], D_loss: 0.5748,  G_loss: 1.7713\n",
      " Epoch [186/300], Batch Step [180/323], D_loss: 0.5216,  G_loss: 1.6126\n",
      " Epoch [186/300], Batch Step [190/323], D_loss: 0.7053,  G_loss: 1.4507\n",
      " Epoch [186/300], Batch Step [200/323], D_loss: 0.6537,  G_loss: 1.6586\n",
      " Epoch [186/300], Batch Step [210/323], D_loss: 0.4271,  G_loss: 1.6180\n",
      " Epoch [186/300], Batch Step [220/323], D_loss: 0.7463,  G_loss: 1.5473\n",
      " Epoch [186/300], Batch Step [230/323], D_loss: 0.6966,  G_loss: 1.5204\n",
      " Epoch [186/300], Batch Step [240/323], D_loss: 0.5590,  G_loss: 1.6928\n",
      " Epoch [186/300], Batch Step [250/323], D_loss: 0.3877,  G_loss: 1.7932\n",
      " Epoch [186/300], Batch Step [260/323], D_loss: 0.6714,  G_loss: 1.5507\n",
      " Epoch [186/300], Batch Step [270/323], D_loss: 0.4886,  G_loss: 1.6691\n",
      " Epoch [186/300], Batch Step [280/323], D_loss: 0.6389,  G_loss: 1.6900\n",
      " Epoch [186/300], Batch Step [290/323], D_loss: 0.5769,  G_loss: 1.4761\n",
      " Epoch [186/300], Batch Step [300/323], D_loss: 0.4846,  G_loss: 1.5839\n",
      " Epoch [186/300], Batch Step [310/323], D_loss: 0.5468,  G_loss: 1.5477\n",
      " Epoch [186/300], Batch Step [320/323], D_loss: 0.6583,  G_loss: 1.6520\n",
      " Epoch [187/300], Batch Step [0/323], D_loss: 0.6992,  G_loss: 1.7721\n",
      " Epoch [187/300], Batch Step [10/323], D_loss: 0.5492,  G_loss: 1.6249\n",
      " Epoch [187/300], Batch Step [20/323], D_loss: 0.5717,  G_loss: 1.6652\n",
      " Epoch [187/300], Batch Step [30/323], D_loss: 0.4742,  G_loss: 1.7201\n",
      " Epoch [187/300], Batch Step [40/323], D_loss: 0.6753,  G_loss: 1.4217\n",
      " Epoch [187/300], Batch Step [50/323], D_loss: 0.8126,  G_loss: 1.8117\n",
      " Epoch [187/300], Batch Step [60/323], D_loss: 0.6455,  G_loss: 1.6404\n",
      " Epoch [187/300], Batch Step [70/323], D_loss: 0.7084,  G_loss: 1.4992\n",
      " Epoch [187/300], Batch Step [80/323], D_loss: 0.5635,  G_loss: 1.6038\n",
      " Epoch [187/300], Batch Step [90/323], D_loss: 0.7870,  G_loss: 1.6628\n",
      " Epoch [187/300], Batch Step [100/323], D_loss: 0.5743,  G_loss: 1.5981\n",
      " Epoch [187/300], Batch Step [110/323], D_loss: 0.6060,  G_loss: 1.6098\n",
      " Epoch [187/300], Batch Step [120/323], D_loss: 0.5893,  G_loss: 1.7576\n",
      " Epoch [187/300], Batch Step [130/323], D_loss: 0.5453,  G_loss: 1.5806\n",
      " Epoch [187/300], Batch Step [140/323], D_loss: 0.5666,  G_loss: 1.6138\n",
      " Epoch [187/300], Batch Step [150/323], D_loss: 0.5471,  G_loss: 1.5955\n",
      " Epoch [187/300], Batch Step [160/323], D_loss: 0.6668,  G_loss: 1.4428\n",
      " Epoch [187/300], Batch Step [170/323], D_loss: 0.6876,  G_loss: 1.6234\n",
      " Epoch [187/300], Batch Step [180/323], D_loss: 0.5794,  G_loss: 1.6108\n",
      " Epoch [187/300], Batch Step [190/323], D_loss: 0.6114,  G_loss: 1.5617\n",
      " Epoch [187/300], Batch Step [200/323], D_loss: 0.7345,  G_loss: 1.5776\n",
      " Epoch [187/300], Batch Step [210/323], D_loss: 0.8819,  G_loss: 1.6509\n",
      " Epoch [187/300], Batch Step [220/323], D_loss: 0.6956,  G_loss: 1.5434\n",
      " Epoch [187/300], Batch Step [230/323], D_loss: 0.7534,  G_loss: 1.6555\n",
      " Epoch [187/300], Batch Step [240/323], D_loss: 0.7110,  G_loss: 1.5127\n",
      " Epoch [187/300], Batch Step [250/323], D_loss: 0.7384,  G_loss: 1.6215\n",
      " Epoch [187/300], Batch Step [260/323], D_loss: 0.5995,  G_loss: 1.5830\n",
      " Epoch [187/300], Batch Step [270/323], D_loss: 0.8666,  G_loss: 1.6795\n",
      " Epoch [187/300], Batch Step [280/323], D_loss: 0.6644,  G_loss: 1.4745\n",
      " Epoch [187/300], Batch Step [290/323], D_loss: 0.7542,  G_loss: 1.6553\n",
      " Epoch [187/300], Batch Step [300/323], D_loss: 0.6811,  G_loss: 1.5323\n",
      " Epoch [187/300], Batch Step [310/323], D_loss: 0.7403,  G_loss: 1.6632\n",
      " Epoch [187/300], Batch Step [320/323], D_loss: 0.4909,  G_loss: 1.6937\n",
      " Epoch [188/300], Batch Step [0/323], D_loss: 0.7919,  G_loss: 1.5922\n",
      " Epoch [188/300], Batch Step [10/323], D_loss: 0.6335,  G_loss: 1.5452\n",
      " Epoch [188/300], Batch Step [20/323], D_loss: 0.4771,  G_loss: 1.7203\n",
      " Epoch [188/300], Batch Step [30/323], D_loss: 0.7745,  G_loss: 1.6634\n",
      " Epoch [188/300], Batch Step [40/323], D_loss: 0.6749,  G_loss: 1.6005\n",
      " Epoch [188/300], Batch Step [50/323], D_loss: 0.5741,  G_loss: 1.6340\n",
      " Epoch [188/300], Batch Step [60/323], D_loss: 0.7621,  G_loss: 1.6554\n",
      " Epoch [188/300], Batch Step [70/323], D_loss: 0.5892,  G_loss: 1.4921\n",
      " Epoch [188/300], Batch Step [80/323], D_loss: 0.5792,  G_loss: 1.5711\n",
      " Epoch [188/300], Batch Step [90/323], D_loss: 0.7324,  G_loss: 1.4049\n",
      " Epoch [188/300], Batch Step [100/323], D_loss: 0.5693,  G_loss: 1.7027\n",
      " Epoch [188/300], Batch Step [110/323], D_loss: 0.7012,  G_loss: 1.5725\n",
      " Epoch [188/300], Batch Step [120/323], D_loss: 0.4796,  G_loss: 1.5832\n",
      " Epoch [188/300], Batch Step [130/323], D_loss: 0.6300,  G_loss: 1.6246\n",
      " Epoch [188/300], Batch Step [140/323], D_loss: 0.6188,  G_loss: 1.5903\n",
      " Epoch [188/300], Batch Step [150/323], D_loss: 0.6527,  G_loss: 1.7718\n",
      " Epoch [188/300], Batch Step [160/323], D_loss: 0.7513,  G_loss: 1.4776\n",
      " Epoch [188/300], Batch Step [170/323], D_loss: 0.5510,  G_loss: 1.5822\n",
      " Epoch [188/300], Batch Step [180/323], D_loss: 0.5196,  G_loss: 1.7390\n",
      " Epoch [188/300], Batch Step [190/323], D_loss: 0.6770,  G_loss: 1.6714\n",
      " Epoch [188/300], Batch Step [200/323], D_loss: 0.7282,  G_loss: 1.5945\n",
      " Epoch [188/300], Batch Step [210/323], D_loss: 0.5253,  G_loss: 1.6636\n",
      " Epoch [188/300], Batch Step [220/323], D_loss: 0.6509,  G_loss: 1.5819\n",
      " Epoch [188/300], Batch Step [230/323], D_loss: 0.7502,  G_loss: 1.4922\n",
      " Epoch [188/300], Batch Step [240/323], D_loss: 0.6375,  G_loss: 1.5609\n",
      " Epoch [188/300], Batch Step [250/323], D_loss: 0.5665,  G_loss: 1.6298\n",
      " Epoch [188/300], Batch Step [260/323], D_loss: 0.5807,  G_loss: 1.6136\n",
      " Epoch [188/300], Batch Step [270/323], D_loss: 0.6827,  G_loss: 1.6435\n",
      " Epoch [188/300], Batch Step [280/323], D_loss: 0.5789,  G_loss: 1.5762\n",
      " Epoch [188/300], Batch Step [290/323], D_loss: 0.6027,  G_loss: 1.7509\n",
      " Epoch [188/300], Batch Step [300/323], D_loss: 0.5505,  G_loss: 1.6767\n",
      " Epoch [188/300], Batch Step [310/323], D_loss: 0.6898,  G_loss: 1.5538\n",
      " Epoch [188/300], Batch Step [320/323], D_loss: 0.6791,  G_loss: 1.6762\n",
      " Epoch [189/300], Batch Step [0/323], D_loss: 0.9337,  G_loss: 1.5512\n",
      " Epoch [189/300], Batch Step [10/323], D_loss: 0.6703,  G_loss: 1.5925\n",
      " Epoch [189/300], Batch Step [20/323], D_loss: 0.6884,  G_loss: 1.5488\n",
      " Epoch [189/300], Batch Step [30/323], D_loss: 0.4867,  G_loss: 1.5405\n",
      " Epoch [189/300], Batch Step [40/323], D_loss: 0.6220,  G_loss: 1.7165\n",
      " Epoch [189/300], Batch Step [50/323], D_loss: 0.5654,  G_loss: 1.4175\n",
      " Epoch [189/300], Batch Step [60/323], D_loss: 0.5685,  G_loss: 1.5906\n",
      " Epoch [189/300], Batch Step [70/323], D_loss: 0.7431,  G_loss: 1.6939\n",
      " Epoch [189/300], Batch Step [80/323], D_loss: 0.6523,  G_loss: 1.4719\n",
      " Epoch [189/300], Batch Step [90/323], D_loss: 0.6241,  G_loss: 1.6321\n",
      " Epoch [189/300], Batch Step [100/323], D_loss: 0.5809,  G_loss: 1.5503\n",
      " Epoch [189/300], Batch Step [110/323], D_loss: 0.6597,  G_loss: 1.5856\n",
      " Epoch [189/300], Batch Step [120/323], D_loss: 0.4239,  G_loss: 1.6575\n",
      " Epoch [189/300], Batch Step [130/323], D_loss: 0.6469,  G_loss: 1.6231\n",
      " Epoch [189/300], Batch Step [140/323], D_loss: 0.5846,  G_loss: 1.6737\n",
      " Epoch [189/300], Batch Step [150/323], D_loss: 0.6285,  G_loss: 1.5861\n",
      " Epoch [189/300], Batch Step [160/323], D_loss: 0.6629,  G_loss: 1.6628\n",
      " Epoch [189/300], Batch Step [170/323], D_loss: 0.6130,  G_loss: 1.4700\n",
      " Epoch [189/300], Batch Step [180/323], D_loss: 0.8518,  G_loss: 1.6407\n",
      " Epoch [189/300], Batch Step [190/323], D_loss: 0.6717,  G_loss: 1.6362\n",
      " Epoch [189/300], Batch Step [200/323], D_loss: 0.8337,  G_loss: 1.4815\n",
      " Epoch [189/300], Batch Step [210/323], D_loss: 0.7155,  G_loss: 1.6120\n",
      " Epoch [189/300], Batch Step [220/323], D_loss: 0.6964,  G_loss: 1.6403\n",
      " Epoch [189/300], Batch Step [230/323], D_loss: 0.7573,  G_loss: 1.7085\n",
      " Epoch [189/300], Batch Step [240/323], D_loss: 0.7027,  G_loss: 1.4933\n",
      " Epoch [189/300], Batch Step [250/323], D_loss: 0.6340,  G_loss: 1.6038\n",
      " Epoch [189/300], Batch Step [260/323], D_loss: 0.6336,  G_loss: 1.6574\n",
      " Epoch [189/300], Batch Step [270/323], D_loss: 0.6016,  G_loss: 1.5535\n",
      " Epoch [189/300], Batch Step [280/323], D_loss: 0.7695,  G_loss: 1.6101\n",
      " Epoch [189/300], Batch Step [290/323], D_loss: 0.5991,  G_loss: 1.4976\n",
      " Epoch [189/300], Batch Step [300/323], D_loss: 0.5804,  G_loss: 1.6202\n",
      " Epoch [189/300], Batch Step [310/323], D_loss: 0.6015,  G_loss: 1.5457\n",
      " Epoch [189/300], Batch Step [320/323], D_loss: 0.6853,  G_loss: 1.7081\n",
      " Epoch [190/300], Batch Step [0/323], D_loss: 0.5892,  G_loss: 1.6578\n",
      " Epoch [190/300], Batch Step [10/323], D_loss: 0.6084,  G_loss: 1.5722\n",
      " Epoch [190/300], Batch Step [20/323], D_loss: 0.6547,  G_loss: 1.6831\n",
      " Epoch [190/300], Batch Step [30/323], D_loss: 0.6969,  G_loss: 1.6599\n",
      " Epoch [190/300], Batch Step [40/323], D_loss: 0.6380,  G_loss: 1.5064\n",
      " Epoch [190/300], Batch Step [50/323], D_loss: 0.6897,  G_loss: 1.6211\n",
      " Epoch [190/300], Batch Step [60/323], D_loss: 0.7186,  G_loss: 1.5110\n",
      " Epoch [190/300], Batch Step [70/323], D_loss: 0.5290,  G_loss: 1.5708\n",
      " Epoch [190/300], Batch Step [80/323], D_loss: 0.6573,  G_loss: 1.5114\n",
      " Epoch [190/300], Batch Step [90/323], D_loss: 0.8001,  G_loss: 1.5199\n",
      " Epoch [190/300], Batch Step [100/323], D_loss: 0.6849,  G_loss: 1.5836\n",
      " Epoch [190/300], Batch Step [110/323], D_loss: 0.5927,  G_loss: 1.6309\n",
      " Epoch [190/300], Batch Step [120/323], D_loss: 0.6734,  G_loss: 1.6413\n",
      " Epoch [190/300], Batch Step [130/323], D_loss: 0.6716,  G_loss: 1.7334\n",
      " Epoch [190/300], Batch Step [140/323], D_loss: 0.5689,  G_loss: 1.6467\n",
      " Epoch [190/300], Batch Step [150/323], D_loss: 0.6231,  G_loss: 1.6086\n",
      " Epoch [190/300], Batch Step [160/323], D_loss: 0.6138,  G_loss: 1.5162\n",
      " Epoch [190/300], Batch Step [170/323], D_loss: 0.6568,  G_loss: 1.7284\n",
      " Epoch [190/300], Batch Step [180/323], D_loss: 0.6280,  G_loss: 1.4577\n",
      " Epoch [190/300], Batch Step [190/323], D_loss: 0.9007,  G_loss: 1.6258\n",
      " Epoch [190/300], Batch Step [200/323], D_loss: 0.4554,  G_loss: 1.6033\n",
      " Epoch [190/300], Batch Step [210/323], D_loss: 0.6642,  G_loss: 1.6025\n",
      " Epoch [190/300], Batch Step [220/323], D_loss: 0.8476,  G_loss: 1.7423\n",
      " Epoch [190/300], Batch Step [230/323], D_loss: 0.6254,  G_loss: 1.5818\n",
      " Epoch [190/300], Batch Step [240/323], D_loss: 0.6741,  G_loss: 1.6786\n",
      " Epoch [190/300], Batch Step [250/323], D_loss: 0.6017,  G_loss: 1.7058\n",
      " Epoch [190/300], Batch Step [260/323], D_loss: 0.6941,  G_loss: 1.5903\n",
      " Epoch [190/300], Batch Step [270/323], D_loss: 0.6351,  G_loss: 1.5487\n",
      " Epoch [190/300], Batch Step [280/323], D_loss: 0.5791,  G_loss: 1.8231\n",
      " Epoch [190/300], Batch Step [290/323], D_loss: 0.6212,  G_loss: 1.4276\n",
      " Epoch [190/300], Batch Step [300/323], D_loss: 0.6229,  G_loss: 1.5272\n",
      " Epoch [190/300], Batch Step [310/323], D_loss: 0.6622,  G_loss: 1.5108\n",
      " Epoch [190/300], Batch Step [320/323], D_loss: 0.5102,  G_loss: 1.6251\n",
      " Epoch [191/300], Batch Step [0/323], D_loss: 0.6128,  G_loss: 1.6263\n",
      " Epoch [191/300], Batch Step [10/323], D_loss: 0.5882,  G_loss: 1.6382\n",
      " Epoch [191/300], Batch Step [20/323], D_loss: 0.6323,  G_loss: 1.5153\n",
      " Epoch [191/300], Batch Step [30/323], D_loss: 0.7653,  G_loss: 1.5780\n",
      " Epoch [191/300], Batch Step [40/323], D_loss: 0.6674,  G_loss: 1.5376\n",
      " Epoch [191/300], Batch Step [50/323], D_loss: 0.6670,  G_loss: 1.6808\n",
      " Epoch [191/300], Batch Step [60/323], D_loss: 0.6725,  G_loss: 1.6830\n",
      " Epoch [191/300], Batch Step [70/323], D_loss: 0.6281,  G_loss: 1.5949\n",
      " Epoch [191/300], Batch Step [80/323], D_loss: 0.6138,  G_loss: 1.6134\n",
      " Epoch [191/300], Batch Step [90/323], D_loss: 0.6189,  G_loss: 1.7425\n",
      " Epoch [191/300], Batch Step [100/323], D_loss: 0.5270,  G_loss: 1.6200\n",
      " Epoch [191/300], Batch Step [110/323], D_loss: 0.6706,  G_loss: 1.5263\n",
      " Epoch [191/300], Batch Step [120/323], D_loss: 0.6380,  G_loss: 1.6201\n",
      " Epoch [191/300], Batch Step [130/323], D_loss: 0.7186,  G_loss: 1.5804\n",
      " Epoch [191/300], Batch Step [140/323], D_loss: 0.6865,  G_loss: 1.6022\n",
      " Epoch [191/300], Batch Step [150/323], D_loss: 0.7287,  G_loss: 1.6120\n",
      " Epoch [191/300], Batch Step [160/323], D_loss: 0.5237,  G_loss: 1.5635\n",
      " Epoch [191/300], Batch Step [170/323], D_loss: 0.6852,  G_loss: 1.7099\n",
      " Epoch [191/300], Batch Step [180/323], D_loss: 0.6231,  G_loss: 1.4728\n",
      " Epoch [191/300], Batch Step [190/323], D_loss: 0.7025,  G_loss: 1.7777\n",
      " Epoch [191/300], Batch Step [200/323], D_loss: 0.6381,  G_loss: 1.5710\n",
      " Epoch [191/300], Batch Step [210/323], D_loss: 0.5698,  G_loss: 1.5109\n",
      " Epoch [191/300], Batch Step [220/323], D_loss: 0.7384,  G_loss: 1.6184\n",
      " Epoch [191/300], Batch Step [230/323], D_loss: 0.6383,  G_loss: 1.5408\n",
      " Epoch [191/300], Batch Step [240/323], D_loss: 0.6101,  G_loss: 1.6028\n",
      " Epoch [191/300], Batch Step [250/323], D_loss: 0.7827,  G_loss: 1.6783\n",
      " Epoch [191/300], Batch Step [260/323], D_loss: 0.5732,  G_loss: 1.5407\n",
      " Epoch [191/300], Batch Step [270/323], D_loss: 0.5767,  G_loss: 1.7334\n",
      " Epoch [191/300], Batch Step [280/323], D_loss: 0.6943,  G_loss: 1.4523\n",
      " Epoch [191/300], Batch Step [290/323], D_loss: 0.6621,  G_loss: 1.5877\n",
      " Epoch [191/300], Batch Step [300/323], D_loss: 0.6223,  G_loss: 1.7069\n",
      " Epoch [191/300], Batch Step [310/323], D_loss: 0.6975,  G_loss: 1.5677\n",
      " Epoch [191/300], Batch Step [320/323], D_loss: 0.7998,  G_loss: 1.4806\n",
      " Epoch [192/300], Batch Step [0/323], D_loss: 0.5308,  G_loss: 1.4803\n",
      " Epoch [192/300], Batch Step [10/323], D_loss: 0.5781,  G_loss: 1.6409\n",
      " Epoch [192/300], Batch Step [20/323], D_loss: 0.5582,  G_loss: 1.6022\n",
      " Epoch [192/300], Batch Step [30/323], D_loss: 0.7967,  G_loss: 1.4825\n",
      " Epoch [192/300], Batch Step [40/323], D_loss: 0.5857,  G_loss: 1.5165\n",
      " Epoch [192/300], Batch Step [50/323], D_loss: 0.6598,  G_loss: 1.6132\n",
      " Epoch [192/300], Batch Step [60/323], D_loss: 0.5622,  G_loss: 1.5943\n",
      " Epoch [192/300], Batch Step [70/323], D_loss: 0.5947,  G_loss: 1.6104\n",
      " Epoch [192/300], Batch Step [80/323], D_loss: 0.5152,  G_loss: 1.5946\n",
      " Epoch [192/300], Batch Step [90/323], D_loss: 0.6349,  G_loss: 1.5618\n",
      " Epoch [192/300], Batch Step [100/323], D_loss: 0.6725,  G_loss: 1.6133\n",
      " Epoch [192/300], Batch Step [110/323], D_loss: 0.7894,  G_loss: 1.6373\n",
      " Epoch [192/300], Batch Step [120/323], D_loss: 0.5508,  G_loss: 1.6692\n",
      " Epoch [192/300], Batch Step [130/323], D_loss: 0.6231,  G_loss: 1.6878\n",
      " Epoch [192/300], Batch Step [140/323], D_loss: 0.6391,  G_loss: 1.6198\n",
      " Epoch [192/300], Batch Step [150/323], D_loss: 0.7146,  G_loss: 1.4944\n",
      " Epoch [192/300], Batch Step [160/323], D_loss: 0.6758,  G_loss: 1.6513\n",
      " Epoch [192/300], Batch Step [170/323], D_loss: 0.6812,  G_loss: 1.5386\n",
      " Epoch [192/300], Batch Step [180/323], D_loss: 0.6450,  G_loss: 1.6330\n",
      " Epoch [192/300], Batch Step [190/323], D_loss: 0.5050,  G_loss: 1.6653\n",
      " Epoch [192/300], Batch Step [200/323], D_loss: 0.8051,  G_loss: 1.5072\n",
      " Epoch [192/300], Batch Step [210/323], D_loss: 0.6901,  G_loss: 1.6447\n",
      " Epoch [192/300], Batch Step [220/323], D_loss: 0.6568,  G_loss: 1.5458\n",
      " Epoch [192/300], Batch Step [230/323], D_loss: 0.6613,  G_loss: 1.4774\n",
      " Epoch [192/300], Batch Step [240/323], D_loss: 0.6893,  G_loss: 1.4996\n",
      " Epoch [192/300], Batch Step [250/323], D_loss: 0.6172,  G_loss: 1.6443\n",
      " Epoch [192/300], Batch Step [260/323], D_loss: 0.5279,  G_loss: 1.7730\n",
      " Epoch [192/300], Batch Step [270/323], D_loss: 0.5694,  G_loss: 1.5114\n",
      " Epoch [192/300], Batch Step [280/323], D_loss: 0.5305,  G_loss: 1.6666\n",
      " Epoch [192/300], Batch Step [290/323], D_loss: 0.7104,  G_loss: 1.5861\n",
      " Epoch [192/300], Batch Step [300/323], D_loss: 0.6671,  G_loss: 1.4696\n",
      " Epoch [192/300], Batch Step [310/323], D_loss: 0.6393,  G_loss: 1.6282\n",
      " Epoch [192/300], Batch Step [320/323], D_loss: 0.5018,  G_loss: 1.6959\n",
      " Epoch [193/300], Batch Step [0/323], D_loss: 0.6590,  G_loss: 1.5674\n",
      " Epoch [193/300], Batch Step [10/323], D_loss: 0.6380,  G_loss: 1.5524\n",
      " Epoch [193/300], Batch Step [20/323], D_loss: 0.7498,  G_loss: 1.5865\n",
      " Epoch [193/300], Batch Step [30/323], D_loss: 0.6458,  G_loss: 1.5975\n",
      " Epoch [193/300], Batch Step [40/323], D_loss: 0.7100,  G_loss: 1.5374\n",
      " Epoch [193/300], Batch Step [50/323], D_loss: 0.5661,  G_loss: 1.5992\n",
      " Epoch [193/300], Batch Step [60/323], D_loss: 0.5130,  G_loss: 1.4823\n",
      " Epoch [193/300], Batch Step [70/323], D_loss: 0.7416,  G_loss: 1.8355\n",
      " Epoch [193/300], Batch Step [80/323], D_loss: 0.6945,  G_loss: 1.4316\n",
      " Epoch [193/300], Batch Step [90/323], D_loss: 0.6844,  G_loss: 1.7403\n",
      " Epoch [193/300], Batch Step [100/323], D_loss: 0.6332,  G_loss: 1.5818\n",
      " Epoch [193/300], Batch Step [110/323], D_loss: 0.6349,  G_loss: 1.6605\n",
      " Epoch [193/300], Batch Step [120/323], D_loss: 0.4817,  G_loss: 1.5361\n",
      " Epoch [193/300], Batch Step [130/323], D_loss: 0.5870,  G_loss: 1.6450\n",
      " Epoch [193/300], Batch Step [140/323], D_loss: 0.4678,  G_loss: 1.5489\n",
      " Epoch [193/300], Batch Step [150/323], D_loss: 0.6940,  G_loss: 1.6191\n",
      " Epoch [193/300], Batch Step [160/323], D_loss: 0.6962,  G_loss: 1.6544\n",
      " Epoch [193/300], Batch Step [170/323], D_loss: 0.8371,  G_loss: 1.5190\n",
      " Epoch [193/300], Batch Step [180/323], D_loss: 0.7049,  G_loss: 1.6416\n",
      " Epoch [193/300], Batch Step [190/323], D_loss: 0.6776,  G_loss: 1.5518\n",
      " Epoch [193/300], Batch Step [200/323], D_loss: 0.4709,  G_loss: 1.6845\n",
      " Epoch [193/300], Batch Step [210/323], D_loss: 0.7162,  G_loss: 1.5954\n",
      " Epoch [193/300], Batch Step [220/323], D_loss: 0.6717,  G_loss: 1.6205\n",
      " Epoch [193/300], Batch Step [230/323], D_loss: 0.6472,  G_loss: 1.5144\n",
      " Epoch [193/300], Batch Step [240/323], D_loss: 0.7917,  G_loss: 1.6728\n",
      " Epoch [193/300], Batch Step [250/323], D_loss: 0.7238,  G_loss: 1.5514\n",
      " Epoch [193/300], Batch Step [260/323], D_loss: 0.5082,  G_loss: 1.6044\n",
      " Epoch [193/300], Batch Step [270/323], D_loss: 0.7017,  G_loss: 1.6351\n",
      " Epoch [193/300], Batch Step [280/323], D_loss: 0.5649,  G_loss: 1.6076\n",
      " Epoch [193/300], Batch Step [290/323], D_loss: 0.6129,  G_loss: 1.7495\n",
      " Epoch [193/300], Batch Step [300/323], D_loss: 0.5918,  G_loss: 1.5974\n",
      " Epoch [193/300], Batch Step [310/323], D_loss: 0.5218,  G_loss: 1.5288\n",
      " Epoch [193/300], Batch Step [320/323], D_loss: 0.6554,  G_loss: 1.6658\n",
      " Epoch [194/300], Batch Step [0/323], D_loss: 0.6640,  G_loss: 1.6040\n",
      " Epoch [194/300], Batch Step [10/323], D_loss: 0.6191,  G_loss: 1.5802\n",
      " Epoch [194/300], Batch Step [20/323], D_loss: 0.8928,  G_loss: 1.7272\n",
      " Epoch [194/300], Batch Step [30/323], D_loss: 0.6414,  G_loss: 1.4156\n",
      " Epoch [194/300], Batch Step [40/323], D_loss: 0.6310,  G_loss: 1.5435\n",
      " Epoch [194/300], Batch Step [50/323], D_loss: 0.8361,  G_loss: 1.5662\n",
      " Epoch [194/300], Batch Step [60/323], D_loss: 0.5900,  G_loss: 1.4819\n",
      " Epoch [194/300], Batch Step [70/323], D_loss: 0.6171,  G_loss: 1.6386\n",
      " Epoch [194/300], Batch Step [80/323], D_loss: 0.8748,  G_loss: 1.7574\n",
      " Epoch [194/300], Batch Step [90/323], D_loss: 0.5406,  G_loss: 1.6219\n",
      " Epoch [194/300], Batch Step [100/323], D_loss: 0.5888,  G_loss: 1.6142\n",
      " Epoch [194/300], Batch Step [110/323], D_loss: 0.6886,  G_loss: 1.5428\n",
      " Epoch [194/300], Batch Step [120/323], D_loss: 0.6955,  G_loss: 1.6127\n",
      " Epoch [194/300], Batch Step [130/323], D_loss: 0.6735,  G_loss: 1.6733\n",
      " Epoch [194/300], Batch Step [140/323], D_loss: 0.5306,  G_loss: 1.5600\n",
      " Epoch [194/300], Batch Step [150/323], D_loss: 0.6262,  G_loss: 1.5824\n",
      " Epoch [194/300], Batch Step [160/323], D_loss: 0.6004,  G_loss: 1.6708\n",
      " Epoch [194/300], Batch Step [170/323], D_loss: 0.7675,  G_loss: 1.4693\n",
      " Epoch [194/300], Batch Step [180/323], D_loss: 0.5434,  G_loss: 1.5080\n",
      " Epoch [194/300], Batch Step [190/323], D_loss: 0.6240,  G_loss: 1.4991\n",
      " Epoch [194/300], Batch Step [200/323], D_loss: 0.6071,  G_loss: 1.5754\n",
      " Epoch [194/300], Batch Step [210/323], D_loss: 0.6350,  G_loss: 1.6823\n",
      " Epoch [194/300], Batch Step [220/323], D_loss: 0.7312,  G_loss: 1.6292\n",
      " Epoch [194/300], Batch Step [230/323], D_loss: 0.5485,  G_loss: 1.4740\n",
      " Epoch [194/300], Batch Step [240/323], D_loss: 0.6320,  G_loss: 1.7942\n",
      " Epoch [194/300], Batch Step [250/323], D_loss: 0.6244,  G_loss: 1.6397\n",
      " Epoch [194/300], Batch Step [260/323], D_loss: 0.5572,  G_loss: 1.5787\n",
      " Epoch [194/300], Batch Step [270/323], D_loss: 0.6002,  G_loss: 1.6453\n",
      " Epoch [194/300], Batch Step [280/323], D_loss: 0.6216,  G_loss: 1.5432\n",
      " Epoch [194/300], Batch Step [290/323], D_loss: 0.6446,  G_loss: 1.6811\n",
      " Epoch [194/300], Batch Step [300/323], D_loss: 0.6394,  G_loss: 1.5065\n",
      " Epoch [194/300], Batch Step [310/323], D_loss: 0.6794,  G_loss: 1.6739\n",
      " Epoch [194/300], Batch Step [320/323], D_loss: 0.6145,  G_loss: 1.5290\n",
      " Epoch [195/300], Batch Step [0/323], D_loss: 0.7638,  G_loss: 1.5718\n",
      " Epoch [195/300], Batch Step [10/323], D_loss: 0.7965,  G_loss: 1.6096\n",
      " Epoch [195/300], Batch Step [20/323], D_loss: 0.6695,  G_loss: 1.5146\n",
      " Epoch [195/300], Batch Step [30/323], D_loss: 0.5541,  G_loss: 1.7754\n",
      " Epoch [195/300], Batch Step [40/323], D_loss: 0.7705,  G_loss: 1.5336\n",
      " Epoch [195/300], Batch Step [50/323], D_loss: 0.7584,  G_loss: 1.4205\n",
      " Epoch [195/300], Batch Step [60/323], D_loss: 0.6512,  G_loss: 1.4942\n",
      " Epoch [195/300], Batch Step [70/323], D_loss: 0.6998,  G_loss: 1.6951\n",
      " Epoch [195/300], Batch Step [80/323], D_loss: 0.7339,  G_loss: 1.5422\n",
      " Epoch [195/300], Batch Step [90/323], D_loss: 0.6546,  G_loss: 1.5898\n",
      " Epoch [195/300], Batch Step [100/323], D_loss: 0.5119,  G_loss: 1.5965\n",
      " Epoch [195/300], Batch Step [110/323], D_loss: 0.6892,  G_loss: 1.5836\n",
      " Epoch [195/300], Batch Step [120/323], D_loss: 0.6056,  G_loss: 1.7468\n",
      " Epoch [195/300], Batch Step [130/323], D_loss: 0.6589,  G_loss: 1.6448\n",
      " Epoch [195/300], Batch Step [140/323], D_loss: 0.6458,  G_loss: 1.5994\n",
      " Epoch [195/300], Batch Step [150/323], D_loss: 0.8212,  G_loss: 1.5640\n",
      " Epoch [195/300], Batch Step [160/323], D_loss: 0.6785,  G_loss: 1.4901\n",
      " Epoch [195/300], Batch Step [170/323], D_loss: 0.7363,  G_loss: 1.6738\n",
      " Epoch [195/300], Batch Step [180/323], D_loss: 0.5793,  G_loss: 1.5959\n",
      " Epoch [195/300], Batch Step [190/323], D_loss: 0.6309,  G_loss: 1.5616\n",
      " Epoch [195/300], Batch Step [200/323], D_loss: 0.6549,  G_loss: 1.5430\n",
      " Epoch [195/300], Batch Step [210/323], D_loss: 0.7076,  G_loss: 1.5857\n",
      " Epoch [195/300], Batch Step [220/323], D_loss: 0.6266,  G_loss: 1.6534\n",
      " Epoch [195/300], Batch Step [230/323], D_loss: 0.5829,  G_loss: 1.5527\n",
      " Epoch [195/300], Batch Step [240/323], D_loss: 0.5526,  G_loss: 1.7774\n",
      " Epoch [195/300], Batch Step [250/323], D_loss: 0.5472,  G_loss: 1.5943\n",
      " Epoch [195/300], Batch Step [260/323], D_loss: 0.7184,  G_loss: 1.6659\n",
      " Epoch [195/300], Batch Step [270/323], D_loss: 0.7438,  G_loss: 1.5511\n",
      " Epoch [195/300], Batch Step [280/323], D_loss: 0.6516,  G_loss: 1.6145\n",
      " Epoch [195/300], Batch Step [290/323], D_loss: 0.6837,  G_loss: 1.5962\n",
      " Epoch [195/300], Batch Step [300/323], D_loss: 0.6945,  G_loss: 1.4784\n",
      " Epoch [195/300], Batch Step [310/323], D_loss: 0.7334,  G_loss: 1.6610\n",
      " Epoch [195/300], Batch Step [320/323], D_loss: 0.7252,  G_loss: 1.5017\n",
      " Epoch [196/300], Batch Step [0/323], D_loss: 0.6493,  G_loss: 1.5419\n",
      " Epoch [196/300], Batch Step [10/323], D_loss: 0.6893,  G_loss: 1.7608\n",
      " Epoch [196/300], Batch Step [20/323], D_loss: 0.6354,  G_loss: 1.5565\n",
      " Epoch [196/300], Batch Step [30/323], D_loss: 0.6785,  G_loss: 1.5746\n",
      " Epoch [196/300], Batch Step [40/323], D_loss: 0.7013,  G_loss: 1.6760\n",
      " Epoch [196/300], Batch Step [50/323], D_loss: 0.6060,  G_loss: 1.6163\n",
      " Epoch [196/300], Batch Step [60/323], D_loss: 0.6271,  G_loss: 1.5645\n",
      " Epoch [196/300], Batch Step [70/323], D_loss: 0.5802,  G_loss: 1.6459\n",
      " Epoch [196/300], Batch Step [80/323], D_loss: 0.5937,  G_loss: 1.4870\n",
      " Epoch [196/300], Batch Step [90/323], D_loss: 0.6150,  G_loss: 1.6571\n",
      " Epoch [196/300], Batch Step [100/323], D_loss: 0.7591,  G_loss: 1.5248\n",
      " Epoch [196/300], Batch Step [110/323], D_loss: 0.6245,  G_loss: 1.6042\n",
      " Epoch [196/300], Batch Step [120/323], D_loss: 0.8118,  G_loss: 1.5849\n",
      " Epoch [196/300], Batch Step [130/323], D_loss: 0.7296,  G_loss: 1.6214\n",
      " Epoch [196/300], Batch Step [140/323], D_loss: 0.5999,  G_loss: 1.5771\n",
      " Epoch [196/300], Batch Step [150/323], D_loss: 0.7926,  G_loss: 1.5879\n",
      " Epoch [196/300], Batch Step [160/323], D_loss: 0.6018,  G_loss: 1.5932\n",
      " Epoch [196/300], Batch Step [170/323], D_loss: 0.7086,  G_loss: 1.6296\n",
      " Epoch [196/300], Batch Step [180/323], D_loss: 0.5338,  G_loss: 1.5399\n",
      " Epoch [196/300], Batch Step [190/323], D_loss: 0.6582,  G_loss: 1.6146\n",
      " Epoch [196/300], Batch Step [200/323], D_loss: 0.5252,  G_loss: 1.5066\n",
      " Epoch [196/300], Batch Step [210/323], D_loss: 0.5274,  G_loss: 1.6600\n",
      " Epoch [196/300], Batch Step [220/323], D_loss: 0.5756,  G_loss: 1.6077\n",
      " Epoch [196/300], Batch Step [230/323], D_loss: 0.7544,  G_loss: 1.7117\n",
      " Epoch [196/300], Batch Step [240/323], D_loss: 0.6198,  G_loss: 1.4811\n",
      " Epoch [196/300], Batch Step [250/323], D_loss: 0.6540,  G_loss: 1.6090\n",
      " Epoch [196/300], Batch Step [260/323], D_loss: 0.8088,  G_loss: 1.5563\n",
      " Epoch [196/300], Batch Step [270/323], D_loss: 0.6046,  G_loss: 1.4637\n",
      " Epoch [196/300], Batch Step [280/323], D_loss: 0.6254,  G_loss: 1.7448\n",
      " Epoch [196/300], Batch Step [290/323], D_loss: 0.6107,  G_loss: 1.6936\n",
      " Epoch [196/300], Batch Step [300/323], D_loss: 0.6593,  G_loss: 1.7539\n",
      " Epoch [196/300], Batch Step [310/323], D_loss: 0.6758,  G_loss: 1.6192\n",
      " Epoch [196/300], Batch Step [320/323], D_loss: 0.6340,  G_loss: 1.5569\n",
      " Epoch [197/300], Batch Step [0/323], D_loss: 0.7107,  G_loss: 1.5229\n",
      " Epoch [197/300], Batch Step [10/323], D_loss: 0.6127,  G_loss: 1.5471\n",
      " Epoch [197/300], Batch Step [20/323], D_loss: 0.6535,  G_loss: 1.6314\n",
      " Epoch [197/300], Batch Step [30/323], D_loss: 0.5105,  G_loss: 1.4638\n",
      " Epoch [197/300], Batch Step [40/323], D_loss: 0.6534,  G_loss: 1.6663\n",
      " Epoch [197/300], Batch Step [50/323], D_loss: 0.6951,  G_loss: 1.5814\n",
      " Epoch [197/300], Batch Step [60/323], D_loss: 0.5889,  G_loss: 1.5346\n",
      " Epoch [197/300], Batch Step [70/323], D_loss: 0.6676,  G_loss: 1.7529\n",
      " Epoch [197/300], Batch Step [80/323], D_loss: 0.6389,  G_loss: 1.6285\n",
      " Epoch [197/300], Batch Step [90/323], D_loss: 0.7082,  G_loss: 1.6951\n",
      " Epoch [197/300], Batch Step [100/323], D_loss: 0.7215,  G_loss: 1.4187\n",
      " Epoch [197/300], Batch Step [110/323], D_loss: 0.5756,  G_loss: 1.6329\n",
      " Epoch [197/300], Batch Step [120/323], D_loss: 0.6901,  G_loss: 1.6247\n",
      " Epoch [197/300], Batch Step [130/323], D_loss: 0.6921,  G_loss: 1.5382\n",
      " Epoch [197/300], Batch Step [140/323], D_loss: 0.8664,  G_loss: 1.5510\n",
      " Epoch [197/300], Batch Step [150/323], D_loss: 0.6354,  G_loss: 1.4690\n",
      " Epoch [197/300], Batch Step [160/323], D_loss: 0.6816,  G_loss: 1.5982\n",
      " Epoch [197/300], Batch Step [170/323], D_loss: 0.8094,  G_loss: 1.5928\n",
      " Epoch [197/300], Batch Step [180/323], D_loss: 0.6466,  G_loss: 1.5597\n",
      " Epoch [197/300], Batch Step [190/323], D_loss: 0.7900,  G_loss: 1.5318\n",
      " Epoch [197/300], Batch Step [200/323], D_loss: 0.5740,  G_loss: 1.6630\n",
      " Epoch [197/300], Batch Step [210/323], D_loss: 0.5209,  G_loss: 1.6553\n",
      " Epoch [197/300], Batch Step [220/323], D_loss: 0.4980,  G_loss: 1.7862\n",
      " Epoch [197/300], Batch Step [230/323], D_loss: 0.7224,  G_loss: 1.5501\n",
      " Epoch [197/300], Batch Step [240/323], D_loss: 0.6501,  G_loss: 1.6432\n",
      " Epoch [197/300], Batch Step [250/323], D_loss: 0.6294,  G_loss: 1.7006\n",
      " Epoch [197/300], Batch Step [260/323], D_loss: 0.6346,  G_loss: 1.6600\n",
      " Epoch [197/300], Batch Step [270/323], D_loss: 0.6397,  G_loss: 1.6758\n",
      " Epoch [197/300], Batch Step [280/323], D_loss: 0.5397,  G_loss: 1.6241\n",
      " Epoch [197/300], Batch Step [290/323], D_loss: 0.6123,  G_loss: 1.7547\n",
      " Epoch [197/300], Batch Step [300/323], D_loss: 0.6240,  G_loss: 1.5389\n",
      " Epoch [197/300], Batch Step [310/323], D_loss: 0.7085,  G_loss: 1.5807\n",
      " Epoch [197/300], Batch Step [320/323], D_loss: 0.4829,  G_loss: 1.6433\n",
      " Epoch [198/300], Batch Step [0/323], D_loss: 0.6696,  G_loss: 1.6359\n",
      " Epoch [198/300], Batch Step [10/323], D_loss: 0.7353,  G_loss: 1.6881\n",
      " Epoch [198/300], Batch Step [20/323], D_loss: 0.6759,  G_loss: 1.4459\n",
      " Epoch [198/300], Batch Step [30/323], D_loss: 0.6677,  G_loss: 1.6574\n",
      " Epoch [198/300], Batch Step [40/323], D_loss: 0.6354,  G_loss: 1.6058\n",
      " Epoch [198/300], Batch Step [50/323], D_loss: 0.6554,  G_loss: 1.5081\n",
      " Epoch [198/300], Batch Step [60/323], D_loss: 0.6304,  G_loss: 1.5215\n",
      " Epoch [198/300], Batch Step [70/323], D_loss: 0.6325,  G_loss: 1.7038\n",
      " Epoch [198/300], Batch Step [80/323], D_loss: 0.6252,  G_loss: 1.4758\n",
      " Epoch [198/300], Batch Step [90/323], D_loss: 0.6426,  G_loss: 1.6564\n",
      " Epoch [198/300], Batch Step [100/323], D_loss: 0.6807,  G_loss: 1.6785\n",
      " Epoch [198/300], Batch Step [110/323], D_loss: 0.6406,  G_loss: 1.4606\n",
      " Epoch [198/300], Batch Step [120/323], D_loss: 0.7187,  G_loss: 1.8408\n",
      " Epoch [198/300], Batch Step [130/323], D_loss: 0.4679,  G_loss: 1.7192\n",
      " Epoch [198/300], Batch Step [140/323], D_loss: 0.5663,  G_loss: 1.5772\n",
      " Epoch [198/300], Batch Step [150/323], D_loss: 0.6542,  G_loss: 1.5603\n",
      " Epoch [198/300], Batch Step [160/323], D_loss: 0.5722,  G_loss: 1.6078\n",
      " Epoch [198/300], Batch Step [170/323], D_loss: 0.7614,  G_loss: 1.6098\n",
      " Epoch [198/300], Batch Step [180/323], D_loss: 0.6886,  G_loss: 1.5760\n",
      " Epoch [198/300], Batch Step [190/323], D_loss: 0.5723,  G_loss: 1.5676\n",
      " Epoch [198/300], Batch Step [200/323], D_loss: 0.6926,  G_loss: 1.5125\n",
      " Epoch [198/300], Batch Step [210/323], D_loss: 0.6704,  G_loss: 1.5441\n",
      " Epoch [198/300], Batch Step [220/323], D_loss: 0.6571,  G_loss: 1.5111\n",
      " Epoch [198/300], Batch Step [230/323], D_loss: 0.6184,  G_loss: 1.6119\n",
      " Epoch [198/300], Batch Step [240/323], D_loss: 0.6166,  G_loss: 1.4693\n",
      " Epoch [198/300], Batch Step [250/323], D_loss: 0.7410,  G_loss: 1.5940\n",
      " Epoch [198/300], Batch Step [260/323], D_loss: 0.6543,  G_loss: 1.7708\n",
      " Epoch [198/300], Batch Step [270/323], D_loss: 0.5234,  G_loss: 1.5902\n",
      " Epoch [198/300], Batch Step [280/323], D_loss: 0.6488,  G_loss: 1.7751\n",
      " Epoch [198/300], Batch Step [290/323], D_loss: 0.6786,  G_loss: 1.5800\n",
      " Epoch [198/300], Batch Step [300/323], D_loss: 0.6567,  G_loss: 1.5083\n",
      " Epoch [198/300], Batch Step [310/323], D_loss: 0.8291,  G_loss: 1.6981\n",
      " Epoch [198/300], Batch Step [320/323], D_loss: 0.5288,  G_loss: 1.6680\n",
      " Epoch [199/300], Batch Step [0/323], D_loss: 0.6675,  G_loss: 1.6895\n",
      " Epoch [199/300], Batch Step [10/323], D_loss: 0.6340,  G_loss: 1.5262\n",
      " Epoch [199/300], Batch Step [20/323], D_loss: 0.7289,  G_loss: 1.6268\n",
      " Epoch [199/300], Batch Step [30/323], D_loss: 0.5714,  G_loss: 1.6802\n",
      " Epoch [199/300], Batch Step [40/323], D_loss: 0.6506,  G_loss: 1.5170\n",
      " Epoch [199/300], Batch Step [50/323], D_loss: 0.6158,  G_loss: 1.5505\n",
      " Epoch [199/300], Batch Step [60/323], D_loss: 0.5621,  G_loss: 1.4894\n",
      " Epoch [199/300], Batch Step [70/323], D_loss: 0.5511,  G_loss: 1.6220\n",
      " Epoch [199/300], Batch Step [80/323], D_loss: 0.6253,  G_loss: 1.5762\n",
      " Epoch [199/300], Batch Step [90/323], D_loss: 0.6659,  G_loss: 1.5391\n",
      " Epoch [199/300], Batch Step [100/323], D_loss: 0.5580,  G_loss: 1.6179\n",
      " Epoch [199/300], Batch Step [110/323], D_loss: 0.6519,  G_loss: 1.6120\n",
      " Epoch [199/300], Batch Step [120/323], D_loss: 0.5787,  G_loss: 1.6687\n",
      " Epoch [199/300], Batch Step [130/323], D_loss: 0.6433,  G_loss: 1.6409\n",
      " Epoch [199/300], Batch Step [140/323], D_loss: 0.5581,  G_loss: 1.5761\n",
      " Epoch [199/300], Batch Step [150/323], D_loss: 0.5405,  G_loss: 1.7264\n",
      " Epoch [199/300], Batch Step [160/323], D_loss: 0.5879,  G_loss: 1.6332\n",
      " Epoch [199/300], Batch Step [170/323], D_loss: 0.7502,  G_loss: 1.6679\n",
      " Epoch [199/300], Batch Step [180/323], D_loss: 0.7900,  G_loss: 1.5303\n",
      " Epoch [199/300], Batch Step [190/323], D_loss: 0.6866,  G_loss: 1.5306\n",
      " Epoch [199/300], Batch Step [200/323], D_loss: 0.4439,  G_loss: 1.5302\n",
      " Epoch [199/300], Batch Step [210/323], D_loss: 0.7547,  G_loss: 1.5654\n",
      " Epoch [199/300], Batch Step [220/323], D_loss: 0.7464,  G_loss: 1.4926\n",
      " Epoch [199/300], Batch Step [230/323], D_loss: 0.6210,  G_loss: 1.7155\n",
      " Epoch [199/300], Batch Step [240/323], D_loss: 0.6334,  G_loss: 1.6509\n",
      " Epoch [199/300], Batch Step [250/323], D_loss: 0.6525,  G_loss: 1.5753\n",
      " Epoch [199/300], Batch Step [260/323], D_loss: 0.6218,  G_loss: 1.7005\n",
      " Epoch [199/300], Batch Step [270/323], D_loss: 0.6317,  G_loss: 1.5972\n",
      " Epoch [199/300], Batch Step [280/323], D_loss: 0.7945,  G_loss: 1.7654\n",
      " Epoch [199/300], Batch Step [290/323], D_loss: 0.5540,  G_loss: 1.4975\n",
      " Epoch [199/300], Batch Step [300/323], D_loss: 0.6288,  G_loss: 1.6097\n",
      " Epoch [199/300], Batch Step [310/323], D_loss: 0.5795,  G_loss: 1.6533\n",
      " Epoch [199/300], Batch Step [320/323], D_loss: 0.6136,  G_loss: 1.5690\n",
      " Epoch [200/300], Batch Step [0/323], D_loss: 0.7893,  G_loss: 1.4985\n",
      " Epoch [200/300], Batch Step [10/323], D_loss: 0.6187,  G_loss: 1.5012\n",
      " Epoch [200/300], Batch Step [20/323], D_loss: 0.6133,  G_loss: 1.6754\n",
      " Epoch [200/300], Batch Step [30/323], D_loss: 0.3613,  G_loss: 1.6582\n",
      " Epoch [200/300], Batch Step [40/323], D_loss: 0.7079,  G_loss: 1.5626\n",
      " Epoch [200/300], Batch Step [50/323], D_loss: 0.6124,  G_loss: 1.4892\n",
      " Epoch [200/300], Batch Step [60/323], D_loss: 0.5755,  G_loss: 1.5265\n",
      " Epoch [200/300], Batch Step [70/323], D_loss: 0.5763,  G_loss: 1.5054\n",
      " Epoch [200/300], Batch Step [80/323], D_loss: 0.6709,  G_loss: 1.6098\n",
      " Epoch [200/300], Batch Step [90/323], D_loss: 0.6754,  G_loss: 1.6661\n",
      " Epoch [200/300], Batch Step [100/323], D_loss: 0.7714,  G_loss: 1.5342\n",
      " Epoch [200/300], Batch Step [110/323], D_loss: 0.5912,  G_loss: 1.6250\n",
      " Epoch [200/300], Batch Step [120/323], D_loss: 0.5092,  G_loss: 1.7454\n",
      " Epoch [200/300], Batch Step [130/323], D_loss: 0.5472,  G_loss: 1.5465\n",
      " Epoch [200/300], Batch Step [140/323], D_loss: 0.5573,  G_loss: 1.5758\n",
      " Epoch [200/300], Batch Step [150/323], D_loss: 0.6696,  G_loss: 1.7280\n",
      " Epoch [200/300], Batch Step [160/323], D_loss: 0.6851,  G_loss: 1.5370\n",
      " Epoch [200/300], Batch Step [170/323], D_loss: 0.7253,  G_loss: 1.4821\n",
      " Epoch [200/300], Batch Step [180/323], D_loss: 0.5933,  G_loss: 1.6905\n",
      " Epoch [200/300], Batch Step [190/323], D_loss: 0.7321,  G_loss: 1.6385\n",
      " Epoch [200/300], Batch Step [200/323], D_loss: 0.7920,  G_loss: 1.5334\n",
      " Epoch [200/300], Batch Step [210/323], D_loss: 0.7470,  G_loss: 1.7591\n",
      " Epoch [200/300], Batch Step [220/323], D_loss: 0.4918,  G_loss: 1.6110\n",
      " Epoch [200/300], Batch Step [230/323], D_loss: 0.5292,  G_loss: 1.6147\n",
      " Epoch [200/300], Batch Step [240/323], D_loss: 0.4490,  G_loss: 1.7034\n",
      " Epoch [200/300], Batch Step [250/323], D_loss: 0.5733,  G_loss: 1.6579\n",
      " Epoch [200/300], Batch Step [260/323], D_loss: 0.6651,  G_loss: 1.5449\n",
      " Epoch [200/300], Batch Step [270/323], D_loss: 0.6932,  G_loss: 1.5950\n",
      " Epoch [200/300], Batch Step [280/323], D_loss: 0.6189,  G_loss: 1.5120\n",
      " Epoch [200/300], Batch Step [290/323], D_loss: 0.5084,  G_loss: 1.5693\n",
      " Epoch [200/300], Batch Step [300/323], D_loss: 0.5781,  G_loss: 1.5930\n",
      " Epoch [200/300], Batch Step [310/323], D_loss: 0.6286,  G_loss: 1.4977\n",
      " Epoch [200/300], Batch Step [320/323], D_loss: 0.6919,  G_loss: 1.6029\n",
      " Epoch [201/300], Batch Step [0/323], D_loss: 0.7177,  G_loss: 1.4681\n",
      " Epoch [201/300], Batch Step [10/323], D_loss: 0.7075,  G_loss: 1.5671\n",
      " Epoch [201/300], Batch Step [20/323], D_loss: 0.6342,  G_loss: 1.7113\n",
      " Epoch [201/300], Batch Step [30/323], D_loss: 0.5309,  G_loss: 1.6799\n",
      " Epoch [201/300], Batch Step [40/323], D_loss: 0.7138,  G_loss: 1.5499\n",
      " Epoch [201/300], Batch Step [50/323], D_loss: 0.7055,  G_loss: 1.4703\n",
      " Epoch [201/300], Batch Step [60/323], D_loss: 0.5118,  G_loss: 1.7388\n",
      " Epoch [201/300], Batch Step [70/323], D_loss: 0.7658,  G_loss: 1.5566\n",
      " Epoch [201/300], Batch Step [80/323], D_loss: 0.7136,  G_loss: 1.5206\n",
      " Epoch [201/300], Batch Step [90/323], D_loss: 0.6814,  G_loss: 1.6614\n",
      " Epoch [201/300], Batch Step [100/323], D_loss: 0.6858,  G_loss: 1.5286\n",
      " Epoch [201/300], Batch Step [110/323], D_loss: 0.6599,  G_loss: 1.7302\n",
      " Epoch [201/300], Batch Step [120/323], D_loss: 0.8199,  G_loss: 1.6758\n",
      " Epoch [201/300], Batch Step [130/323], D_loss: 0.6310,  G_loss: 1.3931\n",
      " Epoch [201/300], Batch Step [140/323], D_loss: 0.5693,  G_loss: 1.7351\n",
      " Epoch [201/300], Batch Step [150/323], D_loss: 0.5737,  G_loss: 1.5551\n",
      " Epoch [201/300], Batch Step [160/323], D_loss: 0.7598,  G_loss: 1.5504\n",
      " Epoch [201/300], Batch Step [170/323], D_loss: 0.6930,  G_loss: 1.7400\n",
      " Epoch [201/300], Batch Step [180/323], D_loss: 0.5140,  G_loss: 1.6769\n",
      " Epoch [201/300], Batch Step [190/323], D_loss: 0.6656,  G_loss: 1.6753\n",
      " Epoch [201/300], Batch Step [200/323], D_loss: 0.5566,  G_loss: 1.4881\n",
      " Epoch [201/300], Batch Step [210/323], D_loss: 0.6663,  G_loss: 1.6453\n",
      " Epoch [201/300], Batch Step [220/323], D_loss: 0.5432,  G_loss: 1.5970\n",
      " Epoch [201/300], Batch Step [230/323], D_loss: 0.8219,  G_loss: 1.5878\n",
      " Epoch [201/300], Batch Step [240/323], D_loss: 0.6142,  G_loss: 1.6494\n",
      " Epoch [201/300], Batch Step [250/323], D_loss: 0.6690,  G_loss: 1.5517\n",
      " Epoch [201/300], Batch Step [260/323], D_loss: 0.6216,  G_loss: 1.6285\n",
      " Epoch [201/300], Batch Step [270/323], D_loss: 0.6360,  G_loss: 1.5922\n",
      " Epoch [201/300], Batch Step [280/323], D_loss: 0.5926,  G_loss: 1.4966\n",
      " Epoch [201/300], Batch Step [290/323], D_loss: 0.7673,  G_loss: 1.5865\n",
      " Epoch [201/300], Batch Step [300/323], D_loss: 0.6311,  G_loss: 1.7528\n",
      " Epoch [201/300], Batch Step [310/323], D_loss: 0.6312,  G_loss: 1.5472\n",
      " Epoch [201/300], Batch Step [320/323], D_loss: 0.5477,  G_loss: 1.5996\n",
      " Epoch [202/300], Batch Step [0/323], D_loss: 0.6232,  G_loss: 1.5037\n",
      " Epoch [202/300], Batch Step [10/323], D_loss: 0.6591,  G_loss: 1.5480\n",
      " Epoch [202/300], Batch Step [20/323], D_loss: 0.6386,  G_loss: 1.5182\n",
      " Epoch [202/300], Batch Step [30/323], D_loss: 0.7391,  G_loss: 1.6228\n",
      " Epoch [202/300], Batch Step [40/323], D_loss: 0.7867,  G_loss: 1.5985\n",
      " Epoch [202/300], Batch Step [50/323], D_loss: 0.7058,  G_loss: 1.5185\n",
      " Epoch [202/300], Batch Step [60/323], D_loss: 0.6201,  G_loss: 1.6061\n",
      " Epoch [202/300], Batch Step [70/323], D_loss: 0.5307,  G_loss: 1.6631\n",
      " Epoch [202/300], Batch Step [80/323], D_loss: 0.5968,  G_loss: 1.6108\n",
      " Epoch [202/300], Batch Step [90/323], D_loss: 0.6566,  G_loss: 1.6479\n",
      " Epoch [202/300], Batch Step [100/323], D_loss: 0.6652,  G_loss: 1.6444\n",
      " Epoch [202/300], Batch Step [110/323], D_loss: 0.6958,  G_loss: 1.6729\n",
      " Epoch [202/300], Batch Step [120/323], D_loss: 0.5801,  G_loss: 1.6070\n",
      " Epoch [202/300], Batch Step [130/323], D_loss: 0.6291,  G_loss: 1.5898\n",
      " Epoch [202/300], Batch Step [140/323], D_loss: 0.7568,  G_loss: 1.5877\n",
      " Epoch [202/300], Batch Step [150/323], D_loss: 0.6177,  G_loss: 1.5127\n",
      " Epoch [202/300], Batch Step [160/323], D_loss: 0.4483,  G_loss: 1.8270\n",
      " Epoch [202/300], Batch Step [170/323], D_loss: 0.4723,  G_loss: 1.5058\n",
      " Epoch [202/300], Batch Step [180/323], D_loss: 0.5905,  G_loss: 1.6642\n",
      " Epoch [202/300], Batch Step [190/323], D_loss: 0.6013,  G_loss: 1.6333\n",
      " Epoch [202/300], Batch Step [200/323], D_loss: 0.6720,  G_loss: 1.3838\n",
      " Epoch [202/300], Batch Step [210/323], D_loss: 0.7436,  G_loss: 1.7482\n",
      " Epoch [202/300], Batch Step [220/323], D_loss: 0.5784,  G_loss: 1.6417\n",
      " Epoch [202/300], Batch Step [230/323], D_loss: 0.7674,  G_loss: 1.5099\n",
      " Epoch [202/300], Batch Step [240/323], D_loss: 0.5739,  G_loss: 1.6365\n",
      " Epoch [202/300], Batch Step [250/323], D_loss: 0.6288,  G_loss: 1.6630\n",
      " Epoch [202/300], Batch Step [260/323], D_loss: 0.5117,  G_loss: 1.5622\n",
      " Epoch [202/300], Batch Step [270/323], D_loss: 0.7998,  G_loss: 1.8118\n",
      " Epoch [202/300], Batch Step [280/323], D_loss: 0.6739,  G_loss: 1.5190\n",
      " Epoch [202/300], Batch Step [290/323], D_loss: 0.7420,  G_loss: 1.5228\n",
      " Epoch [202/300], Batch Step [300/323], D_loss: 0.6064,  G_loss: 1.4624\n",
      " Epoch [202/300], Batch Step [310/323], D_loss: 0.4778,  G_loss: 1.6893\n",
      " Epoch [202/300], Batch Step [320/323], D_loss: 0.7700,  G_loss: 1.5563\n",
      " Epoch [203/300], Batch Step [0/323], D_loss: 0.6774,  G_loss: 1.4422\n",
      " Epoch [203/300], Batch Step [10/323], D_loss: 0.5925,  G_loss: 1.6460\n",
      " Epoch [203/300], Batch Step [20/323], D_loss: 0.5813,  G_loss: 1.6882\n",
      " Epoch [203/300], Batch Step [30/323], D_loss: 0.6420,  G_loss: 1.4341\n",
      " Epoch [203/300], Batch Step [40/323], D_loss: 0.7253,  G_loss: 1.5691\n",
      " Epoch [203/300], Batch Step [50/323], D_loss: 0.4230,  G_loss: 1.6465\n",
      " Epoch [203/300], Batch Step [60/323], D_loss: 0.6336,  G_loss: 1.6143\n",
      " Epoch [203/300], Batch Step [70/323], D_loss: 0.6766,  G_loss: 1.5635\n",
      " Epoch [203/300], Batch Step [80/323], D_loss: 0.6996,  G_loss: 1.4659\n",
      " Epoch [203/300], Batch Step [90/323], D_loss: 0.6760,  G_loss: 1.7087\n",
      " Epoch [203/300], Batch Step [100/323], D_loss: 0.5704,  G_loss: 1.5627\n",
      " Epoch [203/300], Batch Step [110/323], D_loss: 0.6801,  G_loss: 1.5323\n",
      " Epoch [203/300], Batch Step [120/323], D_loss: 0.7619,  G_loss: 1.5085\n",
      " Epoch [203/300], Batch Step [130/323], D_loss: 0.7408,  G_loss: 1.5682\n",
      " Epoch [203/300], Batch Step [140/323], D_loss: 0.7633,  G_loss: 1.5771\n",
      " Epoch [203/300], Batch Step [150/323], D_loss: 0.6640,  G_loss: 1.6672\n",
      " Epoch [203/300], Batch Step [160/323], D_loss: 0.8711,  G_loss: 1.5808\n",
      " Epoch [203/300], Batch Step [170/323], D_loss: 0.5686,  G_loss: 1.5343\n",
      " Epoch [203/300], Batch Step [180/323], D_loss: 0.7489,  G_loss: 1.6482\n",
      " Epoch [203/300], Batch Step [190/323], D_loss: 0.5584,  G_loss: 1.5444\n",
      " Epoch [203/300], Batch Step [200/323], D_loss: 0.6417,  G_loss: 1.6470\n",
      " Epoch [203/300], Batch Step [210/323], D_loss: 0.6690,  G_loss: 1.5977\n",
      " Epoch [203/300], Batch Step [220/323], D_loss: 0.6380,  G_loss: 1.6347\n",
      " Epoch [203/300], Batch Step [230/323], D_loss: 0.6288,  G_loss: 1.5374\n",
      " Epoch [203/300], Batch Step [240/323], D_loss: 0.6699,  G_loss: 1.6311\n",
      " Epoch [203/300], Batch Step [250/323], D_loss: 0.5554,  G_loss: 1.6935\n",
      " Epoch [203/300], Batch Step [260/323], D_loss: 0.5519,  G_loss: 1.6058\n",
      " Epoch [203/300], Batch Step [270/323], D_loss: 0.6613,  G_loss: 1.5759\n",
      " Epoch [203/300], Batch Step [280/323], D_loss: 0.6945,  G_loss: 1.7129\n",
      " Epoch [203/300], Batch Step [290/323], D_loss: 0.7304,  G_loss: 1.6568\n",
      " Epoch [203/300], Batch Step [300/323], D_loss: 0.6701,  G_loss: 1.6163\n",
      " Epoch [203/300], Batch Step [310/323], D_loss: 0.5836,  G_loss: 1.4805\n",
      " Epoch [203/300], Batch Step [320/323], D_loss: 0.6521,  G_loss: 1.6241\n",
      " Epoch [204/300], Batch Step [0/323], D_loss: 0.6138,  G_loss: 1.6485\n",
      " Epoch [204/300], Batch Step [10/323], D_loss: 0.7226,  G_loss: 1.6351\n",
      " Epoch [204/300], Batch Step [20/323], D_loss: 0.6239,  G_loss: 1.3630\n",
      " Epoch [204/300], Batch Step [30/323], D_loss: 0.6546,  G_loss: 1.7388\n",
      " Epoch [204/300], Batch Step [40/323], D_loss: 0.8064,  G_loss: 1.5506\n",
      " Epoch [204/300], Batch Step [50/323], D_loss: 0.6700,  G_loss: 1.4069\n",
      " Epoch [204/300], Batch Step [60/323], D_loss: 0.6797,  G_loss: 1.7092\n",
      " Epoch [204/300], Batch Step [70/323], D_loss: 0.7663,  G_loss: 1.5013\n",
      " Epoch [204/300], Batch Step [80/323], D_loss: 0.6812,  G_loss: 1.5102\n",
      " Epoch [204/300], Batch Step [90/323], D_loss: 0.6116,  G_loss: 1.8020\n",
      " Epoch [204/300], Batch Step [100/323], D_loss: 0.6875,  G_loss: 1.3702\n",
      " Epoch [204/300], Batch Step [110/323], D_loss: 0.6261,  G_loss: 1.5720\n",
      " Epoch [204/300], Batch Step [120/323], D_loss: 0.5323,  G_loss: 1.7938\n",
      " Epoch [204/300], Batch Step [130/323], D_loss: 0.6883,  G_loss: 1.5562\n",
      " Epoch [204/300], Batch Step [140/323], D_loss: 0.5679,  G_loss: 1.5601\n",
      " Epoch [204/300], Batch Step [150/323], D_loss: 0.7543,  G_loss: 1.7618\n",
      " Epoch [204/300], Batch Step [160/323], D_loss: 0.6166,  G_loss: 1.6129\n",
      " Epoch [204/300], Batch Step [170/323], D_loss: 0.4471,  G_loss: 1.6695\n",
      " Epoch [204/300], Batch Step [180/323], D_loss: 0.6439,  G_loss: 1.6691\n",
      " Epoch [204/300], Batch Step [190/323], D_loss: 0.5414,  G_loss: 1.6251\n",
      " Epoch [204/300], Batch Step [200/323], D_loss: 0.6805,  G_loss: 1.6832\n",
      " Epoch [204/300], Batch Step [210/323], D_loss: 0.7803,  G_loss: 1.4843\n",
      " Epoch [204/300], Batch Step [220/323], D_loss: 0.7817,  G_loss: 1.6718\n",
      " Epoch [204/300], Batch Step [230/323], D_loss: 0.5637,  G_loss: 1.6788\n",
      " Epoch [204/300], Batch Step [240/323], D_loss: 0.6079,  G_loss: 1.6501\n",
      " Epoch [204/300], Batch Step [250/323], D_loss: 0.6061,  G_loss: 1.6001\n",
      " Epoch [204/300], Batch Step [260/323], D_loss: 0.7720,  G_loss: 1.5954\n",
      " Epoch [204/300], Batch Step [270/323], D_loss: 0.7141,  G_loss: 1.5739\n",
      " Epoch [204/300], Batch Step [280/323], D_loss: 0.6120,  G_loss: 1.5979\n",
      " Epoch [204/300], Batch Step [290/323], D_loss: 0.6995,  G_loss: 1.6170\n",
      " Epoch [204/300], Batch Step [300/323], D_loss: 0.7082,  G_loss: 1.5308\n",
      " Epoch [204/300], Batch Step [310/323], D_loss: 0.5785,  G_loss: 1.4608\n",
      " Epoch [204/300], Batch Step [320/323], D_loss: 0.6258,  G_loss: 1.6383\n",
      " Epoch [205/300], Batch Step [0/323], D_loss: 0.5310,  G_loss: 1.6549\n",
      " Epoch [205/300], Batch Step [10/323], D_loss: 0.6897,  G_loss: 1.4840\n",
      " Epoch [205/300], Batch Step [20/323], D_loss: 0.5365,  G_loss: 1.7375\n",
      " Epoch [205/300], Batch Step [30/323], D_loss: 0.6950,  G_loss: 1.6243\n",
      " Epoch [205/300], Batch Step [40/323], D_loss: 0.6498,  G_loss: 1.5101\n",
      " Epoch [205/300], Batch Step [50/323], D_loss: 0.7115,  G_loss: 1.7445\n",
      " Epoch [205/300], Batch Step [60/323], D_loss: 0.6115,  G_loss: 1.4040\n",
      " Epoch [205/300], Batch Step [70/323], D_loss: 0.5639,  G_loss: 1.5773\n",
      " Epoch [205/300], Batch Step [80/323], D_loss: 0.5977,  G_loss: 1.5394\n",
      " Epoch [205/300], Batch Step [90/323], D_loss: 0.5903,  G_loss: 1.5615\n",
      " Epoch [205/300], Batch Step [100/323], D_loss: 0.5896,  G_loss: 1.6877\n",
      " Epoch [205/300], Batch Step [110/323], D_loss: 0.4838,  G_loss: 1.7545\n",
      " Epoch [205/300], Batch Step [120/323], D_loss: 0.6522,  G_loss: 1.5403\n",
      " Epoch [205/300], Batch Step [130/323], D_loss: 0.6414,  G_loss: 1.6457\n",
      " Epoch [205/300], Batch Step [140/323], D_loss: 0.5833,  G_loss: 1.7502\n",
      " Epoch [205/300], Batch Step [150/323], D_loss: 0.7680,  G_loss: 1.4792\n",
      " Epoch [205/300], Batch Step [160/323], D_loss: 0.5995,  G_loss: 1.7294\n",
      " Epoch [205/300], Batch Step [170/323], D_loss: 0.5162,  G_loss: 1.7163\n",
      " Epoch [205/300], Batch Step [180/323], D_loss: 0.5266,  G_loss: 1.5695\n",
      " Epoch [205/300], Batch Step [190/323], D_loss: 0.7183,  G_loss: 1.6006\n",
      " Epoch [205/300], Batch Step [200/323], D_loss: 0.6614,  G_loss: 1.5488\n",
      " Epoch [205/300], Batch Step [210/323], D_loss: 0.6564,  G_loss: 1.7936\n",
      " Epoch [205/300], Batch Step [220/323], D_loss: 0.5903,  G_loss: 1.4882\n",
      " Epoch [205/300], Batch Step [230/323], D_loss: 0.7431,  G_loss: 1.6623\n",
      " Epoch [205/300], Batch Step [240/323], D_loss: 0.7369,  G_loss: 1.6706\n",
      " Epoch [205/300], Batch Step [250/323], D_loss: 0.8192,  G_loss: 1.5589\n",
      " Epoch [205/300], Batch Step [260/323], D_loss: 0.6616,  G_loss: 1.5156\n",
      " Epoch [205/300], Batch Step [270/323], D_loss: 0.6467,  G_loss: 1.5585\n",
      " Epoch [205/300], Batch Step [280/323], D_loss: 0.6360,  G_loss: 1.6502\n",
      " Epoch [205/300], Batch Step [290/323], D_loss: 0.6017,  G_loss: 1.4958\n",
      " Epoch [205/300], Batch Step [300/323], D_loss: 0.5955,  G_loss: 1.6708\n",
      " Epoch [205/300], Batch Step [310/323], D_loss: 0.5857,  G_loss: 1.5587\n",
      " Epoch [205/300], Batch Step [320/323], D_loss: 0.5994,  G_loss: 1.7510\n",
      " Epoch [206/300], Batch Step [0/323], D_loss: 0.5133,  G_loss: 1.7121\n",
      " Epoch [206/300], Batch Step [10/323], D_loss: 0.6348,  G_loss: 1.6456\n",
      " Epoch [206/300], Batch Step [20/323], D_loss: 0.5602,  G_loss: 1.5278\n",
      " Epoch [206/300], Batch Step [30/323], D_loss: 0.7295,  G_loss: 1.6909\n",
      " Epoch [206/300], Batch Step [40/323], D_loss: 0.7338,  G_loss: 1.4954\n",
      " Epoch [206/300], Batch Step [50/323], D_loss: 0.5580,  G_loss: 1.6306\n",
      " Epoch [206/300], Batch Step [60/323], D_loss: 0.6644,  G_loss: 1.7814\n",
      " Epoch [206/300], Batch Step [70/323], D_loss: 0.5892,  G_loss: 1.5486\n",
      " Epoch [206/300], Batch Step [80/323], D_loss: 0.6256,  G_loss: 1.7126\n",
      " Epoch [206/300], Batch Step [90/323], D_loss: 0.7516,  G_loss: 1.5872\n",
      " Epoch [206/300], Batch Step [100/323], D_loss: 0.7303,  G_loss: 1.5316\n",
      " Epoch [206/300], Batch Step [110/323], D_loss: 0.7491,  G_loss: 1.5036\n",
      " Epoch [206/300], Batch Step [120/323], D_loss: 0.6545,  G_loss: 1.6921\n",
      " Epoch [206/300], Batch Step [130/323], D_loss: 0.6145,  G_loss: 1.6841\n",
      " Epoch [206/300], Batch Step [140/323], D_loss: 0.4673,  G_loss: 1.6349\n",
      " Epoch [206/300], Batch Step [150/323], D_loss: 0.6239,  G_loss: 1.7770\n",
      " Epoch [206/300], Batch Step [160/323], D_loss: 0.8253,  G_loss: 1.4302\n",
      " Epoch [206/300], Batch Step [170/323], D_loss: 0.6608,  G_loss: 1.7127\n",
      " Epoch [206/300], Batch Step [180/323], D_loss: 0.6901,  G_loss: 1.5896\n",
      " Epoch [206/300], Batch Step [190/323], D_loss: 0.6133,  G_loss: 1.4919\n",
      " Epoch [206/300], Batch Step [200/323], D_loss: 0.6287,  G_loss: 1.6585\n",
      " Epoch [206/300], Batch Step [210/323], D_loss: 0.7314,  G_loss: 1.5719\n",
      " Epoch [206/300], Batch Step [220/323], D_loss: 0.6499,  G_loss: 1.6341\n",
      " Epoch [206/300], Batch Step [230/323], D_loss: 0.4822,  G_loss: 1.6738\n",
      " Epoch [206/300], Batch Step [240/323], D_loss: 0.6091,  G_loss: 1.5511\n",
      " Epoch [206/300], Batch Step [250/323], D_loss: 0.7620,  G_loss: 1.6240\n",
      " Epoch [206/300], Batch Step [260/323], D_loss: 0.7194,  G_loss: 1.4493\n",
      " Epoch [206/300], Batch Step [270/323], D_loss: 0.6364,  G_loss: 1.4892\n",
      " Epoch [206/300], Batch Step [280/323], D_loss: 0.6113,  G_loss: 1.7127\n",
      " Epoch [206/300], Batch Step [290/323], D_loss: 0.6837,  G_loss: 1.5575\n",
      " Epoch [206/300], Batch Step [300/323], D_loss: 0.6099,  G_loss: 1.7239\n",
      " Epoch [206/300], Batch Step [310/323], D_loss: 0.4743,  G_loss: 1.5879\n",
      " Epoch [206/300], Batch Step [320/323], D_loss: 0.4982,  G_loss: 1.5882\n",
      " Epoch [207/300], Batch Step [0/323], D_loss: 0.6965,  G_loss: 1.5999\n",
      " Epoch [207/300], Batch Step [10/323], D_loss: 0.5877,  G_loss: 1.6790\n",
      " Epoch [207/300], Batch Step [20/323], D_loss: 0.4504,  G_loss: 1.6387\n",
      " Epoch [207/300], Batch Step [30/323], D_loss: 0.5153,  G_loss: 1.6375\n",
      " Epoch [207/300], Batch Step [40/323], D_loss: 0.5576,  G_loss: 1.6963\n",
      " Epoch [207/300], Batch Step [50/323], D_loss: 0.6155,  G_loss: 1.5797\n",
      " Epoch [207/300], Batch Step [60/323], D_loss: 0.6591,  G_loss: 1.4901\n",
      " Epoch [207/300], Batch Step [70/323], D_loss: 0.7443,  G_loss: 1.6949\n",
      " Epoch [207/300], Batch Step [80/323], D_loss: 0.5926,  G_loss: 1.6672\n",
      " Epoch [207/300], Batch Step [90/323], D_loss: 0.4970,  G_loss: 1.5500\n",
      " Epoch [207/300], Batch Step [100/323], D_loss: 0.6982,  G_loss: 1.5161\n",
      " Epoch [207/300], Batch Step [110/323], D_loss: 0.6298,  G_loss: 1.6857\n",
      " Epoch [207/300], Batch Step [120/323], D_loss: 0.5651,  G_loss: 1.6796\n",
      " Epoch [207/300], Batch Step [130/323], D_loss: 0.5707,  G_loss: 1.4773\n",
      " Epoch [207/300], Batch Step [140/323], D_loss: 0.8433,  G_loss: 1.5201\n",
      " Epoch [207/300], Batch Step [150/323], D_loss: 0.5075,  G_loss: 1.6640\n",
      " Epoch [207/300], Batch Step [160/323], D_loss: 0.6557,  G_loss: 1.5456\n",
      " Epoch [207/300], Batch Step [170/323], D_loss: 0.6750,  G_loss: 1.7719\n",
      " Epoch [207/300], Batch Step [180/323], D_loss: 0.4805,  G_loss: 1.5199\n",
      " Epoch [207/300], Batch Step [190/323], D_loss: 0.5953,  G_loss: 1.6380\n",
      " Epoch [207/300], Batch Step [200/323], D_loss: 0.6323,  G_loss: 1.5801\n",
      " Epoch [207/300], Batch Step [210/323], D_loss: 0.6915,  G_loss: 1.5479\n",
      " Epoch [207/300], Batch Step [220/323], D_loss: 0.7999,  G_loss: 1.6029\n",
      " Epoch [207/300], Batch Step [230/323], D_loss: 0.6685,  G_loss: 1.6652\n",
      " Epoch [207/300], Batch Step [240/323], D_loss: 0.6299,  G_loss: 1.6275\n",
      " Epoch [207/300], Batch Step [250/323], D_loss: 0.6087,  G_loss: 1.6084\n",
      " Epoch [207/300], Batch Step [260/323], D_loss: 0.5055,  G_loss: 1.6796\n",
      " Epoch [207/300], Batch Step [270/323], D_loss: 0.5566,  G_loss: 1.6250\n",
      " Epoch [207/300], Batch Step [280/323], D_loss: 0.6438,  G_loss: 1.4930\n",
      " Epoch [207/300], Batch Step [290/323], D_loss: 0.6555,  G_loss: 1.8061\n",
      " Epoch [207/300], Batch Step [300/323], D_loss: 0.5868,  G_loss: 1.7196\n",
      " Epoch [207/300], Batch Step [310/323], D_loss: 0.7726,  G_loss: 1.6741\n",
      " Epoch [207/300], Batch Step [320/323], D_loss: 0.7601,  G_loss: 1.5989\n",
      " Epoch [208/300], Batch Step [0/323], D_loss: 0.6634,  G_loss: 1.6238\n",
      " Epoch [208/300], Batch Step [10/323], D_loss: 0.6053,  G_loss: 1.6349\n",
      " Epoch [208/300], Batch Step [20/323], D_loss: 0.6998,  G_loss: 1.5725\n",
      " Epoch [208/300], Batch Step [30/323], D_loss: 0.6824,  G_loss: 1.6534\n",
      " Epoch [208/300], Batch Step [40/323], D_loss: 0.6007,  G_loss: 1.5665\n",
      " Epoch [208/300], Batch Step [50/323], D_loss: 0.5965,  G_loss: 1.5970\n",
      " Epoch [208/300], Batch Step [60/323], D_loss: 0.6043,  G_loss: 1.6547\n",
      " Epoch [208/300], Batch Step [70/323], D_loss: 0.4811,  G_loss: 1.5806\n",
      " Epoch [208/300], Batch Step [80/323], D_loss: 0.5833,  G_loss: 1.6345\n",
      " Epoch [208/300], Batch Step [90/323], D_loss: 0.6641,  G_loss: 1.6576\n",
      " Epoch [208/300], Batch Step [100/323], D_loss: 0.4764,  G_loss: 1.5417\n",
      " Epoch [208/300], Batch Step [110/323], D_loss: 0.6225,  G_loss: 1.6703\n",
      " Epoch [208/300], Batch Step [120/323], D_loss: 0.6999,  G_loss: 1.5664\n",
      " Epoch [208/300], Batch Step [130/323], D_loss: 0.6155,  G_loss: 1.5176\n",
      " Epoch [208/300], Batch Step [140/323], D_loss: 0.4891,  G_loss: 1.7101\n",
      " Epoch [208/300], Batch Step [150/323], D_loss: 0.6565,  G_loss: 1.7579\n",
      " Epoch [208/300], Batch Step [160/323], D_loss: 0.7420,  G_loss: 1.3646\n",
      " Epoch [208/300], Batch Step [170/323], D_loss: 0.5590,  G_loss: 1.7891\n",
      " Epoch [208/300], Batch Step [180/323], D_loss: 0.5787,  G_loss: 1.6408\n",
      " Epoch [208/300], Batch Step [190/323], D_loss: 0.4708,  G_loss: 1.6413\n",
      " Epoch [208/300], Batch Step [200/323], D_loss: 0.5981,  G_loss: 1.7365\n",
      " Epoch [208/300], Batch Step [210/323], D_loss: 0.7327,  G_loss: 1.4623\n",
      " Epoch [208/300], Batch Step [220/323], D_loss: 0.6567,  G_loss: 1.7587\n",
      " Epoch [208/300], Batch Step [230/323], D_loss: 0.5767,  G_loss: 1.5965\n",
      " Epoch [208/300], Batch Step [240/323], D_loss: 0.6454,  G_loss: 1.5500\n",
      " Epoch [208/300], Batch Step [250/323], D_loss: 0.6357,  G_loss: 1.5480\n",
      " Epoch [208/300], Batch Step [260/323], D_loss: 0.7275,  G_loss: 1.5393\n",
      " Epoch [208/300], Batch Step [270/323], D_loss: 0.7119,  G_loss: 1.5975\n",
      " Epoch [208/300], Batch Step [280/323], D_loss: 0.9151,  G_loss: 1.5251\n",
      " Epoch [208/300], Batch Step [290/323], D_loss: 0.7244,  G_loss: 1.6337\n",
      " Epoch [208/300], Batch Step [300/323], D_loss: 0.6865,  G_loss: 1.6587\n",
      " Epoch [208/300], Batch Step [310/323], D_loss: 0.4947,  G_loss: 1.5421\n",
      " Epoch [208/300], Batch Step [320/323], D_loss: 0.5855,  G_loss: 1.6533\n",
      " Epoch [209/300], Batch Step [0/323], D_loss: 0.7093,  G_loss: 1.7940\n",
      " Epoch [209/300], Batch Step [10/323], D_loss: 0.6686,  G_loss: 1.7626\n",
      " Epoch [209/300], Batch Step [20/323], D_loss: 0.5366,  G_loss: 1.5873\n",
      " Epoch [209/300], Batch Step [30/323], D_loss: 0.6270,  G_loss: 1.5692\n",
      " Epoch [209/300], Batch Step [40/323], D_loss: 0.6134,  G_loss: 1.6390\n",
      " Epoch [209/300], Batch Step [50/323], D_loss: 0.6456,  G_loss: 1.4833\n",
      " Epoch [209/300], Batch Step [60/323], D_loss: 0.6871,  G_loss: 1.6825\n",
      " Epoch [209/300], Batch Step [70/323], D_loss: 0.6544,  G_loss: 1.6214\n",
      " Epoch [209/300], Batch Step [80/323], D_loss: 0.6082,  G_loss: 1.4536\n",
      " Epoch [209/300], Batch Step [90/323], D_loss: 0.7749,  G_loss: 1.5726\n",
      " Epoch [209/300], Batch Step [100/323], D_loss: 0.6682,  G_loss: 1.5905\n",
      " Epoch [209/300], Batch Step [110/323], D_loss: 0.4951,  G_loss: 1.6699\n",
      " Epoch [209/300], Batch Step [120/323], D_loss: 0.6500,  G_loss: 1.6477\n",
      " Epoch [209/300], Batch Step [130/323], D_loss: 0.6281,  G_loss: 1.4576\n",
      " Epoch [209/300], Batch Step [140/323], D_loss: 0.6568,  G_loss: 1.7023\n",
      " Epoch [209/300], Batch Step [150/323], D_loss: 0.6138,  G_loss: 1.6151\n",
      " Epoch [209/300], Batch Step [160/323], D_loss: 0.7366,  G_loss: 1.6288\n",
      " Epoch [209/300], Batch Step [170/323], D_loss: 0.5402,  G_loss: 1.4760\n",
      " Epoch [209/300], Batch Step [180/323], D_loss: 0.5694,  G_loss: 1.5770\n",
      " Epoch [209/300], Batch Step [190/323], D_loss: 0.7226,  G_loss: 1.8161\n",
      " Epoch [209/300], Batch Step [200/323], D_loss: 0.6576,  G_loss: 1.3362\n",
      " Epoch [209/300], Batch Step [210/323], D_loss: 0.6566,  G_loss: 1.9109\n",
      " Epoch [209/300], Batch Step [220/323], D_loss: 0.6105,  G_loss: 1.6546\n",
      " Epoch [209/300], Batch Step [230/323], D_loss: 0.5723,  G_loss: 1.5749\n",
      " Epoch [209/300], Batch Step [240/323], D_loss: 0.5844,  G_loss: 1.7810\n",
      " Epoch [209/300], Batch Step [250/323], D_loss: 0.5792,  G_loss: 1.5357\n",
      " Epoch [209/300], Batch Step [260/323], D_loss: 0.6450,  G_loss: 1.5114\n",
      " Epoch [209/300], Batch Step [270/323], D_loss: 0.6011,  G_loss: 1.5855\n",
      " Epoch [209/300], Batch Step [280/323], D_loss: 0.7445,  G_loss: 1.4146\n",
      " Epoch [209/300], Batch Step [290/323], D_loss: 0.8449,  G_loss: 1.5809\n",
      " Epoch [209/300], Batch Step [300/323], D_loss: 0.8127,  G_loss: 1.5811\n",
      " Epoch [209/300], Batch Step [310/323], D_loss: 0.4908,  G_loss: 1.5868\n",
      " Epoch [209/300], Batch Step [320/323], D_loss: 0.5084,  G_loss: 1.5289\n",
      " Epoch [210/300], Batch Step [0/323], D_loss: 0.6875,  G_loss: 1.4138\n",
      " Epoch [210/300], Batch Step [10/323], D_loss: 0.4945,  G_loss: 1.7050\n",
      " Epoch [210/300], Batch Step [20/323], D_loss: 0.7502,  G_loss: 1.6412\n",
      " Epoch [210/300], Batch Step [30/323], D_loss: 0.6066,  G_loss: 1.5432\n",
      " Epoch [210/300], Batch Step [40/323], D_loss: 0.4859,  G_loss: 1.7659\n",
      " Epoch [210/300], Batch Step [50/323], D_loss: 0.7127,  G_loss: 1.6562\n",
      " Epoch [210/300], Batch Step [60/323], D_loss: 0.6831,  G_loss: 1.6101\n",
      " Epoch [210/300], Batch Step [70/323], D_loss: 0.7286,  G_loss: 1.7659\n",
      " Epoch [210/300], Batch Step [80/323], D_loss: 0.6985,  G_loss: 1.5276\n",
      " Epoch [210/300], Batch Step [90/323], D_loss: 0.5151,  G_loss: 1.6331\n",
      " Epoch [210/300], Batch Step [100/323], D_loss: 0.4685,  G_loss: 1.5692\n",
      " Epoch [210/300], Batch Step [110/323], D_loss: 0.6576,  G_loss: 1.4764\n",
      " Epoch [210/300], Batch Step [120/323], D_loss: 0.6187,  G_loss: 1.7419\n",
      " Epoch [210/300], Batch Step [130/323], D_loss: 0.6967,  G_loss: 1.6432\n",
      " Epoch [210/300], Batch Step [140/323], D_loss: 0.6630,  G_loss: 1.5114\n",
      " Epoch [210/300], Batch Step [150/323], D_loss: 0.7131,  G_loss: 1.5979\n",
      " Epoch [210/300], Batch Step [160/323], D_loss: 0.6553,  G_loss: 1.7126\n",
      " Epoch [210/300], Batch Step [170/323], D_loss: 0.6516,  G_loss: 1.4292\n",
      " Epoch [210/300], Batch Step [180/323], D_loss: 0.6299,  G_loss: 1.5707\n",
      " Epoch [210/300], Batch Step [190/323], D_loss: 0.5571,  G_loss: 1.6133\n",
      " Epoch [210/300], Batch Step [200/323], D_loss: 0.7587,  G_loss: 1.6105\n",
      " Epoch [210/300], Batch Step [210/323], D_loss: 0.6212,  G_loss: 1.5116\n",
      " Epoch [210/300], Batch Step [220/323], D_loss: 0.8608,  G_loss: 1.7504\n",
      " Epoch [210/300], Batch Step [230/323], D_loss: 0.7215,  G_loss: 1.5493\n",
      " Epoch [210/300], Batch Step [240/323], D_loss: 0.5628,  G_loss: 1.5609\n",
      " Epoch [210/300], Batch Step [250/323], D_loss: 0.5834,  G_loss: 1.7077\n",
      " Epoch [210/300], Batch Step [260/323], D_loss: 0.6372,  G_loss: 1.7269\n",
      " Epoch [210/300], Batch Step [270/323], D_loss: 0.7105,  G_loss: 1.4351\n",
      " Epoch [210/300], Batch Step [280/323], D_loss: 0.5244,  G_loss: 1.5509\n",
      " Epoch [210/300], Batch Step [290/323], D_loss: 0.7763,  G_loss: 1.7239\n",
      " Epoch [210/300], Batch Step [300/323], D_loss: 0.5940,  G_loss: 1.6171\n",
      " Epoch [210/300], Batch Step [310/323], D_loss: 0.7364,  G_loss: 1.5720\n",
      " Epoch [210/300], Batch Step [320/323], D_loss: 0.6818,  G_loss: 1.5025\n",
      " Epoch [211/300], Batch Step [0/323], D_loss: 0.6976,  G_loss: 1.6373\n",
      " Epoch [211/300], Batch Step [10/323], D_loss: 0.7237,  G_loss: 1.5533\n",
      " Epoch [211/300], Batch Step [20/323], D_loss: 0.6985,  G_loss: 1.5045\n",
      " Epoch [211/300], Batch Step [30/323], D_loss: 0.6086,  G_loss: 1.6322\n",
      " Epoch [211/300], Batch Step [40/323], D_loss: 0.5947,  G_loss: 1.6628\n",
      " Epoch [211/300], Batch Step [50/323], D_loss: 0.5350,  G_loss: 1.6130\n",
      " Epoch [211/300], Batch Step [60/323], D_loss: 0.5034,  G_loss: 1.6787\n",
      " Epoch [211/300], Batch Step [70/323], D_loss: 0.6820,  G_loss: 1.5259\n",
      " Epoch [211/300], Batch Step [80/323], D_loss: 0.6524,  G_loss: 1.6260\n",
      " Epoch [211/300], Batch Step [90/323], D_loss: 0.7406,  G_loss: 1.6310\n",
      " Epoch [211/300], Batch Step [100/323], D_loss: 0.6206,  G_loss: 1.6136\n",
      " Epoch [211/300], Batch Step [110/323], D_loss: 0.6299,  G_loss: 1.7536\n",
      " Epoch [211/300], Batch Step [120/323], D_loss: 0.6456,  G_loss: 1.6215\n",
      " Epoch [211/300], Batch Step [130/323], D_loss: 0.6414,  G_loss: 1.7348\n",
      " Epoch [211/300], Batch Step [140/323], D_loss: 0.7454,  G_loss: 1.6344\n",
      " Epoch [211/300], Batch Step [150/323], D_loss: 0.6018,  G_loss: 1.5314\n",
      " Epoch [211/300], Batch Step [160/323], D_loss: 0.6346,  G_loss: 1.7276\n",
      " Epoch [211/300], Batch Step [170/323], D_loss: 0.5578,  G_loss: 1.5824\n",
      " Epoch [211/300], Batch Step [180/323], D_loss: 0.6372,  G_loss: 1.7089\n",
      " Epoch [211/300], Batch Step [190/323], D_loss: 0.6987,  G_loss: 1.7205\n",
      " Epoch [211/300], Batch Step [200/323], D_loss: 0.6316,  G_loss: 1.6089\n",
      " Epoch [211/300], Batch Step [210/323], D_loss: 0.6534,  G_loss: 1.5546\n",
      " Epoch [211/300], Batch Step [220/323], D_loss: 0.6881,  G_loss: 1.6915\n",
      " Epoch [211/300], Batch Step [230/323], D_loss: 0.6536,  G_loss: 1.5644\n",
      " Epoch [211/300], Batch Step [240/323], D_loss: 0.6787,  G_loss: 1.6473\n",
      " Epoch [211/300], Batch Step [250/323], D_loss: 0.5495,  G_loss: 1.7938\n",
      " Epoch [211/300], Batch Step [260/323], D_loss: 0.6193,  G_loss: 1.5965\n",
      " Epoch [211/300], Batch Step [270/323], D_loss: 0.6812,  G_loss: 1.6284\n",
      " Epoch [211/300], Batch Step [280/323], D_loss: 0.4946,  G_loss: 1.6119\n",
      " Epoch [211/300], Batch Step [290/323], D_loss: 0.6737,  G_loss: 1.5472\n",
      " Epoch [211/300], Batch Step [300/323], D_loss: 0.5871,  G_loss: 1.6615\n",
      " Epoch [211/300], Batch Step [310/323], D_loss: 0.5091,  G_loss: 1.5387\n",
      " Epoch [211/300], Batch Step [320/323], D_loss: 0.5944,  G_loss: 1.5869\n",
      " Epoch [212/300], Batch Step [0/323], D_loss: 0.7235,  G_loss: 1.6546\n",
      " Epoch [212/300], Batch Step [10/323], D_loss: 0.7094,  G_loss: 1.5631\n",
      " Epoch [212/300], Batch Step [20/323], D_loss: 0.6234,  G_loss: 1.5723\n",
      " Epoch [212/300], Batch Step [30/323], D_loss: 0.6038,  G_loss: 1.5044\n",
      " Epoch [212/300], Batch Step [40/323], D_loss: 0.5862,  G_loss: 1.4370\n",
      " Epoch [212/300], Batch Step [50/323], D_loss: 0.5407,  G_loss: 1.6927\n",
      " Epoch [212/300], Batch Step [60/323], D_loss: 0.6883,  G_loss: 1.4524\n",
      " Epoch [212/300], Batch Step [70/323], D_loss: 0.6974,  G_loss: 1.7806\n",
      " Epoch [212/300], Batch Step [80/323], D_loss: 0.4567,  G_loss: 1.7236\n",
      " Epoch [212/300], Batch Step [90/323], D_loss: 0.7037,  G_loss: 1.5021\n",
      " Epoch [212/300], Batch Step [100/323], D_loss: 0.5582,  G_loss: 1.5091\n",
      " Epoch [212/300], Batch Step [110/323], D_loss: 0.5706,  G_loss: 1.7410\n",
      " Epoch [212/300], Batch Step [120/323], D_loss: 0.6956,  G_loss: 1.5622\n",
      " Epoch [212/300], Batch Step [130/323], D_loss: 0.5699,  G_loss: 1.6420\n",
      " Epoch [212/300], Batch Step [140/323], D_loss: 0.6962,  G_loss: 1.6299\n",
      " Epoch [212/300], Batch Step [150/323], D_loss: 0.6903,  G_loss: 1.5413\n",
      " Epoch [212/300], Batch Step [160/323], D_loss: 0.6618,  G_loss: 1.8386\n",
      " Epoch [212/300], Batch Step [170/323], D_loss: 0.5742,  G_loss: 1.6975\n",
      " Epoch [212/300], Batch Step [180/323], D_loss: 0.7214,  G_loss: 1.6148\n",
      " Epoch [212/300], Batch Step [190/323], D_loss: 0.5207,  G_loss: 1.7325\n",
      " Epoch [212/300], Batch Step [200/323], D_loss: 0.6913,  G_loss: 1.6137\n",
      " Epoch [212/300], Batch Step [210/323], D_loss: 0.5388,  G_loss: 1.5511\n",
      " Epoch [212/300], Batch Step [220/323], D_loss: 0.6522,  G_loss: 1.5336\n",
      " Epoch [212/300], Batch Step [230/323], D_loss: 0.5388,  G_loss: 1.7486\n",
      " Epoch [212/300], Batch Step [240/323], D_loss: 0.5548,  G_loss: 1.7269\n",
      " Epoch [212/300], Batch Step [250/323], D_loss: 0.5663,  G_loss: 1.4280\n",
      " Epoch [212/300], Batch Step [260/323], D_loss: 0.7030,  G_loss: 1.6105\n",
      " Epoch [212/300], Batch Step [270/323], D_loss: 0.6375,  G_loss: 1.6035\n",
      " Epoch [212/300], Batch Step [280/323], D_loss: 0.6910,  G_loss: 1.5949\n",
      " Epoch [212/300], Batch Step [290/323], D_loss: 0.6735,  G_loss: 1.6340\n",
      " Epoch [212/300], Batch Step [300/323], D_loss: 0.5590,  G_loss: 1.6857\n",
      " Epoch [212/300], Batch Step [310/323], D_loss: 0.7559,  G_loss: 1.5098\n",
      " Epoch [212/300], Batch Step [320/323], D_loss: 0.6961,  G_loss: 1.7223\n",
      " Epoch [213/300], Batch Step [0/323], D_loss: 0.6043,  G_loss: 1.6065\n",
      " Epoch [213/300], Batch Step [10/323], D_loss: 0.5126,  G_loss: 1.5506\n",
      " Epoch [213/300], Batch Step [20/323], D_loss: 0.5947,  G_loss: 1.6576\n",
      " Epoch [213/300], Batch Step [30/323], D_loss: 0.7759,  G_loss: 1.4149\n",
      " Epoch [213/300], Batch Step [40/323], D_loss: 0.7516,  G_loss: 1.8030\n",
      " Epoch [213/300], Batch Step [50/323], D_loss: 0.7411,  G_loss: 1.5370\n",
      " Epoch [213/300], Batch Step [60/323], D_loss: 0.5147,  G_loss: 1.6011\n",
      " Epoch [213/300], Batch Step [70/323], D_loss: 0.6099,  G_loss: 1.7045\n",
      " Epoch [213/300], Batch Step [80/323], D_loss: 0.5266,  G_loss: 1.5257\n",
      " Epoch [213/300], Batch Step [90/323], D_loss: 0.5726,  G_loss: 1.6164\n",
      " Epoch [213/300], Batch Step [100/323], D_loss: 0.5458,  G_loss: 1.5394\n",
      " Epoch [213/300], Batch Step [110/323], D_loss: 0.6252,  G_loss: 1.6536\n",
      " Epoch [213/300], Batch Step [120/323], D_loss: 0.7485,  G_loss: 1.6174\n",
      " Epoch [213/300], Batch Step [130/323], D_loss: 0.6459,  G_loss: 1.5226\n",
      " Epoch [213/300], Batch Step [140/323], D_loss: 0.5394,  G_loss: 1.6062\n",
      " Epoch [213/300], Batch Step [150/323], D_loss: 0.6619,  G_loss: 1.7049\n",
      " Epoch [213/300], Batch Step [160/323], D_loss: 0.6836,  G_loss: 1.3774\n",
      " Epoch [213/300], Batch Step [170/323], D_loss: 0.7528,  G_loss: 1.5834\n",
      " Epoch [213/300], Batch Step [180/323], D_loss: 0.6354,  G_loss: 1.5530\n",
      " Epoch [213/300], Batch Step [190/323], D_loss: 0.4854,  G_loss: 1.5695\n",
      " Epoch [213/300], Batch Step [200/323], D_loss: 0.3813,  G_loss: 1.7397\n",
      " Epoch [213/300], Batch Step [210/323], D_loss: 0.5100,  G_loss: 1.5742\n",
      " Epoch [213/300], Batch Step [220/323], D_loss: 0.6413,  G_loss: 1.7260\n",
      " Epoch [213/300], Batch Step [230/323], D_loss: 0.6377,  G_loss: 1.4981\n",
      " Epoch [213/300], Batch Step [240/323], D_loss: 0.7052,  G_loss: 1.5150\n",
      " Epoch [213/300], Batch Step [250/323], D_loss: 0.7900,  G_loss: 1.8033\n",
      " Epoch [213/300], Batch Step [260/323], D_loss: 0.5335,  G_loss: 1.5225\n",
      " Epoch [213/300], Batch Step [270/323], D_loss: 0.7118,  G_loss: 1.5550\n",
      " Epoch [213/300], Batch Step [280/323], D_loss: 0.6260,  G_loss: 1.6213\n",
      " Epoch [213/300], Batch Step [290/323], D_loss: 0.5785,  G_loss: 1.5640\n",
      " Epoch [213/300], Batch Step [300/323], D_loss: 0.6948,  G_loss: 1.5650\n",
      " Epoch [213/300], Batch Step [310/323], D_loss: 0.7405,  G_loss: 1.5772\n",
      " Epoch [213/300], Batch Step [320/323], D_loss: 0.4925,  G_loss: 1.5582\n",
      " Epoch [214/300], Batch Step [0/323], D_loss: 0.5502,  G_loss: 1.5214\n",
      " Epoch [214/300], Batch Step [10/323], D_loss: 0.8177,  G_loss: 1.5794\n",
      " Epoch [214/300], Batch Step [20/323], D_loss: 0.5489,  G_loss: 1.6194\n",
      " Epoch [214/300], Batch Step [30/323], D_loss: 0.5322,  G_loss: 1.7846\n",
      " Epoch [214/300], Batch Step [40/323], D_loss: 0.5909,  G_loss: 1.6309\n",
      " Epoch [214/300], Batch Step [50/323], D_loss: 0.6143,  G_loss: 1.5483\n",
      " Epoch [214/300], Batch Step [60/323], D_loss: 0.7251,  G_loss: 1.6220\n",
      " Epoch [214/300], Batch Step [70/323], D_loss: 0.4311,  G_loss: 1.5654\n",
      " Epoch [214/300], Batch Step [80/323], D_loss: 0.5517,  G_loss: 1.5836\n",
      " Epoch [214/300], Batch Step [90/323], D_loss: 0.7314,  G_loss: 1.6616\n",
      " Epoch [214/300], Batch Step [100/323], D_loss: 0.6147,  G_loss: 1.5785\n",
      " Epoch [214/300], Batch Step [110/323], D_loss: 0.6216,  G_loss: 1.7383\n",
      " Epoch [214/300], Batch Step [120/323], D_loss: 0.6825,  G_loss: 1.7676\n",
      " Epoch [214/300], Batch Step [130/323], D_loss: 0.6139,  G_loss: 1.4209\n",
      " Epoch [214/300], Batch Step [140/323], D_loss: 0.5043,  G_loss: 1.6007\n",
      " Epoch [214/300], Batch Step [150/323], D_loss: 0.7294,  G_loss: 1.5158\n",
      " Epoch [214/300], Batch Step [160/323], D_loss: 0.6975,  G_loss: 1.5809\n",
      " Epoch [214/300], Batch Step [170/323], D_loss: 0.6152,  G_loss: 1.6260\n",
      " Epoch [214/300], Batch Step [180/323], D_loss: 0.6649,  G_loss: 1.5861\n",
      " Epoch [214/300], Batch Step [190/323], D_loss: 0.5341,  G_loss: 1.5252\n",
      " Epoch [214/300], Batch Step [200/323], D_loss: 0.6817,  G_loss: 1.7557\n",
      " Epoch [214/300], Batch Step [210/323], D_loss: 0.7299,  G_loss: 1.4383\n",
      " Epoch [214/300], Batch Step [220/323], D_loss: 0.7053,  G_loss: 1.5015\n",
      " Epoch [214/300], Batch Step [230/323], D_loss: 0.7933,  G_loss: 1.7007\n",
      " Epoch [214/300], Batch Step [240/323], D_loss: 0.7234,  G_loss: 1.5629\n",
      " Epoch [214/300], Batch Step [250/323], D_loss: 0.5664,  G_loss: 1.5923\n",
      " Epoch [214/300], Batch Step [260/323], D_loss: 0.5417,  G_loss: 1.9036\n",
      " Epoch [214/300], Batch Step [270/323], D_loss: 0.5869,  G_loss: 1.5948\n",
      " Epoch [214/300], Batch Step [280/323], D_loss: 0.6855,  G_loss: 1.5564\n",
      " Epoch [214/300], Batch Step [290/323], D_loss: 0.7942,  G_loss: 1.6337\n",
      " Epoch [214/300], Batch Step [300/323], D_loss: 0.7232,  G_loss: 1.6675\n",
      " Epoch [214/300], Batch Step [310/323], D_loss: 0.7068,  G_loss: 1.5542\n",
      " Epoch [214/300], Batch Step [320/323], D_loss: 0.7250,  G_loss: 1.6574\n",
      " Epoch [215/300], Batch Step [0/323], D_loss: 0.5945,  G_loss: 1.5987\n",
      " Epoch [215/300], Batch Step [10/323], D_loss: 0.5525,  G_loss: 1.6172\n",
      " Epoch [215/300], Batch Step [20/323], D_loss: 0.6868,  G_loss: 1.6148\n",
      " Epoch [215/300], Batch Step [30/323], D_loss: 0.5830,  G_loss: 1.5493\n",
      " Epoch [215/300], Batch Step [40/323], D_loss: 0.7648,  G_loss: 1.6678\n",
      " Epoch [215/300], Batch Step [50/323], D_loss: 0.7068,  G_loss: 1.4450\n",
      " Epoch [215/300], Batch Step [60/323], D_loss: 0.7093,  G_loss: 1.4701\n",
      " Epoch [215/300], Batch Step [70/323], D_loss: 0.7179,  G_loss: 1.6856\n",
      " Epoch [215/300], Batch Step [80/323], D_loss: 0.5793,  G_loss: 1.5370\n",
      " Epoch [215/300], Batch Step [90/323], D_loss: 0.6659,  G_loss: 1.8246\n",
      " Epoch [215/300], Batch Step [100/323], D_loss: 0.5053,  G_loss: 1.6165\n",
      " Epoch [215/300], Batch Step [110/323], D_loss: 0.6109,  G_loss: 1.5914\n",
      " Epoch [215/300], Batch Step [120/323], D_loss: 0.6932,  G_loss: 1.6388\n",
      " Epoch [215/300], Batch Step [130/323], D_loss: 0.7286,  G_loss: 1.5621\n",
      " Epoch [215/300], Batch Step [140/323], D_loss: 0.7549,  G_loss: 1.6467\n",
      " Epoch [215/300], Batch Step [150/323], D_loss: 0.5095,  G_loss: 1.7235\n",
      " Epoch [215/300], Batch Step [160/323], D_loss: 0.6619,  G_loss: 1.4510\n",
      " Epoch [215/300], Batch Step [170/323], D_loss: 0.5676,  G_loss: 1.6002\n",
      " Epoch [215/300], Batch Step [180/323], D_loss: 0.6845,  G_loss: 1.6441\n",
      " Epoch [215/300], Batch Step [190/323], D_loss: 0.7286,  G_loss: 1.5533\n",
      " Epoch [215/300], Batch Step [200/323], D_loss: 0.5155,  G_loss: 1.7052\n",
      " Epoch [215/300], Batch Step [210/323], D_loss: 0.7082,  G_loss: 1.5687\n",
      " Epoch [215/300], Batch Step [220/323], D_loss: 0.6070,  G_loss: 1.6967\n",
      " Epoch [215/300], Batch Step [230/323], D_loss: 0.7457,  G_loss: 1.7006\n",
      " Epoch [215/300], Batch Step [240/323], D_loss: 0.4764,  G_loss: 1.5308\n",
      " Epoch [215/300], Batch Step [250/323], D_loss: 0.4365,  G_loss: 1.6548\n",
      " Epoch [215/300], Batch Step [260/323], D_loss: 0.6821,  G_loss: 1.7033\n",
      " Epoch [215/300], Batch Step [270/323], D_loss: 0.5471,  G_loss: 1.5987\n",
      " Epoch [215/300], Batch Step [280/323], D_loss: 0.5194,  G_loss: 1.6909\n",
      " Epoch [215/300], Batch Step [290/323], D_loss: 0.6648,  G_loss: 1.6476\n",
      " Epoch [215/300], Batch Step [300/323], D_loss: 0.6275,  G_loss: 1.5554\n",
      " Epoch [215/300], Batch Step [310/323], D_loss: 0.6066,  G_loss: 1.6126\n",
      " Epoch [215/300], Batch Step [320/323], D_loss: 0.5803,  G_loss: 1.6381\n",
      " Epoch [216/300], Batch Step [0/323], D_loss: 0.6079,  G_loss: 1.5684\n",
      " Epoch [216/300], Batch Step [10/323], D_loss: 0.6111,  G_loss: 1.5798\n",
      " Epoch [216/300], Batch Step [20/323], D_loss: 0.6704,  G_loss: 1.5574\n",
      " Epoch [216/300], Batch Step [30/323], D_loss: 0.6461,  G_loss: 1.4944\n",
      " Epoch [216/300], Batch Step [40/323], D_loss: 0.6364,  G_loss: 1.6298\n",
      " Epoch [216/300], Batch Step [50/323], D_loss: 0.7619,  G_loss: 1.6640\n",
      " Epoch [216/300], Batch Step [60/323], D_loss: 0.6284,  G_loss: 1.5444\n",
      " Epoch [216/300], Batch Step [70/323], D_loss: 0.5789,  G_loss: 1.7709\n",
      " Epoch [216/300], Batch Step [80/323], D_loss: 0.6681,  G_loss: 1.7599\n",
      " Epoch [216/300], Batch Step [90/323], D_loss: 0.7812,  G_loss: 1.7049\n",
      " Epoch [216/300], Batch Step [100/323], D_loss: 0.5316,  G_loss: 1.6065\n",
      " Epoch [216/300], Batch Step [110/323], D_loss: 0.6239,  G_loss: 1.7502\n",
      " Epoch [216/300], Batch Step [120/323], D_loss: 0.5782,  G_loss: 1.5672\n",
      " Epoch [216/300], Batch Step [130/323], D_loss: 0.8019,  G_loss: 1.6210\n",
      " Epoch [216/300], Batch Step [140/323], D_loss: 0.7879,  G_loss: 1.4861\n",
      " Epoch [216/300], Batch Step [150/323], D_loss: 0.5986,  G_loss: 1.6789\n",
      " Epoch [216/300], Batch Step [160/323], D_loss: 0.6284,  G_loss: 1.6446\n",
      " Epoch [216/300], Batch Step [170/323], D_loss: 0.6482,  G_loss: 1.4228\n",
      " Epoch [216/300], Batch Step [180/323], D_loss: 0.6118,  G_loss: 1.8730\n",
      " Epoch [216/300], Batch Step [190/323], D_loss: 0.6125,  G_loss: 1.5839\n",
      " Epoch [216/300], Batch Step [200/323], D_loss: 0.6000,  G_loss: 1.7170\n",
      " Epoch [216/300], Batch Step [210/323], D_loss: 0.7218,  G_loss: 1.4856\n",
      " Epoch [216/300], Batch Step [220/323], D_loss: 0.6432,  G_loss: 1.4582\n",
      " Epoch [216/300], Batch Step [230/323], D_loss: 0.7069,  G_loss: 1.6663\n",
      " Epoch [216/300], Batch Step [240/323], D_loss: 0.7396,  G_loss: 1.4762\n",
      " Epoch [216/300], Batch Step [250/323], D_loss: 0.6693,  G_loss: 1.8080\n",
      " Epoch [216/300], Batch Step [260/323], D_loss: 0.7440,  G_loss: 1.5879\n",
      " Epoch [216/300], Batch Step [270/323], D_loss: 0.6753,  G_loss: 1.6055\n",
      " Epoch [216/300], Batch Step [280/323], D_loss: 0.6760,  G_loss: 1.6193\n",
      " Epoch [216/300], Batch Step [290/323], D_loss: 0.7983,  G_loss: 1.5812\n",
      " Epoch [216/300], Batch Step [300/323], D_loss: 0.7149,  G_loss: 1.5906\n",
      " Epoch [216/300], Batch Step [310/323], D_loss: 0.5550,  G_loss: 1.5878\n",
      " Epoch [216/300], Batch Step [320/323], D_loss: 0.5927,  G_loss: 1.5773\n",
      " Epoch [217/300], Batch Step [0/323], D_loss: 0.6396,  G_loss: 1.6105\n",
      " Epoch [217/300], Batch Step [10/323], D_loss: 0.5704,  G_loss: 1.6251\n",
      " Epoch [217/300], Batch Step [20/323], D_loss: 0.5949,  G_loss: 1.6487\n",
      " Epoch [217/300], Batch Step [30/323], D_loss: 0.4998,  G_loss: 1.7176\n",
      " Epoch [217/300], Batch Step [40/323], D_loss: 0.6139,  G_loss: 1.5103\n",
      " Epoch [217/300], Batch Step [50/323], D_loss: 0.6419,  G_loss: 1.5807\n",
      " Epoch [217/300], Batch Step [60/323], D_loss: 0.7240,  G_loss: 1.6259\n",
      " Epoch [217/300], Batch Step [70/323], D_loss: 0.6319,  G_loss: 1.4444\n",
      " Epoch [217/300], Batch Step [80/323], D_loss: 0.8024,  G_loss: 1.5592\n",
      " Epoch [217/300], Batch Step [90/323], D_loss: 0.5242,  G_loss: 1.6562\n",
      " Epoch [217/300], Batch Step [100/323], D_loss: 0.7562,  G_loss: 1.6102\n",
      " Epoch [217/300], Batch Step [110/323], D_loss: 0.5410,  G_loss: 1.5639\n",
      " Epoch [217/300], Batch Step [120/323], D_loss: 0.5526,  G_loss: 1.6404\n",
      " Epoch [217/300], Batch Step [130/323], D_loss: 0.6767,  G_loss: 1.5087\n",
      " Epoch [217/300], Batch Step [140/323], D_loss: 0.5515,  G_loss: 1.6409\n",
      " Epoch [217/300], Batch Step [150/323], D_loss: 0.7073,  G_loss: 1.6858\n",
      " Epoch [217/300], Batch Step [160/323], D_loss: 0.6198,  G_loss: 1.5296\n",
      " Epoch [217/300], Batch Step [170/323], D_loss: 0.5858,  G_loss: 1.7453\n",
      " Epoch [217/300], Batch Step [180/323], D_loss: 0.5840,  G_loss: 1.5797\n",
      " Epoch [217/300], Batch Step [190/323], D_loss: 0.5528,  G_loss: 1.5303\n",
      " Epoch [217/300], Batch Step [200/323], D_loss: 0.6732,  G_loss: 1.5628\n",
      " Epoch [217/300], Batch Step [210/323], D_loss: 0.5498,  G_loss: 1.6205\n",
      " Epoch [217/300], Batch Step [220/323], D_loss: 0.5379,  G_loss: 1.6778\n",
      " Epoch [217/300], Batch Step [230/323], D_loss: 0.5695,  G_loss: 1.6256\n",
      " Epoch [217/300], Batch Step [240/323], D_loss: 0.7051,  G_loss: 1.4890\n",
      " Epoch [217/300], Batch Step [250/323], D_loss: 0.6990,  G_loss: 1.7430\n",
      " Epoch [217/300], Batch Step [260/323], D_loss: 0.7953,  G_loss: 1.5093\n",
      " Epoch [217/300], Batch Step [270/323], D_loss: 0.6638,  G_loss: 1.5026\n",
      " Epoch [217/300], Batch Step [280/323], D_loss: 0.5541,  G_loss: 1.7399\n",
      " Epoch [217/300], Batch Step [290/323], D_loss: 0.6454,  G_loss: 1.7071\n",
      " Epoch [217/300], Batch Step [300/323], D_loss: 0.8224,  G_loss: 1.5591\n",
      " Epoch [217/300], Batch Step [310/323], D_loss: 0.5856,  G_loss: 1.6300\n",
      " Epoch [217/300], Batch Step [320/323], D_loss: 0.4454,  G_loss: 1.6852\n",
      " Epoch [218/300], Batch Step [0/323], D_loss: 0.7275,  G_loss: 1.7198\n",
      " Epoch [218/300], Batch Step [10/323], D_loss: 0.5550,  G_loss: 1.5241\n",
      " Epoch [218/300], Batch Step [20/323], D_loss: 0.5771,  G_loss: 1.4921\n",
      " Epoch [218/300], Batch Step [30/323], D_loss: 0.6081,  G_loss: 1.7293\n",
      " Epoch [218/300], Batch Step [40/323], D_loss: 0.7838,  G_loss: 1.5231\n",
      " Epoch [218/300], Batch Step [50/323], D_loss: 0.5227,  G_loss: 1.6994\n",
      " Epoch [218/300], Batch Step [60/323], D_loss: 0.5760,  G_loss: 1.8325\n",
      " Epoch [218/300], Batch Step [70/323], D_loss: 0.7195,  G_loss: 1.5185\n",
      " Epoch [218/300], Batch Step [80/323], D_loss: 0.7385,  G_loss: 1.7011\n",
      " Epoch [218/300], Batch Step [90/323], D_loss: 0.6590,  G_loss: 1.6148\n",
      " Epoch [218/300], Batch Step [100/323], D_loss: 0.6805,  G_loss: 1.6280\n",
      " Epoch [218/300], Batch Step [110/323], D_loss: 0.4676,  G_loss: 1.6716\n",
      " Epoch [218/300], Batch Step [120/323], D_loss: 0.6482,  G_loss: 1.7218\n",
      " Epoch [218/300], Batch Step [130/323], D_loss: 0.5454,  G_loss: 1.5325\n",
      " Epoch [218/300], Batch Step [140/323], D_loss: 0.6388,  G_loss: 1.7276\n",
      " Epoch [218/300], Batch Step [150/323], D_loss: 0.6409,  G_loss: 1.6539\n",
      " Epoch [218/300], Batch Step [160/323], D_loss: 0.7997,  G_loss: 1.5498\n",
      " Epoch [218/300], Batch Step [170/323], D_loss: 0.7122,  G_loss: 1.5320\n",
      " Epoch [218/300], Batch Step [180/323], D_loss: 0.5227,  G_loss: 1.5728\n",
      " Epoch [218/300], Batch Step [190/323], D_loss: 0.6288,  G_loss: 1.7059\n",
      " Epoch [218/300], Batch Step [200/323], D_loss: 0.7236,  G_loss: 1.5200\n",
      " Epoch [218/300], Batch Step [210/323], D_loss: 0.6726,  G_loss: 1.5510\n",
      " Epoch [218/300], Batch Step [220/323], D_loss: 0.5491,  G_loss: 1.7182\n",
      " Epoch [218/300], Batch Step [230/323], D_loss: 0.5911,  G_loss: 1.5393\n",
      " Epoch [218/300], Batch Step [240/323], D_loss: 0.6565,  G_loss: 1.8343\n",
      " Epoch [218/300], Batch Step [250/323], D_loss: 0.7264,  G_loss: 1.5882\n",
      " Epoch [218/300], Batch Step [260/323], D_loss: 0.6633,  G_loss: 1.6646\n",
      " Epoch [218/300], Batch Step [270/323], D_loss: 0.7991,  G_loss: 1.5849\n",
      " Epoch [218/300], Batch Step [280/323], D_loss: 0.5297,  G_loss: 1.6326\n",
      " Epoch [218/300], Batch Step [290/323], D_loss: 0.5671,  G_loss: 1.6007\n",
      " Epoch [218/300], Batch Step [300/323], D_loss: 0.8064,  G_loss: 1.6128\n",
      " Epoch [218/300], Batch Step [310/323], D_loss: 0.7068,  G_loss: 1.6398\n",
      " Epoch [218/300], Batch Step [320/323], D_loss: 0.6303,  G_loss: 1.4616\n",
      " Epoch [219/300], Batch Step [0/323], D_loss: 0.7373,  G_loss: 1.4334\n",
      " Epoch [219/300], Batch Step [10/323], D_loss: 0.6530,  G_loss: 1.5544\n",
      " Epoch [219/300], Batch Step [20/323], D_loss: 0.6509,  G_loss: 1.5858\n",
      " Epoch [219/300], Batch Step [30/323], D_loss: 0.5773,  G_loss: 1.7264\n",
      " Epoch [219/300], Batch Step [40/323], D_loss: 0.5600,  G_loss: 1.7162\n",
      " Epoch [219/300], Batch Step [50/323], D_loss: 0.6094,  G_loss: 1.5629\n",
      " Epoch [219/300], Batch Step [60/323], D_loss: 0.3983,  G_loss: 1.7479\n",
      " Epoch [219/300], Batch Step [70/323], D_loss: 0.6064,  G_loss: 1.7004\n",
      " Epoch [219/300], Batch Step [80/323], D_loss: 0.6318,  G_loss: 1.5087\n",
      " Epoch [219/300], Batch Step [90/323], D_loss: 0.4752,  G_loss: 1.6734\n",
      " Epoch [219/300], Batch Step [100/323], D_loss: 0.6232,  G_loss: 1.6928\n",
      " Epoch [219/300], Batch Step [110/323], D_loss: 0.7771,  G_loss: 1.4706\n",
      " Epoch [219/300], Batch Step [120/323], D_loss: 0.7481,  G_loss: 1.5994\n",
      " Epoch [219/300], Batch Step [130/323], D_loss: 0.5765,  G_loss: 1.7797\n",
      " Epoch [219/300], Batch Step [140/323], D_loss: 0.7497,  G_loss: 1.5758\n",
      " Epoch [219/300], Batch Step [150/323], D_loss: 0.5452,  G_loss: 1.5345\n",
      " Epoch [219/300], Batch Step [160/323], D_loss: 0.6183,  G_loss: 1.8117\n",
      " Epoch [219/300], Batch Step [170/323], D_loss: 0.5135,  G_loss: 1.4927\n",
      " Epoch [219/300], Batch Step [180/323], D_loss: 0.6433,  G_loss: 1.7750\n",
      " Epoch [219/300], Batch Step [190/323], D_loss: 0.8275,  G_loss: 1.6361\n",
      " Epoch [219/300], Batch Step [200/323], D_loss: 0.7078,  G_loss: 1.6039\n",
      " Epoch [219/300], Batch Step [210/323], D_loss: 0.6222,  G_loss: 1.5806\n",
      " Epoch [219/300], Batch Step [220/323], D_loss: 0.8747,  G_loss: 1.6430\n",
      " Epoch [219/300], Batch Step [230/323], D_loss: 0.7429,  G_loss: 1.4744\n",
      " Epoch [219/300], Batch Step [240/323], D_loss: 0.6837,  G_loss: 1.5848\n",
      " Epoch [219/300], Batch Step [250/323], D_loss: 0.6694,  G_loss: 1.7188\n",
      " Epoch [219/300], Batch Step [260/323], D_loss: 0.6559,  G_loss: 1.4923\n",
      " Epoch [219/300], Batch Step [270/323], D_loss: 0.7724,  G_loss: 1.5766\n",
      " Epoch [219/300], Batch Step [280/323], D_loss: 0.6118,  G_loss: 1.5371\n",
      " Epoch [219/300], Batch Step [290/323], D_loss: 0.5575,  G_loss: 1.5584\n",
      " Epoch [219/300], Batch Step [300/323], D_loss: 0.6123,  G_loss: 1.5495\n",
      " Epoch [219/300], Batch Step [310/323], D_loss: 0.6411,  G_loss: 1.4781\n",
      " Epoch [219/300], Batch Step [320/323], D_loss: 0.4685,  G_loss: 1.9104\n",
      " Epoch [220/300], Batch Step [0/323], D_loss: 0.8735,  G_loss: 1.8922\n",
      " Epoch [220/300], Batch Step [10/323], D_loss: 0.5214,  G_loss: 1.5059\n",
      " Epoch [220/300], Batch Step [20/323], D_loss: 0.7081,  G_loss: 1.6262\n",
      " Epoch [220/300], Batch Step [30/323], D_loss: 0.7761,  G_loss: 1.6209\n",
      " Epoch [220/300], Batch Step [40/323], D_loss: 0.7183,  G_loss: 1.5199\n",
      " Epoch [220/300], Batch Step [50/323], D_loss: 0.7240,  G_loss: 1.6759\n",
      " Epoch [220/300], Batch Step [60/323], D_loss: 0.7134,  G_loss: 1.5580\n",
      " Epoch [220/300], Batch Step [70/323], D_loss: 0.6455,  G_loss: 1.6154\n",
      " Epoch [220/300], Batch Step [80/323], D_loss: 0.7197,  G_loss: 1.5114\n",
      " Epoch [220/300], Batch Step [90/323], D_loss: 0.5635,  G_loss: 1.6246\n",
      " Epoch [220/300], Batch Step [100/323], D_loss: 0.6448,  G_loss: 1.5696\n",
      " Epoch [220/300], Batch Step [110/323], D_loss: 0.7452,  G_loss: 1.4883\n",
      " Epoch [220/300], Batch Step [120/323], D_loss: 0.4921,  G_loss: 1.5047\n",
      " Epoch [220/300], Batch Step [130/323], D_loss: 0.6601,  G_loss: 1.6021\n",
      " Epoch [220/300], Batch Step [140/323], D_loss: 0.6046,  G_loss: 1.6335\n",
      " Epoch [220/300], Batch Step [150/323], D_loss: 0.6816,  G_loss: 1.6605\n",
      " Epoch [220/300], Batch Step [160/323], D_loss: 0.6124,  G_loss: 1.5439\n",
      " Epoch [220/300], Batch Step [170/323], D_loss: 0.4964,  G_loss: 1.5723\n",
      " Epoch [220/300], Batch Step [180/323], D_loss: 0.5156,  G_loss: 1.6589\n",
      " Epoch [220/300], Batch Step [190/323], D_loss: 0.5757,  G_loss: 1.7415\n",
      " Epoch [220/300], Batch Step [200/323], D_loss: 0.5810,  G_loss: 1.5333\n",
      " Epoch [220/300], Batch Step [210/323], D_loss: 0.6174,  G_loss: 1.5504\n",
      " Epoch [220/300], Batch Step [220/323], D_loss: 0.5477,  G_loss: 1.6208\n",
      " Epoch [220/300], Batch Step [230/323], D_loss: 0.5697,  G_loss: 1.5457\n",
      " Epoch [220/300], Batch Step [240/323], D_loss: 0.6396,  G_loss: 1.5936\n",
      " Epoch [220/300], Batch Step [250/323], D_loss: 0.6879,  G_loss: 1.5986\n",
      " Epoch [220/300], Batch Step [260/323], D_loss: 0.5093,  G_loss: 1.7536\n",
      " Epoch [220/300], Batch Step [270/323], D_loss: 0.6783,  G_loss: 1.6919\n",
      " Epoch [220/300], Batch Step [280/323], D_loss: 0.5911,  G_loss: 1.4543\n",
      " Epoch [220/300], Batch Step [290/323], D_loss: 0.6478,  G_loss: 1.5248\n",
      " Epoch [220/300], Batch Step [300/323], D_loss: 0.5112,  G_loss: 1.7080\n",
      " Epoch [220/300], Batch Step [310/323], D_loss: 0.6105,  G_loss: 1.5973\n",
      " Epoch [220/300], Batch Step [320/323], D_loss: 0.7062,  G_loss: 1.5962\n",
      " Epoch [221/300], Batch Step [0/323], D_loss: 0.5381,  G_loss: 1.7128\n",
      " Epoch [221/300], Batch Step [10/323], D_loss: 0.5601,  G_loss: 1.6693\n",
      " Epoch [221/300], Batch Step [20/323], D_loss: 0.8554,  G_loss: 1.5681\n",
      " Epoch [221/300], Batch Step [30/323], D_loss: 0.6872,  G_loss: 1.6624\n",
      " Epoch [221/300], Batch Step [40/323], D_loss: 0.6718,  G_loss: 1.5951\n",
      " Epoch [221/300], Batch Step [50/323], D_loss: 0.6083,  G_loss: 1.5400\n",
      " Epoch [221/300], Batch Step [60/323], D_loss: 0.5944,  G_loss: 1.6153\n",
      " Epoch [221/300], Batch Step [70/323], D_loss: 0.6633,  G_loss: 1.5299\n",
      " Epoch [221/300], Batch Step [80/323], D_loss: 0.6605,  G_loss: 1.6566\n",
      " Epoch [221/300], Batch Step [90/323], D_loss: 0.6020,  G_loss: 1.6199\n",
      " Epoch [221/300], Batch Step [100/323], D_loss: 0.6567,  G_loss: 1.5515\n",
      " Epoch [221/300], Batch Step [110/323], D_loss: 0.7942,  G_loss: 1.5599\n",
      " Epoch [221/300], Batch Step [120/323], D_loss: 0.5681,  G_loss: 1.5362\n",
      " Epoch [221/300], Batch Step [130/323], D_loss: 0.7867,  G_loss: 1.8642\n",
      " Epoch [221/300], Batch Step [140/323], D_loss: 0.7366,  G_loss: 1.5022\n",
      " Epoch [221/300], Batch Step [150/323], D_loss: 0.6898,  G_loss: 1.6383\n",
      " Epoch [221/300], Batch Step [160/323], D_loss: 0.6221,  G_loss: 1.6906\n",
      " Epoch [221/300], Batch Step [170/323], D_loss: 0.6596,  G_loss: 1.6438\n",
      " Epoch [221/300], Batch Step [180/323], D_loss: 0.8061,  G_loss: 1.5992\n",
      " Epoch [221/300], Batch Step [190/323], D_loss: 0.6368,  G_loss: 1.6707\n",
      " Epoch [221/300], Batch Step [200/323], D_loss: 0.6018,  G_loss: 1.6754\n",
      " Epoch [221/300], Batch Step [210/323], D_loss: 0.6330,  G_loss: 1.5461\n",
      " Epoch [221/300], Batch Step [220/323], D_loss: 0.6790,  G_loss: 1.5553\n",
      " Epoch [221/300], Batch Step [230/323], D_loss: 0.6364,  G_loss: 1.6268\n",
      " Epoch [221/300], Batch Step [240/323], D_loss: 0.6742,  G_loss: 1.6554\n",
      " Epoch [221/300], Batch Step [250/323], D_loss: 0.7420,  G_loss: 1.6771\n",
      " Epoch [221/300], Batch Step [260/323], D_loss: 0.7294,  G_loss: 1.6071\n",
      " Epoch [221/300], Batch Step [270/323], D_loss: 0.6731,  G_loss: 1.4226\n",
      " Epoch [221/300], Batch Step [280/323], D_loss: 0.6354,  G_loss: 1.7088\n",
      " Epoch [221/300], Batch Step [290/323], D_loss: 0.5804,  G_loss: 1.5761\n",
      " Epoch [221/300], Batch Step [300/323], D_loss: 0.5963,  G_loss: 1.5700\n",
      " Epoch [221/300], Batch Step [310/323], D_loss: 0.6816,  G_loss: 1.5265\n",
      " Epoch [221/300], Batch Step [320/323], D_loss: 0.6064,  G_loss: 1.7159\n",
      " Epoch [222/300], Batch Step [0/323], D_loss: 0.5920,  G_loss: 1.7224\n",
      " Epoch [222/300], Batch Step [10/323], D_loss: 0.7695,  G_loss: 1.5611\n",
      " Epoch [222/300], Batch Step [20/323], D_loss: 0.6970,  G_loss: 1.5678\n",
      " Epoch [222/300], Batch Step [30/323], D_loss: 0.6860,  G_loss: 1.7488\n",
      " Epoch [222/300], Batch Step [40/323], D_loss: 0.6624,  G_loss: 1.6832\n",
      " Epoch [222/300], Batch Step [50/323], D_loss: 0.5346,  G_loss: 1.4187\n",
      " Epoch [222/300], Batch Step [60/323], D_loss: 0.6890,  G_loss: 1.6778\n",
      " Epoch [222/300], Batch Step [70/323], D_loss: 0.5062,  G_loss: 1.7469\n",
      " Epoch [222/300], Batch Step [80/323], D_loss: 0.6783,  G_loss: 1.6694\n",
      " Epoch [222/300], Batch Step [90/323], D_loss: 0.6855,  G_loss: 1.4534\n",
      " Epoch [222/300], Batch Step [100/323], D_loss: 0.5488,  G_loss: 1.7476\n",
      " Epoch [222/300], Batch Step [110/323], D_loss: 0.6516,  G_loss: 1.6889\n",
      " Epoch [222/300], Batch Step [120/323], D_loss: 0.6991,  G_loss: 1.6026\n",
      " Epoch [222/300], Batch Step [130/323], D_loss: 0.5458,  G_loss: 1.6519\n",
      " Epoch [222/300], Batch Step [140/323], D_loss: 0.5459,  G_loss: 1.5344\n",
      " Epoch [222/300], Batch Step [150/323], D_loss: 0.7488,  G_loss: 1.5909\n",
      " Epoch [222/300], Batch Step [160/323], D_loss: 0.6188,  G_loss: 1.6542\n",
      " Epoch [222/300], Batch Step [170/323], D_loss: 0.7568,  G_loss: 1.6561\n",
      " Epoch [222/300], Batch Step [180/323], D_loss: 0.6135,  G_loss: 1.4690\n",
      " Epoch [222/300], Batch Step [190/323], D_loss: 0.7042,  G_loss: 1.5770\n",
      " Epoch [222/300], Batch Step [200/323], D_loss: 0.5375,  G_loss: 1.6482\n",
      " Epoch [222/300], Batch Step [210/323], D_loss: 0.6088,  G_loss: 1.5424\n",
      " Epoch [222/300], Batch Step [220/323], D_loss: 0.6672,  G_loss: 1.6384\n",
      " Epoch [222/300], Batch Step [230/323], D_loss: 0.6463,  G_loss: 1.5114\n",
      " Epoch [222/300], Batch Step [240/323], D_loss: 0.4809,  G_loss: 1.5350\n",
      " Epoch [222/300], Batch Step [250/323], D_loss: 0.6287,  G_loss: 1.6609\n",
      " Epoch [222/300], Batch Step [260/323], D_loss: 0.5985,  G_loss: 1.7829\n",
      " Epoch [222/300], Batch Step [270/323], D_loss: 0.7187,  G_loss: 1.4793\n",
      " Epoch [222/300], Batch Step [280/323], D_loss: 0.6879,  G_loss: 1.6659\n",
      " Epoch [222/300], Batch Step [290/323], D_loss: 0.6217,  G_loss: 1.5696\n",
      " Epoch [222/300], Batch Step [300/323], D_loss: 0.5062,  G_loss: 1.6110\n",
      " Epoch [222/300], Batch Step [310/323], D_loss: 0.5928,  G_loss: 1.7579\n",
      " Epoch [222/300], Batch Step [320/323], D_loss: 0.5617,  G_loss: 1.6086\n",
      " Epoch [223/300], Batch Step [0/323], D_loss: 0.7026,  G_loss: 1.6649\n",
      " Epoch [223/300], Batch Step [10/323], D_loss: 0.6198,  G_loss: 1.6251\n",
      " Epoch [223/300], Batch Step [20/323], D_loss: 0.6389,  G_loss: 1.6128\n",
      " Epoch [223/300], Batch Step [30/323], D_loss: 0.6051,  G_loss: 1.5998\n",
      " Epoch [223/300], Batch Step [40/323], D_loss: 0.4989,  G_loss: 1.6216\n",
      " Epoch [223/300], Batch Step [50/323], D_loss: 0.6801,  G_loss: 1.5673\n",
      " Epoch [223/300], Batch Step [60/323], D_loss: 0.5938,  G_loss: 1.6424\n",
      " Epoch [223/300], Batch Step [70/323], D_loss: 0.5959,  G_loss: 1.5741\n",
      " Epoch [223/300], Batch Step [80/323], D_loss: 0.7931,  G_loss: 1.5963\n",
      " Epoch [223/300], Batch Step [90/323], D_loss: 0.6888,  G_loss: 1.6907\n",
      " Epoch [223/300], Batch Step [100/323], D_loss: 0.7257,  G_loss: 1.5525\n",
      " Epoch [223/300], Batch Step [110/323], D_loss: 0.7291,  G_loss: 1.7543\n",
      " Epoch [223/300], Batch Step [120/323], D_loss: 0.6363,  G_loss: 1.6400\n",
      " Epoch [223/300], Batch Step [130/323], D_loss: 0.5465,  G_loss: 1.6477\n",
      " Epoch [223/300], Batch Step [140/323], D_loss: 0.7176,  G_loss: 1.7753\n",
      " Epoch [223/300], Batch Step [150/323], D_loss: 0.4198,  G_loss: 1.5677\n",
      " Epoch [223/300], Batch Step [160/323], D_loss: 0.6025,  G_loss: 1.6325\n",
      " Epoch [223/300], Batch Step [170/323], D_loss: 0.6359,  G_loss: 1.5718\n",
      " Epoch [223/300], Batch Step [180/323], D_loss: 0.4890,  G_loss: 1.5375\n",
      " Epoch [223/300], Batch Step [190/323], D_loss: 0.5749,  G_loss: 1.6196\n",
      " Epoch [223/300], Batch Step [200/323], D_loss: 0.5745,  G_loss: 1.4510\n",
      " Epoch [223/300], Batch Step [210/323], D_loss: 0.7123,  G_loss: 1.5518\n",
      " Epoch [223/300], Batch Step [220/323], D_loss: 0.7848,  G_loss: 1.5737\n",
      " Epoch [223/300], Batch Step [230/323], D_loss: 0.6682,  G_loss: 1.5849\n",
      " Epoch [223/300], Batch Step [240/323], D_loss: 0.6388,  G_loss: 1.5973\n",
      " Epoch [223/300], Batch Step [250/323], D_loss: 0.5366,  G_loss: 1.6987\n",
      " Epoch [223/300], Batch Step [260/323], D_loss: 0.6568,  G_loss: 1.5901\n",
      " Epoch [223/300], Batch Step [270/323], D_loss: 0.5717,  G_loss: 1.6026\n",
      " Epoch [223/300], Batch Step [280/323], D_loss: 0.6572,  G_loss: 1.6538\n",
      " Epoch [223/300], Batch Step [290/323], D_loss: 0.5327,  G_loss: 1.6871\n",
      " Epoch [223/300], Batch Step [300/323], D_loss: 0.6399,  G_loss: 1.7490\n",
      " Epoch [223/300], Batch Step [310/323], D_loss: 0.6683,  G_loss: 1.6722\n",
      " Epoch [223/300], Batch Step [320/323], D_loss: 0.7092,  G_loss: 1.5869\n",
      " Epoch [224/300], Batch Step [0/323], D_loss: 0.6165,  G_loss: 1.4971\n",
      " Epoch [224/300], Batch Step [10/323], D_loss: 0.7966,  G_loss: 1.4343\n",
      " Epoch [224/300], Batch Step [20/323], D_loss: 0.6021,  G_loss: 1.7374\n",
      " Epoch [224/300], Batch Step [30/323], D_loss: 0.7816,  G_loss: 1.7449\n",
      " Epoch [224/300], Batch Step [40/323], D_loss: 0.6103,  G_loss: 1.6056\n",
      " Epoch [224/300], Batch Step [50/323], D_loss: 0.7070,  G_loss: 1.4911\n",
      " Epoch [224/300], Batch Step [60/323], D_loss: 0.5616,  G_loss: 1.7425\n",
      " Epoch [224/300], Batch Step [70/323], D_loss: 0.5806,  G_loss: 1.6666\n",
      " Epoch [224/300], Batch Step [80/323], D_loss: 0.5125,  G_loss: 1.6203\n",
      " Epoch [224/300], Batch Step [90/323], D_loss: 0.6034,  G_loss: 1.7290\n",
      " Epoch [224/300], Batch Step [100/323], D_loss: 0.7010,  G_loss: 1.7370\n",
      " Epoch [224/300], Batch Step [110/323], D_loss: 0.4626,  G_loss: 1.6714\n",
      " Epoch [224/300], Batch Step [120/323], D_loss: 0.5583,  G_loss: 1.6553\n",
      " Epoch [224/300], Batch Step [130/323], D_loss: 0.6352,  G_loss: 1.6820\n",
      " Epoch [224/300], Batch Step [140/323], D_loss: 0.4426,  G_loss: 1.5172\n",
      " Epoch [224/300], Batch Step [150/323], D_loss: 0.7045,  G_loss: 1.6379\n",
      " Epoch [224/300], Batch Step [160/323], D_loss: 0.6183,  G_loss: 1.5146\n",
      " Epoch [224/300], Batch Step [170/323], D_loss: 0.7575,  G_loss: 1.6506\n",
      " Epoch [224/300], Batch Step [180/323], D_loss: 0.7805,  G_loss: 1.5472\n",
      " Epoch [224/300], Batch Step [190/323], D_loss: 0.5698,  G_loss: 1.4644\n",
      " Epoch [224/300], Batch Step [200/323], D_loss: 0.7041,  G_loss: 1.5547\n",
      " Epoch [224/300], Batch Step [210/323], D_loss: 0.6942,  G_loss: 1.6061\n",
      " Epoch [224/300], Batch Step [220/323], D_loss: 0.6745,  G_loss: 1.6406\n",
      " Epoch [224/300], Batch Step [230/323], D_loss: 0.5015,  G_loss: 1.5030\n",
      " Epoch [224/300], Batch Step [240/323], D_loss: 0.6660,  G_loss: 1.5827\n",
      " Epoch [224/300], Batch Step [250/323], D_loss: 0.6030,  G_loss: 1.6715\n",
      " Epoch [224/300], Batch Step [260/323], D_loss: 0.7283,  G_loss: 1.6320\n",
      " Epoch [224/300], Batch Step [270/323], D_loss: 0.5696,  G_loss: 1.4370\n",
      " Epoch [224/300], Batch Step [280/323], D_loss: 0.6530,  G_loss: 1.7343\n",
      " Epoch [224/300], Batch Step [290/323], D_loss: 0.5276,  G_loss: 1.6485\n",
      " Epoch [224/300], Batch Step [300/323], D_loss: 0.6471,  G_loss: 1.5216\n",
      " Epoch [224/300], Batch Step [310/323], D_loss: 0.6285,  G_loss: 1.4949\n",
      " Epoch [224/300], Batch Step [320/323], D_loss: 0.6223,  G_loss: 1.6950\n",
      " Epoch [225/300], Batch Step [0/323], D_loss: 0.5903,  G_loss: 1.6643\n",
      " Epoch [225/300], Batch Step [10/323], D_loss: 0.6775,  G_loss: 1.6463\n",
      " Epoch [225/300], Batch Step [20/323], D_loss: 0.5040,  G_loss: 1.4957\n",
      " Epoch [225/300], Batch Step [30/323], D_loss: 0.5512,  G_loss: 1.6566\n",
      " Epoch [225/300], Batch Step [40/323], D_loss: 0.6784,  G_loss: 1.4463\n",
      " Epoch [225/300], Batch Step [50/323], D_loss: 0.6680,  G_loss: 1.7471\n",
      " Epoch [225/300], Batch Step [60/323], D_loss: 0.7020,  G_loss: 1.7855\n",
      " Epoch [225/300], Batch Step [70/323], D_loss: 0.6420,  G_loss: 1.6389\n",
      " Epoch [225/300], Batch Step [80/323], D_loss: 0.5864,  G_loss: 1.6184\n",
      " Epoch [225/300], Batch Step [90/323], D_loss: 0.6666,  G_loss: 1.7367\n",
      " Epoch [225/300], Batch Step [100/323], D_loss: 0.6500,  G_loss: 1.7605\n",
      " Epoch [225/300], Batch Step [110/323], D_loss: 0.6054,  G_loss: 1.7188\n",
      " Epoch [225/300], Batch Step [120/323], D_loss: 0.6665,  G_loss: 1.6381\n",
      " Epoch [225/300], Batch Step [130/323], D_loss: 0.6780,  G_loss: 1.7998\n",
      " Epoch [225/300], Batch Step [140/323], D_loss: 0.5431,  G_loss: 1.7309\n",
      " Epoch [225/300], Batch Step [150/323], D_loss: 0.6767,  G_loss: 1.4673\n",
      " Epoch [225/300], Batch Step [160/323], D_loss: 0.8533,  G_loss: 1.6373\n",
      " Epoch [225/300], Batch Step [170/323], D_loss: 0.4918,  G_loss: 1.5527\n",
      " Epoch [225/300], Batch Step [180/323], D_loss: 0.8060,  G_loss: 1.4865\n",
      " Epoch [225/300], Batch Step [190/323], D_loss: 0.6028,  G_loss: 1.4763\n",
      " Epoch [225/300], Batch Step [200/323], D_loss: 0.5714,  G_loss: 1.4783\n",
      " Epoch [225/300], Batch Step [210/323], D_loss: 0.6425,  G_loss: 1.6116\n",
      " Epoch [225/300], Batch Step [220/323], D_loss: 0.6028,  G_loss: 1.6458\n",
      " Epoch [225/300], Batch Step [230/323], D_loss: 0.6530,  G_loss: 1.6124\n",
      " Epoch [225/300], Batch Step [240/323], D_loss: 0.5070,  G_loss: 1.5747\n",
      " Epoch [225/300], Batch Step [250/323], D_loss: 0.5749,  G_loss: 1.5394\n",
      " Epoch [225/300], Batch Step [260/323], D_loss: 0.6055,  G_loss: 1.7247\n",
      " Epoch [225/300], Batch Step [270/323], D_loss: 0.7663,  G_loss: 1.6185\n",
      " Epoch [225/300], Batch Step [280/323], D_loss: 0.6943,  G_loss: 1.5897\n",
      " Epoch [225/300], Batch Step [290/323], D_loss: 0.5812,  G_loss: 1.4746\n",
      " Epoch [225/300], Batch Step [300/323], D_loss: 0.6654,  G_loss: 1.7762\n",
      " Epoch [225/300], Batch Step [310/323], D_loss: 0.5762,  G_loss: 1.7265\n",
      " Epoch [225/300], Batch Step [320/323], D_loss: 0.7372,  G_loss: 1.5670\n",
      " Epoch [226/300], Batch Step [0/323], D_loss: 0.6245,  G_loss: 1.6448\n",
      " Epoch [226/300], Batch Step [10/323], D_loss: 0.6768,  G_loss: 1.6139\n",
      " Epoch [226/300], Batch Step [20/323], D_loss: 0.6795,  G_loss: 1.6066\n",
      " Epoch [226/300], Batch Step [30/323], D_loss: 0.7124,  G_loss: 1.5219\n",
      " Epoch [226/300], Batch Step [40/323], D_loss: 0.5910,  G_loss: 1.7073\n",
      " Epoch [226/300], Batch Step [50/323], D_loss: 0.8208,  G_loss: 1.5339\n",
      " Epoch [226/300], Batch Step [60/323], D_loss: 0.7045,  G_loss: 1.4743\n",
      " Epoch [226/300], Batch Step [70/323], D_loss: 0.7243,  G_loss: 1.4683\n",
      " Epoch [226/300], Batch Step [80/323], D_loss: 0.5608,  G_loss: 1.7149\n",
      " Epoch [226/300], Batch Step [90/323], D_loss: 0.7042,  G_loss: 1.5293\n",
      " Epoch [226/300], Batch Step [100/323], D_loss: 0.6861,  G_loss: 1.4507\n",
      " Epoch [226/300], Batch Step [110/323], D_loss: 0.5734,  G_loss: 1.8404\n",
      " Epoch [226/300], Batch Step [120/323], D_loss: 0.6652,  G_loss: 1.6695\n",
      " Epoch [226/300], Batch Step [130/323], D_loss: 0.6303,  G_loss: 1.4162\n",
      " Epoch [226/300], Batch Step [140/323], D_loss: 0.5630,  G_loss: 1.8884\n",
      " Epoch [226/300], Batch Step [150/323], D_loss: 0.6778,  G_loss: 1.6893\n",
      " Epoch [226/300], Batch Step [160/323], D_loss: 0.6447,  G_loss: 1.5985\n",
      " Epoch [226/300], Batch Step [170/323], D_loss: 0.6144,  G_loss: 1.6746\n",
      " Epoch [226/300], Batch Step [180/323], D_loss: 0.5908,  G_loss: 1.6311\n",
      " Epoch [226/300], Batch Step [190/323], D_loss: 0.7697,  G_loss: 1.7520\n",
      " Epoch [226/300], Batch Step [200/323], D_loss: 0.5933,  G_loss: 1.6280\n",
      " Epoch [226/300], Batch Step [210/323], D_loss: 0.6550,  G_loss: 1.5712\n",
      " Epoch [226/300], Batch Step [220/323], D_loss: 0.6745,  G_loss: 1.5905\n",
      " Epoch [226/300], Batch Step [230/323], D_loss: 0.6107,  G_loss: 1.6706\n",
      " Epoch [226/300], Batch Step [240/323], D_loss: 0.6965,  G_loss: 1.5970\n",
      " Epoch [226/300], Batch Step [250/323], D_loss: 0.5226,  G_loss: 1.6972\n",
      " Epoch [226/300], Batch Step [260/323], D_loss: 0.5040,  G_loss: 1.8112\n",
      " Epoch [226/300], Batch Step [270/323], D_loss: 0.6364,  G_loss: 1.6124\n",
      " Epoch [226/300], Batch Step [280/323], D_loss: 0.6314,  G_loss: 1.6949\n",
      " Epoch [226/300], Batch Step [290/323], D_loss: 0.6091,  G_loss: 1.5407\n",
      " Epoch [226/300], Batch Step [300/323], D_loss: 0.5746,  G_loss: 1.6610\n",
      " Epoch [226/300], Batch Step [310/323], D_loss: 0.6815,  G_loss: 1.5616\n",
      " Epoch [226/300], Batch Step [320/323], D_loss: 0.8325,  G_loss: 1.5817\n",
      " Epoch [227/300], Batch Step [0/323], D_loss: 0.5886,  G_loss: 1.5732\n",
      " Epoch [227/300], Batch Step [10/323], D_loss: 0.5589,  G_loss: 1.6874\n",
      " Epoch [227/300], Batch Step [20/323], D_loss: 0.6660,  G_loss: 1.6303\n",
      " Epoch [227/300], Batch Step [30/323], D_loss: 0.5429,  G_loss: 1.7108\n",
      " Epoch [227/300], Batch Step [40/323], D_loss: 0.5117,  G_loss: 1.5708\n",
      " Epoch [227/300], Batch Step [50/323], D_loss: 0.7257,  G_loss: 1.6498\n",
      " Epoch [227/300], Batch Step [60/323], D_loss: 0.6735,  G_loss: 1.6344\n",
      " Epoch [227/300], Batch Step [70/323], D_loss: 0.6497,  G_loss: 1.5538\n",
      " Epoch [227/300], Batch Step [80/323], D_loss: 0.7704,  G_loss: 1.5112\n",
      " Epoch [227/300], Batch Step [90/323], D_loss: 0.6467,  G_loss: 1.4971\n",
      " Epoch [227/300], Batch Step [100/323], D_loss: 0.7126,  G_loss: 1.5467\n",
      " Epoch [227/300], Batch Step [110/323], D_loss: 0.5322,  G_loss: 1.6128\n",
      " Epoch [227/300], Batch Step [120/323], D_loss: 0.7499,  G_loss: 1.5997\n",
      " Epoch [227/300], Batch Step [130/323], D_loss: 0.5903,  G_loss: 1.5542\n",
      " Epoch [227/300], Batch Step [140/323], D_loss: 0.7207,  G_loss: 1.7876\n",
      " Epoch [227/300], Batch Step [150/323], D_loss: 0.6323,  G_loss: 1.7137\n",
      " Epoch [227/300], Batch Step [160/323], D_loss: 0.8092,  G_loss: 1.6518\n",
      " Epoch [227/300], Batch Step [170/323], D_loss: 0.6160,  G_loss: 1.7451\n",
      " Epoch [227/300], Batch Step [180/323], D_loss: 0.8217,  G_loss: 1.6762\n",
      " Epoch [227/300], Batch Step [190/323], D_loss: 0.6069,  G_loss: 1.6679\n",
      " Epoch [227/300], Batch Step [200/323], D_loss: 0.7325,  G_loss: 1.6200\n",
      " Epoch [227/300], Batch Step [210/323], D_loss: 0.6838,  G_loss: 1.6436\n",
      " Epoch [227/300], Batch Step [220/323], D_loss: 0.5919,  G_loss: 1.6305\n",
      " Epoch [227/300], Batch Step [230/323], D_loss: 0.4980,  G_loss: 1.5692\n",
      " Epoch [227/300], Batch Step [240/323], D_loss: 0.6237,  G_loss: 1.5788\n",
      " Epoch [227/300], Batch Step [250/323], D_loss: 0.6280,  G_loss: 1.6025\n",
      " Epoch [227/300], Batch Step [260/323], D_loss: 0.6080,  G_loss: 1.5888\n",
      " Epoch [227/300], Batch Step [270/323], D_loss: 0.8042,  G_loss: 1.6508\n",
      " Epoch [227/300], Batch Step [280/323], D_loss: 0.8167,  G_loss: 1.5927\n",
      " Epoch [227/300], Batch Step [290/323], D_loss: 0.5982,  G_loss: 1.6157\n",
      " Epoch [227/300], Batch Step [300/323], D_loss: 0.8079,  G_loss: 1.5823\n",
      " Epoch [227/300], Batch Step [310/323], D_loss: 0.4910,  G_loss: 1.5876\n",
      " Epoch [227/300], Batch Step [320/323], D_loss: 0.6358,  G_loss: 1.6065\n",
      " Epoch [228/300], Batch Step [0/323], D_loss: 0.8400,  G_loss: 1.5674\n",
      " Epoch [228/300], Batch Step [10/323], D_loss: 0.5199,  G_loss: 1.6000\n",
      " Epoch [228/300], Batch Step [20/323], D_loss: 0.4962,  G_loss: 1.6722\n",
      " Epoch [228/300], Batch Step [30/323], D_loss: 0.6191,  G_loss: 1.5210\n",
      " Epoch [228/300], Batch Step [40/323], D_loss: 0.7442,  G_loss: 1.6397\n",
      " Epoch [228/300], Batch Step [50/323], D_loss: 0.6078,  G_loss: 1.6543\n",
      " Epoch [228/300], Batch Step [60/323], D_loss: 0.6006,  G_loss: 1.6170\n",
      " Epoch [228/300], Batch Step [70/323], D_loss: 0.5307,  G_loss: 1.6186\n",
      " Epoch [228/300], Batch Step [80/323], D_loss: 0.6478,  G_loss: 1.6575\n",
      " Epoch [228/300], Batch Step [90/323], D_loss: 0.8674,  G_loss: 1.5573\n",
      " Epoch [228/300], Batch Step [100/323], D_loss: 0.6077,  G_loss: 1.7920\n",
      " Epoch [228/300], Batch Step [110/323], D_loss: 0.5590,  G_loss: 1.6508\n",
      " Epoch [228/300], Batch Step [120/323], D_loss: 0.6299,  G_loss: 1.5669\n",
      " Epoch [228/300], Batch Step [130/323], D_loss: 0.7150,  G_loss: 1.8069\n",
      " Epoch [228/300], Batch Step [140/323], D_loss: 0.7537,  G_loss: 1.5595\n",
      " Epoch [228/300], Batch Step [150/323], D_loss: 0.5553,  G_loss: 1.5704\n",
      " Epoch [228/300], Batch Step [160/323], D_loss: 0.6038,  G_loss: 1.7187\n",
      " Epoch [228/300], Batch Step [170/323], D_loss: 0.4939,  G_loss: 1.6811\n",
      " Epoch [228/300], Batch Step [180/323], D_loss: 0.5456,  G_loss: 1.4581\n",
      " Epoch [228/300], Batch Step [190/323], D_loss: 0.6222,  G_loss: 1.4656\n",
      " Epoch [228/300], Batch Step [200/323], D_loss: 0.7374,  G_loss: 1.7174\n",
      " Epoch [228/300], Batch Step [210/323], D_loss: 0.6786,  G_loss: 1.4811\n",
      " Epoch [228/300], Batch Step [220/323], D_loss: 0.6213,  G_loss: 1.5146\n",
      " Epoch [228/300], Batch Step [230/323], D_loss: 0.6739,  G_loss: 1.8264\n",
      " Epoch [228/300], Batch Step [240/323], D_loss: 0.7197,  G_loss: 1.5667\n",
      " Epoch [228/300], Batch Step [250/323], D_loss: 0.6572,  G_loss: 1.5683\n",
      " Epoch [228/300], Batch Step [260/323], D_loss: 0.7198,  G_loss: 1.7088\n",
      " Epoch [228/300], Batch Step [270/323], D_loss: 0.6928,  G_loss: 1.5592\n",
      " Epoch [228/300], Batch Step [280/323], D_loss: 0.6942,  G_loss: 1.6047\n",
      " Epoch [228/300], Batch Step [290/323], D_loss: 0.6538,  G_loss: 1.6262\n",
      " Epoch [228/300], Batch Step [300/323], D_loss: 0.7321,  G_loss: 1.5076\n",
      " Epoch [228/300], Batch Step [310/323], D_loss: 0.6637,  G_loss: 1.6328\n",
      " Epoch [228/300], Batch Step [320/323], D_loss: 0.5532,  G_loss: 1.5461\n",
      " Epoch [229/300], Batch Step [0/323], D_loss: 0.6650,  G_loss: 1.5756\n",
      " Epoch [229/300], Batch Step [10/323], D_loss: 0.8000,  G_loss: 1.7399\n",
      " Epoch [229/300], Batch Step [20/323], D_loss: 0.6910,  G_loss: 1.6044\n",
      " Epoch [229/300], Batch Step [30/323], D_loss: 0.5975,  G_loss: 1.6881\n",
      " Epoch [229/300], Batch Step [40/323], D_loss: 0.5155,  G_loss: 1.6812\n",
      " Epoch [229/300], Batch Step [50/323], D_loss: 0.5986,  G_loss: 1.7121\n",
      " Epoch [229/300], Batch Step [60/323], D_loss: 0.6742,  G_loss: 1.6563\n",
      " Epoch [229/300], Batch Step [70/323], D_loss: 0.5362,  G_loss: 1.5087\n",
      " Epoch [229/300], Batch Step [80/323], D_loss: 0.8220,  G_loss: 1.7160\n",
      " Epoch [229/300], Batch Step [90/323], D_loss: 0.7169,  G_loss: 1.7674\n",
      " Epoch [229/300], Batch Step [100/323], D_loss: 0.5871,  G_loss: 1.5793\n",
      " Epoch [229/300], Batch Step [110/323], D_loss: 0.5657,  G_loss: 1.7999\n",
      " Epoch [229/300], Batch Step [120/323], D_loss: 0.6072,  G_loss: 1.5312\n",
      " Epoch [229/300], Batch Step [130/323], D_loss: 0.5145,  G_loss: 1.6255\n",
      " Epoch [229/300], Batch Step [140/323], D_loss: 0.5177,  G_loss: 1.6508\n",
      " Epoch [229/300], Batch Step [150/323], D_loss: 0.6259,  G_loss: 1.6913\n",
      " Epoch [229/300], Batch Step [160/323], D_loss: 0.6567,  G_loss: 1.6202\n",
      " Epoch [229/300], Batch Step [170/323], D_loss: 0.6696,  G_loss: 1.5264\n",
      " Epoch [229/300], Batch Step [180/323], D_loss: 0.4726,  G_loss: 1.5874\n",
      " Epoch [229/300], Batch Step [190/323], D_loss: 0.7937,  G_loss: 1.6061\n",
      " Epoch [229/300], Batch Step [200/323], D_loss: 0.7094,  G_loss: 1.6848\n",
      " Epoch [229/300], Batch Step [210/323], D_loss: 0.5536,  G_loss: 1.4891\n",
      " Epoch [229/300], Batch Step [220/323], D_loss: 0.7862,  G_loss: 1.6376\n",
      " Epoch [229/300], Batch Step [230/323], D_loss: 0.6703,  G_loss: 1.7190\n",
      " Epoch [229/300], Batch Step [240/323], D_loss: 0.6133,  G_loss: 1.7149\n",
      " Epoch [229/300], Batch Step [250/323], D_loss: 0.7624,  G_loss: 1.5491\n",
      " Epoch [229/300], Batch Step [260/323], D_loss: 0.6412,  G_loss: 1.6537\n",
      " Epoch [229/300], Batch Step [270/323], D_loss: 0.6434,  G_loss: 1.6995\n",
      " Epoch [229/300], Batch Step [280/323], D_loss: 0.5531,  G_loss: 1.4889\n",
      " Epoch [229/300], Batch Step [290/323], D_loss: 0.6468,  G_loss: 1.5300\n",
      " Epoch [229/300], Batch Step [300/323], D_loss: 0.6401,  G_loss: 1.6364\n",
      " Epoch [229/300], Batch Step [310/323], D_loss: 0.7290,  G_loss: 1.5867\n",
      " Epoch [229/300], Batch Step [320/323], D_loss: 0.7189,  G_loss: 1.6474\n",
      " Epoch [230/300], Batch Step [0/323], D_loss: 0.7001,  G_loss: 1.5642\n",
      " Epoch [230/300], Batch Step [10/323], D_loss: 0.6545,  G_loss: 1.5486\n",
      " Epoch [230/300], Batch Step [20/323], D_loss: 0.6738,  G_loss: 1.6217\n",
      " Epoch [230/300], Batch Step [30/323], D_loss: 0.5632,  G_loss: 1.5251\n",
      " Epoch [230/300], Batch Step [40/323], D_loss: 0.6428,  G_loss: 1.7087\n",
      " Epoch [230/300], Batch Step [50/323], D_loss: 0.4760,  G_loss: 1.5531\n",
      " Epoch [230/300], Batch Step [60/323], D_loss: 0.7745,  G_loss: 1.5684\n",
      " Epoch [230/300], Batch Step [70/323], D_loss: 0.5255,  G_loss: 1.7371\n",
      " Epoch [230/300], Batch Step [80/323], D_loss: 0.6030,  G_loss: 1.4893\n",
      " Epoch [230/300], Batch Step [90/323], D_loss: 0.6149,  G_loss: 1.5891\n",
      " Epoch [230/300], Batch Step [100/323], D_loss: 0.5375,  G_loss: 1.5210\n",
      " Epoch [230/300], Batch Step [110/323], D_loss: 0.5883,  G_loss: 1.5085\n",
      " Epoch [230/300], Batch Step [120/323], D_loss: 0.7421,  G_loss: 1.7324\n",
      " Epoch [230/300], Batch Step [130/323], D_loss: 0.6972,  G_loss: 1.5178\n",
      " Epoch [230/300], Batch Step [140/323], D_loss: 0.5015,  G_loss: 1.6607\n",
      " Epoch [230/300], Batch Step [150/323], D_loss: 0.5081,  G_loss: 1.7249\n",
      " Epoch [230/300], Batch Step [160/323], D_loss: 0.6765,  G_loss: 1.4842\n",
      " Epoch [230/300], Batch Step [170/323], D_loss: 0.6828,  G_loss: 1.6557\n",
      " Epoch [230/300], Batch Step [180/323], D_loss: 0.6513,  G_loss: 1.6312\n",
      " Epoch [230/300], Batch Step [190/323], D_loss: 0.5720,  G_loss: 1.5589\n",
      " Epoch [230/300], Batch Step [200/323], D_loss: 0.5801,  G_loss: 1.5761\n",
      " Epoch [230/300], Batch Step [210/323], D_loss: 0.6135,  G_loss: 1.8411\n",
      " Epoch [230/300], Batch Step [220/323], D_loss: 0.7067,  G_loss: 1.6709\n",
      " Epoch [230/300], Batch Step [230/323], D_loss: 0.7035,  G_loss: 1.5301\n",
      " Epoch [230/300], Batch Step [240/323], D_loss: 0.7363,  G_loss: 1.5932\n",
      " Epoch [230/300], Batch Step [250/323], D_loss: 0.6713,  G_loss: 1.6296\n",
      " Epoch [230/300], Batch Step [260/323], D_loss: 0.5854,  G_loss: 1.6485\n",
      " Epoch [230/300], Batch Step [270/323], D_loss: 0.6624,  G_loss: 1.7060\n",
      " Epoch [230/300], Batch Step [280/323], D_loss: 0.6602,  G_loss: 1.7153\n",
      " Epoch [230/300], Batch Step [290/323], D_loss: 0.5404,  G_loss: 1.4146\n",
      " Epoch [230/300], Batch Step [300/323], D_loss: 0.7699,  G_loss: 1.6507\n",
      " Epoch [230/300], Batch Step [310/323], D_loss: 0.6383,  G_loss: 1.5376\n",
      " Epoch [230/300], Batch Step [320/323], D_loss: 0.6738,  G_loss: 1.7338\n",
      " Epoch [231/300], Batch Step [0/323], D_loss: 0.7516,  G_loss: 1.6238\n",
      " Epoch [231/300], Batch Step [10/323], D_loss: 0.7086,  G_loss: 1.4647\n",
      " Epoch [231/300], Batch Step [20/323], D_loss: 0.8155,  G_loss: 1.6637\n",
      " Epoch [231/300], Batch Step [30/323], D_loss: 0.6970,  G_loss: 1.6085\n",
      " Epoch [231/300], Batch Step [40/323], D_loss: 0.6009,  G_loss: 1.5667\n",
      " Epoch [231/300], Batch Step [50/323], D_loss: 0.5567,  G_loss: 1.6083\n",
      " Epoch [231/300], Batch Step [60/323], D_loss: 0.6743,  G_loss: 1.5599\n",
      " Epoch [231/300], Batch Step [70/323], D_loss: 0.4427,  G_loss: 1.5845\n",
      " Epoch [231/300], Batch Step [80/323], D_loss: 0.5570,  G_loss: 1.6961\n",
      " Epoch [231/300], Batch Step [90/323], D_loss: 0.5542,  G_loss: 1.6734\n",
      " Epoch [231/300], Batch Step [100/323], D_loss: 0.7000,  G_loss: 1.5838\n",
      " Epoch [231/300], Batch Step [110/323], D_loss: 0.5702,  G_loss: 1.6101\n",
      " Epoch [231/300], Batch Step [120/323], D_loss: 0.7660,  G_loss: 1.6597\n",
      " Epoch [231/300], Batch Step [130/323], D_loss: 0.6802,  G_loss: 1.5318\n",
      " Epoch [231/300], Batch Step [140/323], D_loss: 0.7090,  G_loss: 1.6497\n",
      " Epoch [231/300], Batch Step [150/323], D_loss: 0.5996,  G_loss: 1.5284\n",
      " Epoch [231/300], Batch Step [160/323], D_loss: 0.5650,  G_loss: 1.5611\n",
      " Epoch [231/300], Batch Step [170/323], D_loss: 0.5843,  G_loss: 1.6414\n",
      " Epoch [231/300], Batch Step [180/323], D_loss: 0.5360,  G_loss: 1.5418\n",
      " Epoch [231/300], Batch Step [190/323], D_loss: 0.5961,  G_loss: 1.6850\n",
      " Epoch [231/300], Batch Step [200/323], D_loss: 0.5600,  G_loss: 1.6575\n",
      " Epoch [231/300], Batch Step [210/323], D_loss: 0.6888,  G_loss: 1.6052\n",
      " Epoch [231/300], Batch Step [220/323], D_loss: 0.5470,  G_loss: 1.6036\n",
      " Epoch [231/300], Batch Step [230/323], D_loss: 0.6436,  G_loss: 1.5047\n",
      " Epoch [231/300], Batch Step [240/323], D_loss: 0.6393,  G_loss: 1.6175\n",
      " Epoch [231/300], Batch Step [250/323], D_loss: 0.4673,  G_loss: 1.4947\n",
      " Epoch [231/300], Batch Step [260/323], D_loss: 0.5803,  G_loss: 1.6501\n",
      " Epoch [231/300], Batch Step [270/323], D_loss: 0.6377,  G_loss: 1.5332\n",
      " Epoch [231/300], Batch Step [280/323], D_loss: 0.7233,  G_loss: 1.5468\n",
      " Epoch [231/300], Batch Step [290/323], D_loss: 0.5682,  G_loss: 1.6202\n",
      " Epoch [231/300], Batch Step [300/323], D_loss: 0.6887,  G_loss: 1.5229\n",
      " Epoch [231/300], Batch Step [310/323], D_loss: 0.5348,  G_loss: 1.5684\n",
      " Epoch [231/300], Batch Step [320/323], D_loss: 0.5435,  G_loss: 1.7032\n",
      " Epoch [232/300], Batch Step [0/323], D_loss: 0.7235,  G_loss: 1.6423\n",
      " Epoch [232/300], Batch Step [10/323], D_loss: 0.5860,  G_loss: 1.4403\n",
      " Epoch [232/300], Batch Step [20/323], D_loss: 0.6507,  G_loss: 1.7278\n",
      " Epoch [232/300], Batch Step [30/323], D_loss: 0.7685,  G_loss: 1.7249\n",
      " Epoch [232/300], Batch Step [40/323], D_loss: 0.6477,  G_loss: 1.5609\n",
      " Epoch [232/300], Batch Step [50/323], D_loss: 0.5462,  G_loss: 1.6679\n",
      " Epoch [232/300], Batch Step [60/323], D_loss: 0.6590,  G_loss: 1.5660\n",
      " Epoch [232/300], Batch Step [70/323], D_loss: 0.5459,  G_loss: 1.6257\n",
      " Epoch [232/300], Batch Step [80/323], D_loss: 0.6449,  G_loss: 1.7266\n",
      " Epoch [232/300], Batch Step [90/323], D_loss: 0.6254,  G_loss: 1.5640\n",
      " Epoch [232/300], Batch Step [100/323], D_loss: 0.6102,  G_loss: 1.5476\n",
      " Epoch [232/300], Batch Step [110/323], D_loss: 0.4678,  G_loss: 1.6045\n",
      " Epoch [232/300], Batch Step [120/323], D_loss: 0.5311,  G_loss: 1.5726\n",
      " Epoch [232/300], Batch Step [130/323], D_loss: 0.6354,  G_loss: 1.7289\n",
      " Epoch [232/300], Batch Step [140/323], D_loss: 0.6646,  G_loss: 1.6929\n",
      " Epoch [232/300], Batch Step [150/323], D_loss: 0.6860,  G_loss: 1.6221\n",
      " Epoch [232/300], Batch Step [160/323], D_loss: 0.8140,  G_loss: 1.6236\n",
      " Epoch [232/300], Batch Step [170/323], D_loss: 0.5837,  G_loss: 1.6397\n",
      " Epoch [232/300], Batch Step [180/323], D_loss: 0.5082,  G_loss: 1.7775\n",
      " Epoch [232/300], Batch Step [190/323], D_loss: 0.7956,  G_loss: 1.6607\n",
      " Epoch [232/300], Batch Step [200/323], D_loss: 0.8584,  G_loss: 1.5050\n",
      " Epoch [232/300], Batch Step [210/323], D_loss: 0.6284,  G_loss: 1.6931\n",
      " Epoch [232/300], Batch Step [220/323], D_loss: 0.5525,  G_loss: 1.6571\n",
      " Epoch [232/300], Batch Step [230/323], D_loss: 0.5657,  G_loss: 1.5444\n",
      " Epoch [232/300], Batch Step [240/323], D_loss: 0.5178,  G_loss: 1.7107\n",
      " Epoch [232/300], Batch Step [250/323], D_loss: 0.5690,  G_loss: 1.6225\n",
      " Epoch [232/300], Batch Step [260/323], D_loss: 0.4193,  G_loss: 1.7411\n",
      " Epoch [232/300], Batch Step [270/323], D_loss: 0.5165,  G_loss: 1.6869\n",
      " Epoch [232/300], Batch Step [280/323], D_loss: 0.5563,  G_loss: 1.4544\n",
      " Epoch [232/300], Batch Step [290/323], D_loss: 0.7151,  G_loss: 1.6606\n",
      " Epoch [232/300], Batch Step [300/323], D_loss: 0.5616,  G_loss: 1.6881\n",
      " Epoch [232/300], Batch Step [310/323], D_loss: 0.8497,  G_loss: 1.4282\n",
      " Epoch [232/300], Batch Step [320/323], D_loss: 0.6581,  G_loss: 1.5963\n",
      " Epoch [233/300], Batch Step [0/323], D_loss: 0.7220,  G_loss: 1.6388\n",
      " Epoch [233/300], Batch Step [10/323], D_loss: 0.8057,  G_loss: 1.7214\n",
      " Epoch [233/300], Batch Step [20/323], D_loss: 0.7623,  G_loss: 1.5332\n",
      " Epoch [233/300], Batch Step [30/323], D_loss: 0.8315,  G_loss: 1.6910\n",
      " Epoch [233/300], Batch Step [40/323], D_loss: 0.7051,  G_loss: 1.6354\n",
      " Epoch [233/300], Batch Step [50/323], D_loss: 0.7501,  G_loss: 1.6033\n",
      " Epoch [233/300], Batch Step [60/323], D_loss: 0.6278,  G_loss: 1.6693\n",
      " Epoch [233/300], Batch Step [70/323], D_loss: 0.5435,  G_loss: 1.5129\n",
      " Epoch [233/300], Batch Step [80/323], D_loss: 0.6047,  G_loss: 1.5598\n",
      " Epoch [233/300], Batch Step [90/323], D_loss: 0.6026,  G_loss: 1.5990\n",
      " Epoch [233/300], Batch Step [100/323], D_loss: 0.6589,  G_loss: 1.5993\n",
      " Epoch [233/300], Batch Step [110/323], D_loss: 0.8307,  G_loss: 1.4415\n",
      " Epoch [233/300], Batch Step [120/323], D_loss: 0.6807,  G_loss: 1.6345\n",
      " Epoch [233/300], Batch Step [130/323], D_loss: 0.7001,  G_loss: 1.5702\n",
      " Epoch [233/300], Batch Step [140/323], D_loss: 0.6080,  G_loss: 1.5816\n",
      " Epoch [233/300], Batch Step [150/323], D_loss: 0.7490,  G_loss: 1.6182\n",
      " Epoch [233/300], Batch Step [160/323], D_loss: 0.7046,  G_loss: 1.6399\n",
      " Epoch [233/300], Batch Step [170/323], D_loss: 0.5930,  G_loss: 1.5059\n",
      " Epoch [233/300], Batch Step [180/323], D_loss: 0.6858,  G_loss: 1.6014\n",
      " Epoch [233/300], Batch Step [190/323], D_loss: 0.5908,  G_loss: 1.7004\n",
      " Epoch [233/300], Batch Step [200/323], D_loss: 0.6911,  G_loss: 1.6427\n",
      " Epoch [233/300], Batch Step [210/323], D_loss: 0.6508,  G_loss: 1.4607\n",
      " Epoch [233/300], Batch Step [220/323], D_loss: 0.6458,  G_loss: 1.8925\n",
      " Epoch [233/300], Batch Step [230/323], D_loss: 0.5765,  G_loss: 1.5612\n",
      " Epoch [233/300], Batch Step [240/323], D_loss: 0.6624,  G_loss: 1.6097\n",
      " Epoch [233/300], Batch Step [250/323], D_loss: 0.5464,  G_loss: 1.5432\n",
      " Epoch [233/300], Batch Step [260/323], D_loss: 0.5561,  G_loss: 1.6118\n",
      " Epoch [233/300], Batch Step [270/323], D_loss: 0.5933,  G_loss: 1.6498\n",
      " Epoch [233/300], Batch Step [280/323], D_loss: 0.8952,  G_loss: 1.5628\n",
      " Epoch [233/300], Batch Step [290/323], D_loss: 0.6998,  G_loss: 1.7200\n",
      " Epoch [233/300], Batch Step [300/323], D_loss: 0.5344,  G_loss: 1.4961\n",
      " Epoch [233/300], Batch Step [310/323], D_loss: 0.6352,  G_loss: 1.6504\n",
      " Epoch [233/300], Batch Step [320/323], D_loss: 0.6815,  G_loss: 1.6091\n",
      " Epoch [234/300], Batch Step [0/323], D_loss: 0.5702,  G_loss: 1.6475\n",
      " Epoch [234/300], Batch Step [10/323], D_loss: 0.6965,  G_loss: 1.7042\n",
      " Epoch [234/300], Batch Step [20/323], D_loss: 0.5421,  G_loss: 1.5959\n",
      " Epoch [234/300], Batch Step [30/323], D_loss: 0.6276,  G_loss: 1.5969\n",
      " Epoch [234/300], Batch Step [40/323], D_loss: 0.5768,  G_loss: 1.6169\n",
      " Epoch [234/300], Batch Step [50/323], D_loss: 0.8627,  G_loss: 1.8179\n",
      " Epoch [234/300], Batch Step [60/323], D_loss: 0.5465,  G_loss: 1.5743\n",
      " Epoch [234/300], Batch Step [70/323], D_loss: 0.7470,  G_loss: 1.7008\n",
      " Epoch [234/300], Batch Step [80/323], D_loss: 0.7109,  G_loss: 1.6316\n",
      " Epoch [234/300], Batch Step [90/323], D_loss: 0.7953,  G_loss: 1.6275\n",
      " Epoch [234/300], Batch Step [100/323], D_loss: 0.7230,  G_loss: 1.4442\n",
      " Epoch [234/300], Batch Step [110/323], D_loss: 0.6800,  G_loss: 1.5192\n",
      " Epoch [234/300], Batch Step [120/323], D_loss: 0.6280,  G_loss: 1.6324\n",
      " Epoch [234/300], Batch Step [130/323], D_loss: 0.7297,  G_loss: 1.6344\n",
      " Epoch [234/300], Batch Step [140/323], D_loss: 0.6835,  G_loss: 1.6151\n",
      " Epoch [234/300], Batch Step [150/323], D_loss: 0.6351,  G_loss: 1.5768\n",
      " Epoch [234/300], Batch Step [160/323], D_loss: 0.8129,  G_loss: 1.5305\n",
      " Epoch [234/300], Batch Step [170/323], D_loss: 0.6984,  G_loss: 1.5001\n",
      " Epoch [234/300], Batch Step [180/323], D_loss: 0.5969,  G_loss: 1.6385\n",
      " Epoch [234/300], Batch Step [190/323], D_loss: 0.7713,  G_loss: 1.5682\n",
      " Epoch [234/300], Batch Step [200/323], D_loss: 0.6973,  G_loss: 1.4951\n",
      " Epoch [234/300], Batch Step [210/323], D_loss: 0.6758,  G_loss: 1.6476\n",
      " Epoch [234/300], Batch Step [220/323], D_loss: 0.6876,  G_loss: 1.6172\n",
      " Epoch [234/300], Batch Step [230/323], D_loss: 0.8446,  G_loss: 1.6751\n",
      " Epoch [234/300], Batch Step [240/323], D_loss: 0.6909,  G_loss: 1.7015\n",
      " Epoch [234/300], Batch Step [250/323], D_loss: 0.5551,  G_loss: 1.4885\n",
      " Epoch [234/300], Batch Step [260/323], D_loss: 0.5541,  G_loss: 1.5780\n",
      " Epoch [234/300], Batch Step [270/323], D_loss: 0.7877,  G_loss: 1.5826\n",
      " Epoch [234/300], Batch Step [280/323], D_loss: 0.6037,  G_loss: 1.6813\n",
      " Epoch [234/300], Batch Step [290/323], D_loss: 0.7798,  G_loss: 1.6409\n",
      " Epoch [234/300], Batch Step [300/323], D_loss: 0.8149,  G_loss: 1.5361\n",
      " Epoch [234/300], Batch Step [310/323], D_loss: 0.6620,  G_loss: 1.6469\n",
      " Epoch [234/300], Batch Step [320/323], D_loss: 0.6634,  G_loss: 1.6181\n",
      " Epoch [235/300], Batch Step [0/323], D_loss: 0.6973,  G_loss: 1.6274\n",
      " Epoch [235/300], Batch Step [10/323], D_loss: 0.7057,  G_loss: 1.5066\n",
      " Epoch [235/300], Batch Step [20/323], D_loss: 0.5029,  G_loss: 1.8538\n",
      " Epoch [235/300], Batch Step [30/323], D_loss: 0.6936,  G_loss: 1.6242\n",
      " Epoch [235/300], Batch Step [40/323], D_loss: 0.6083,  G_loss: 1.5475\n",
      " Epoch [235/300], Batch Step [50/323], D_loss: 0.6172,  G_loss: 1.6817\n",
      " Epoch [235/300], Batch Step [60/323], D_loss: 0.7056,  G_loss: 1.5883\n",
      " Epoch [235/300], Batch Step [70/323], D_loss: 0.6610,  G_loss: 1.6979\n",
      " Epoch [235/300], Batch Step [80/323], D_loss: 0.4473,  G_loss: 1.6363\n",
      " Epoch [235/300], Batch Step [90/323], D_loss: 0.7007,  G_loss: 1.5812\n",
      " Epoch [235/300], Batch Step [100/323], D_loss: 0.7557,  G_loss: 1.5739\n",
      " Epoch [235/300], Batch Step [110/323], D_loss: 0.7292,  G_loss: 1.5545\n",
      " Epoch [235/300], Batch Step [120/323], D_loss: 0.7246,  G_loss: 1.5291\n",
      " Epoch [235/300], Batch Step [130/323], D_loss: 0.7427,  G_loss: 1.5694\n",
      " Epoch [235/300], Batch Step [140/323], D_loss: 0.5574,  G_loss: 1.5865\n",
      " Epoch [235/300], Batch Step [150/323], D_loss: 0.7876,  G_loss: 1.6146\n",
      " Epoch [235/300], Batch Step [160/323], D_loss: 0.6515,  G_loss: 1.5872\n",
      " Epoch [235/300], Batch Step [170/323], D_loss: 0.5135,  G_loss: 1.5451\n",
      " Epoch [235/300], Batch Step [180/323], D_loss: 0.5601,  G_loss: 1.7802\n",
      " Epoch [235/300], Batch Step [190/323], D_loss: 0.7289,  G_loss: 1.6163\n",
      " Epoch [235/300], Batch Step [200/323], D_loss: 0.6638,  G_loss: 1.5605\n",
      " Epoch [235/300], Batch Step [210/323], D_loss: 0.6209,  G_loss: 1.7365\n",
      " Epoch [235/300], Batch Step [220/323], D_loss: 0.6330,  G_loss: 1.6062\n",
      " Epoch [235/300], Batch Step [230/323], D_loss: 0.6429,  G_loss: 1.6527\n",
      " Epoch [235/300], Batch Step [240/323], D_loss: 0.7280,  G_loss: 1.7109\n",
      " Epoch [235/300], Batch Step [250/323], D_loss: 0.6139,  G_loss: 1.5303\n",
      " Epoch [235/300], Batch Step [260/323], D_loss: 0.8148,  G_loss: 1.6461\n",
      " Epoch [235/300], Batch Step [270/323], D_loss: 0.7006,  G_loss: 1.5053\n",
      " Epoch [235/300], Batch Step [280/323], D_loss: 0.7355,  G_loss: 1.5884\n",
      " Epoch [235/300], Batch Step [290/323], D_loss: 0.7299,  G_loss: 1.7229\n",
      " Epoch [235/300], Batch Step [300/323], D_loss: 0.7973,  G_loss: 1.4835\n",
      " Epoch [235/300], Batch Step [310/323], D_loss: 0.6898,  G_loss: 1.5254\n",
      " Epoch [235/300], Batch Step [320/323], D_loss: 0.7310,  G_loss: 1.7711\n",
      " Epoch [236/300], Batch Step [0/323], D_loss: 0.5790,  G_loss: 1.7182\n",
      " Epoch [236/300], Batch Step [10/323], D_loss: 0.8421,  G_loss: 1.3953\n",
      " Epoch [236/300], Batch Step [20/323], D_loss: 0.5133,  G_loss: 1.5841\n",
      " Epoch [236/300], Batch Step [30/323], D_loss: 0.5751,  G_loss: 1.6229\n",
      " Epoch [236/300], Batch Step [40/323], D_loss: 0.5769,  G_loss: 1.5491\n",
      " Epoch [236/300], Batch Step [50/323], D_loss: 0.7871,  G_loss: 1.6200\n",
      " Epoch [236/300], Batch Step [60/323], D_loss: 0.8474,  G_loss: 1.4770\n",
      " Epoch [236/300], Batch Step [70/323], D_loss: 0.5882,  G_loss: 1.6891\n",
      " Epoch [236/300], Batch Step [80/323], D_loss: 0.7010,  G_loss: 1.5270\n",
      " Epoch [236/300], Batch Step [90/323], D_loss: 0.6291,  G_loss: 1.6071\n",
      " Epoch [236/300], Batch Step [100/323], D_loss: 0.8854,  G_loss: 1.7367\n",
      " Epoch [236/300], Batch Step [110/323], D_loss: 0.6062,  G_loss: 1.5487\n",
      " Epoch [236/300], Batch Step [120/323], D_loss: 0.4119,  G_loss: 1.8097\n",
      " Epoch [236/300], Batch Step [130/323], D_loss: 0.7590,  G_loss: 1.6442\n",
      " Epoch [236/300], Batch Step [140/323], D_loss: 0.6459,  G_loss: 1.6463\n",
      " Epoch [236/300], Batch Step [150/323], D_loss: 0.5728,  G_loss: 1.7698\n",
      " Epoch [236/300], Batch Step [160/323], D_loss: 0.4846,  G_loss: 1.5098\n",
      " Epoch [236/300], Batch Step [170/323], D_loss: 0.5517,  G_loss: 1.6531\n",
      " Epoch [236/300], Batch Step [180/323], D_loss: 0.6213,  G_loss: 1.7546\n",
      " Epoch [236/300], Batch Step [190/323], D_loss: 0.7199,  G_loss: 1.5853\n",
      " Epoch [236/300], Batch Step [200/323], D_loss: 0.6971,  G_loss: 1.5447\n",
      " Epoch [236/300], Batch Step [210/323], D_loss: 0.5587,  G_loss: 1.6425\n",
      " Epoch [236/300], Batch Step [220/323], D_loss: 0.7428,  G_loss: 1.6037\n",
      " Epoch [236/300], Batch Step [230/323], D_loss: 0.7237,  G_loss: 1.4700\n",
      " Epoch [236/300], Batch Step [240/323], D_loss: 0.6402,  G_loss: 1.4720\n",
      " Epoch [236/300], Batch Step [250/323], D_loss: 0.6603,  G_loss: 1.7795\n",
      " Epoch [236/300], Batch Step [260/323], D_loss: 0.5694,  G_loss: 1.5970\n",
      " Epoch [236/300], Batch Step [270/323], D_loss: 0.7487,  G_loss: 1.4663\n",
      " Epoch [236/300], Batch Step [280/323], D_loss: 0.5829,  G_loss: 1.7239\n",
      " Epoch [236/300], Batch Step [290/323], D_loss: 0.6582,  G_loss: 1.7151\n",
      " Epoch [236/300], Batch Step [300/323], D_loss: 0.8023,  G_loss: 1.6202\n",
      " Epoch [236/300], Batch Step [310/323], D_loss: 0.6174,  G_loss: 1.4556\n",
      " Epoch [236/300], Batch Step [320/323], D_loss: 0.7053,  G_loss: 1.6952\n",
      " Epoch [237/300], Batch Step [0/323], D_loss: 0.7627,  G_loss: 1.5770\n",
      " Epoch [237/300], Batch Step [10/323], D_loss: 0.6059,  G_loss: 1.6693\n",
      " Epoch [237/300], Batch Step [20/323], D_loss: 0.6687,  G_loss: 1.7301\n",
      " Epoch [237/300], Batch Step [30/323], D_loss: 0.7019,  G_loss: 1.5043\n",
      " Epoch [237/300], Batch Step [40/323], D_loss: 0.5414,  G_loss: 1.7212\n",
      " Epoch [237/300], Batch Step [50/323], D_loss: 0.6698,  G_loss: 1.6117\n",
      " Epoch [237/300], Batch Step [60/323], D_loss: 0.6253,  G_loss: 1.6216\n",
      " Epoch [237/300], Batch Step [70/323], D_loss: 0.5177,  G_loss: 1.6285\n",
      " Epoch [237/300], Batch Step [80/323], D_loss: 0.7649,  G_loss: 1.5665\n",
      " Epoch [237/300], Batch Step [90/323], D_loss: 0.7206,  G_loss: 1.5926\n",
      " Epoch [237/300], Batch Step [100/323], D_loss: 0.7088,  G_loss: 1.4808\n",
      " Epoch [237/300], Batch Step [110/323], D_loss: 0.5543,  G_loss: 1.7368\n",
      " Epoch [237/300], Batch Step [120/323], D_loss: 0.5760,  G_loss: 1.7992\n",
      " Epoch [237/300], Batch Step [130/323], D_loss: 0.6345,  G_loss: 1.5188\n",
      " Epoch [237/300], Batch Step [140/323], D_loss: 0.8760,  G_loss: 1.6821\n",
      " Epoch [237/300], Batch Step [150/323], D_loss: 0.6330,  G_loss: 1.5876\n",
      " Epoch [237/300], Batch Step [160/323], D_loss: 0.5638,  G_loss: 1.6536\n",
      " Epoch [237/300], Batch Step [170/323], D_loss: 0.7065,  G_loss: 1.5517\n",
      " Epoch [237/300], Batch Step [180/323], D_loss: 0.5902,  G_loss: 1.5862\n",
      " Epoch [237/300], Batch Step [190/323], D_loss: 0.6137,  G_loss: 1.6550\n",
      " Epoch [237/300], Batch Step [200/323], D_loss: 0.6511,  G_loss: 1.6516\n",
      " Epoch [237/300], Batch Step [210/323], D_loss: 0.6618,  G_loss: 1.5698\n",
      " Epoch [237/300], Batch Step [220/323], D_loss: 0.7621,  G_loss: 1.5580\n",
      " Epoch [237/300], Batch Step [230/323], D_loss: 0.7874,  G_loss: 1.6121\n",
      " Epoch [237/300], Batch Step [240/323], D_loss: 0.6659,  G_loss: 1.6348\n",
      " Epoch [237/300], Batch Step [250/323], D_loss: 0.8424,  G_loss: 1.4262\n",
      " Epoch [237/300], Batch Step [260/323], D_loss: 0.4946,  G_loss: 1.5877\n",
      " Epoch [237/300], Batch Step [270/323], D_loss: 0.8266,  G_loss: 1.6756\n",
      " Epoch [237/300], Batch Step [280/323], D_loss: 0.7165,  G_loss: 1.6808\n",
      " Epoch [237/300], Batch Step [290/323], D_loss: 0.5447,  G_loss: 1.6547\n",
      " Epoch [237/300], Batch Step [300/323], D_loss: 0.5678,  G_loss: 1.6353\n",
      " Epoch [237/300], Batch Step [310/323], D_loss: 0.6404,  G_loss: 1.5447\n",
      " Epoch [237/300], Batch Step [320/323], D_loss: 0.6102,  G_loss: 1.5379\n",
      " Epoch [238/300], Batch Step [0/323], D_loss: 0.5661,  G_loss: 1.7108\n",
      " Epoch [238/300], Batch Step [10/323], D_loss: 0.7413,  G_loss: 1.7255\n",
      " Epoch [238/300], Batch Step [20/323], D_loss: 0.6280,  G_loss: 1.4010\n",
      " Epoch [238/300], Batch Step [30/323], D_loss: 0.6291,  G_loss: 1.6328\n",
      " Epoch [238/300], Batch Step [40/323], D_loss: 0.6034,  G_loss: 1.6191\n",
      " Epoch [238/300], Batch Step [50/323], D_loss: 0.6325,  G_loss: 1.6624\n",
      " Epoch [238/300], Batch Step [60/323], D_loss: 0.6833,  G_loss: 1.6865\n",
      " Epoch [238/300], Batch Step [70/323], D_loss: 0.7227,  G_loss: 1.4394\n",
      " Epoch [238/300], Batch Step [80/323], D_loss: 0.5402,  G_loss: 1.6757\n",
      " Epoch [238/300], Batch Step [90/323], D_loss: 0.5457,  G_loss: 1.7354\n",
      " Epoch [238/300], Batch Step [100/323], D_loss: 0.8264,  G_loss: 1.5205\n",
      " Epoch [238/300], Batch Step [110/323], D_loss: 0.5086,  G_loss: 1.7657\n",
      " Epoch [238/300], Batch Step [120/323], D_loss: 0.7362,  G_loss: 1.6051\n",
      " Epoch [238/300], Batch Step [130/323], D_loss: 0.6138,  G_loss: 1.5872\n",
      " Epoch [238/300], Batch Step [140/323], D_loss: 0.7087,  G_loss: 1.7893\n",
      " Epoch [238/300], Batch Step [150/323], D_loss: 0.6124,  G_loss: 1.6234\n",
      " Epoch [238/300], Batch Step [160/323], D_loss: 0.6817,  G_loss: 1.7438\n",
      " Epoch [238/300], Batch Step [170/323], D_loss: 0.6058,  G_loss: 1.5952\n",
      " Epoch [238/300], Batch Step [180/323], D_loss: 0.5152,  G_loss: 1.6738\n",
      " Epoch [238/300], Batch Step [190/323], D_loss: 0.4030,  G_loss: 1.8634\n",
      " Epoch [238/300], Batch Step [200/323], D_loss: 0.6251,  G_loss: 1.5076\n",
      " Epoch [238/300], Batch Step [210/323], D_loss: 0.4571,  G_loss: 1.6040\n",
      " Epoch [238/300], Batch Step [220/323], D_loss: 0.6742,  G_loss: 1.5462\n",
      " Epoch [238/300], Batch Step [230/323], D_loss: 0.5555,  G_loss: 1.4634\n",
      " Epoch [238/300], Batch Step [240/323], D_loss: 0.6187,  G_loss: 1.6427\n",
      " Epoch [238/300], Batch Step [250/323], D_loss: 0.6985,  G_loss: 1.6487\n",
      " Epoch [238/300], Batch Step [260/323], D_loss: 0.6575,  G_loss: 1.5450\n",
      " Epoch [238/300], Batch Step [270/323], D_loss: 0.5499,  G_loss: 1.7023\n",
      " Epoch [238/300], Batch Step [280/323], D_loss: 0.5734,  G_loss: 1.7330\n",
      " Epoch [238/300], Batch Step [290/323], D_loss: 0.6380,  G_loss: 1.5882\n",
      " Epoch [238/300], Batch Step [300/323], D_loss: 0.6538,  G_loss: 1.7195\n",
      " Epoch [238/300], Batch Step [310/323], D_loss: 0.6679,  G_loss: 1.5883\n",
      " Epoch [238/300], Batch Step [320/323], D_loss: 0.7062,  G_loss: 1.5227\n",
      " Epoch [239/300], Batch Step [0/323], D_loss: 0.5434,  G_loss: 1.5423\n",
      " Epoch [239/300], Batch Step [10/323], D_loss: 0.5423,  G_loss: 1.6873\n",
      " Epoch [239/300], Batch Step [20/323], D_loss: 0.7143,  G_loss: 1.6542\n",
      " Epoch [239/300], Batch Step [30/323], D_loss: 0.7098,  G_loss: 1.5384\n",
      " Epoch [239/300], Batch Step [40/323], D_loss: 0.7015,  G_loss: 1.5392\n",
      " Epoch [239/300], Batch Step [50/323], D_loss: 0.7318,  G_loss: 1.6816\n",
      " Epoch [239/300], Batch Step [60/323], D_loss: 0.7183,  G_loss: 1.4538\n",
      " Epoch [239/300], Batch Step [70/323], D_loss: 0.4400,  G_loss: 1.5271\n",
      " Epoch [239/300], Batch Step [80/323], D_loss: 0.7714,  G_loss: 1.6146\n",
      " Epoch [239/300], Batch Step [90/323], D_loss: 0.7649,  G_loss: 1.5644\n",
      " Epoch [239/300], Batch Step [100/323], D_loss: 0.7068,  G_loss: 1.6526\n",
      " Epoch [239/300], Batch Step [110/323], D_loss: 0.5359,  G_loss: 1.5994\n",
      " Epoch [239/300], Batch Step [120/323], D_loss: 0.6597,  G_loss: 1.5395\n",
      " Epoch [239/300], Batch Step [130/323], D_loss: 0.6047,  G_loss: 1.5365\n",
      " Epoch [239/300], Batch Step [140/323], D_loss: 0.5765,  G_loss: 1.7631\n",
      " Epoch [239/300], Batch Step [150/323], D_loss: 0.5572,  G_loss: 1.5479\n",
      " Epoch [239/300], Batch Step [160/323], D_loss: 0.6131,  G_loss: 1.6165\n",
      " Epoch [239/300], Batch Step [170/323], D_loss: 0.4825,  G_loss: 1.6594\n",
      " Epoch [239/300], Batch Step [180/323], D_loss: 0.5805,  G_loss: 1.5625\n",
      " Epoch [239/300], Batch Step [190/323], D_loss: 0.6172,  G_loss: 1.6064\n",
      " Epoch [239/300], Batch Step [200/323], D_loss: 0.6937,  G_loss: 1.6836\n",
      " Epoch [239/300], Batch Step [210/323], D_loss: 0.6244,  G_loss: 1.5351\n",
      " Epoch [239/300], Batch Step [220/323], D_loss: 0.4903,  G_loss: 1.5994\n",
      " Epoch [239/300], Batch Step [230/323], D_loss: 0.6324,  G_loss: 1.4928\n",
      " Epoch [239/300], Batch Step [240/323], D_loss: 0.6631,  G_loss: 1.6719\n",
      " Epoch [239/300], Batch Step [250/323], D_loss: 0.6852,  G_loss: 1.5558\n",
      " Epoch [239/300], Batch Step [260/323], D_loss: 0.6672,  G_loss: 1.7547\n",
      " Epoch [239/300], Batch Step [270/323], D_loss: 0.7013,  G_loss: 1.6579\n",
      " Epoch [239/300], Batch Step [280/323], D_loss: 0.6356,  G_loss: 1.6238\n",
      " Epoch [239/300], Batch Step [290/323], D_loss: 0.7449,  G_loss: 1.6499\n",
      " Epoch [239/300], Batch Step [300/323], D_loss: 0.5926,  G_loss: 1.6978\n",
      " Epoch [239/300], Batch Step [310/323], D_loss: 0.6007,  G_loss: 1.5274\n",
      " Epoch [239/300], Batch Step [320/323], D_loss: 0.8238,  G_loss: 1.6414\n",
      " Epoch [240/300], Batch Step [0/323], D_loss: 0.5892,  G_loss: 1.5786\n",
      " Epoch [240/300], Batch Step [10/323], D_loss: 0.6064,  G_loss: 1.6662\n",
      " Epoch [240/300], Batch Step [20/323], D_loss: 0.6027,  G_loss: 1.6714\n",
      " Epoch [240/300], Batch Step [30/323], D_loss: 0.6596,  G_loss: 1.6417\n",
      " Epoch [240/300], Batch Step [40/323], D_loss: 0.6592,  G_loss: 1.6397\n",
      " Epoch [240/300], Batch Step [50/323], D_loss: 0.6339,  G_loss: 1.3599\n",
      " Epoch [240/300], Batch Step [60/323], D_loss: 0.8208,  G_loss: 1.7703\n",
      " Epoch [240/300], Batch Step [70/323], D_loss: 0.6748,  G_loss: 1.5193\n",
      " Epoch [240/300], Batch Step [80/323], D_loss: 0.5374,  G_loss: 1.6368\n",
      " Epoch [240/300], Batch Step [90/323], D_loss: 0.7040,  G_loss: 1.6601\n",
      " Epoch [240/300], Batch Step [100/323], D_loss: 0.6309,  G_loss: 1.5261\n",
      " Epoch [240/300], Batch Step [110/323], D_loss: 0.7070,  G_loss: 1.6966\n",
      " Epoch [240/300], Batch Step [120/323], D_loss: 0.5741,  G_loss: 1.6922\n",
      " Epoch [240/300], Batch Step [130/323], D_loss: 0.6623,  G_loss: 1.5518\n",
      " Epoch [240/300], Batch Step [140/323], D_loss: 0.5654,  G_loss: 1.6918\n",
      " Epoch [240/300], Batch Step [150/323], D_loss: 0.6101,  G_loss: 1.6442\n",
      " Epoch [240/300], Batch Step [160/323], D_loss: 0.6760,  G_loss: 1.5680\n",
      " Epoch [240/300], Batch Step [170/323], D_loss: 0.5758,  G_loss: 1.6426\n",
      " Epoch [240/300], Batch Step [180/323], D_loss: 0.6114,  G_loss: 1.5087\n",
      " Epoch [240/300], Batch Step [190/323], D_loss: 0.6609,  G_loss: 1.8022\n",
      " Epoch [240/300], Batch Step [200/323], D_loss: 0.6815,  G_loss: 1.6433\n",
      " Epoch [240/300], Batch Step [210/323], D_loss: 0.5448,  G_loss: 1.6503\n",
      " Epoch [240/300], Batch Step [220/323], D_loss: 0.8093,  G_loss: 1.7522\n",
      " Epoch [240/300], Batch Step [230/323], D_loss: 0.7494,  G_loss: 1.3836\n",
      " Epoch [240/300], Batch Step [240/323], D_loss: 0.5488,  G_loss: 1.6893\n",
      " Epoch [240/300], Batch Step [250/323], D_loss: 0.5656,  G_loss: 1.6772\n",
      " Epoch [240/300], Batch Step [260/323], D_loss: 0.5093,  G_loss: 1.5769\n",
      " Epoch [240/300], Batch Step [270/323], D_loss: 0.5459,  G_loss: 1.6254\n",
      " Epoch [240/300], Batch Step [280/323], D_loss: 0.5913,  G_loss: 1.7143\n",
      " Epoch [240/300], Batch Step [290/323], D_loss: 0.5933,  G_loss: 1.6320\n",
      " Epoch [240/300], Batch Step [300/323], D_loss: 0.7486,  G_loss: 1.6425\n",
      " Epoch [240/300], Batch Step [310/323], D_loss: 0.6536,  G_loss: 1.5923\n",
      " Epoch [240/300], Batch Step [320/323], D_loss: 0.6240,  G_loss: 1.7742\n",
      " Epoch [241/300], Batch Step [0/323], D_loss: 0.5756,  G_loss: 1.7751\n",
      " Epoch [241/300], Batch Step [10/323], D_loss: 0.7309,  G_loss: 1.6467\n",
      " Epoch [241/300], Batch Step [20/323], D_loss: 0.7846,  G_loss: 1.6133\n",
      " Epoch [241/300], Batch Step [30/323], D_loss: 0.6900,  G_loss: 1.5017\n",
      " Epoch [241/300], Batch Step [40/323], D_loss: 0.4969,  G_loss: 1.6511\n",
      " Epoch [241/300], Batch Step [50/323], D_loss: 0.5505,  G_loss: 1.5568\n",
      " Epoch [241/300], Batch Step [60/323], D_loss: 0.6767,  G_loss: 1.6995\n",
      " Epoch [241/300], Batch Step [70/323], D_loss: 0.6150,  G_loss: 1.5831\n",
      " Epoch [241/300], Batch Step [80/323], D_loss: 0.7182,  G_loss: 1.6684\n",
      " Epoch [241/300], Batch Step [90/323], D_loss: 0.7248,  G_loss: 1.5402\n",
      " Epoch [241/300], Batch Step [100/323], D_loss: 0.5647,  G_loss: 1.4968\n",
      " Epoch [241/300], Batch Step [110/323], D_loss: 0.6110,  G_loss: 1.8027\n",
      " Epoch [241/300], Batch Step [120/323], D_loss: 0.7703,  G_loss: 1.5988\n",
      " Epoch [241/300], Batch Step [130/323], D_loss: 0.6292,  G_loss: 1.6750\n",
      " Epoch [241/300], Batch Step [140/323], D_loss: 0.6059,  G_loss: 1.5475\n",
      " Epoch [241/300], Batch Step [150/323], D_loss: 0.8004,  G_loss: 1.5735\n",
      " Epoch [241/300], Batch Step [160/323], D_loss: 0.7571,  G_loss: 1.5611\n",
      " Epoch [241/300], Batch Step [170/323], D_loss: 0.6942,  G_loss: 1.5774\n",
      " Epoch [241/300], Batch Step [180/323], D_loss: 0.6165,  G_loss: 1.5351\n",
      " Epoch [241/300], Batch Step [190/323], D_loss: 0.5300,  G_loss: 1.6920\n",
      " Epoch [241/300], Batch Step [200/323], D_loss: 0.6353,  G_loss: 1.6445\n",
      " Epoch [241/300], Batch Step [210/323], D_loss: 0.5297,  G_loss: 1.5325\n",
      " Epoch [241/300], Batch Step [220/323], D_loss: 0.6197,  G_loss: 1.5278\n",
      " Epoch [241/300], Batch Step [230/323], D_loss: 0.5487,  G_loss: 1.7780\n",
      " Epoch [241/300], Batch Step [240/323], D_loss: 0.7358,  G_loss: 1.5586\n",
      " Epoch [241/300], Batch Step [250/323], D_loss: 0.6985,  G_loss: 1.6398\n",
      " Epoch [241/300], Batch Step [260/323], D_loss: 0.6750,  G_loss: 1.6841\n",
      " Epoch [241/300], Batch Step [270/323], D_loss: 0.6383,  G_loss: 1.5611\n",
      " Epoch [241/300], Batch Step [280/323], D_loss: 0.6535,  G_loss: 1.5821\n",
      " Epoch [241/300], Batch Step [290/323], D_loss: 0.7087,  G_loss: 1.7137\n",
      " Epoch [241/300], Batch Step [300/323], D_loss: 0.6218,  G_loss: 1.7213\n",
      " Epoch [241/300], Batch Step [310/323], D_loss: 0.6659,  G_loss: 1.5378\n",
      " Epoch [241/300], Batch Step [320/323], D_loss: 0.7356,  G_loss: 1.7817\n",
      " Epoch [242/300], Batch Step [0/323], D_loss: 0.8081,  G_loss: 1.7046\n",
      " Epoch [242/300], Batch Step [10/323], D_loss: 0.6511,  G_loss: 1.5307\n",
      " Epoch [242/300], Batch Step [20/323], D_loss: 0.7230,  G_loss: 1.6428\n",
      " Epoch [242/300], Batch Step [30/323], D_loss: 0.6297,  G_loss: 1.6603\n",
      " Epoch [242/300], Batch Step [40/323], D_loss: 0.6503,  G_loss: 1.5861\n",
      " Epoch [242/300], Batch Step [50/323], D_loss: 0.5957,  G_loss: 1.4616\n",
      " Epoch [242/300], Batch Step [60/323], D_loss: 0.6773,  G_loss: 1.7977\n",
      " Epoch [242/300], Batch Step [70/323], D_loss: 0.6630,  G_loss: 1.5849\n",
      " Epoch [242/300], Batch Step [80/323], D_loss: 0.5898,  G_loss: 1.4570\n",
      " Epoch [242/300], Batch Step [90/323], D_loss: 0.6671,  G_loss: 1.6852\n",
      " Epoch [242/300], Batch Step [100/323], D_loss: 0.7443,  G_loss: 1.6671\n",
      " Epoch [242/300], Batch Step [110/323], D_loss: 0.4989,  G_loss: 1.6564\n",
      " Epoch [242/300], Batch Step [120/323], D_loss: 0.6535,  G_loss: 1.6830\n",
      " Epoch [242/300], Batch Step [130/323], D_loss: 0.7584,  G_loss: 1.6555\n",
      " Epoch [242/300], Batch Step [140/323], D_loss: 0.6173,  G_loss: 1.5741\n",
      " Epoch [242/300], Batch Step [150/323], D_loss: 0.5002,  G_loss: 1.6789\n",
      " Epoch [242/300], Batch Step [160/323], D_loss: 0.7511,  G_loss: 1.6009\n",
      " Epoch [242/300], Batch Step [170/323], D_loss: 0.4858,  G_loss: 1.6972\n",
      " Epoch [242/300], Batch Step [180/323], D_loss: 0.8423,  G_loss: 1.5669\n",
      " Epoch [242/300], Batch Step [190/323], D_loss: 0.6124,  G_loss: 1.5648\n",
      " Epoch [242/300], Batch Step [200/323], D_loss: 0.6358,  G_loss: 1.6189\n",
      " Epoch [242/300], Batch Step [210/323], D_loss: 0.6735,  G_loss: 1.5573\n",
      " Epoch [242/300], Batch Step [220/323], D_loss: 0.7292,  G_loss: 1.4988\n",
      " Epoch [242/300], Batch Step [230/323], D_loss: 0.5355,  G_loss: 1.4579\n",
      " Epoch [242/300], Batch Step [240/323], D_loss: 0.7535,  G_loss: 1.7768\n",
      " Epoch [242/300], Batch Step [250/323], D_loss: 0.6326,  G_loss: 1.5456\n",
      " Epoch [242/300], Batch Step [260/323], D_loss: 0.7360,  G_loss: 1.6232\n",
      " Epoch [242/300], Batch Step [270/323], D_loss: 0.4913,  G_loss: 1.6447\n",
      " Epoch [242/300], Batch Step [280/323], D_loss: 0.6160,  G_loss: 1.5693\n",
      " Epoch [242/300], Batch Step [290/323], D_loss: 0.7554,  G_loss: 1.6771\n",
      " Epoch [242/300], Batch Step [300/323], D_loss: 0.6640,  G_loss: 1.7096\n",
      " Epoch [242/300], Batch Step [310/323], D_loss: 0.6963,  G_loss: 1.8439\n",
      " Epoch [242/300], Batch Step [320/323], D_loss: 0.5972,  G_loss: 1.7133\n",
      " Epoch [243/300], Batch Step [0/323], D_loss: 0.7180,  G_loss: 1.5828\n",
      " Epoch [243/300], Batch Step [10/323], D_loss: 0.7890,  G_loss: 1.5761\n",
      " Epoch [243/300], Batch Step [20/323], D_loss: 0.6093,  G_loss: 1.8069\n",
      " Epoch [243/300], Batch Step [30/323], D_loss: 0.4815,  G_loss: 1.5285\n",
      " Epoch [243/300], Batch Step [40/323], D_loss: 0.7613,  G_loss: 1.6235\n",
      " Epoch [243/300], Batch Step [50/323], D_loss: 0.7469,  G_loss: 1.6444\n",
      " Epoch [243/300], Batch Step [60/323], D_loss: 0.6597,  G_loss: 1.6545\n",
      " Epoch [243/300], Batch Step [70/323], D_loss: 0.5852,  G_loss: 1.6053\n",
      " Epoch [243/300], Batch Step [80/323], D_loss: 0.6378,  G_loss: 1.6107\n",
      " Epoch [243/300], Batch Step [90/323], D_loss: 0.6382,  G_loss: 1.6020\n",
      " Epoch [243/300], Batch Step [100/323], D_loss: 0.6015,  G_loss: 1.6688\n",
      " Epoch [243/300], Batch Step [110/323], D_loss: 0.6089,  G_loss: 1.6123\n",
      " Epoch [243/300], Batch Step [120/323], D_loss: 0.6280,  G_loss: 1.5150\n",
      " Epoch [243/300], Batch Step [130/323], D_loss: 0.7324,  G_loss: 1.5782\n",
      " Epoch [243/300], Batch Step [140/323], D_loss: 0.5647,  G_loss: 1.5676\n",
      " Epoch [243/300], Batch Step [150/323], D_loss: 0.6290,  G_loss: 1.4700\n",
      " Epoch [243/300], Batch Step [160/323], D_loss: 0.5993,  G_loss: 1.5723\n",
      " Epoch [243/300], Batch Step [170/323], D_loss: 0.8010,  G_loss: 1.6451\n",
      " Epoch [243/300], Batch Step [180/323], D_loss: 0.6554,  G_loss: 1.6185\n",
      " Epoch [243/300], Batch Step [190/323], D_loss: 0.5301,  G_loss: 1.6811\n",
      " Epoch [243/300], Batch Step [200/323], D_loss: 0.6982,  G_loss: 1.6722\n",
      " Epoch [243/300], Batch Step [210/323], D_loss: 0.7427,  G_loss: 1.6903\n",
      " Epoch [243/300], Batch Step [220/323], D_loss: 0.6889,  G_loss: 1.5824\n",
      " Epoch [243/300], Batch Step [230/323], D_loss: 0.6303,  G_loss: 1.5263\n",
      " Epoch [243/300], Batch Step [240/323], D_loss: 0.5783,  G_loss: 1.5884\n",
      " Epoch [243/300], Batch Step [250/323], D_loss: 0.7321,  G_loss: 1.5267\n",
      " Epoch [243/300], Batch Step [260/323], D_loss: 0.6759,  G_loss: 1.4915\n",
      " Epoch [243/300], Batch Step [270/323], D_loss: 0.6314,  G_loss: 1.6336\n",
      " Epoch [243/300], Batch Step [280/323], D_loss: 0.6256,  G_loss: 1.6087\n",
      " Epoch [243/300], Batch Step [290/323], D_loss: 0.7086,  G_loss: 1.6089\n",
      " Epoch [243/300], Batch Step [300/323], D_loss: 0.6283,  G_loss: 1.6047\n",
      " Epoch [243/300], Batch Step [310/323], D_loss: 0.6675,  G_loss: 1.6105\n",
      " Epoch [243/300], Batch Step [320/323], D_loss: 0.5943,  G_loss: 1.6307\n",
      " Epoch [244/300], Batch Step [0/323], D_loss: 0.7357,  G_loss: 1.5479\n",
      " Epoch [244/300], Batch Step [10/323], D_loss: 0.6568,  G_loss: 1.6110\n",
      " Epoch [244/300], Batch Step [20/323], D_loss: 0.7722,  G_loss: 1.6361\n",
      " Epoch [244/300], Batch Step [30/323], D_loss: 0.5262,  G_loss: 1.5526\n",
      " Epoch [244/300], Batch Step [40/323], D_loss: 0.7450,  G_loss: 1.6530\n",
      " Epoch [244/300], Batch Step [50/323], D_loss: 0.7928,  G_loss: 1.4838\n",
      " Epoch [244/300], Batch Step [60/323], D_loss: 0.4703,  G_loss: 1.5855\n",
      " Epoch [244/300], Batch Step [70/323], D_loss: 0.6018,  G_loss: 1.6381\n",
      " Epoch [244/300], Batch Step [80/323], D_loss: 0.5632,  G_loss: 1.5845\n",
      " Epoch [244/300], Batch Step [90/323], D_loss: 0.8302,  G_loss: 1.6558\n",
      " Epoch [244/300], Batch Step [100/323], D_loss: 0.6122,  G_loss: 1.4301\n",
      " Epoch [244/300], Batch Step [110/323], D_loss: 0.6399,  G_loss: 1.6266\n",
      " Epoch [244/300], Batch Step [120/323], D_loss: 0.7029,  G_loss: 1.6028\n",
      " Epoch [244/300], Batch Step [130/323], D_loss: 0.6623,  G_loss: 1.6071\n",
      " Epoch [244/300], Batch Step [140/323], D_loss: 0.5824,  G_loss: 1.6894\n",
      " Epoch [244/300], Batch Step [150/323], D_loss: 0.6753,  G_loss: 1.5256\n",
      " Epoch [244/300], Batch Step [160/323], D_loss: 0.6843,  G_loss: 1.4672\n",
      " Epoch [244/300], Batch Step [170/323], D_loss: 0.5629,  G_loss: 1.6937\n",
      " Epoch [244/300], Batch Step [180/323], D_loss: 0.7011,  G_loss: 1.5043\n",
      " Epoch [244/300], Batch Step [190/323], D_loss: 0.7228,  G_loss: 1.6040\n",
      " Epoch [244/300], Batch Step [200/323], D_loss: 0.6440,  G_loss: 1.7568\n",
      " Epoch [244/300], Batch Step [210/323], D_loss: 0.6645,  G_loss: 1.6645\n",
      " Epoch [244/300], Batch Step [220/323], D_loss: 0.7599,  G_loss: 1.5587\n",
      " Epoch [244/300], Batch Step [230/323], D_loss: 0.6071,  G_loss: 1.6809\n",
      " Epoch [244/300], Batch Step [240/323], D_loss: 0.6286,  G_loss: 1.6979\n",
      " Epoch [244/300], Batch Step [250/323], D_loss: 0.6755,  G_loss: 1.5881\n",
      " Epoch [244/300], Batch Step [260/323], D_loss: 0.7174,  G_loss: 1.5266\n",
      " Epoch [244/300], Batch Step [270/323], D_loss: 0.4694,  G_loss: 1.6394\n",
      " Epoch [244/300], Batch Step [280/323], D_loss: 0.6833,  G_loss: 1.6051\n",
      " Epoch [244/300], Batch Step [290/323], D_loss: 0.6308,  G_loss: 1.5780\n",
      " Epoch [244/300], Batch Step [300/323], D_loss: 0.6739,  G_loss: 1.7172\n",
      " Epoch [244/300], Batch Step [310/323], D_loss: 0.8148,  G_loss: 1.6259\n",
      " Epoch [244/300], Batch Step [320/323], D_loss: 0.6733,  G_loss: 1.5864\n",
      " Epoch [245/300], Batch Step [0/323], D_loss: 0.5093,  G_loss: 1.6061\n",
      " Epoch [245/300], Batch Step [10/323], D_loss: 0.7032,  G_loss: 1.3992\n",
      " Epoch [245/300], Batch Step [20/323], D_loss: 0.7075,  G_loss: 1.6810\n",
      " Epoch [245/300], Batch Step [30/323], D_loss: 0.6461,  G_loss: 1.7727\n",
      " Epoch [245/300], Batch Step [40/323], D_loss: 0.6466,  G_loss: 1.5117\n",
      " Epoch [245/300], Batch Step [50/323], D_loss: 0.6790,  G_loss: 1.6610\n",
      " Epoch [245/300], Batch Step [60/323], D_loss: 0.6508,  G_loss: 1.5509\n",
      " Epoch [245/300], Batch Step [70/323], D_loss: 0.6561,  G_loss: 1.5256\n",
      " Epoch [245/300], Batch Step [80/323], D_loss: 0.6954,  G_loss: 1.8446\n",
      " Epoch [245/300], Batch Step [90/323], D_loss: 0.6890,  G_loss: 1.4953\n",
      " Epoch [245/300], Batch Step [100/323], D_loss: 0.8237,  G_loss: 1.6461\n",
      " Epoch [245/300], Batch Step [110/323], D_loss: 0.6729,  G_loss: 1.5616\n",
      " Epoch [245/300], Batch Step [120/323], D_loss: 0.7094,  G_loss: 1.6840\n",
      " Epoch [245/300], Batch Step [130/323], D_loss: 0.5266,  G_loss: 1.6587\n",
      " Epoch [245/300], Batch Step [140/323], D_loss: 0.5718,  G_loss: 1.5331\n",
      " Epoch [245/300], Batch Step [150/323], D_loss: 0.4655,  G_loss: 1.5021\n",
      " Epoch [245/300], Batch Step [160/323], D_loss: 0.6692,  G_loss: 1.6473\n",
      " Epoch [245/300], Batch Step [170/323], D_loss: 0.6797,  G_loss: 1.4429\n",
      " Epoch [245/300], Batch Step [180/323], D_loss: 0.6556,  G_loss: 1.6836\n",
      " Epoch [245/300], Batch Step [190/323], D_loss: 0.7102,  G_loss: 1.5749\n",
      " Epoch [245/300], Batch Step [200/323], D_loss: 0.6417,  G_loss: 1.6353\n",
      " Epoch [245/300], Batch Step [210/323], D_loss: 0.7104,  G_loss: 1.5634\n",
      " Epoch [245/300], Batch Step [220/323], D_loss: 0.5025,  G_loss: 1.5480\n",
      " Epoch [245/300], Batch Step [230/323], D_loss: 0.5261,  G_loss: 1.6398\n",
      " Epoch [245/300], Batch Step [240/323], D_loss: 0.5232,  G_loss: 1.6981\n",
      " Epoch [245/300], Batch Step [250/323], D_loss: 0.6495,  G_loss: 1.5327\n",
      " Epoch [245/300], Batch Step [260/323], D_loss: 0.5794,  G_loss: 1.6514\n",
      " Epoch [245/300], Batch Step [270/323], D_loss: 0.5555,  G_loss: 1.6136\n",
      " Epoch [245/300], Batch Step [280/323], D_loss: 0.6860,  G_loss: 1.5880\n",
      " Epoch [245/300], Batch Step [290/323], D_loss: 0.6221,  G_loss: 1.6470\n",
      " Epoch [245/300], Batch Step [300/323], D_loss: 0.5199,  G_loss: 1.5922\n",
      " Epoch [245/300], Batch Step [310/323], D_loss: 0.6068,  G_loss: 1.6408\n",
      " Epoch [245/300], Batch Step [320/323], D_loss: 0.6772,  G_loss: 1.5298\n",
      " Epoch [246/300], Batch Step [0/323], D_loss: 0.5659,  G_loss: 1.5236\n",
      " Epoch [246/300], Batch Step [10/323], D_loss: 0.7025,  G_loss: 1.5747\n",
      " Epoch [246/300], Batch Step [20/323], D_loss: 0.6895,  G_loss: 1.6006\n",
      " Epoch [246/300], Batch Step [30/323], D_loss: 0.5914,  G_loss: 1.6439\n",
      " Epoch [246/300], Batch Step [40/323], D_loss: 0.5877,  G_loss: 1.6816\n",
      " Epoch [246/300], Batch Step [50/323], D_loss: 0.6458,  G_loss: 1.6189\n",
      " Epoch [246/300], Batch Step [60/323], D_loss: 0.7715,  G_loss: 1.6875\n",
      " Epoch [246/300], Batch Step [70/323], D_loss: 0.6013,  G_loss: 1.4990\n",
      " Epoch [246/300], Batch Step [80/323], D_loss: 0.6546,  G_loss: 1.5537\n",
      " Epoch [246/300], Batch Step [90/323], D_loss: 0.5876,  G_loss: 1.6900\n",
      " Epoch [246/300], Batch Step [100/323], D_loss: 0.6997,  G_loss: 1.5881\n",
      " Epoch [246/300], Batch Step [110/323], D_loss: 0.4858,  G_loss: 1.7139\n",
      " Epoch [246/300], Batch Step [120/323], D_loss: 0.6223,  G_loss: 1.6261\n",
      " Epoch [246/300], Batch Step [130/323], D_loss: 0.7963,  G_loss: 1.5798\n",
      " Epoch [246/300], Batch Step [140/323], D_loss: 0.6505,  G_loss: 1.6085\n",
      " Epoch [246/300], Batch Step [150/323], D_loss: 0.5611,  G_loss: 1.7824\n",
      " Epoch [246/300], Batch Step [160/323], D_loss: 0.5630,  G_loss: 1.5993\n",
      " Epoch [246/300], Batch Step [170/323], D_loss: 0.6158,  G_loss: 1.6950\n",
      " Epoch [246/300], Batch Step [180/323], D_loss: 0.5507,  G_loss: 1.5794\n",
      " Epoch [246/300], Batch Step [190/323], D_loss: 0.7980,  G_loss: 1.6232\n",
      " Epoch [246/300], Batch Step [200/323], D_loss: 0.6084,  G_loss: 1.5710\n",
      " Epoch [246/300], Batch Step [210/323], D_loss: 0.6333,  G_loss: 1.7312\n",
      " Epoch [246/300], Batch Step [220/323], D_loss: 0.6179,  G_loss: 1.5874\n",
      " Epoch [246/300], Batch Step [230/323], D_loss: 0.5418,  G_loss: 1.5040\n",
      " Epoch [246/300], Batch Step [240/323], D_loss: 0.6863,  G_loss: 1.6277\n",
      " Epoch [246/300], Batch Step [250/323], D_loss: 0.5608,  G_loss: 1.7593\n",
      " Epoch [246/300], Batch Step [260/323], D_loss: 0.6343,  G_loss: 1.6919\n",
      " Epoch [246/300], Batch Step [270/323], D_loss: 0.6306,  G_loss: 1.4691\n",
      " Epoch [246/300], Batch Step [280/323], D_loss: 0.6509,  G_loss: 1.4727\n",
      " Epoch [246/300], Batch Step [290/323], D_loss: 0.6274,  G_loss: 1.5391\n",
      " Epoch [246/300], Batch Step [300/323], D_loss: 0.6307,  G_loss: 1.5437\n",
      " Epoch [246/300], Batch Step [310/323], D_loss: 0.6495,  G_loss: 1.5936\n",
      " Epoch [246/300], Batch Step [320/323], D_loss: 0.8547,  G_loss: 1.6202\n",
      " Epoch [247/300], Batch Step [0/323], D_loss: 0.7582,  G_loss: 1.6358\n",
      " Epoch [247/300], Batch Step [10/323], D_loss: 0.5910,  G_loss: 1.5911\n",
      " Epoch [247/300], Batch Step [20/323], D_loss: 0.6875,  G_loss: 1.6196\n",
      " Epoch [247/300], Batch Step [30/323], D_loss: 0.6083,  G_loss: 1.6499\n",
      " Epoch [247/300], Batch Step [40/323], D_loss: 0.6087,  G_loss: 1.6670\n",
      " Epoch [247/300], Batch Step [50/323], D_loss: 0.7081,  G_loss: 1.6871\n",
      " Epoch [247/300], Batch Step [60/323], D_loss: 0.6262,  G_loss: 1.5240\n",
      " Epoch [247/300], Batch Step [70/323], D_loss: 0.6541,  G_loss: 1.7034\n",
      " Epoch [247/300], Batch Step [80/323], D_loss: 0.6364,  G_loss: 1.3946\n",
      " Epoch [247/300], Batch Step [90/323], D_loss: 0.6734,  G_loss: 1.5472\n",
      " Epoch [247/300], Batch Step [100/323], D_loss: 0.6222,  G_loss: 1.6155\n",
      " Epoch [247/300], Batch Step [110/323], D_loss: 0.6147,  G_loss: 1.6134\n",
      " Epoch [247/300], Batch Step [120/323], D_loss: 0.8082,  G_loss: 1.8615\n",
      " Epoch [247/300], Batch Step [130/323], D_loss: 0.5964,  G_loss: 1.6990\n",
      " Epoch [247/300], Batch Step [140/323], D_loss: 0.7761,  G_loss: 1.5989\n",
      " Epoch [247/300], Batch Step [150/323], D_loss: 0.7286,  G_loss: 1.5421\n",
      " Epoch [247/300], Batch Step [160/323], D_loss: 0.6755,  G_loss: 1.6889\n",
      " Epoch [247/300], Batch Step [170/323], D_loss: 0.7598,  G_loss: 1.6641\n",
      " Epoch [247/300], Batch Step [180/323], D_loss: 0.6055,  G_loss: 1.4641\n",
      " Epoch [247/300], Batch Step [190/323], D_loss: 0.6272,  G_loss: 1.6915\n",
      " Epoch [247/300], Batch Step [200/323], D_loss: 0.6652,  G_loss: 1.6714\n",
      " Epoch [247/300], Batch Step [210/323], D_loss: 0.6447,  G_loss: 1.6065\n",
      " Epoch [247/300], Batch Step [220/323], D_loss: 0.8006,  G_loss: 1.5451\n",
      " Epoch [247/300], Batch Step [230/323], D_loss: 0.7169,  G_loss: 1.4248\n",
      " Epoch [247/300], Batch Step [240/323], D_loss: 0.5065,  G_loss: 1.7580\n",
      " Epoch [247/300], Batch Step [250/323], D_loss: 0.7069,  G_loss: 1.6800\n",
      " Epoch [247/300], Batch Step [260/323], D_loss: 0.7686,  G_loss: 1.4822\n",
      " Epoch [247/300], Batch Step [270/323], D_loss: 0.8423,  G_loss: 1.6785\n",
      " Epoch [247/300], Batch Step [280/323], D_loss: 0.7025,  G_loss: 1.6109\n",
      " Epoch [247/300], Batch Step [290/323], D_loss: 0.4799,  G_loss: 1.6091\n",
      " Epoch [247/300], Batch Step [300/323], D_loss: 0.6543,  G_loss: 1.6432\n",
      " Epoch [247/300], Batch Step [310/323], D_loss: 0.5108,  G_loss: 1.6955\n",
      " Epoch [247/300], Batch Step [320/323], D_loss: 0.4632,  G_loss: 1.8332\n",
      " Epoch [248/300], Batch Step [0/323], D_loss: 0.7354,  G_loss: 1.7354\n",
      " Epoch [248/300], Batch Step [10/323], D_loss: 0.7293,  G_loss: 1.5122\n",
      " Epoch [248/300], Batch Step [20/323], D_loss: 0.6917,  G_loss: 1.5779\n",
      " Epoch [248/300], Batch Step [30/323], D_loss: 0.7102,  G_loss: 1.7033\n",
      " Epoch [248/300], Batch Step [40/323], D_loss: 0.5561,  G_loss: 1.4583\n",
      " Epoch [248/300], Batch Step [50/323], D_loss: 0.6839,  G_loss: 1.6851\n",
      " Epoch [248/300], Batch Step [60/323], D_loss: 0.6740,  G_loss: 1.4584\n",
      " Epoch [248/300], Batch Step [70/323], D_loss: 0.6995,  G_loss: 1.6341\n",
      " Epoch [248/300], Batch Step [80/323], D_loss: 0.4244,  G_loss: 1.6898\n",
      " Epoch [248/300], Batch Step [90/323], D_loss: 0.6706,  G_loss: 1.6808\n",
      " Epoch [248/300], Batch Step [100/323], D_loss: 0.5864,  G_loss: 1.5457\n",
      " Epoch [248/300], Batch Step [110/323], D_loss: 0.7346,  G_loss: 1.6100\n",
      " Epoch [248/300], Batch Step [120/323], D_loss: 0.5708,  G_loss: 1.5643\n",
      " Epoch [248/300], Batch Step [130/323], D_loss: 0.6832,  G_loss: 1.5704\n",
      " Epoch [248/300], Batch Step [140/323], D_loss: 0.7315,  G_loss: 1.7627\n",
      " Epoch [248/300], Batch Step [150/323], D_loss: 0.6730,  G_loss: 1.7281\n",
      " Epoch [248/300], Batch Step [160/323], D_loss: 0.6958,  G_loss: 1.5458\n",
      " Epoch [248/300], Batch Step [170/323], D_loss: 0.5552,  G_loss: 1.5952\n",
      " Epoch [248/300], Batch Step [180/323], D_loss: 0.8811,  G_loss: 1.6741\n",
      " Epoch [248/300], Batch Step [190/323], D_loss: 0.6070,  G_loss: 1.5942\n",
      " Epoch [248/300], Batch Step [200/323], D_loss: 0.5821,  G_loss: 1.7076\n",
      " Epoch [248/300], Batch Step [210/323], D_loss: 0.5186,  G_loss: 1.6353\n",
      " Epoch [248/300], Batch Step [220/323], D_loss: 0.6596,  G_loss: 1.7341\n",
      " Epoch [248/300], Batch Step [230/323], D_loss: 0.6908,  G_loss: 1.4163\n",
      " Epoch [248/300], Batch Step [240/323], D_loss: 0.5674,  G_loss: 1.9289\n",
      " Epoch [248/300], Batch Step [250/323], D_loss: 0.6250,  G_loss: 1.6402\n",
      " Epoch [248/300], Batch Step [260/323], D_loss: 0.6436,  G_loss: 1.5761\n",
      " Epoch [248/300], Batch Step [270/323], D_loss: 0.5611,  G_loss: 1.7667\n",
      " Epoch [248/300], Batch Step [280/323], D_loss: 0.7451,  G_loss: 1.6461\n",
      " Epoch [248/300], Batch Step [290/323], D_loss: 0.7520,  G_loss: 1.4994\n",
      " Epoch [248/300], Batch Step [300/323], D_loss: 0.4987,  G_loss: 1.5894\n",
      " Epoch [248/300], Batch Step [310/323], D_loss: 0.5382,  G_loss: 1.8169\n",
      " Epoch [248/300], Batch Step [320/323], D_loss: 0.6137,  G_loss: 1.5727\n",
      " Epoch [249/300], Batch Step [0/323], D_loss: 0.5833,  G_loss: 1.6003\n",
      " Epoch [249/300], Batch Step [10/323], D_loss: 0.5120,  G_loss: 1.7705\n",
      " Epoch [249/300], Batch Step [20/323], D_loss: 0.6901,  G_loss: 1.4689\n",
      " Epoch [249/300], Batch Step [30/323], D_loss: 0.7248,  G_loss: 1.6104\n",
      " Epoch [249/300], Batch Step [40/323], D_loss: 0.6678,  G_loss: 1.7086\n",
      " Epoch [249/300], Batch Step [50/323], D_loss: 0.5388,  G_loss: 1.5129\n",
      " Epoch [249/300], Batch Step [60/323], D_loss: 0.6271,  G_loss: 1.5939\n",
      " Epoch [249/300], Batch Step [70/323], D_loss: 0.7463,  G_loss: 1.6195\n",
      " Epoch [249/300], Batch Step [80/323], D_loss: 0.5445,  G_loss: 1.6638\n",
      " Epoch [249/300], Batch Step [90/323], D_loss: 0.5557,  G_loss: 1.7779\n",
      " Epoch [249/300], Batch Step [100/323], D_loss: 0.6944,  G_loss: 1.6197\n",
      " Epoch [249/300], Batch Step [110/323], D_loss: 0.5508,  G_loss: 1.6929\n",
      " Epoch [249/300], Batch Step [120/323], D_loss: 0.6442,  G_loss: 1.6046\n",
      " Epoch [249/300], Batch Step [130/323], D_loss: 0.5126,  G_loss: 1.6400\n",
      " Epoch [249/300], Batch Step [140/323], D_loss: 0.6125,  G_loss: 1.7482\n",
      " Epoch [249/300], Batch Step [150/323], D_loss: 0.6124,  G_loss: 1.6702\n",
      " Epoch [249/300], Batch Step [160/323], D_loss: 0.7878,  G_loss: 1.7346\n",
      " Epoch [249/300], Batch Step [170/323], D_loss: 0.6536,  G_loss: 1.5472\n",
      " Epoch [249/300], Batch Step [180/323], D_loss: 0.5590,  G_loss: 1.7709\n",
      " Epoch [249/300], Batch Step [190/323], D_loss: 0.5945,  G_loss: 1.5149\n",
      " Epoch [249/300], Batch Step [200/323], D_loss: 0.7635,  G_loss: 1.5258\n",
      " Epoch [249/300], Batch Step [210/323], D_loss: 0.4861,  G_loss: 1.6430\n",
      " Epoch [249/300], Batch Step [220/323], D_loss: 0.5610,  G_loss: 1.6661\n",
      " Epoch [249/300], Batch Step [230/323], D_loss: 0.5583,  G_loss: 1.7229\n",
      " Epoch [249/300], Batch Step [240/323], D_loss: 0.7059,  G_loss: 1.5908\n",
      " Epoch [249/300], Batch Step [250/323], D_loss: 0.6593,  G_loss: 1.5814\n",
      " Epoch [249/300], Batch Step [260/323], D_loss: 0.6160,  G_loss: 1.4832\n",
      " Epoch [249/300], Batch Step [270/323], D_loss: 0.6241,  G_loss: 1.6228\n",
      " Epoch [249/300], Batch Step [280/323], D_loss: 0.5834,  G_loss: 1.5204\n",
      " Epoch [249/300], Batch Step [290/323], D_loss: 0.7649,  G_loss: 1.8352\n",
      " Epoch [249/300], Batch Step [300/323], D_loss: 0.6511,  G_loss: 1.4137\n",
      " Epoch [249/300], Batch Step [310/323], D_loss: 0.5250,  G_loss: 1.5328\n",
      " Epoch [249/300], Batch Step [320/323], D_loss: 0.6350,  G_loss: 1.6150\n",
      " Epoch [250/300], Batch Step [0/323], D_loss: 0.8186,  G_loss: 1.5000\n",
      " Epoch [250/300], Batch Step [10/323], D_loss: 0.6912,  G_loss: 1.5632\n",
      " Epoch [250/300], Batch Step [20/323], D_loss: 0.6428,  G_loss: 1.7810\n",
      " Epoch [250/300], Batch Step [30/323], D_loss: 0.5936,  G_loss: 1.5521\n",
      " Epoch [250/300], Batch Step [40/323], D_loss: 0.5033,  G_loss: 1.6297\n",
      " Epoch [250/300], Batch Step [50/323], D_loss: 0.6428,  G_loss: 1.7208\n",
      " Epoch [250/300], Batch Step [60/323], D_loss: 0.6940,  G_loss: 1.6799\n",
      " Epoch [250/300], Batch Step [70/323], D_loss: 0.6657,  G_loss: 1.6508\n",
      " Epoch [250/300], Batch Step [80/323], D_loss: 0.5257,  G_loss: 1.7695\n",
      " Epoch [250/300], Batch Step [90/323], D_loss: 0.4824,  G_loss: 1.5090\n",
      " Epoch [250/300], Batch Step [100/323], D_loss: 0.6787,  G_loss: 1.6876\n",
      " Epoch [250/300], Batch Step [110/323], D_loss: 0.5600,  G_loss: 1.6234\n",
      " Epoch [250/300], Batch Step [120/323], D_loss: 0.8644,  G_loss: 1.5925\n",
      " Epoch [250/300], Batch Step [130/323], D_loss: 0.6651,  G_loss: 1.6490\n",
      " Epoch [250/300], Batch Step [140/323], D_loss: 0.5722,  G_loss: 1.5563\n",
      " Epoch [250/300], Batch Step [150/323], D_loss: 0.5454,  G_loss: 1.5651\n",
      " Epoch [250/300], Batch Step [160/323], D_loss: 0.5339,  G_loss: 1.6235\n",
      " Epoch [250/300], Batch Step [170/323], D_loss: 0.6177,  G_loss: 1.6179\n",
      " Epoch [250/300], Batch Step [180/323], D_loss: 0.5800,  G_loss: 1.5638\n",
      " Epoch [250/300], Batch Step [190/323], D_loss: 0.6893,  G_loss: 1.5803\n",
      " Epoch [250/300], Batch Step [200/323], D_loss: 0.6556,  G_loss: 1.6007\n",
      " Epoch [250/300], Batch Step [210/323], D_loss: 0.6896,  G_loss: 1.7266\n",
      " Epoch [250/300], Batch Step [220/323], D_loss: 0.6963,  G_loss: 1.7300\n",
      " Epoch [250/300], Batch Step [230/323], D_loss: 0.7419,  G_loss: 1.5183\n",
      " Epoch [250/300], Batch Step [240/323], D_loss: 0.6039,  G_loss: 1.6359\n",
      " Epoch [250/300], Batch Step [250/323], D_loss: 0.7751,  G_loss: 1.6682\n",
      " Epoch [250/300], Batch Step [260/323], D_loss: 0.5657,  G_loss: 1.5224\n",
      " Epoch [250/300], Batch Step [270/323], D_loss: 0.8119,  G_loss: 1.5269\n",
      " Epoch [250/300], Batch Step [280/323], D_loss: 0.6402,  G_loss: 1.5875\n",
      " Epoch [250/300], Batch Step [290/323], D_loss: 0.5376,  G_loss: 1.6989\n",
      " Epoch [250/300], Batch Step [300/323], D_loss: 0.5823,  G_loss: 1.7722\n",
      " Epoch [250/300], Batch Step [310/323], D_loss: 0.6073,  G_loss: 1.5842\n",
      " Epoch [250/300], Batch Step [320/323], D_loss: 0.5362,  G_loss: 1.6857\n",
      " Epoch [251/300], Batch Step [0/323], D_loss: 0.5130,  G_loss: 1.6027\n",
      " Epoch [251/300], Batch Step [10/323], D_loss: 0.4215,  G_loss: 1.7244\n",
      " Epoch [251/300], Batch Step [20/323], D_loss: 0.5736,  G_loss: 1.8859\n",
      " Epoch [251/300], Batch Step [30/323], D_loss: 0.5812,  G_loss: 1.4666\n",
      " Epoch [251/300], Batch Step [40/323], D_loss: 0.7277,  G_loss: 1.6929\n",
      " Epoch [251/300], Batch Step [50/323], D_loss: 0.5669,  G_loss: 1.5056\n",
      " Epoch [251/300], Batch Step [60/323], D_loss: 0.5160,  G_loss: 1.5777\n",
      " Epoch [251/300], Batch Step [70/323], D_loss: 0.5931,  G_loss: 1.7376\n",
      " Epoch [251/300], Batch Step [80/323], D_loss: 0.6438,  G_loss: 1.6626\n",
      " Epoch [251/300], Batch Step [90/323], D_loss: 0.7026,  G_loss: 1.5146\n",
      " Epoch [251/300], Batch Step [100/323], D_loss: 0.7931,  G_loss: 1.5829\n",
      " Epoch [251/300], Batch Step [110/323], D_loss: 0.6810,  G_loss: 1.5650\n",
      " Epoch [251/300], Batch Step [120/323], D_loss: 0.7951,  G_loss: 1.5086\n",
      " Epoch [251/300], Batch Step [130/323], D_loss: 0.7068,  G_loss: 1.6493\n",
      " Epoch [251/300], Batch Step [140/323], D_loss: 0.6639,  G_loss: 1.5914\n",
      " Epoch [251/300], Batch Step [150/323], D_loss: 0.5592,  G_loss: 1.5762\n",
      " Epoch [251/300], Batch Step [160/323], D_loss: 0.6137,  G_loss: 1.5586\n",
      " Epoch [251/300], Batch Step [170/323], D_loss: 0.7239,  G_loss: 1.6674\n",
      " Epoch [251/300], Batch Step [180/323], D_loss: 0.6404,  G_loss: 1.6592\n",
      " Epoch [251/300], Batch Step [190/323], D_loss: 0.5019,  G_loss: 1.6040\n",
      " Epoch [251/300], Batch Step [200/323], D_loss: 0.6549,  G_loss: 1.7052\n",
      " Epoch [251/300], Batch Step [210/323], D_loss: 0.6715,  G_loss: 1.4275\n",
      " Epoch [251/300], Batch Step [220/323], D_loss: 0.5259,  G_loss: 1.6833\n",
      " Epoch [251/300], Batch Step [230/323], D_loss: 0.7755,  G_loss: 1.6645\n",
      " Epoch [251/300], Batch Step [240/323], D_loss: 0.6759,  G_loss: 1.4704\n",
      " Epoch [251/300], Batch Step [250/323], D_loss: 0.5511,  G_loss: 1.6628\n",
      " Epoch [251/300], Batch Step [260/323], D_loss: 0.6985,  G_loss: 1.7566\n",
      " Epoch [251/300], Batch Step [270/323], D_loss: 0.6447,  G_loss: 1.5650\n",
      " Epoch [251/300], Batch Step [280/323], D_loss: 0.7580,  G_loss: 1.6703\n",
      " Epoch [251/300], Batch Step [290/323], D_loss: 0.7256,  G_loss: 1.6519\n",
      " Epoch [251/300], Batch Step [300/323], D_loss: 0.6732,  G_loss: 1.6520\n",
      " Epoch [251/300], Batch Step [310/323], D_loss: 0.4724,  G_loss: 1.5574\n",
      " Epoch [251/300], Batch Step [320/323], D_loss: 0.7641,  G_loss: 1.7363\n",
      " Epoch [252/300], Batch Step [0/323], D_loss: 0.6301,  G_loss: 1.7498\n",
      " Epoch [252/300], Batch Step [10/323], D_loss: 0.7060,  G_loss: 1.8368\n",
      " Epoch [252/300], Batch Step [20/323], D_loss: 0.5520,  G_loss: 1.5571\n",
      " Epoch [252/300], Batch Step [30/323], D_loss: 0.5398,  G_loss: 1.7654\n",
      " Epoch [252/300], Batch Step [40/323], D_loss: 0.7142,  G_loss: 1.6388\n",
      " Epoch [252/300], Batch Step [50/323], D_loss: 0.6477,  G_loss: 1.4824\n",
      " Epoch [252/300], Batch Step [60/323], D_loss: 0.7087,  G_loss: 1.6524\n",
      " Epoch [252/300], Batch Step [70/323], D_loss: 0.6196,  G_loss: 1.6326\n",
      " Epoch [252/300], Batch Step [80/323], D_loss: 0.5697,  G_loss: 1.5590\n",
      " Epoch [252/300], Batch Step [90/323], D_loss: 0.8024,  G_loss: 1.6321\n",
      " Epoch [252/300], Batch Step [100/323], D_loss: 0.7301,  G_loss: 1.6416\n",
      " Epoch [252/300], Batch Step [110/323], D_loss: 0.4961,  G_loss: 1.6596\n",
      " Epoch [252/300], Batch Step [120/323], D_loss: 0.6912,  G_loss: 1.7220\n",
      " Epoch [252/300], Batch Step [130/323], D_loss: 0.7016,  G_loss: 1.5895\n",
      " Epoch [252/300], Batch Step [140/323], D_loss: 0.6426,  G_loss: 1.5701\n",
      " Epoch [252/300], Batch Step [150/323], D_loss: 0.6477,  G_loss: 1.6566\n",
      " Epoch [252/300], Batch Step [160/323], D_loss: 0.5050,  G_loss: 1.6773\n",
      " Epoch [252/300], Batch Step [170/323], D_loss: 0.6601,  G_loss: 1.6222\n",
      " Epoch [252/300], Batch Step [180/323], D_loss: 0.5620,  G_loss: 1.5839\n",
      " Epoch [252/300], Batch Step [190/323], D_loss: 0.6806,  G_loss: 1.6017\n",
      " Epoch [252/300], Batch Step [200/323], D_loss: 0.6823,  G_loss: 1.7899\n",
      " Epoch [252/300], Batch Step [210/323], D_loss: 0.6096,  G_loss: 1.5258\n",
      " Epoch [252/300], Batch Step [220/323], D_loss: 0.5307,  G_loss: 1.7164\n",
      " Epoch [252/300], Batch Step [230/323], D_loss: 0.6850,  G_loss: 1.6915\n",
      " Epoch [252/300], Batch Step [240/323], D_loss: 0.6985,  G_loss: 1.6037\n",
      " Epoch [252/300], Batch Step [250/323], D_loss: 0.6753,  G_loss: 1.6126\n",
      " Epoch [252/300], Batch Step [260/323], D_loss: 0.6574,  G_loss: 1.5150\n",
      " Epoch [252/300], Batch Step [270/323], D_loss: 0.6767,  G_loss: 1.6451\n",
      " Epoch [252/300], Batch Step [280/323], D_loss: 0.7652,  G_loss: 1.7141\n",
      " Epoch [252/300], Batch Step [290/323], D_loss: 0.5727,  G_loss: 1.4970\n",
      " Epoch [252/300], Batch Step [300/323], D_loss: 0.6032,  G_loss: 1.7521\n",
      " Epoch [252/300], Batch Step [310/323], D_loss: 0.7322,  G_loss: 1.5970\n",
      " Epoch [252/300], Batch Step [320/323], D_loss: 0.6362,  G_loss: 1.4102\n",
      " Epoch [253/300], Batch Step [0/323], D_loss: 0.6342,  G_loss: 1.5586\n",
      " Epoch [253/300], Batch Step [10/323], D_loss: 0.6515,  G_loss: 1.8473\n",
      " Epoch [253/300], Batch Step [20/323], D_loss: 0.6501,  G_loss: 1.4774\n",
      " Epoch [253/300], Batch Step [30/323], D_loss: 0.6743,  G_loss: 1.6086\n",
      " Epoch [253/300], Batch Step [40/323], D_loss: 0.5998,  G_loss: 1.6461\n",
      " Epoch [253/300], Batch Step [50/323], D_loss: 0.4810,  G_loss: 1.7374\n",
      " Epoch [253/300], Batch Step [60/323], D_loss: 0.6141,  G_loss: 1.6452\n",
      " Epoch [253/300], Batch Step [70/323], D_loss: 0.6123,  G_loss: 1.5976\n",
      " Epoch [253/300], Batch Step [80/323], D_loss: 0.6380,  G_loss: 1.5644\n",
      " Epoch [253/300], Batch Step [90/323], D_loss: 0.6401,  G_loss: 1.5246\n",
      " Epoch [253/300], Batch Step [100/323], D_loss: 0.6864,  G_loss: 1.6270\n",
      " Epoch [253/300], Batch Step [110/323], D_loss: 0.5875,  G_loss: 1.7109\n",
      " Epoch [253/300], Batch Step [120/323], D_loss: 0.5461,  G_loss: 1.6114\n",
      " Epoch [253/300], Batch Step [130/323], D_loss: 0.5207,  G_loss: 1.6965\n",
      " Epoch [253/300], Batch Step [140/323], D_loss: 0.5728,  G_loss: 1.7902\n",
      " Epoch [253/300], Batch Step [150/323], D_loss: 0.6350,  G_loss: 1.6839\n",
      " Epoch [253/300], Batch Step [160/323], D_loss: 0.5553,  G_loss: 1.5920\n",
      " Epoch [253/300], Batch Step [170/323], D_loss: 0.5046,  G_loss: 1.5413\n",
      " Epoch [253/300], Batch Step [180/323], D_loss: 0.5855,  G_loss: 1.6125\n",
      " Epoch [253/300], Batch Step [190/323], D_loss: 0.7191,  G_loss: 1.7816\n",
      " Epoch [253/300], Batch Step [200/323], D_loss: 0.6035,  G_loss: 1.5614\n",
      " Epoch [253/300], Batch Step [210/323], D_loss: 0.6582,  G_loss: 1.5755\n",
      " Epoch [253/300], Batch Step [220/323], D_loss: 0.6047,  G_loss: 1.6850\n",
      " Epoch [253/300], Batch Step [230/323], D_loss: 0.4488,  G_loss: 1.6923\n",
      " Epoch [253/300], Batch Step [240/323], D_loss: 0.6300,  G_loss: 1.6167\n",
      " Epoch [253/300], Batch Step [250/323], D_loss: 0.6302,  G_loss: 1.5711\n",
      " Epoch [253/300], Batch Step [260/323], D_loss: 0.6652,  G_loss: 1.5158\n",
      " Epoch [253/300], Batch Step [270/323], D_loss: 0.7010,  G_loss: 1.8855\n",
      " Epoch [253/300], Batch Step [280/323], D_loss: 0.4906,  G_loss: 1.5490\n",
      " Epoch [253/300], Batch Step [290/323], D_loss: 0.6456,  G_loss: 1.5803\n",
      " Epoch [253/300], Batch Step [300/323], D_loss: 0.6913,  G_loss: 1.7294\n",
      " Epoch [253/300], Batch Step [310/323], D_loss: 0.6009,  G_loss: 1.5116\n",
      " Epoch [253/300], Batch Step [320/323], D_loss: 0.6371,  G_loss: 1.5515\n",
      " Epoch [254/300], Batch Step [0/323], D_loss: 0.6648,  G_loss: 1.6080\n",
      " Epoch [254/300], Batch Step [10/323], D_loss: 0.6932,  G_loss: 1.6270\n",
      " Epoch [254/300], Batch Step [20/323], D_loss: 0.7024,  G_loss: 1.5893\n",
      " Epoch [254/300], Batch Step [30/323], D_loss: 0.4788,  G_loss: 1.5995\n",
      " Epoch [254/300], Batch Step [40/323], D_loss: 0.6481,  G_loss: 1.6252\n",
      " Epoch [254/300], Batch Step [50/323], D_loss: 0.5554,  G_loss: 1.5512\n",
      " Epoch [254/300], Batch Step [60/323], D_loss: 0.6479,  G_loss: 1.8013\n",
      " Epoch [254/300], Batch Step [70/323], D_loss: 0.5977,  G_loss: 1.7075\n",
      " Epoch [254/300], Batch Step [80/323], D_loss: 0.6107,  G_loss: 1.7091\n",
      " Epoch [254/300], Batch Step [90/323], D_loss: 0.5861,  G_loss: 1.5329\n",
      " Epoch [254/300], Batch Step [100/323], D_loss: 0.6565,  G_loss: 1.5901\n",
      " Epoch [254/300], Batch Step [110/323], D_loss: 0.5779,  G_loss: 1.7428\n",
      " Epoch [254/300], Batch Step [120/323], D_loss: 0.6496,  G_loss: 1.5840\n",
      " Epoch [254/300], Batch Step [130/323], D_loss: 0.5221,  G_loss: 1.5961\n",
      " Epoch [254/300], Batch Step [140/323], D_loss: 0.5451,  G_loss: 1.7277\n",
      " Epoch [254/300], Batch Step [150/323], D_loss: 0.6965,  G_loss: 1.6738\n",
      " Epoch [254/300], Batch Step [160/323], D_loss: 0.5332,  G_loss: 1.6429\n",
      " Epoch [254/300], Batch Step [170/323], D_loss: 0.8188,  G_loss: 1.5887\n",
      " Epoch [254/300], Batch Step [180/323], D_loss: 0.7268,  G_loss: 1.5829\n",
      " Epoch [254/300], Batch Step [190/323], D_loss: 0.6542,  G_loss: 1.6176\n",
      " Epoch [254/300], Batch Step [200/323], D_loss: 0.6604,  G_loss: 1.5409\n",
      " Epoch [254/300], Batch Step [210/323], D_loss: 0.6740,  G_loss: 1.6448\n",
      " Epoch [254/300], Batch Step [220/323], D_loss: 0.7272,  G_loss: 1.5195\n",
      " Epoch [254/300], Batch Step [230/323], D_loss: 0.5233,  G_loss: 1.5710\n",
      " Epoch [254/300], Batch Step [240/323], D_loss: 0.5992,  G_loss: 1.6591\n",
      " Epoch [254/300], Batch Step [250/323], D_loss: 0.5766,  G_loss: 1.6413\n",
      " Epoch [254/300], Batch Step [260/323], D_loss: 0.7357,  G_loss: 1.5556\n",
      " Epoch [254/300], Batch Step [270/323], D_loss: 0.6102,  G_loss: 1.5225\n",
      " Epoch [254/300], Batch Step [280/323], D_loss: 0.6789,  G_loss: 1.6835\n",
      " Epoch [254/300], Batch Step [290/323], D_loss: 0.4640,  G_loss: 1.7668\n",
      " Epoch [254/300], Batch Step [300/323], D_loss: 0.6093,  G_loss: 1.6645\n",
      " Epoch [254/300], Batch Step [310/323], D_loss: 0.6150,  G_loss: 1.4973\n",
      " Epoch [254/300], Batch Step [320/323], D_loss: 0.7244,  G_loss: 1.6535\n",
      " Epoch [255/300], Batch Step [0/323], D_loss: 0.6117,  G_loss: 1.6203\n",
      " Epoch [255/300], Batch Step [10/323], D_loss: 0.7060,  G_loss: 1.6159\n",
      " Epoch [255/300], Batch Step [20/323], D_loss: 0.6206,  G_loss: 1.6293\n",
      " Epoch [255/300], Batch Step [30/323], D_loss: 0.5399,  G_loss: 1.7289\n",
      " Epoch [255/300], Batch Step [40/323], D_loss: 0.7187,  G_loss: 1.6461\n",
      " Epoch [255/300], Batch Step [50/323], D_loss: 0.8444,  G_loss: 1.6185\n",
      " Epoch [255/300], Batch Step [60/323], D_loss: 0.6301,  G_loss: 1.7592\n",
      " Epoch [255/300], Batch Step [70/323], D_loss: 0.7598,  G_loss: 1.6872\n",
      " Epoch [255/300], Batch Step [80/323], D_loss: 0.6728,  G_loss: 1.6566\n",
      " Epoch [255/300], Batch Step [90/323], D_loss: 0.5795,  G_loss: 1.6376\n",
      " Epoch [255/300], Batch Step [100/323], D_loss: 0.6315,  G_loss: 1.5142\n",
      " Epoch [255/300], Batch Step [110/323], D_loss: 0.6036,  G_loss: 1.6142\n",
      " Epoch [255/300], Batch Step [120/323], D_loss: 0.6004,  G_loss: 1.6313\n",
      " Epoch [255/300], Batch Step [130/323], D_loss: 0.6213,  G_loss: 1.4639\n",
      " Epoch [255/300], Batch Step [140/323], D_loss: 0.7054,  G_loss: 1.6187\n",
      " Epoch [255/300], Batch Step [150/323], D_loss: 0.5882,  G_loss: 1.6427\n",
      " Epoch [255/300], Batch Step [160/323], D_loss: 0.5913,  G_loss: 1.5622\n",
      " Epoch [255/300], Batch Step [170/323], D_loss: 0.6325,  G_loss: 1.5777\n",
      " Epoch [255/300], Batch Step [180/323], D_loss: 0.5534,  G_loss: 1.6375\n",
      " Epoch [255/300], Batch Step [190/323], D_loss: 0.4299,  G_loss: 1.7515\n",
      " Epoch [255/300], Batch Step [200/323], D_loss: 0.6864,  G_loss: 1.5834\n",
      " Epoch [255/300], Batch Step [210/323], D_loss: 0.6512,  G_loss: 1.6094\n",
      " Epoch [255/300], Batch Step [220/323], D_loss: 0.5703,  G_loss: 1.7446\n",
      " Epoch [255/300], Batch Step [230/323], D_loss: 0.6574,  G_loss: 1.6687\n",
      " Epoch [255/300], Batch Step [240/323], D_loss: 0.5423,  G_loss: 1.6288\n",
      " Epoch [255/300], Batch Step [250/323], D_loss: 0.6901,  G_loss: 1.6541\n",
      " Epoch [255/300], Batch Step [260/323], D_loss: 0.6283,  G_loss: 1.6506\n",
      " Epoch [255/300], Batch Step [270/323], D_loss: 0.6276,  G_loss: 1.4930\n",
      " Epoch [255/300], Batch Step [280/323], D_loss: 0.7060,  G_loss: 1.7469\n",
      " Epoch [255/300], Batch Step [290/323], D_loss: 0.5612,  G_loss: 1.7048\n",
      " Epoch [255/300], Batch Step [300/323], D_loss: 0.7094,  G_loss: 1.5044\n",
      " Epoch [255/300], Batch Step [310/323], D_loss: 0.7354,  G_loss: 1.7200\n",
      " Epoch [255/300], Batch Step [320/323], D_loss: 0.5707,  G_loss: 1.4917\n",
      " Epoch [256/300], Batch Step [0/323], D_loss: 0.7400,  G_loss: 1.5038\n",
      " Epoch [256/300], Batch Step [10/323], D_loss: 0.7477,  G_loss: 1.5920\n",
      " Epoch [256/300], Batch Step [20/323], D_loss: 0.7540,  G_loss: 1.6078\n",
      " Epoch [256/300], Batch Step [30/323], D_loss: 0.4470,  G_loss: 1.5677\n",
      " Epoch [256/300], Batch Step [40/323], D_loss: 0.5351,  G_loss: 1.6644\n",
      " Epoch [256/300], Batch Step [50/323], D_loss: 0.8154,  G_loss: 1.4351\n",
      " Epoch [256/300], Batch Step [60/323], D_loss: 0.5816,  G_loss: 1.6703\n",
      " Epoch [256/300], Batch Step [70/323], D_loss: 0.7575,  G_loss: 1.9842\n",
      " Epoch [256/300], Batch Step [80/323], D_loss: 0.6695,  G_loss: 1.4886\n",
      " Epoch [256/300], Batch Step [90/323], D_loss: 0.7475,  G_loss: 1.6304\n",
      " Epoch [256/300], Batch Step [100/323], D_loss: 0.5823,  G_loss: 1.7755\n",
      " Epoch [256/300], Batch Step [110/323], D_loss: 0.6595,  G_loss: 1.5041\n",
      " Epoch [256/300], Batch Step [120/323], D_loss: 0.6413,  G_loss: 1.5850\n",
      " Epoch [256/300], Batch Step [130/323], D_loss: 0.6842,  G_loss: 1.3996\n",
      " Epoch [256/300], Batch Step [140/323], D_loss: 0.6008,  G_loss: 1.7104\n",
      " Epoch [256/300], Batch Step [150/323], D_loss: 0.7833,  G_loss: 1.5141\n",
      " Epoch [256/300], Batch Step [160/323], D_loss: 0.6173,  G_loss: 1.4724\n",
      " Epoch [256/300], Batch Step [170/323], D_loss: 0.6808,  G_loss: 1.7419\n",
      " Epoch [256/300], Batch Step [180/323], D_loss: 0.5819,  G_loss: 1.6301\n",
      " Epoch [256/300], Batch Step [190/323], D_loss: 0.6987,  G_loss: 1.6862\n",
      " Epoch [256/300], Batch Step [200/323], D_loss: 0.6193,  G_loss: 1.5264\n",
      " Epoch [256/300], Batch Step [210/323], D_loss: 0.5377,  G_loss: 1.6567\n",
      " Epoch [256/300], Batch Step [220/323], D_loss: 0.7540,  G_loss: 1.7919\n",
      " Epoch [256/300], Batch Step [230/323], D_loss: 0.6608,  G_loss: 1.4874\n",
      " Epoch [256/300], Batch Step [240/323], D_loss: 0.6058,  G_loss: 1.8088\n",
      " Epoch [256/300], Batch Step [250/323], D_loss: 0.6720,  G_loss: 1.4338\n",
      " Epoch [256/300], Batch Step [260/323], D_loss: 0.6675,  G_loss: 1.6323\n",
      " Epoch [256/300], Batch Step [270/323], D_loss: 0.5483,  G_loss: 1.7522\n",
      " Epoch [256/300], Batch Step [280/323], D_loss: 0.6283,  G_loss: 1.4455\n",
      " Epoch [256/300], Batch Step [290/323], D_loss: 0.6004,  G_loss: 1.5716\n",
      " Epoch [256/300], Batch Step [300/323], D_loss: 0.7450,  G_loss: 1.6249\n",
      " Epoch [256/300], Batch Step [310/323], D_loss: 0.6500,  G_loss: 1.6185\n",
      " Epoch [256/300], Batch Step [320/323], D_loss: 0.5526,  G_loss: 1.6304\n",
      " Epoch [257/300], Batch Step [0/323], D_loss: 0.5608,  G_loss: 1.6479\n",
      " Epoch [257/300], Batch Step [10/323], D_loss: 0.5185,  G_loss: 1.6187\n",
      " Epoch [257/300], Batch Step [20/323], D_loss: 0.6087,  G_loss: 1.5344\n",
      " Epoch [257/300], Batch Step [30/323], D_loss: 0.5548,  G_loss: 1.6361\n",
      " Epoch [257/300], Batch Step [40/323], D_loss: 0.7190,  G_loss: 1.6602\n",
      " Epoch [257/300], Batch Step [50/323], D_loss: 0.5694,  G_loss: 1.7113\n",
      " Epoch [257/300], Batch Step [60/323], D_loss: 0.5159,  G_loss: 1.6063\n",
      " Epoch [257/300], Batch Step [70/323], D_loss: 0.7177,  G_loss: 1.5451\n",
      " Epoch [257/300], Batch Step [80/323], D_loss: 0.8497,  G_loss: 1.6054\n",
      " Epoch [257/300], Batch Step [90/323], D_loss: 0.7501,  G_loss: 1.5675\n",
      " Epoch [257/300], Batch Step [100/323], D_loss: 0.6868,  G_loss: 1.5835\n",
      " Epoch [257/300], Batch Step [110/323], D_loss: 0.5667,  G_loss: 1.7240\n",
      " Epoch [257/300], Batch Step [120/323], D_loss: 0.5543,  G_loss: 1.5445\n",
      " Epoch [257/300], Batch Step [130/323], D_loss: 0.6238,  G_loss: 1.7393\n",
      " Epoch [257/300], Batch Step [140/323], D_loss: 0.5780,  G_loss: 1.6519\n",
      " Epoch [257/300], Batch Step [150/323], D_loss: 0.6243,  G_loss: 1.5960\n",
      " Epoch [257/300], Batch Step [160/323], D_loss: 0.6232,  G_loss: 1.7194\n",
      " Epoch [257/300], Batch Step [170/323], D_loss: 0.6679,  G_loss: 1.5275\n",
      " Epoch [257/300], Batch Step [180/323], D_loss: 0.5545,  G_loss: 1.6797\n",
      " Epoch [257/300], Batch Step [190/323], D_loss: 0.8128,  G_loss: 1.5415\n",
      " Epoch [257/300], Batch Step [200/323], D_loss: 0.7205,  G_loss: 1.5644\n",
      " Epoch [257/300], Batch Step [210/323], D_loss: 0.4179,  G_loss: 1.5230\n",
      " Epoch [257/300], Batch Step [220/323], D_loss: 0.7689,  G_loss: 1.5929\n",
      " Epoch [257/300], Batch Step [230/323], D_loss: 0.6386,  G_loss: 1.6337\n",
      " Epoch [257/300], Batch Step [240/323], D_loss: 0.6294,  G_loss: 1.5767\n",
      " Epoch [257/300], Batch Step [250/323], D_loss: 0.5851,  G_loss: 1.6289\n",
      " Epoch [257/300], Batch Step [260/323], D_loss: 0.5195,  G_loss: 1.6076\n",
      " Epoch [257/300], Batch Step [270/323], D_loss: 0.5831,  G_loss: 1.6231\n",
      " Epoch [257/300], Batch Step [280/323], D_loss: 0.6335,  G_loss: 1.6425\n",
      " Epoch [257/300], Batch Step [290/323], D_loss: 0.5369,  G_loss: 1.7411\n",
      " Epoch [257/300], Batch Step [300/323], D_loss: 0.6479,  G_loss: 1.5756\n",
      " Epoch [257/300], Batch Step [310/323], D_loss: 0.6386,  G_loss: 1.5351\n",
      " Epoch [257/300], Batch Step [320/323], D_loss: 0.6420,  G_loss: 1.6421\n",
      " Epoch [258/300], Batch Step [0/323], D_loss: 0.7976,  G_loss: 1.7003\n",
      " Epoch [258/300], Batch Step [10/323], D_loss: 0.5217,  G_loss: 1.6328\n",
      " Epoch [258/300], Batch Step [20/323], D_loss: 0.5825,  G_loss: 1.6726\n",
      " Epoch [258/300], Batch Step [30/323], D_loss: 0.5241,  G_loss: 1.6370\n",
      " Epoch [258/300], Batch Step [40/323], D_loss: 0.6179,  G_loss: 1.6761\n",
      " Epoch [258/300], Batch Step [50/323], D_loss: 0.7203,  G_loss: 1.5688\n",
      " Epoch [258/300], Batch Step [60/323], D_loss: 0.4450,  G_loss: 1.6669\n",
      " Epoch [258/300], Batch Step [70/323], D_loss: 0.6595,  G_loss: 1.6076\n",
      " Epoch [258/300], Batch Step [80/323], D_loss: 0.7936,  G_loss: 1.6931\n",
      " Epoch [258/300], Batch Step [90/323], D_loss: 0.7521,  G_loss: 1.7173\n",
      " Epoch [258/300], Batch Step [100/323], D_loss: 0.4228,  G_loss: 1.6091\n",
      " Epoch [258/300], Batch Step [110/323], D_loss: 0.6494,  G_loss: 1.7340\n",
      " Epoch [258/300], Batch Step [120/323], D_loss: 0.5986,  G_loss: 1.6519\n",
      " Epoch [258/300], Batch Step [130/323], D_loss: 0.6836,  G_loss: 1.6832\n",
      " Epoch [258/300], Batch Step [140/323], D_loss: 0.6710,  G_loss: 1.7764\n",
      " Epoch [258/300], Batch Step [150/323], D_loss: 0.6722,  G_loss: 1.5807\n",
      " Epoch [258/300], Batch Step [160/323], D_loss: 0.6997,  G_loss: 1.5461\n",
      " Epoch [258/300], Batch Step [170/323], D_loss: 0.4945,  G_loss: 1.6842\n",
      " Epoch [258/300], Batch Step [180/323], D_loss: 0.8267,  G_loss: 1.5711\n",
      " Epoch [258/300], Batch Step [190/323], D_loss: 0.8039,  G_loss: 1.3989\n",
      " Epoch [258/300], Batch Step [200/323], D_loss: 0.6925,  G_loss: 1.5777\n",
      " Epoch [258/300], Batch Step [210/323], D_loss: 0.6629,  G_loss: 1.6474\n",
      " Epoch [258/300], Batch Step [220/323], D_loss: 0.6188,  G_loss: 1.4682\n",
      " Epoch [258/300], Batch Step [230/323], D_loss: 0.6696,  G_loss: 1.5736\n",
      " Epoch [258/300], Batch Step [240/323], D_loss: 0.7915,  G_loss: 1.7112\n",
      " Epoch [258/300], Batch Step [250/323], D_loss: 0.8072,  G_loss: 1.6414\n",
      " Epoch [258/300], Batch Step [260/323], D_loss: 0.5775,  G_loss: 1.7250\n",
      " Epoch [258/300], Batch Step [270/323], D_loss: 0.4740,  G_loss: 1.6571\n",
      " Epoch [258/300], Batch Step [280/323], D_loss: 0.6843,  G_loss: 1.6027\n",
      " Epoch [258/300], Batch Step [290/323], D_loss: 0.7216,  G_loss: 1.6515\n",
      " Epoch [258/300], Batch Step [300/323], D_loss: 0.6454,  G_loss: 1.7314\n",
      " Epoch [258/300], Batch Step [310/323], D_loss: 0.5478,  G_loss: 1.6592\n",
      " Epoch [258/300], Batch Step [320/323], D_loss: 0.6299,  G_loss: 1.5967\n",
      " Epoch [259/300], Batch Step [0/323], D_loss: 0.7557,  G_loss: 1.5406\n",
      " Epoch [259/300], Batch Step [10/323], D_loss: 0.5696,  G_loss: 1.6296\n",
      " Epoch [259/300], Batch Step [20/323], D_loss: 0.5854,  G_loss: 1.5518\n",
      " Epoch [259/300], Batch Step [30/323], D_loss: 0.6806,  G_loss: 1.6601\n",
      " Epoch [259/300], Batch Step [40/323], D_loss: 0.5764,  G_loss: 1.6543\n",
      " Epoch [259/300], Batch Step [50/323], D_loss: 0.6818,  G_loss: 1.7075\n",
      " Epoch [259/300], Batch Step [60/323], D_loss: 0.6447,  G_loss: 1.4515\n",
      " Epoch [259/300], Batch Step [70/323], D_loss: 0.7554,  G_loss: 1.6849\n",
      " Epoch [259/300], Batch Step [80/323], D_loss: 0.6766,  G_loss: 1.7108\n",
      " Epoch [259/300], Batch Step [90/323], D_loss: 0.6345,  G_loss: 1.5986\n",
      " Epoch [259/300], Batch Step [100/323], D_loss: 0.6580,  G_loss: 1.6753\n",
      " Epoch [259/300], Batch Step [110/323], D_loss: 0.7881,  G_loss: 1.5343\n",
      " Epoch [259/300], Batch Step [120/323], D_loss: 0.6624,  G_loss: 1.5450\n",
      " Epoch [259/300], Batch Step [130/323], D_loss: 0.6283,  G_loss: 1.6734\n",
      " Epoch [259/300], Batch Step [140/323], D_loss: 0.7555,  G_loss: 1.5043\n",
      " Epoch [259/300], Batch Step [150/323], D_loss: 0.4356,  G_loss: 1.6287\n",
      " Epoch [259/300], Batch Step [160/323], D_loss: 0.8628,  G_loss: 1.5682\n",
      " Epoch [259/300], Batch Step [170/323], D_loss: 0.5304,  G_loss: 1.6355\n",
      " Epoch [259/300], Batch Step [180/323], D_loss: 0.5919,  G_loss: 1.5948\n",
      " Epoch [259/300], Batch Step [190/323], D_loss: 0.4967,  G_loss: 1.6802\n",
      " Epoch [259/300], Batch Step [200/323], D_loss: 0.5700,  G_loss: 1.7246\n",
      " Epoch [259/300], Batch Step [210/323], D_loss: 0.5441,  G_loss: 1.4785\n",
      " Epoch [259/300], Batch Step [220/323], D_loss: 0.7913,  G_loss: 1.6279\n",
      " Epoch [259/300], Batch Step [230/323], D_loss: 0.6836,  G_loss: 1.6518\n",
      " Epoch [259/300], Batch Step [240/323], D_loss: 0.6467,  G_loss: 1.5926\n",
      " Epoch [259/300], Batch Step [250/323], D_loss: 0.5003,  G_loss: 1.6027\n",
      " Epoch [259/300], Batch Step [260/323], D_loss: 0.4658,  G_loss: 1.7644\n",
      " Epoch [259/300], Batch Step [270/323], D_loss: 0.5618,  G_loss: 1.7748\n",
      " Epoch [259/300], Batch Step [280/323], D_loss: 0.6429,  G_loss: 1.6141\n",
      " Epoch [259/300], Batch Step [290/323], D_loss: 0.6978,  G_loss: 1.5429\n",
      " Epoch [259/300], Batch Step [300/323], D_loss: 0.5633,  G_loss: 1.7954\n",
      " Epoch [259/300], Batch Step [310/323], D_loss: 0.6631,  G_loss: 1.6815\n",
      " Epoch [259/300], Batch Step [320/323], D_loss: 0.6249,  G_loss: 1.5579\n",
      " Epoch [260/300], Batch Step [0/323], D_loss: 0.6843,  G_loss: 1.6381\n",
      " Epoch [260/300], Batch Step [10/323], D_loss: 0.6099,  G_loss: 1.4637\n",
      " Epoch [260/300], Batch Step [20/323], D_loss: 0.7487,  G_loss: 1.8417\n",
      " Epoch [260/300], Batch Step [30/323], D_loss: 0.8337,  G_loss: 1.5776\n",
      " Epoch [260/300], Batch Step [40/323], D_loss: 0.6098,  G_loss: 1.5699\n",
      " Epoch [260/300], Batch Step [50/323], D_loss: 0.6185,  G_loss: 1.6477\n",
      " Epoch [260/300], Batch Step [60/323], D_loss: 0.5695,  G_loss: 1.6764\n",
      " Epoch [260/300], Batch Step [70/323], D_loss: 0.6057,  G_loss: 1.6562\n",
      " Epoch [260/300], Batch Step [80/323], D_loss: 0.6262,  G_loss: 1.5834\n",
      " Epoch [260/300], Batch Step [90/323], D_loss: 0.6021,  G_loss: 1.4416\n",
      " Epoch [260/300], Batch Step [100/323], D_loss: 0.6753,  G_loss: 1.6353\n",
      " Epoch [260/300], Batch Step [110/323], D_loss: 0.6312,  G_loss: 1.6148\n",
      " Epoch [260/300], Batch Step [120/323], D_loss: 0.7019,  G_loss: 1.4942\n",
      " Epoch [260/300], Batch Step [130/323], D_loss: 0.5524,  G_loss: 1.7182\n",
      " Epoch [260/300], Batch Step [140/323], D_loss: 0.6748,  G_loss: 1.6740\n",
      " Epoch [260/300], Batch Step [150/323], D_loss: 0.5491,  G_loss: 1.7464\n",
      " Epoch [260/300], Batch Step [160/323], D_loss: 0.6952,  G_loss: 1.6059\n",
      " Epoch [260/300], Batch Step [170/323], D_loss: 0.6083,  G_loss: 1.4708\n",
      " Epoch [260/300], Batch Step [180/323], D_loss: 0.7227,  G_loss: 1.5867\n",
      " Epoch [260/300], Batch Step [190/323], D_loss: 0.7032,  G_loss: 1.6681\n",
      " Epoch [260/300], Batch Step [200/323], D_loss: 0.6394,  G_loss: 1.6034\n",
      " Epoch [260/300], Batch Step [210/323], D_loss: 0.5053,  G_loss: 1.6738\n",
      " Epoch [260/300], Batch Step [220/323], D_loss: 0.6637,  G_loss: 1.5818\n",
      " Epoch [260/300], Batch Step [230/323], D_loss: 0.6242,  G_loss: 1.6578\n",
      " Epoch [260/300], Batch Step [240/323], D_loss: 0.5077,  G_loss: 1.5951\n",
      " Epoch [260/300], Batch Step [250/323], D_loss: 0.6346,  G_loss: 1.6486\n",
      " Epoch [260/300], Batch Step [260/323], D_loss: 0.4671,  G_loss: 1.6349\n",
      " Epoch [260/300], Batch Step [270/323], D_loss: 0.5441,  G_loss: 1.5335\n",
      " Epoch [260/300], Batch Step [280/323], D_loss: 0.6142,  G_loss: 1.5828\n",
      " Epoch [260/300], Batch Step [290/323], D_loss: 0.6240,  G_loss: 1.6184\n",
      " Epoch [260/300], Batch Step [300/323], D_loss: 0.5627,  G_loss: 1.6199\n",
      " Epoch [260/300], Batch Step [310/323], D_loss: 0.5886,  G_loss: 1.5919\n",
      " Epoch [260/300], Batch Step [320/323], D_loss: 0.5754,  G_loss: 1.5774\n",
      " Epoch [261/300], Batch Step [0/323], D_loss: 0.5834,  G_loss: 1.6525\n",
      " Epoch [261/300], Batch Step [10/323], D_loss: 0.6079,  G_loss: 1.5501\n",
      " Epoch [261/300], Batch Step [20/323], D_loss: 0.5437,  G_loss: 1.5614\n",
      " Epoch [261/300], Batch Step [30/323], D_loss: 0.6676,  G_loss: 1.5571\n",
      " Epoch [261/300], Batch Step [40/323], D_loss: 0.4521,  G_loss: 1.7264\n",
      " Epoch [261/300], Batch Step [50/323], D_loss: 0.6006,  G_loss: 1.6880\n",
      " Epoch [261/300], Batch Step [60/323], D_loss: 0.8075,  G_loss: 1.5753\n",
      " Epoch [261/300], Batch Step [70/323], D_loss: 0.5876,  G_loss: 1.5433\n",
      " Epoch [261/300], Batch Step [80/323], D_loss: 0.6050,  G_loss: 1.8359\n",
      " Epoch [261/300], Batch Step [90/323], D_loss: 0.7536,  G_loss: 1.6416\n",
      " Epoch [261/300], Batch Step [100/323], D_loss: 0.6577,  G_loss: 1.5601\n",
      " Epoch [261/300], Batch Step [110/323], D_loss: 0.7036,  G_loss: 1.6163\n",
      " Epoch [261/300], Batch Step [120/323], D_loss: 0.7498,  G_loss: 1.5593\n",
      " Epoch [261/300], Batch Step [130/323], D_loss: 0.6732,  G_loss: 1.6272\n",
      " Epoch [261/300], Batch Step [140/323], D_loss: 0.6464,  G_loss: 1.5693\n",
      " Epoch [261/300], Batch Step [150/323], D_loss: 0.6590,  G_loss: 1.5384\n",
      " Epoch [261/300], Batch Step [160/323], D_loss: 0.7542,  G_loss: 1.6951\n",
      " Epoch [261/300], Batch Step [170/323], D_loss: 0.6172,  G_loss: 1.6810\n",
      " Epoch [261/300], Batch Step [180/323], D_loss: 0.6534,  G_loss: 1.5373\n",
      " Epoch [261/300], Batch Step [190/323], D_loss: 0.7809,  G_loss: 1.6506\n",
      " Epoch [261/300], Batch Step [200/323], D_loss: 0.7286,  G_loss: 1.6379\n",
      " Epoch [261/300], Batch Step [210/323], D_loss: 0.5242,  G_loss: 1.6529\n",
      " Epoch [261/300], Batch Step [220/323], D_loss: 0.6194,  G_loss: 1.5925\n",
      " Epoch [261/300], Batch Step [230/323], D_loss: 0.6526,  G_loss: 1.5195\n",
      " Epoch [261/300], Batch Step [240/323], D_loss: 0.4872,  G_loss: 1.7539\n",
      " Epoch [261/300], Batch Step [250/323], D_loss: 0.6057,  G_loss: 1.5255\n",
      " Epoch [261/300], Batch Step [260/323], D_loss: 0.6865,  G_loss: 1.5275\n",
      " Epoch [261/300], Batch Step [270/323], D_loss: 0.5553,  G_loss: 1.6426\n",
      " Epoch [261/300], Batch Step [280/323], D_loss: 0.5714,  G_loss: 1.6037\n",
      " Epoch [261/300], Batch Step [290/323], D_loss: 0.8827,  G_loss: 1.6508\n",
      " Epoch [261/300], Batch Step [300/323], D_loss: 0.8043,  G_loss: 1.6093\n",
      " Epoch [261/300], Batch Step [310/323], D_loss: 0.7363,  G_loss: 1.7091\n",
      " Epoch [261/300], Batch Step [320/323], D_loss: 0.5220,  G_loss: 1.6491\n",
      " Epoch [262/300], Batch Step [0/323], D_loss: 0.5560,  G_loss: 1.6797\n",
      " Epoch [262/300], Batch Step [10/323], D_loss: 0.6832,  G_loss: 1.5934\n",
      " Epoch [262/300], Batch Step [20/323], D_loss: 0.5185,  G_loss: 1.7028\n",
      " Epoch [262/300], Batch Step [30/323], D_loss: 0.6531,  G_loss: 1.7346\n",
      " Epoch [262/300], Batch Step [40/323], D_loss: 0.6094,  G_loss: 1.6823\n",
      " Epoch [262/300], Batch Step [50/323], D_loss: 0.5653,  G_loss: 1.4377\n",
      " Epoch [262/300], Batch Step [60/323], D_loss: 0.6212,  G_loss: 1.6575\n",
      " Epoch [262/300], Batch Step [70/323], D_loss: 0.6143,  G_loss: 1.6142\n",
      " Epoch [262/300], Batch Step [80/323], D_loss: 0.6434,  G_loss: 1.5793\n",
      " Epoch [262/300], Batch Step [90/323], D_loss: 0.5587,  G_loss: 1.6870\n",
      " Epoch [262/300], Batch Step [100/323], D_loss: 0.6374,  G_loss: 1.5270\n",
      " Epoch [262/300], Batch Step [110/323], D_loss: 0.4423,  G_loss: 1.7654\n",
      " Epoch [262/300], Batch Step [120/323], D_loss: 0.8118,  G_loss: 1.7663\n",
      " Epoch [262/300], Batch Step [130/323], D_loss: 0.6400,  G_loss: 1.5110\n",
      " Epoch [262/300], Batch Step [140/323], D_loss: 0.5821,  G_loss: 1.7253\n",
      " Epoch [262/300], Batch Step [150/323], D_loss: 0.4996,  G_loss: 1.6612\n",
      " Epoch [262/300], Batch Step [160/323], D_loss: 0.5159,  G_loss: 1.7011\n",
      " Epoch [262/300], Batch Step [170/323], D_loss: 0.6151,  G_loss: 1.5693\n",
      " Epoch [262/300], Batch Step [180/323], D_loss: 0.5909,  G_loss: 1.5968\n",
      " Epoch [262/300], Batch Step [190/323], D_loss: 0.6504,  G_loss: 1.5770\n",
      " Epoch [262/300], Batch Step [200/323], D_loss: 0.7348,  G_loss: 1.5021\n",
      " Epoch [262/300], Batch Step [210/323], D_loss: 0.6139,  G_loss: 1.5110\n",
      " Epoch [262/300], Batch Step [220/323], D_loss: 0.7200,  G_loss: 1.5743\n",
      " Epoch [262/300], Batch Step [230/323], D_loss: 0.6894,  G_loss: 1.7103\n",
      " Epoch [262/300], Batch Step [240/323], D_loss: 0.7463,  G_loss: 1.6163\n",
      " Epoch [262/300], Batch Step [250/323], D_loss: 0.8137,  G_loss: 1.5055\n",
      " Epoch [262/300], Batch Step [260/323], D_loss: 0.5684,  G_loss: 1.5276\n",
      " Epoch [262/300], Batch Step [270/323], D_loss: 0.7039,  G_loss: 1.7009\n",
      " Epoch [262/300], Batch Step [280/323], D_loss: 0.6298,  G_loss: 1.5574\n",
      " Epoch [262/300], Batch Step [290/323], D_loss: 0.7230,  G_loss: 1.5897\n",
      " Epoch [262/300], Batch Step [300/323], D_loss: 0.6364,  G_loss: 1.6059\n",
      " Epoch [262/300], Batch Step [310/323], D_loss: 0.6458,  G_loss: 1.6036\n",
      " Epoch [262/300], Batch Step [320/323], D_loss: 0.4086,  G_loss: 1.7519\n",
      " Epoch [263/300], Batch Step [0/323], D_loss: 0.5689,  G_loss: 1.7512\n",
      " Epoch [263/300], Batch Step [10/323], D_loss: 0.5428,  G_loss: 1.4502\n",
      " Epoch [263/300], Batch Step [20/323], D_loss: 0.5968,  G_loss: 1.5999\n",
      " Epoch [263/300], Batch Step [30/323], D_loss: 0.5797,  G_loss: 1.6775\n",
      " Epoch [263/300], Batch Step [40/323], D_loss: 0.6214,  G_loss: 1.7361\n",
      " Epoch [263/300], Batch Step [50/323], D_loss: 0.6417,  G_loss: 1.4091\n",
      " Epoch [263/300], Batch Step [60/323], D_loss: 0.6483,  G_loss: 1.6191\n",
      " Epoch [263/300], Batch Step [70/323], D_loss: 0.5606,  G_loss: 1.5541\n",
      " Epoch [263/300], Batch Step [80/323], D_loss: 0.7116,  G_loss: 1.6839\n",
      " Epoch [263/300], Batch Step [90/323], D_loss: 0.7349,  G_loss: 1.5432\n",
      " Epoch [263/300], Batch Step [100/323], D_loss: 0.8999,  G_loss: 1.5379\n",
      " Epoch [263/300], Batch Step [110/323], D_loss: 0.6943,  G_loss: 1.7420\n",
      " Epoch [263/300], Batch Step [120/323], D_loss: 0.6965,  G_loss: 1.7439\n",
      " Epoch [263/300], Batch Step [130/323], D_loss: 0.5871,  G_loss: 1.4732\n",
      " Epoch [263/300], Batch Step [140/323], D_loss: 0.5934,  G_loss: 1.6586\n",
      " Epoch [263/300], Batch Step [150/323], D_loss: 0.5287,  G_loss: 1.7458\n",
      " Epoch [263/300], Batch Step [160/323], D_loss: 0.6233,  G_loss: 1.6073\n",
      " Epoch [263/300], Batch Step [170/323], D_loss: 0.6257,  G_loss: 1.6075\n",
      " Epoch [263/300], Batch Step [180/323], D_loss: 0.5562,  G_loss: 1.6210\n",
      " Epoch [263/300], Batch Step [190/323], D_loss: 0.6494,  G_loss: 1.7550\n",
      " Epoch [263/300], Batch Step [200/323], D_loss: 0.7691,  G_loss: 1.7012\n",
      " Epoch [263/300], Batch Step [210/323], D_loss: 0.5525,  G_loss: 1.6014\n",
      " Epoch [263/300], Batch Step [220/323], D_loss: 0.5186,  G_loss: 1.5696\n",
      " Epoch [263/300], Batch Step [230/323], D_loss: 0.5905,  G_loss: 1.7227\n",
      " Epoch [263/300], Batch Step [240/323], D_loss: 0.6855,  G_loss: 1.5612\n",
      " Epoch [263/300], Batch Step [250/323], D_loss: 0.5465,  G_loss: 1.7510\n",
      " Epoch [263/300], Batch Step [260/323], D_loss: 0.6938,  G_loss: 1.6454\n",
      " Epoch [263/300], Batch Step [270/323], D_loss: 0.6055,  G_loss: 1.5630\n",
      " Epoch [263/300], Batch Step [280/323], D_loss: 0.5803,  G_loss: 1.6913\n",
      " Epoch [263/300], Batch Step [290/323], D_loss: 0.7721,  G_loss: 1.5756\n",
      " Epoch [263/300], Batch Step [300/323], D_loss: 0.6178,  G_loss: 1.6625\n",
      " Epoch [263/300], Batch Step [310/323], D_loss: 0.5054,  G_loss: 1.5762\n",
      " Epoch [263/300], Batch Step [320/323], D_loss: 0.6077,  G_loss: 1.5626\n",
      " Epoch [264/300], Batch Step [0/323], D_loss: 0.5889,  G_loss: 1.6377\n",
      " Epoch [264/300], Batch Step [10/323], D_loss: 0.6329,  G_loss: 1.6095\n",
      " Epoch [264/300], Batch Step [20/323], D_loss: 0.5547,  G_loss: 1.6624\n",
      " Epoch [264/300], Batch Step [30/323], D_loss: 0.6235,  G_loss: 1.6487\n",
      " Epoch [264/300], Batch Step [40/323], D_loss: 0.8375,  G_loss: 1.5622\n",
      " Epoch [264/300], Batch Step [50/323], D_loss: 0.5903,  G_loss: 1.5796\n",
      " Epoch [264/300], Batch Step [60/323], D_loss: 0.6365,  G_loss: 1.6706\n",
      " Epoch [264/300], Batch Step [70/323], D_loss: 0.6776,  G_loss: 1.6141\n",
      " Epoch [264/300], Batch Step [80/323], D_loss: 0.6573,  G_loss: 1.7069\n",
      " Epoch [264/300], Batch Step [90/323], D_loss: 0.6067,  G_loss: 1.7387\n",
      " Epoch [264/300], Batch Step [100/323], D_loss: 0.5736,  G_loss: 1.7280\n",
      " Epoch [264/300], Batch Step [110/323], D_loss: 0.6159,  G_loss: 1.5777\n",
      " Epoch [264/300], Batch Step [120/323], D_loss: 0.7040,  G_loss: 1.6266\n",
      " Epoch [264/300], Batch Step [130/323], D_loss: 0.5319,  G_loss: 1.5848\n",
      " Epoch [264/300], Batch Step [140/323], D_loss: 0.6264,  G_loss: 1.6797\n",
      " Epoch [264/300], Batch Step [150/323], D_loss: 0.6865,  G_loss: 1.5641\n",
      " Epoch [264/300], Batch Step [160/323], D_loss: 0.6469,  G_loss: 1.5740\n",
      " Epoch [264/300], Batch Step [170/323], D_loss: 0.5383,  G_loss: 1.6938\n",
      " Epoch [264/300], Batch Step [180/323], D_loss: 0.7022,  G_loss: 1.5879\n",
      " Epoch [264/300], Batch Step [190/323], D_loss: 0.5085,  G_loss: 1.7027\n",
      " Epoch [264/300], Batch Step [200/323], D_loss: 0.6298,  G_loss: 1.6398\n",
      " Epoch [264/300], Batch Step [210/323], D_loss: 0.6506,  G_loss: 1.6779\n",
      " Epoch [264/300], Batch Step [220/323], D_loss: 0.6502,  G_loss: 1.6274\n",
      " Epoch [264/300], Batch Step [230/323], D_loss: 0.7054,  G_loss: 1.7529\n",
      " Epoch [264/300], Batch Step [240/323], D_loss: 0.5751,  G_loss: 1.7000\n",
      " Epoch [264/300], Batch Step [250/323], D_loss: 0.6726,  G_loss: 1.6514\n",
      " Epoch [264/300], Batch Step [260/323], D_loss: 0.6094,  G_loss: 1.5636\n",
      " Epoch [264/300], Batch Step [270/323], D_loss: 0.6140,  G_loss: 1.5789\n",
      " Epoch [264/300], Batch Step [280/323], D_loss: 0.5779,  G_loss: 1.6385\n",
      " Epoch [264/300], Batch Step [290/323], D_loss: 0.5397,  G_loss: 1.4800\n",
      " Epoch [264/300], Batch Step [300/323], D_loss: 0.6188,  G_loss: 1.6458\n",
      " Epoch [264/300], Batch Step [310/323], D_loss: 0.6071,  G_loss: 1.6539\n",
      " Epoch [264/300], Batch Step [320/323], D_loss: 0.6269,  G_loss: 1.4515\n",
      " Epoch [265/300], Batch Step [0/323], D_loss: 0.6720,  G_loss: 1.4088\n",
      " Epoch [265/300], Batch Step [10/323], D_loss: 0.6103,  G_loss: 1.6256\n",
      " Epoch [265/300], Batch Step [20/323], D_loss: 0.5942,  G_loss: 1.5633\n",
      " Epoch [265/300], Batch Step [30/323], D_loss: 0.5855,  G_loss: 1.6562\n",
      " Epoch [265/300], Batch Step [40/323], D_loss: 0.7328,  G_loss: 1.6709\n",
      " Epoch [265/300], Batch Step [50/323], D_loss: 0.5342,  G_loss: 1.6666\n",
      " Epoch [265/300], Batch Step [60/323], D_loss: 0.5299,  G_loss: 1.6727\n",
      " Epoch [265/300], Batch Step [70/323], D_loss: 0.5396,  G_loss: 1.6527\n",
      " Epoch [265/300], Batch Step [80/323], D_loss: 0.5712,  G_loss: 1.7760\n",
      " Epoch [265/300], Batch Step [90/323], D_loss: 0.6048,  G_loss: 1.6178\n",
      " Epoch [265/300], Batch Step [100/323], D_loss: 0.6759,  G_loss: 1.5973\n",
      " Epoch [265/300], Batch Step [110/323], D_loss: 0.9226,  G_loss: 1.5982\n",
      " Epoch [265/300], Batch Step [120/323], D_loss: 0.7070,  G_loss: 1.5542\n",
      " Epoch [265/300], Batch Step [130/323], D_loss: 0.5958,  G_loss: 1.5102\n",
      " Epoch [265/300], Batch Step [140/323], D_loss: 0.5953,  G_loss: 1.6138\n",
      " Epoch [265/300], Batch Step [150/323], D_loss: 0.5799,  G_loss: 1.6399\n",
      " Epoch [265/300], Batch Step [160/323], D_loss: 0.8365,  G_loss: 1.8266\n",
      " Epoch [265/300], Batch Step [170/323], D_loss: 0.8637,  G_loss: 1.5878\n",
      " Epoch [265/300], Batch Step [180/323], D_loss: 0.6045,  G_loss: 1.6592\n",
      " Epoch [265/300], Batch Step [190/323], D_loss: 0.6456,  G_loss: 1.5331\n",
      " Epoch [265/300], Batch Step [200/323], D_loss: 0.6550,  G_loss: 1.6088\n",
      " Epoch [265/300], Batch Step [210/323], D_loss: 0.6511,  G_loss: 1.7044\n",
      " Epoch [265/300], Batch Step [220/323], D_loss: 0.6094,  G_loss: 1.6097\n",
      " Epoch [265/300], Batch Step [230/323], D_loss: 0.7429,  G_loss: 1.5516\n",
      " Epoch [265/300], Batch Step [240/323], D_loss: 0.6244,  G_loss: 1.6820\n",
      " Epoch [265/300], Batch Step [250/323], D_loss: 0.4607,  G_loss: 1.6864\n",
      " Epoch [265/300], Batch Step [260/323], D_loss: 0.6500,  G_loss: 1.7205\n",
      " Epoch [265/300], Batch Step [270/323], D_loss: 0.5643,  G_loss: 1.6428\n",
      " Epoch [265/300], Batch Step [280/323], D_loss: 0.6895,  G_loss: 1.5326\n",
      " Epoch [265/300], Batch Step [290/323], D_loss: 0.5772,  G_loss: 1.5166\n",
      " Epoch [265/300], Batch Step [300/323], D_loss: 0.6604,  G_loss: 1.6827\n",
      " Epoch [265/300], Batch Step [310/323], D_loss: 0.5376,  G_loss: 1.6298\n",
      " Epoch [265/300], Batch Step [320/323], D_loss: 0.6651,  G_loss: 1.7514\n",
      " Epoch [266/300], Batch Step [0/323], D_loss: 0.5494,  G_loss: 1.6439\n",
      " Epoch [266/300], Batch Step [10/323], D_loss: 0.6181,  G_loss: 1.5630\n",
      " Epoch [266/300], Batch Step [20/323], D_loss: 0.4901,  G_loss: 1.6855\n",
      " Epoch [266/300], Batch Step [30/323], D_loss: 0.6052,  G_loss: 1.6440\n",
      " Epoch [266/300], Batch Step [40/323], D_loss: 0.6700,  G_loss: 1.6652\n",
      " Epoch [266/300], Batch Step [50/323], D_loss: 0.6215,  G_loss: 1.5898\n",
      " Epoch [266/300], Batch Step [60/323], D_loss: 0.6649,  G_loss: 1.5856\n",
      " Epoch [266/300], Batch Step [70/323], D_loss: 0.6492,  G_loss: 1.7303\n",
      " Epoch [266/300], Batch Step [80/323], D_loss: 0.6106,  G_loss: 1.5829\n",
      " Epoch [266/300], Batch Step [90/323], D_loss: 0.5179,  G_loss: 1.6084\n",
      " Epoch [266/300], Batch Step [100/323], D_loss: 0.5121,  G_loss: 1.7471\n",
      " Epoch [266/300], Batch Step [110/323], D_loss: 0.7182,  G_loss: 1.6901\n",
      " Epoch [266/300], Batch Step [120/323], D_loss: 0.5866,  G_loss: 1.6464\n",
      " Epoch [266/300], Batch Step [130/323], D_loss: 0.7994,  G_loss: 1.7607\n",
      " Epoch [266/300], Batch Step [140/323], D_loss: 0.6345,  G_loss: 1.4614\n",
      " Epoch [266/300], Batch Step [150/323], D_loss: 0.7641,  G_loss: 1.6967\n",
      " Epoch [266/300], Batch Step [160/323], D_loss: 0.5917,  G_loss: 1.6020\n",
      " Epoch [266/300], Batch Step [170/323], D_loss: 0.6994,  G_loss: 1.6869\n",
      " Epoch [266/300], Batch Step [180/323], D_loss: 0.6773,  G_loss: 1.6162\n",
      " Epoch [266/300], Batch Step [190/323], D_loss: 0.6455,  G_loss: 1.4999\n",
      " Epoch [266/300], Batch Step [200/323], D_loss: 0.7370,  G_loss: 1.5330\n",
      " Epoch [266/300], Batch Step [210/323], D_loss: 0.7447,  G_loss: 1.6560\n",
      " Epoch [266/300], Batch Step [220/323], D_loss: 0.7520,  G_loss: 1.4710\n",
      " Epoch [266/300], Batch Step [230/323], D_loss: 0.5803,  G_loss: 1.5851\n",
      " Epoch [266/300], Batch Step [240/323], D_loss: 0.7977,  G_loss: 1.6704\n",
      " Epoch [266/300], Batch Step [250/323], D_loss: 0.5741,  G_loss: 1.5266\n",
      " Epoch [266/300], Batch Step [260/323], D_loss: 0.5361,  G_loss: 1.6288\n",
      " Epoch [266/300], Batch Step [270/323], D_loss: 0.7275,  G_loss: 1.6464\n",
      " Epoch [266/300], Batch Step [280/323], D_loss: 0.6191,  G_loss: 1.5794\n",
      " Epoch [266/300], Batch Step [290/323], D_loss: 0.4436,  G_loss: 1.7349\n",
      " Epoch [266/300], Batch Step [300/323], D_loss: 0.6321,  G_loss: 1.6791\n",
      " Epoch [266/300], Batch Step [310/323], D_loss: 0.5989,  G_loss: 1.5281\n",
      " Epoch [266/300], Batch Step [320/323], D_loss: 0.5968,  G_loss: 1.7398\n",
      " Epoch [267/300], Batch Step [0/323], D_loss: 0.5938,  G_loss: 1.7176\n",
      " Epoch [267/300], Batch Step [10/323], D_loss: 0.7544,  G_loss: 1.5293\n",
      " Epoch [267/300], Batch Step [20/323], D_loss: 0.7199,  G_loss: 1.5370\n",
      " Epoch [267/300], Batch Step [30/323], D_loss: 0.6748,  G_loss: 1.5887\n",
      " Epoch [267/300], Batch Step [40/323], D_loss: 0.6598,  G_loss: 1.5966\n",
      " Epoch [267/300], Batch Step [50/323], D_loss: 0.5750,  G_loss: 1.6485\n",
      " Epoch [267/300], Batch Step [60/323], D_loss: 0.5373,  G_loss: 1.6322\n",
      " Epoch [267/300], Batch Step [70/323], D_loss: 0.6411,  G_loss: 1.5855\n",
      " Epoch [267/300], Batch Step [80/323], D_loss: 0.5309,  G_loss: 1.6185\n",
      " Epoch [267/300], Batch Step [90/323], D_loss: 0.5458,  G_loss: 1.5527\n",
      " Epoch [267/300], Batch Step [100/323], D_loss: 0.5927,  G_loss: 1.6279\n",
      " Epoch [267/300], Batch Step [110/323], D_loss: 0.7343,  G_loss: 1.5727\n",
      " Epoch [267/300], Batch Step [120/323], D_loss: 0.6452,  G_loss: 1.6739\n",
      " Epoch [267/300], Batch Step [130/323], D_loss: 0.7096,  G_loss: 1.6383\n",
      " Epoch [267/300], Batch Step [140/323], D_loss: 0.6725,  G_loss: 1.6221\n",
      " Epoch [267/300], Batch Step [150/323], D_loss: 0.8691,  G_loss: 1.5623\n",
      " Epoch [267/300], Batch Step [160/323], D_loss: 0.6705,  G_loss: 1.7590\n",
      " Epoch [267/300], Batch Step [170/323], D_loss: 0.6422,  G_loss: 1.5544\n",
      " Epoch [267/300], Batch Step [180/323], D_loss: 0.6257,  G_loss: 1.6420\n",
      " Epoch [267/300], Batch Step [190/323], D_loss: 0.7173,  G_loss: 1.6757\n",
      " Epoch [267/300], Batch Step [200/323], D_loss: 0.6720,  G_loss: 1.6965\n",
      " Epoch [267/300], Batch Step [210/323], D_loss: 0.5914,  G_loss: 1.6089\n",
      " Epoch [267/300], Batch Step [220/323], D_loss: 0.6763,  G_loss: 1.4515\n",
      " Epoch [267/300], Batch Step [230/323], D_loss: 0.6173,  G_loss: 1.4919\n",
      " Epoch [267/300], Batch Step [240/323], D_loss: 0.5865,  G_loss: 1.6489\n",
      " Epoch [267/300], Batch Step [250/323], D_loss: 0.5726,  G_loss: 1.6090\n",
      " Epoch [267/300], Batch Step [260/323], D_loss: 0.5829,  G_loss: 1.6829\n",
      " Epoch [267/300], Batch Step [270/323], D_loss: 0.6494,  G_loss: 1.6884\n",
      " Epoch [267/300], Batch Step [280/323], D_loss: 0.7669,  G_loss: 1.7443\n",
      " Epoch [267/300], Batch Step [290/323], D_loss: 0.6829,  G_loss: 1.5915\n",
      " Epoch [267/300], Batch Step [300/323], D_loss: 0.6076,  G_loss: 1.4663\n",
      " Epoch [267/300], Batch Step [310/323], D_loss: 0.5452,  G_loss: 1.7533\n",
      " Epoch [267/300], Batch Step [320/323], D_loss: 0.6306,  G_loss: 1.6744\n",
      " Epoch [268/300], Batch Step [0/323], D_loss: 0.6243,  G_loss: 1.6604\n",
      " Epoch [268/300], Batch Step [10/323], D_loss: 0.5986,  G_loss: 1.5940\n",
      " Epoch [268/300], Batch Step [20/323], D_loss: 0.5970,  G_loss: 1.7617\n",
      " Epoch [268/300], Batch Step [30/323], D_loss: 0.5946,  G_loss: 1.6313\n",
      " Epoch [268/300], Batch Step [40/323], D_loss: 0.5140,  G_loss: 1.6963\n",
      " Epoch [268/300], Batch Step [50/323], D_loss: 0.6335,  G_loss: 1.6442\n",
      " Epoch [268/300], Batch Step [60/323], D_loss: 0.4982,  G_loss: 1.9244\n",
      " Epoch [268/300], Batch Step [70/323], D_loss: 0.5651,  G_loss: 1.6108\n",
      " Epoch [268/300], Batch Step [80/323], D_loss: 0.8998,  G_loss: 1.4979\n",
      " Epoch [268/300], Batch Step [90/323], D_loss: 0.6264,  G_loss: 1.5844\n",
      " Epoch [268/300], Batch Step [100/323], D_loss: 0.7112,  G_loss: 1.6168\n",
      " Epoch [268/300], Batch Step [110/323], D_loss: 0.7158,  G_loss: 1.6576\n",
      " Epoch [268/300], Batch Step [120/323], D_loss: 0.5356,  G_loss: 1.5774\n",
      " Epoch [268/300], Batch Step [130/323], D_loss: 0.5507,  G_loss: 1.6144\n",
      " Epoch [268/300], Batch Step [140/323], D_loss: 0.5194,  G_loss: 1.6245\n",
      " Epoch [268/300], Batch Step [150/323], D_loss: 0.7506,  G_loss: 1.5937\n",
      " Epoch [268/300], Batch Step [160/323], D_loss: 0.5830,  G_loss: 1.6266\n",
      " Epoch [268/300], Batch Step [170/323], D_loss: 0.5803,  G_loss: 1.6539\n",
      " Epoch [268/300], Batch Step [180/323], D_loss: 0.7172,  G_loss: 1.5224\n",
      " Epoch [268/300], Batch Step [190/323], D_loss: 0.5062,  G_loss: 1.5550\n",
      " Epoch [268/300], Batch Step [200/323], D_loss: 0.6023,  G_loss: 1.6442\n",
      " Epoch [268/300], Batch Step [210/323], D_loss: 0.6530,  G_loss: 1.6580\n",
      " Epoch [268/300], Batch Step [220/323], D_loss: 0.6490,  G_loss: 1.6916\n",
      " Epoch [268/300], Batch Step [230/323], D_loss: 0.6291,  G_loss: 1.5888\n",
      " Epoch [268/300], Batch Step [240/323], D_loss: 0.5760,  G_loss: 1.5663\n",
      " Epoch [268/300], Batch Step [250/323], D_loss: 0.6863,  G_loss: 1.7065\n",
      " Epoch [268/300], Batch Step [260/323], D_loss: 0.7256,  G_loss: 1.6481\n",
      " Epoch [268/300], Batch Step [270/323], D_loss: 0.6681,  G_loss: 1.6121\n",
      " Epoch [268/300], Batch Step [280/323], D_loss: 0.6040,  G_loss: 1.7317\n",
      " Epoch [268/300], Batch Step [290/323], D_loss: 0.5220,  G_loss: 1.6684\n",
      " Epoch [268/300], Batch Step [300/323], D_loss: 0.5752,  G_loss: 1.4806\n",
      " Epoch [268/300], Batch Step [310/323], D_loss: 0.7371,  G_loss: 1.7674\n",
      " Epoch [268/300], Batch Step [320/323], D_loss: 0.7172,  G_loss: 1.6208\n",
      " Epoch [269/300], Batch Step [0/323], D_loss: 0.4952,  G_loss: 1.6328\n",
      " Epoch [269/300], Batch Step [10/323], D_loss: 0.6758,  G_loss: 1.5971\n",
      " Epoch [269/300], Batch Step [20/323], D_loss: 0.6888,  G_loss: 1.5409\n",
      " Epoch [269/300], Batch Step [30/323], D_loss: 0.5454,  G_loss: 1.5977\n",
      " Epoch [269/300], Batch Step [40/323], D_loss: 0.6260,  G_loss: 1.6893\n",
      " Epoch [269/300], Batch Step [50/323], D_loss: 0.5093,  G_loss: 1.5370\n",
      " Epoch [269/300], Batch Step [60/323], D_loss: 0.6765,  G_loss: 1.5904\n",
      " Epoch [269/300], Batch Step [70/323], D_loss: 0.6782,  G_loss: 1.5920\n",
      " Epoch [269/300], Batch Step [80/323], D_loss: 0.5866,  G_loss: 1.6664\n",
      " Epoch [269/300], Batch Step [90/323], D_loss: 0.5374,  G_loss: 1.5826\n",
      " Epoch [269/300], Batch Step [100/323], D_loss: 0.6707,  G_loss: 1.5889\n",
      " Epoch [269/300], Batch Step [110/323], D_loss: 0.4748,  G_loss: 1.5474\n",
      " Epoch [269/300], Batch Step [120/323], D_loss: 0.6180,  G_loss: 1.7636\n",
      " Epoch [269/300], Batch Step [130/323], D_loss: 0.7040,  G_loss: 1.6540\n",
      " Epoch [269/300], Batch Step [140/323], D_loss: 0.5893,  G_loss: 1.5053\n",
      " Epoch [269/300], Batch Step [150/323], D_loss: 0.5998,  G_loss: 1.5867\n",
      " Epoch [269/300], Batch Step [160/323], D_loss: 0.6059,  G_loss: 1.7484\n",
      " Epoch [269/300], Batch Step [170/323], D_loss: 0.6670,  G_loss: 1.6644\n",
      " Epoch [269/300], Batch Step [180/323], D_loss: 0.6617,  G_loss: 1.6877\n",
      " Epoch [269/300], Batch Step [190/323], D_loss: 0.6225,  G_loss: 1.5533\n",
      " Epoch [269/300], Batch Step [200/323], D_loss: 0.6682,  G_loss: 1.5985\n",
      " Epoch [269/300], Batch Step [210/323], D_loss: 0.5746,  G_loss: 1.5916\n",
      " Epoch [269/300], Batch Step [220/323], D_loss: 0.7248,  G_loss: 1.5737\n",
      " Epoch [269/300], Batch Step [230/323], D_loss: 0.5472,  G_loss: 1.7047\n",
      " Epoch [269/300], Batch Step [240/323], D_loss: 0.6471,  G_loss: 1.7923\n",
      " Epoch [269/300], Batch Step [250/323], D_loss: 0.5987,  G_loss: 1.4409\n",
      " Epoch [269/300], Batch Step [260/323], D_loss: 0.6311,  G_loss: 1.6736\n",
      " Epoch [269/300], Batch Step [270/323], D_loss: 0.7252,  G_loss: 1.6859\n",
      " Epoch [269/300], Batch Step [280/323], D_loss: 0.6604,  G_loss: 1.5297\n",
      " Epoch [269/300], Batch Step [290/323], D_loss: 0.7033,  G_loss: 1.6360\n",
      " Epoch [269/300], Batch Step [300/323], D_loss: 0.7325,  G_loss: 1.7692\n",
      " Epoch [269/300], Batch Step [310/323], D_loss: 0.5441,  G_loss: 1.4508\n",
      " Epoch [269/300], Batch Step [320/323], D_loss: 0.5770,  G_loss: 1.6750\n",
      " Epoch [270/300], Batch Step [0/323], D_loss: 0.7124,  G_loss: 1.7472\n",
      " Epoch [270/300], Batch Step [10/323], D_loss: 0.7638,  G_loss: 1.5263\n",
      " Epoch [270/300], Batch Step [20/323], D_loss: 0.5018,  G_loss: 1.6492\n",
      " Epoch [270/300], Batch Step [30/323], D_loss: 0.5453,  G_loss: 1.6747\n",
      " Epoch [270/300], Batch Step [40/323], D_loss: 0.6566,  G_loss: 1.4845\n",
      " Epoch [270/300], Batch Step [50/323], D_loss: 0.7538,  G_loss: 1.7549\n",
      " Epoch [270/300], Batch Step [60/323], D_loss: 0.4875,  G_loss: 1.6214\n",
      " Epoch [270/300], Batch Step [70/323], D_loss: 0.5627,  G_loss: 1.6394\n",
      " Epoch [270/300], Batch Step [80/323], D_loss: 0.5064,  G_loss: 1.5949\n",
      " Epoch [270/300], Batch Step [90/323], D_loss: 0.5637,  G_loss: 1.5744\n",
      " Epoch [270/300], Batch Step [100/323], D_loss: 0.5619,  G_loss: 1.6003\n",
      " Epoch [270/300], Batch Step [110/323], D_loss: 0.6102,  G_loss: 1.7274\n",
      " Epoch [270/300], Batch Step [120/323], D_loss: 0.8210,  G_loss: 1.5527\n",
      " Epoch [270/300], Batch Step [130/323], D_loss: 0.7412,  G_loss: 1.5365\n",
      " Epoch [270/300], Batch Step [140/323], D_loss: 0.5760,  G_loss: 1.5789\n",
      " Epoch [270/300], Batch Step [150/323], D_loss: 0.5676,  G_loss: 1.5435\n",
      " Epoch [270/300], Batch Step [160/323], D_loss: 0.6837,  G_loss: 1.6423\n",
      " Epoch [270/300], Batch Step [170/323], D_loss: 0.5776,  G_loss: 1.6537\n",
      " Epoch [270/300], Batch Step [180/323], D_loss: 0.7346,  G_loss: 1.6482\n",
      " Epoch [270/300], Batch Step [190/323], D_loss: 0.6007,  G_loss: 1.4780\n",
      " Epoch [270/300], Batch Step [200/323], D_loss: 0.8796,  G_loss: 1.8026\n",
      " Epoch [270/300], Batch Step [210/323], D_loss: 0.6024,  G_loss: 1.5210\n",
      " Epoch [270/300], Batch Step [220/323], D_loss: 0.6000,  G_loss: 1.4957\n",
      " Epoch [270/300], Batch Step [230/323], D_loss: 0.5516,  G_loss: 1.6462\n",
      " Epoch [270/300], Batch Step [240/323], D_loss: 0.6954,  G_loss: 1.5648\n",
      " Epoch [270/300], Batch Step [250/323], D_loss: 0.6770,  G_loss: 1.5936\n",
      " Epoch [270/300], Batch Step [260/323], D_loss: 0.6191,  G_loss: 1.5549\n",
      " Epoch [270/300], Batch Step [270/323], D_loss: 0.4448,  G_loss: 1.5716\n",
      " Epoch [270/300], Batch Step [280/323], D_loss: 0.5820,  G_loss: 1.7302\n",
      " Epoch [270/300], Batch Step [290/323], D_loss: 0.6184,  G_loss: 1.5390\n",
      " Epoch [270/300], Batch Step [300/323], D_loss: 0.5744,  G_loss: 1.6426\n",
      " Epoch [270/300], Batch Step [310/323], D_loss: 0.5882,  G_loss: 1.6755\n",
      " Epoch [270/300], Batch Step [320/323], D_loss: 0.6486,  G_loss: 1.6773\n",
      " Epoch [271/300], Batch Step [0/323], D_loss: 0.5518,  G_loss: 1.6854\n",
      " Epoch [271/300], Batch Step [10/323], D_loss: 0.7715,  G_loss: 1.5854\n",
      " Epoch [271/300], Batch Step [20/323], D_loss: 0.5780,  G_loss: 1.6623\n",
      " Epoch [271/300], Batch Step [30/323], D_loss: 0.7283,  G_loss: 1.7449\n",
      " Epoch [271/300], Batch Step [40/323], D_loss: 0.5026,  G_loss: 1.5590\n",
      " Epoch [271/300], Batch Step [50/323], D_loss: 0.7936,  G_loss: 1.4967\n",
      " Epoch [271/300], Batch Step [60/323], D_loss: 0.5901,  G_loss: 1.5616\n",
      " Epoch [271/300], Batch Step [70/323], D_loss: 0.6332,  G_loss: 1.7029\n",
      " Epoch [271/300], Batch Step [80/323], D_loss: 0.6762,  G_loss: 1.5652\n",
      " Epoch [271/300], Batch Step [90/323], D_loss: 0.4841,  G_loss: 1.6608\n",
      " Epoch [271/300], Batch Step [100/323], D_loss: 0.5385,  G_loss: 1.6855\n",
      " Epoch [271/300], Batch Step [110/323], D_loss: 0.5676,  G_loss: 1.6291\n",
      " Epoch [271/300], Batch Step [120/323], D_loss: 0.7507,  G_loss: 1.7963\n",
      " Epoch [271/300], Batch Step [130/323], D_loss: 0.5549,  G_loss: 1.5698\n",
      " Epoch [271/300], Batch Step [140/323], D_loss: 0.7526,  G_loss: 1.6215\n",
      " Epoch [271/300], Batch Step [150/323], D_loss: 0.5015,  G_loss: 1.5504\n",
      " Epoch [271/300], Batch Step [160/323], D_loss: 0.6722,  G_loss: 1.6792\n",
      " Epoch [271/300], Batch Step [170/323], D_loss: 0.5312,  G_loss: 1.5495\n",
      " Epoch [271/300], Batch Step [180/323], D_loss: 0.7169,  G_loss: 1.7171\n",
      " Epoch [271/300], Batch Step [190/323], D_loss: 0.5585,  G_loss: 1.4497\n",
      " Epoch [271/300], Batch Step [200/323], D_loss: 0.6627,  G_loss: 1.6706\n",
      " Epoch [271/300], Batch Step [210/323], D_loss: 0.6182,  G_loss: 1.5796\n",
      " Epoch [271/300], Batch Step [220/323], D_loss: 0.6133,  G_loss: 1.6947\n",
      " Epoch [271/300], Batch Step [230/323], D_loss: 0.6745,  G_loss: 1.3823\n",
      " Epoch [271/300], Batch Step [240/323], D_loss: 0.5987,  G_loss: 1.6175\n",
      " Epoch [271/300], Batch Step [250/323], D_loss: 0.7454,  G_loss: 1.7025\n",
      " Epoch [271/300], Batch Step [260/323], D_loss: 0.6547,  G_loss: 1.5412\n",
      " Epoch [271/300], Batch Step [270/323], D_loss: 0.6650,  G_loss: 1.6784\n",
      " Epoch [271/300], Batch Step [280/323], D_loss: 0.5275,  G_loss: 1.7082\n",
      " Epoch [271/300], Batch Step [290/323], D_loss: 0.6352,  G_loss: 1.6249\n",
      " Epoch [271/300], Batch Step [300/323], D_loss: 0.6177,  G_loss: 1.6604\n",
      " Epoch [271/300], Batch Step [310/323], D_loss: 0.6717,  G_loss: 1.6677\n",
      " Epoch [271/300], Batch Step [320/323], D_loss: 0.6256,  G_loss: 1.7124\n",
      " Epoch [272/300], Batch Step [0/323], D_loss: 0.6818,  G_loss: 1.7506\n",
      " Epoch [272/300], Batch Step [10/323], D_loss: 0.6367,  G_loss: 1.6026\n",
      " Epoch [272/300], Batch Step [20/323], D_loss: 0.6700,  G_loss: 1.7222\n",
      " Epoch [272/300], Batch Step [30/323], D_loss: 0.5796,  G_loss: 1.6333\n",
      " Epoch [272/300], Batch Step [40/323], D_loss: 0.6887,  G_loss: 1.5988\n",
      " Epoch [272/300], Batch Step [50/323], D_loss: 0.7113,  G_loss: 1.5427\n",
      " Epoch [272/300], Batch Step [60/323], D_loss: 0.6022,  G_loss: 1.5840\n",
      " Epoch [272/300], Batch Step [70/323], D_loss: 0.7356,  G_loss: 1.6832\n",
      " Epoch [272/300], Batch Step [80/323], D_loss: 0.6006,  G_loss: 1.5721\n",
      " Epoch [272/300], Batch Step [90/323], D_loss: 0.5128,  G_loss: 1.6387\n",
      " Epoch [272/300], Batch Step [100/323], D_loss: 0.7805,  G_loss: 1.4611\n",
      " Epoch [272/300], Batch Step [110/323], D_loss: 0.4846,  G_loss: 1.6470\n",
      " Epoch [272/300], Batch Step [120/323], D_loss: 0.6645,  G_loss: 1.7552\n",
      " Epoch [272/300], Batch Step [130/323], D_loss: 0.6066,  G_loss: 1.6108\n",
      " Epoch [272/300], Batch Step [140/323], D_loss: 0.5229,  G_loss: 1.6953\n",
      " Epoch [272/300], Batch Step [150/323], D_loss: 0.7428,  G_loss: 1.7106\n",
      " Epoch [272/300], Batch Step [160/323], D_loss: 0.7065,  G_loss: 1.6558\n",
      " Epoch [272/300], Batch Step [170/323], D_loss: 0.5158,  G_loss: 1.6843\n",
      " Epoch [272/300], Batch Step [180/323], D_loss: 0.7767,  G_loss: 1.7547\n",
      " Epoch [272/300], Batch Step [190/323], D_loss: 0.6521,  G_loss: 1.4356\n",
      " Epoch [272/300], Batch Step [200/323], D_loss: 0.6259,  G_loss: 1.7161\n",
      " Epoch [272/300], Batch Step [210/323], D_loss: 0.6300,  G_loss: 1.5788\n",
      " Epoch [272/300], Batch Step [220/323], D_loss: 0.6746,  G_loss: 1.5634\n",
      " Epoch [272/300], Batch Step [230/323], D_loss: 0.7337,  G_loss: 1.6816\n",
      " Epoch [272/300], Batch Step [240/323], D_loss: 0.4962,  G_loss: 1.6635\n",
      " Epoch [272/300], Batch Step [250/323], D_loss: 0.7534,  G_loss: 1.4696\n",
      " Epoch [272/300], Batch Step [260/323], D_loss: 0.5812,  G_loss: 1.4738\n",
      " Epoch [272/300], Batch Step [270/323], D_loss: 0.7511,  G_loss: 1.7323\n",
      " Epoch [272/300], Batch Step [280/323], D_loss: 0.6681,  G_loss: 1.5301\n",
      " Epoch [272/300], Batch Step [290/323], D_loss: 0.5719,  G_loss: 1.5897\n",
      " Epoch [272/300], Batch Step [300/323], D_loss: 0.6699,  G_loss: 1.6948\n",
      " Epoch [272/300], Batch Step [310/323], D_loss: 0.7169,  G_loss: 1.6199\n",
      " Epoch [272/300], Batch Step [320/323], D_loss: 0.7462,  G_loss: 1.5732\n",
      " Epoch [273/300], Batch Step [0/323], D_loss: 0.4877,  G_loss: 1.5913\n",
      " Epoch [273/300], Batch Step [10/323], D_loss: 0.6776,  G_loss: 1.6300\n",
      " Epoch [273/300], Batch Step [20/323], D_loss: 0.6646,  G_loss: 1.6010\n",
      " Epoch [273/300], Batch Step [30/323], D_loss: 0.6186,  G_loss: 1.6296\n",
      " Epoch [273/300], Batch Step [40/323], D_loss: 0.7259,  G_loss: 1.4798\n",
      " Epoch [273/300], Batch Step [50/323], D_loss: 0.5879,  G_loss: 1.4981\n",
      " Epoch [273/300], Batch Step [60/323], D_loss: 0.6097,  G_loss: 1.7090\n",
      " Epoch [273/300], Batch Step [70/323], D_loss: 0.6848,  G_loss: 1.4955\n",
      " Epoch [273/300], Batch Step [80/323], D_loss: 0.5247,  G_loss: 1.6749\n",
      " Epoch [273/300], Batch Step [90/323], D_loss: 0.8563,  G_loss: 1.6929\n",
      " Epoch [273/300], Batch Step [100/323], D_loss: 0.6601,  G_loss: 1.5257\n",
      " Epoch [273/300], Batch Step [110/323], D_loss: 0.5348,  G_loss: 1.7601\n",
      " Epoch [273/300], Batch Step [120/323], D_loss: 0.5665,  G_loss: 1.6835\n",
      " Epoch [273/300], Batch Step [130/323], D_loss: 0.6477,  G_loss: 1.5054\n",
      " Epoch [273/300], Batch Step [140/323], D_loss: 0.5906,  G_loss: 1.4517\n",
      " Epoch [273/300], Batch Step [150/323], D_loss: 0.6124,  G_loss: 1.6454\n",
      " Epoch [273/300], Batch Step [160/323], D_loss: 0.6168,  G_loss: 1.6325\n",
      " Epoch [273/300], Batch Step [170/323], D_loss: 0.7411,  G_loss: 1.4837\n",
      " Epoch [273/300], Batch Step [180/323], D_loss: 0.5856,  G_loss: 1.5560\n",
      " Epoch [273/300], Batch Step [190/323], D_loss: 0.7687,  G_loss: 1.7474\n",
      " Epoch [273/300], Batch Step [200/323], D_loss: 0.7170,  G_loss: 1.5367\n",
      " Epoch [273/300], Batch Step [210/323], D_loss: 0.7116,  G_loss: 1.6457\n",
      " Epoch [273/300], Batch Step [220/323], D_loss: 0.6946,  G_loss: 1.6323\n",
      " Epoch [273/300], Batch Step [230/323], D_loss: 0.4917,  G_loss: 1.6598\n",
      " Epoch [273/300], Batch Step [240/323], D_loss: 0.7361,  G_loss: 1.7099\n",
      " Epoch [273/300], Batch Step [250/323], D_loss: 0.6687,  G_loss: 1.3964\n",
      " Epoch [273/300], Batch Step [260/323], D_loss: 0.6633,  G_loss: 1.6706\n",
      " Epoch [273/300], Batch Step [270/323], D_loss: 0.4674,  G_loss: 1.6879\n",
      " Epoch [273/300], Batch Step [280/323], D_loss: 0.5765,  G_loss: 1.7019\n",
      " Epoch [273/300], Batch Step [290/323], D_loss: 0.7803,  G_loss: 1.5756\n",
      " Epoch [273/300], Batch Step [300/323], D_loss: 0.6657,  G_loss: 1.6433\n",
      " Epoch [273/300], Batch Step [310/323], D_loss: 0.7934,  G_loss: 1.6267\n",
      " Epoch [273/300], Batch Step [320/323], D_loss: 0.6065,  G_loss: 1.5960\n",
      " Epoch [274/300], Batch Step [0/323], D_loss: 0.4963,  G_loss: 1.6472\n",
      " Epoch [274/300], Batch Step [10/323], D_loss: 0.6647,  G_loss: 1.5319\n",
      " Epoch [274/300], Batch Step [20/323], D_loss: 0.6371,  G_loss: 1.6324\n",
      " Epoch [274/300], Batch Step [30/323], D_loss: 0.8029,  G_loss: 1.6301\n",
      " Epoch [274/300], Batch Step [40/323], D_loss: 0.5121,  G_loss: 1.5064\n",
      " Epoch [274/300], Batch Step [50/323], D_loss: 0.5222,  G_loss: 1.6698\n",
      " Epoch [274/300], Batch Step [60/323], D_loss: 0.6539,  G_loss: 1.5227\n",
      " Epoch [274/300], Batch Step [70/323], D_loss: 0.5220,  G_loss: 1.5287\n",
      " Epoch [274/300], Batch Step [80/323], D_loss: 0.8238,  G_loss: 1.6102\n",
      " Epoch [274/300], Batch Step [90/323], D_loss: 0.5543,  G_loss: 1.5469\n",
      " Epoch [274/300], Batch Step [100/323], D_loss: 0.6674,  G_loss: 1.7048\n",
      " Epoch [274/300], Batch Step [110/323], D_loss: 0.6201,  G_loss: 1.7724\n",
      " Epoch [274/300], Batch Step [120/323], D_loss: 0.6111,  G_loss: 1.5379\n",
      " Epoch [274/300], Batch Step [130/323], D_loss: 0.6443,  G_loss: 1.6908\n",
      " Epoch [274/300], Batch Step [140/323], D_loss: 0.6171,  G_loss: 1.8067\n",
      " Epoch [274/300], Batch Step [150/323], D_loss: 0.5958,  G_loss: 1.4826\n",
      " Epoch [274/300], Batch Step [160/323], D_loss: 0.6204,  G_loss: 1.5439\n",
      " Epoch [274/300], Batch Step [170/323], D_loss: 0.2908,  G_loss: 1.8863\n",
      " Epoch [274/300], Batch Step [180/323], D_loss: 0.5181,  G_loss: 1.5571\n",
      " Epoch [274/300], Batch Step [190/323], D_loss: 0.6288,  G_loss: 1.4852\n",
      " Epoch [274/300], Batch Step [200/323], D_loss: 0.6138,  G_loss: 1.6912\n",
      " Epoch [274/300], Batch Step [210/323], D_loss: 0.5893,  G_loss: 1.6326\n",
      " Epoch [274/300], Batch Step [220/323], D_loss: 0.6173,  G_loss: 1.4695\n",
      " Epoch [274/300], Batch Step [230/323], D_loss: 0.5880,  G_loss: 1.5471\n",
      " Epoch [274/300], Batch Step [240/323], D_loss: 0.7392,  G_loss: 1.8147\n",
      " Epoch [274/300], Batch Step [250/323], D_loss: 0.5305,  G_loss: 1.5340\n",
      " Epoch [274/300], Batch Step [260/323], D_loss: 0.5604,  G_loss: 1.6984\n",
      " Epoch [274/300], Batch Step [270/323], D_loss: 0.4517,  G_loss: 1.5653\n",
      " Epoch [274/300], Batch Step [280/323], D_loss: 0.6891,  G_loss: 1.7183\n",
      " Epoch [274/300], Batch Step [290/323], D_loss: 0.6520,  G_loss: 1.6507\n",
      " Epoch [274/300], Batch Step [300/323], D_loss: 0.6154,  G_loss: 1.6865\n",
      " Epoch [274/300], Batch Step [310/323], D_loss: 0.6223,  G_loss: 1.7283\n",
      " Epoch [274/300], Batch Step [320/323], D_loss: 0.4919,  G_loss: 1.6850\n",
      " Epoch [275/300], Batch Step [0/323], D_loss: 0.5580,  G_loss: 1.7205\n",
      " Epoch [275/300], Batch Step [10/323], D_loss: 0.5960,  G_loss: 1.7000\n",
      " Epoch [275/300], Batch Step [20/323], D_loss: 0.5153,  G_loss: 1.7743\n",
      " Epoch [275/300], Batch Step [30/323], D_loss: 0.7060,  G_loss: 1.6064\n",
      " Epoch [275/300], Batch Step [40/323], D_loss: 0.6321,  G_loss: 1.5760\n",
      " Epoch [275/300], Batch Step [50/323], D_loss: 0.6496,  G_loss: 1.5850\n",
      " Epoch [275/300], Batch Step [60/323], D_loss: 0.6477,  G_loss: 1.5555\n",
      " Epoch [275/300], Batch Step [70/323], D_loss: 0.6232,  G_loss: 1.5164\n",
      " Epoch [275/300], Batch Step [80/323], D_loss: 0.5726,  G_loss: 1.5732\n",
      " Epoch [275/300], Batch Step [90/323], D_loss: 0.7672,  G_loss: 1.5755\n",
      " Epoch [275/300], Batch Step [100/323], D_loss: 0.5272,  G_loss: 1.6463\n",
      " Epoch [275/300], Batch Step [110/323], D_loss: 0.6958,  G_loss: 1.6585\n",
      " Epoch [275/300], Batch Step [120/323], D_loss: 0.5725,  G_loss: 1.5917\n",
      " Epoch [275/300], Batch Step [130/323], D_loss: 0.6665,  G_loss: 1.6376\n",
      " Epoch [275/300], Batch Step [140/323], D_loss: 0.5929,  G_loss: 1.5896\n",
      " Epoch [275/300], Batch Step [150/323], D_loss: 0.6360,  G_loss: 1.6286\n",
      " Epoch [275/300], Batch Step [160/323], D_loss: 0.4931,  G_loss: 1.7362\n",
      " Epoch [275/300], Batch Step [170/323], D_loss: 0.6384,  G_loss: 1.5735\n",
      " Epoch [275/300], Batch Step [180/323], D_loss: 0.5890,  G_loss: 1.6112\n",
      " Epoch [275/300], Batch Step [190/323], D_loss: 0.5505,  G_loss: 1.7252\n",
      " Epoch [275/300], Batch Step [200/323], D_loss: 0.6148,  G_loss: 1.5463\n",
      " Epoch [275/300], Batch Step [210/323], D_loss: 0.6771,  G_loss: 1.5833\n",
      " Epoch [275/300], Batch Step [220/323], D_loss: 0.7498,  G_loss: 1.6504\n",
      " Epoch [275/300], Batch Step [230/323], D_loss: 0.4878,  G_loss: 1.7222\n",
      " Epoch [275/300], Batch Step [240/323], D_loss: 0.7598,  G_loss: 1.6744\n",
      " Epoch [275/300], Batch Step [250/323], D_loss: 0.6255,  G_loss: 1.5631\n",
      " Epoch [275/300], Batch Step [260/323], D_loss: 0.6085,  G_loss: 1.6999\n",
      " Epoch [275/300], Batch Step [270/323], D_loss: 0.4858,  G_loss: 1.7153\n",
      " Epoch [275/300], Batch Step [280/323], D_loss: 0.5546,  G_loss: 1.5760\n",
      " Epoch [275/300], Batch Step [290/323], D_loss: 0.6695,  G_loss: 1.6499\n",
      " Epoch [275/300], Batch Step [300/323], D_loss: 0.7737,  G_loss: 1.5832\n",
      " Epoch [275/300], Batch Step [310/323], D_loss: 0.5657,  G_loss: 1.6444\n",
      " Epoch [275/300], Batch Step [320/323], D_loss: 0.5345,  G_loss: 1.6492\n",
      " Epoch [276/300], Batch Step [0/323], D_loss: 0.6228,  G_loss: 1.6069\n",
      " Epoch [276/300], Batch Step [10/323], D_loss: 0.4915,  G_loss: 1.6504\n",
      " Epoch [276/300], Batch Step [20/323], D_loss: 0.5158,  G_loss: 1.5640\n",
      " Epoch [276/300], Batch Step [30/323], D_loss: 0.6004,  G_loss: 1.7062\n",
      " Epoch [276/300], Batch Step [40/323], D_loss: 0.6128,  G_loss: 1.5332\n",
      " Epoch [276/300], Batch Step [50/323], D_loss: 0.6486,  G_loss: 1.5360\n",
      " Epoch [276/300], Batch Step [60/323], D_loss: 0.5613,  G_loss: 1.6584\n",
      " Epoch [276/300], Batch Step [70/323], D_loss: 0.6599,  G_loss: 1.6415\n",
      " Epoch [276/300], Batch Step [80/323], D_loss: 0.7027,  G_loss: 1.6568\n",
      " Epoch [276/300], Batch Step [90/323], D_loss: 0.6487,  G_loss: 1.4671\n",
      " Epoch [276/300], Batch Step [100/323], D_loss: 0.5737,  G_loss: 1.6412\n",
      " Epoch [276/300], Batch Step [110/323], D_loss: 0.4701,  G_loss: 1.7135\n",
      " Epoch [276/300], Batch Step [120/323], D_loss: 0.7700,  G_loss: 1.6412\n",
      " Epoch [276/300], Batch Step [130/323], D_loss: 0.7059,  G_loss: 1.6477\n",
      " Epoch [276/300], Batch Step [140/323], D_loss: 0.6038,  G_loss: 1.7670\n",
      " Epoch [276/300], Batch Step [150/323], D_loss: 0.6521,  G_loss: 1.4694\n",
      " Epoch [276/300], Batch Step [160/323], D_loss: 0.5540,  G_loss: 1.6229\n",
      " Epoch [276/300], Batch Step [170/323], D_loss: 0.4953,  G_loss: 1.7079\n",
      " Epoch [276/300], Batch Step [180/323], D_loss: 0.6792,  G_loss: 1.6572\n",
      " Epoch [276/300], Batch Step [190/323], D_loss: 0.6274,  G_loss: 1.5128\n",
      " Epoch [276/300], Batch Step [200/323], D_loss: 0.5147,  G_loss: 1.6251\n",
      " Epoch [276/300], Batch Step [210/323], D_loss: 0.7198,  G_loss: 1.6931\n",
      " Epoch [276/300], Batch Step [220/323], D_loss: 0.5467,  G_loss: 1.6516\n",
      " Epoch [276/300], Batch Step [230/323], D_loss: 0.5211,  G_loss: 1.4392\n",
      " Epoch [276/300], Batch Step [240/323], D_loss: 0.5888,  G_loss: 1.7302\n",
      " Epoch [276/300], Batch Step [250/323], D_loss: 0.4870,  G_loss: 1.5774\n",
      " Epoch [276/300], Batch Step [260/323], D_loss: 0.7057,  G_loss: 1.6028\n",
      " Epoch [276/300], Batch Step [270/323], D_loss: 0.6986,  G_loss: 1.6276\n",
      " Epoch [276/300], Batch Step [280/323], D_loss: 0.5088,  G_loss: 1.6275\n",
      " Epoch [276/300], Batch Step [290/323], D_loss: 0.4249,  G_loss: 1.7900\n",
      " Epoch [276/300], Batch Step [300/323], D_loss: 0.7235,  G_loss: 1.5461\n",
      " Epoch [276/300], Batch Step [310/323], D_loss: 0.6337,  G_loss: 1.5096\n",
      " Epoch [276/300], Batch Step [320/323], D_loss: 0.5994,  G_loss: 1.7260\n",
      " Epoch [277/300], Batch Step [0/323], D_loss: 0.5079,  G_loss: 1.7826\n",
      " Epoch [277/300], Batch Step [10/323], D_loss: 0.5667,  G_loss: 1.5541\n",
      " Epoch [277/300], Batch Step [20/323], D_loss: 0.6528,  G_loss: 1.5534\n",
      " Epoch [277/300], Batch Step [30/323], D_loss: 0.6837,  G_loss: 1.6432\n",
      " Epoch [277/300], Batch Step [40/323], D_loss: 0.6406,  G_loss: 1.5855\n",
      " Epoch [277/300], Batch Step [50/323], D_loss: 0.6965,  G_loss: 1.6343\n",
      " Epoch [277/300], Batch Step [60/323], D_loss: 0.7934,  G_loss: 1.4932\n",
      " Epoch [277/300], Batch Step [70/323], D_loss: 0.6414,  G_loss: 1.7134\n",
      " Epoch [277/300], Batch Step [80/323], D_loss: 0.5357,  G_loss: 1.7779\n",
      " Epoch [277/300], Batch Step [90/323], D_loss: 0.7330,  G_loss: 1.6557\n",
      " Epoch [277/300], Batch Step [100/323], D_loss: 0.5954,  G_loss: 1.5595\n",
      " Epoch [277/300], Batch Step [110/323], D_loss: 0.6060,  G_loss: 1.6094\n",
      " Epoch [277/300], Batch Step [120/323], D_loss: 0.7042,  G_loss: 1.5816\n",
      " Epoch [277/300], Batch Step [130/323], D_loss: 0.6135,  G_loss: 1.5095\n",
      " Epoch [277/300], Batch Step [140/323], D_loss: 0.5230,  G_loss: 1.7272\n",
      " Epoch [277/300], Batch Step [150/323], D_loss: 0.7093,  G_loss: 1.5352\n",
      " Epoch [277/300], Batch Step [160/323], D_loss: 0.5970,  G_loss: 1.6392\n",
      " Epoch [277/300], Batch Step [170/323], D_loss: 0.6129,  G_loss: 1.5516\n",
      " Epoch [277/300], Batch Step [180/323], D_loss: 0.5672,  G_loss: 1.6298\n",
      " Epoch [277/300], Batch Step [190/323], D_loss: 0.6349,  G_loss: 1.4649\n",
      " Epoch [277/300], Batch Step [200/323], D_loss: 0.5519,  G_loss: 1.7131\n",
      " Epoch [277/300], Batch Step [210/323], D_loss: 0.4220,  G_loss: 1.6570\n",
      " Epoch [277/300], Batch Step [220/323], D_loss: 0.6903,  G_loss: 1.5992\n",
      " Epoch [277/300], Batch Step [230/323], D_loss: 0.5277,  G_loss: 1.6314\n",
      " Epoch [277/300], Batch Step [240/323], D_loss: 0.7146,  G_loss: 1.6016\n",
      " Epoch [277/300], Batch Step [250/323], D_loss: 0.6721,  G_loss: 1.6407\n",
      " Epoch [277/300], Batch Step [260/323], D_loss: 0.6552,  G_loss: 1.6905\n",
      " Epoch [277/300], Batch Step [270/323], D_loss: 0.5692,  G_loss: 1.4140\n",
      " Epoch [277/300], Batch Step [280/323], D_loss: 0.5987,  G_loss: 1.7354\n",
      " Epoch [277/300], Batch Step [290/323], D_loss: 0.6285,  G_loss: 1.6135\n",
      " Epoch [277/300], Batch Step [300/323], D_loss: 0.6633,  G_loss: 1.4350\n",
      " Epoch [277/300], Batch Step [310/323], D_loss: 0.5182,  G_loss: 1.7675\n",
      " Epoch [277/300], Batch Step [320/323], D_loss: 0.5428,  G_loss: 1.6506\n",
      " Epoch [278/300], Batch Step [0/323], D_loss: 0.5670,  G_loss: 1.6022\n",
      " Epoch [278/300], Batch Step [10/323], D_loss: 0.6514,  G_loss: 1.5143\n",
      " Epoch [278/300], Batch Step [20/323], D_loss: 0.6011,  G_loss: 1.6624\n",
      " Epoch [278/300], Batch Step [30/323], D_loss: 0.6799,  G_loss: 1.6155\n",
      " Epoch [278/300], Batch Step [40/323], D_loss: 0.6618,  G_loss: 1.4861\n",
      " Epoch [278/300], Batch Step [50/323], D_loss: 0.5217,  G_loss: 1.7289\n",
      " Epoch [278/300], Batch Step [60/323], D_loss: 0.5989,  G_loss: 1.7252\n",
      " Epoch [278/300], Batch Step [70/323], D_loss: 0.6293,  G_loss: 1.4743\n",
      " Epoch [278/300], Batch Step [80/323], D_loss: 0.7546,  G_loss: 1.8331\n",
      " Epoch [278/300], Batch Step [90/323], D_loss: 0.7311,  G_loss: 1.6575\n",
      " Epoch [278/300], Batch Step [100/323], D_loss: 0.7009,  G_loss: 1.4338\n",
      " Epoch [278/300], Batch Step [110/323], D_loss: 0.5956,  G_loss: 1.5894\n",
      " Epoch [278/300], Batch Step [120/323], D_loss: 0.6702,  G_loss: 1.5304\n",
      " Epoch [278/300], Batch Step [130/323], D_loss: 0.5434,  G_loss: 1.6890\n",
      " Epoch [278/300], Batch Step [140/323], D_loss: 0.5598,  G_loss: 1.5793\n",
      " Epoch [278/300], Batch Step [150/323], D_loss: 0.6380,  G_loss: 1.4552\n",
      " Epoch [278/300], Batch Step [160/323], D_loss: 0.6113,  G_loss: 1.5871\n",
      " Epoch [278/300], Batch Step [170/323], D_loss: 0.4847,  G_loss: 1.6262\n",
      " Epoch [278/300], Batch Step [180/323], D_loss: 0.5654,  G_loss: 1.7731\n",
      " Epoch [278/300], Batch Step [190/323], D_loss: 0.6096,  G_loss: 1.6141\n",
      " Epoch [278/300], Batch Step [200/323], D_loss: 0.6587,  G_loss: 1.7123\n",
      " Epoch [278/300], Batch Step [210/323], D_loss: 0.5259,  G_loss: 1.5777\n",
      " Epoch [278/300], Batch Step [220/323], D_loss: 0.6075,  G_loss: 1.5702\n",
      " Epoch [278/300], Batch Step [230/323], D_loss: 0.5206,  G_loss: 1.5916\n",
      " Epoch [278/300], Batch Step [240/323], D_loss: 0.5951,  G_loss: 1.5789\n",
      " Epoch [278/300], Batch Step [250/323], D_loss: 0.5949,  G_loss: 1.5545\n",
      " Epoch [278/300], Batch Step [260/323], D_loss: 0.6318,  G_loss: 1.5861\n",
      " Epoch [278/300], Batch Step [270/323], D_loss: 0.7828,  G_loss: 1.9418\n",
      " Epoch [278/300], Batch Step [280/323], D_loss: 0.4800,  G_loss: 1.6699\n",
      " Epoch [278/300], Batch Step [290/323], D_loss: 0.5260,  G_loss: 1.7070\n",
      " Epoch [278/300], Batch Step [300/323], D_loss: 0.6335,  G_loss: 1.6806\n",
      " Epoch [278/300], Batch Step [310/323], D_loss: 0.5711,  G_loss: 1.7682\n",
      " Epoch [278/300], Batch Step [320/323], D_loss: 0.6468,  G_loss: 1.7114\n",
      " Epoch [279/300], Batch Step [0/323], D_loss: 0.5737,  G_loss: 1.5399\n",
      " Epoch [279/300], Batch Step [10/323], D_loss: 0.7332,  G_loss: 1.4852\n",
      " Epoch [279/300], Batch Step [20/323], D_loss: 0.5357,  G_loss: 1.6714\n",
      " Epoch [279/300], Batch Step [30/323], D_loss: 0.6089,  G_loss: 1.7729\n",
      " Epoch [279/300], Batch Step [40/323], D_loss: 0.6872,  G_loss: 1.5813\n",
      " Epoch [279/300], Batch Step [50/323], D_loss: 0.6531,  G_loss: 1.6475\n",
      " Epoch [279/300], Batch Step [60/323], D_loss: 0.6643,  G_loss: 1.6158\n",
      " Epoch [279/300], Batch Step [70/323], D_loss: 0.7838,  G_loss: 1.7017\n",
      " Epoch [279/300], Batch Step [80/323], D_loss: 0.6236,  G_loss: 1.5453\n",
      " Epoch [279/300], Batch Step [90/323], D_loss: 0.5502,  G_loss: 1.6530\n",
      " Epoch [279/300], Batch Step [100/323], D_loss: 0.6029,  G_loss: 1.5985\n",
      " Epoch [279/300], Batch Step [110/323], D_loss: 0.8223,  G_loss: 1.6629\n",
      " Epoch [279/300], Batch Step [120/323], D_loss: 0.7821,  G_loss: 1.5720\n",
      " Epoch [279/300], Batch Step [130/323], D_loss: 0.5506,  G_loss: 1.5679\n",
      " Epoch [279/300], Batch Step [140/323], D_loss: 0.7125,  G_loss: 1.7159\n",
      " Epoch [279/300], Batch Step [150/323], D_loss: 0.7257,  G_loss: 1.6224\n",
      " Epoch [279/300], Batch Step [160/323], D_loss: 0.7166,  G_loss: 1.5450\n",
      " Epoch [279/300], Batch Step [170/323], D_loss: 0.5136,  G_loss: 1.6831\n",
      " Epoch [279/300], Batch Step [180/323], D_loss: 0.6267,  G_loss: 1.5890\n",
      " Epoch [279/300], Batch Step [190/323], D_loss: 0.6581,  G_loss: 1.5969\n",
      " Epoch [279/300], Batch Step [200/323], D_loss: 0.7356,  G_loss: 1.5621\n",
      " Epoch [279/300], Batch Step [210/323], D_loss: 0.6182,  G_loss: 1.7560\n",
      " Epoch [279/300], Batch Step [220/323], D_loss: 0.6599,  G_loss: 1.6473\n",
      " Epoch [279/300], Batch Step [230/323], D_loss: 0.7766,  G_loss: 1.5121\n",
      " Epoch [279/300], Batch Step [240/323], D_loss: 0.6016,  G_loss: 1.7029\n",
      " Epoch [279/300], Batch Step [250/323], D_loss: 0.5894,  G_loss: 1.5163\n",
      " Epoch [279/300], Batch Step [260/323], D_loss: 0.5855,  G_loss: 1.6093\n",
      " Epoch [279/300], Batch Step [270/323], D_loss: 0.6224,  G_loss: 1.5966\n",
      " Epoch [279/300], Batch Step [280/323], D_loss: 0.5606,  G_loss: 1.7721\n",
      " Epoch [279/300], Batch Step [290/323], D_loss: 0.6271,  G_loss: 1.6491\n",
      " Epoch [279/300], Batch Step [300/323], D_loss: 0.7440,  G_loss: 1.5876\n",
      " Epoch [279/300], Batch Step [310/323], D_loss: 0.5794,  G_loss: 1.6210\n",
      " Epoch [279/300], Batch Step [320/323], D_loss: 0.7741,  G_loss: 1.6407\n",
      " Epoch [280/300], Batch Step [0/323], D_loss: 0.4825,  G_loss: 1.6081\n",
      " Epoch [280/300], Batch Step [10/323], D_loss: 0.6853,  G_loss: 1.5991\n",
      " Epoch [280/300], Batch Step [20/323], D_loss: 0.5334,  G_loss: 1.6632\n",
      " Epoch [280/300], Batch Step [30/323], D_loss: 0.5381,  G_loss: 1.6011\n",
      " Epoch [280/300], Batch Step [40/323], D_loss: 0.4663,  G_loss: 1.6464\n",
      " Epoch [280/300], Batch Step [50/323], D_loss: 0.6538,  G_loss: 1.5633\n",
      " Epoch [280/300], Batch Step [60/323], D_loss: 0.6815,  G_loss: 1.6075\n",
      " Epoch [280/300], Batch Step [70/323], D_loss: 0.6929,  G_loss: 1.7778\n",
      " Epoch [280/300], Batch Step [80/323], D_loss: 0.7460,  G_loss: 1.4697\n",
      " Epoch [280/300], Batch Step [90/323], D_loss: 0.7068,  G_loss: 1.4662\n",
      " Epoch [280/300], Batch Step [100/323], D_loss: 0.6092,  G_loss: 1.6414\n",
      " Epoch [280/300], Batch Step [110/323], D_loss: 0.5770,  G_loss: 1.6906\n",
      " Epoch [280/300], Batch Step [120/323], D_loss: 0.6629,  G_loss: 1.5431\n",
      " Epoch [280/300], Batch Step [130/323], D_loss: 0.6034,  G_loss: 1.5556\n",
      " Epoch [280/300], Batch Step [140/323], D_loss: 0.5232,  G_loss: 1.8241\n",
      " Epoch [280/300], Batch Step [150/323], D_loss: 0.6429,  G_loss: 1.5473\n",
      " Epoch [280/300], Batch Step [160/323], D_loss: 0.6590,  G_loss: 1.5005\n",
      " Epoch [280/300], Batch Step [170/323], D_loss: 0.7032,  G_loss: 1.7671\n",
      " Epoch [280/300], Batch Step [180/323], D_loss: 0.5065,  G_loss: 1.5668\n",
      " Epoch [280/300], Batch Step [190/323], D_loss: 0.6194,  G_loss: 1.7651\n",
      " Epoch [280/300], Batch Step [200/323], D_loss: 0.5224,  G_loss: 1.6918\n",
      " Epoch [280/300], Batch Step [210/323], D_loss: 0.5748,  G_loss: 1.6552\n",
      " Epoch [280/300], Batch Step [220/323], D_loss: 0.6009,  G_loss: 1.6113\n",
      " Epoch [280/300], Batch Step [230/323], D_loss: 0.5419,  G_loss: 1.6725\n",
      " Epoch [280/300], Batch Step [240/323], D_loss: 0.5463,  G_loss: 1.6937\n",
      " Epoch [280/300], Batch Step [250/323], D_loss: 0.7706,  G_loss: 1.4342\n",
      " Epoch [280/300], Batch Step [260/323], D_loss: 0.6787,  G_loss: 1.6253\n",
      " Epoch [280/300], Batch Step [270/323], D_loss: 0.6854,  G_loss: 1.5856\n",
      " Epoch [280/300], Batch Step [280/323], D_loss: 0.6126,  G_loss: 1.4885\n",
      " Epoch [280/300], Batch Step [290/323], D_loss: 0.6229,  G_loss: 1.7138\n",
      " Epoch [280/300], Batch Step [300/323], D_loss: 0.6065,  G_loss: 1.5393\n",
      " Epoch [280/300], Batch Step [310/323], D_loss: 0.7933,  G_loss: 1.5528\n",
      " Epoch [280/300], Batch Step [320/323], D_loss: 0.5662,  G_loss: 1.7799\n",
      " Epoch [281/300], Batch Step [0/323], D_loss: 0.6819,  G_loss: 1.7796\n",
      " Epoch [281/300], Batch Step [10/323], D_loss: 0.5812,  G_loss: 1.4490\n",
      " Epoch [281/300], Batch Step [20/323], D_loss: 0.5493,  G_loss: 1.6606\n",
      " Epoch [281/300], Batch Step [30/323], D_loss: 0.5608,  G_loss: 1.6942\n",
      " Epoch [281/300], Batch Step [40/323], D_loss: 0.6108,  G_loss: 1.4974\n",
      " Epoch [281/300], Batch Step [50/323], D_loss: 0.5969,  G_loss: 1.6756\n",
      " Epoch [281/300], Batch Step [60/323], D_loss: 0.5972,  G_loss: 1.6238\n",
      " Epoch [281/300], Batch Step [70/323], D_loss: 0.6595,  G_loss: 1.7066\n",
      " Epoch [281/300], Batch Step [80/323], D_loss: 0.7371,  G_loss: 1.5875\n",
      " Epoch [281/300], Batch Step [90/323], D_loss: 0.5481,  G_loss: 1.7281\n",
      " Epoch [281/300], Batch Step [100/323], D_loss: 0.5622,  G_loss: 1.6834\n",
      " Epoch [281/300], Batch Step [110/323], D_loss: 0.5972,  G_loss: 1.5110\n",
      " Epoch [281/300], Batch Step [120/323], D_loss: 0.7919,  G_loss: 1.7071\n",
      " Epoch [281/300], Batch Step [130/323], D_loss: 0.6047,  G_loss: 1.6541\n",
      " Epoch [281/300], Batch Step [140/323], D_loss: 0.5603,  G_loss: 1.6159\n",
      " Epoch [281/300], Batch Step [150/323], D_loss: 0.6166,  G_loss: 1.5648\n",
      " Epoch [281/300], Batch Step [160/323], D_loss: 0.5530,  G_loss: 1.5031\n",
      " Epoch [281/300], Batch Step [170/323], D_loss: 0.6236,  G_loss: 1.5620\n",
      " Epoch [281/300], Batch Step [180/323], D_loss: 0.6088,  G_loss: 1.6367\n",
      " Epoch [281/300], Batch Step [190/323], D_loss: 0.6092,  G_loss: 1.5324\n",
      " Epoch [281/300], Batch Step [200/323], D_loss: 0.4511,  G_loss: 1.6776\n",
      " Epoch [281/300], Batch Step [210/323], D_loss: 0.4454,  G_loss: 1.7643\n",
      " Epoch [281/300], Batch Step [220/323], D_loss: 0.5518,  G_loss: 1.5772\n",
      " Epoch [281/300], Batch Step [230/323], D_loss: 0.5298,  G_loss: 1.6321\n",
      " Epoch [281/300], Batch Step [240/323], D_loss: 0.6255,  G_loss: 1.4847\n",
      " Epoch [281/300], Batch Step [250/323], D_loss: 0.4849,  G_loss: 1.6549\n",
      " Epoch [281/300], Batch Step [260/323], D_loss: 0.7414,  G_loss: 1.6061\n",
      " Epoch [281/300], Batch Step [270/323], D_loss: 0.5753,  G_loss: 1.6253\n",
      " Epoch [281/300], Batch Step [280/323], D_loss: 0.7749,  G_loss: 1.7960\n",
      " Epoch [281/300], Batch Step [290/323], D_loss: 0.6881,  G_loss: 1.5160\n",
      " Epoch [281/300], Batch Step [300/323], D_loss: 0.5670,  G_loss: 1.5693\n",
      " Epoch [281/300], Batch Step [310/323], D_loss: 0.6400,  G_loss: 1.7124\n",
      " Epoch [281/300], Batch Step [320/323], D_loss: 0.6926,  G_loss: 1.5168\n",
      " Epoch [282/300], Batch Step [0/323], D_loss: 0.8460,  G_loss: 1.4349\n",
      " Epoch [282/300], Batch Step [10/323], D_loss: 0.5483,  G_loss: 1.6586\n",
      " Epoch [282/300], Batch Step [20/323], D_loss: 0.5537,  G_loss: 1.6171\n",
      " Epoch [282/300], Batch Step [30/323], D_loss: 0.5949,  G_loss: 1.5218\n",
      " Epoch [282/300], Batch Step [40/323], D_loss: 0.6892,  G_loss: 1.7207\n",
      " Epoch [282/300], Batch Step [50/323], D_loss: 0.6051,  G_loss: 1.6513\n",
      " Epoch [282/300], Batch Step [60/323], D_loss: 1.0464,  G_loss: 1.5092\n",
      " Epoch [282/300], Batch Step [70/323], D_loss: 0.6705,  G_loss: 1.5590\n",
      " Epoch [282/300], Batch Step [80/323], D_loss: 0.5800,  G_loss: 1.6870\n",
      " Epoch [282/300], Batch Step [90/323], D_loss: 0.6623,  G_loss: 1.6770\n",
      " Epoch [282/300], Batch Step [100/323], D_loss: 0.7133,  G_loss: 1.5999\n",
      " Epoch [282/300], Batch Step [110/323], D_loss: 0.5116,  G_loss: 1.6063\n",
      " Epoch [282/300], Batch Step [120/323], D_loss: 0.6978,  G_loss: 1.5705\n",
      " Epoch [282/300], Batch Step [130/323], D_loss: 0.6436,  G_loss: 1.5503\n",
      " Epoch [282/300], Batch Step [140/323], D_loss: 0.7149,  G_loss: 1.7554\n",
      " Epoch [282/300], Batch Step [150/323], D_loss: 0.5171,  G_loss: 1.7084\n",
      " Epoch [282/300], Batch Step [160/323], D_loss: 0.5090,  G_loss: 1.6090\n",
      " Epoch [282/300], Batch Step [170/323], D_loss: 0.5971,  G_loss: 1.6846\n",
      " Epoch [282/300], Batch Step [180/323], D_loss: 0.6259,  G_loss: 1.5665\n",
      " Epoch [282/300], Batch Step [190/323], D_loss: 0.6395,  G_loss: 1.5903\n",
      " Epoch [282/300], Batch Step [200/323], D_loss: 0.5437,  G_loss: 1.5922\n",
      " Epoch [282/300], Batch Step [210/323], D_loss: 0.5470,  G_loss: 1.6669\n",
      " Epoch [282/300], Batch Step [220/323], D_loss: 0.6299,  G_loss: 1.5107\n",
      " Epoch [282/300], Batch Step [230/323], D_loss: 0.5608,  G_loss: 1.6183\n",
      " Epoch [282/300], Batch Step [240/323], D_loss: 0.6063,  G_loss: 1.6665\n",
      " Epoch [282/300], Batch Step [250/323], D_loss: 0.5133,  G_loss: 1.6669\n",
      " Epoch [282/300], Batch Step [260/323], D_loss: 0.6433,  G_loss: 1.7987\n",
      " Epoch [282/300], Batch Step [270/323], D_loss: 0.6117,  G_loss: 1.6673\n",
      " Epoch [282/300], Batch Step [280/323], D_loss: 0.7592,  G_loss: 1.4858\n",
      " Epoch [282/300], Batch Step [290/323], D_loss: 0.7952,  G_loss: 1.6532\n",
      " Epoch [282/300], Batch Step [300/323], D_loss: 0.5381,  G_loss: 1.6440\n",
      " Epoch [282/300], Batch Step [310/323], D_loss: 0.6352,  G_loss: 1.5831\n",
      " Epoch [282/300], Batch Step [320/323], D_loss: 0.6847,  G_loss: 1.6169\n",
      " Epoch [283/300], Batch Step [0/323], D_loss: 0.6159,  G_loss: 1.6512\n",
      " Epoch [283/300], Batch Step [10/323], D_loss: 0.6297,  G_loss: 1.6902\n",
      " Epoch [283/300], Batch Step [20/323], D_loss: 0.7717,  G_loss: 1.5505\n",
      " Epoch [283/300], Batch Step [30/323], D_loss: 0.6490,  G_loss: 1.5572\n",
      " Epoch [283/300], Batch Step [40/323], D_loss: 0.6974,  G_loss: 1.6682\n",
      " Epoch [283/300], Batch Step [50/323], D_loss: 0.6810,  G_loss: 1.5828\n",
      " Epoch [283/300], Batch Step [60/323], D_loss: 0.6064,  G_loss: 1.5186\n",
      " Epoch [283/300], Batch Step [70/323], D_loss: 0.6846,  G_loss: 1.7055\n",
      " Epoch [283/300], Batch Step [80/323], D_loss: 0.7327,  G_loss: 1.5532\n",
      " Epoch [283/300], Batch Step [90/323], D_loss: 0.6668,  G_loss: 1.5807\n",
      " Epoch [283/300], Batch Step [100/323], D_loss: 0.7144,  G_loss: 1.6773\n",
      " Epoch [283/300], Batch Step [110/323], D_loss: 0.7138,  G_loss: 1.6660\n",
      " Epoch [283/300], Batch Step [120/323], D_loss: 0.7576,  G_loss: 1.4639\n",
      " Epoch [283/300], Batch Step [130/323], D_loss: 0.6566,  G_loss: 1.7038\n",
      " Epoch [283/300], Batch Step [140/323], D_loss: 0.4377,  G_loss: 1.5931\n",
      " Epoch [283/300], Batch Step [150/323], D_loss: 0.7690,  G_loss: 1.7899\n",
      " Epoch [283/300], Batch Step [160/323], D_loss: 0.4963,  G_loss: 1.6141\n",
      " Epoch [283/300], Batch Step [170/323], D_loss: 0.6069,  G_loss: 1.6440\n",
      " Epoch [283/300], Batch Step [180/323], D_loss: 0.6658,  G_loss: 1.5310\n",
      " Epoch [283/300], Batch Step [190/323], D_loss: 0.5346,  G_loss: 1.7290\n",
      " Epoch [283/300], Batch Step [200/323], D_loss: 0.4859,  G_loss: 1.6554\n",
      " Epoch [283/300], Batch Step [210/323], D_loss: 0.6249,  G_loss: 1.6226\n",
      " Epoch [283/300], Batch Step [220/323], D_loss: 0.6672,  G_loss: 1.6287\n",
      " Epoch [283/300], Batch Step [230/323], D_loss: 0.5317,  G_loss: 1.6938\n",
      " Epoch [283/300], Batch Step [240/323], D_loss: 0.5467,  G_loss: 1.6221\n",
      " Epoch [283/300], Batch Step [250/323], D_loss: 0.5001,  G_loss: 1.6476\n",
      " Epoch [283/300], Batch Step [260/323], D_loss: 0.5978,  G_loss: 1.5332\n",
      " Epoch [283/300], Batch Step [270/323], D_loss: 0.6055,  G_loss: 1.6205\n",
      " Epoch [283/300], Batch Step [280/323], D_loss: 0.6131,  G_loss: 1.6403\n",
      " Epoch [283/300], Batch Step [290/323], D_loss: 0.5636,  G_loss: 1.5520\n",
      " Epoch [283/300], Batch Step [300/323], D_loss: 0.5534,  G_loss: 1.7084\n",
      " Epoch [283/300], Batch Step [310/323], D_loss: 0.7084,  G_loss: 1.6098\n",
      " Epoch [283/300], Batch Step [320/323], D_loss: 0.6712,  G_loss: 1.6512\n",
      " Epoch [284/300], Batch Step [0/323], D_loss: 0.5387,  G_loss: 1.6886\n",
      " Epoch [284/300], Batch Step [10/323], D_loss: 0.4705,  G_loss: 1.8699\n",
      " Epoch [284/300], Batch Step [20/323], D_loss: 0.6899,  G_loss: 1.5543\n",
      " Epoch [284/300], Batch Step [30/323], D_loss: 0.5122,  G_loss: 1.5228\n",
      " Epoch [284/300], Batch Step [40/323], D_loss: 0.5897,  G_loss: 1.7290\n",
      " Epoch [284/300], Batch Step [50/323], D_loss: 0.7009,  G_loss: 1.5115\n",
      " Epoch [284/300], Batch Step [60/323], D_loss: 0.6436,  G_loss: 1.5246\n",
      " Epoch [284/300], Batch Step [70/323], D_loss: 0.5443,  G_loss: 1.5609\n",
      " Epoch [284/300], Batch Step [80/323], D_loss: 0.6615,  G_loss: 1.6588\n",
      " Epoch [284/300], Batch Step [90/323], D_loss: 0.6951,  G_loss: 1.6363\n",
      " Epoch [284/300], Batch Step [100/323], D_loss: 0.6871,  G_loss: 1.5533\n",
      " Epoch [284/300], Batch Step [110/323], D_loss: 0.6202,  G_loss: 1.7541\n",
      " Epoch [284/300], Batch Step [120/323], D_loss: 0.5724,  G_loss: 1.6869\n",
      " Epoch [284/300], Batch Step [130/323], D_loss: 0.6017,  G_loss: 1.5888\n",
      " Epoch [284/300], Batch Step [140/323], D_loss: 0.5917,  G_loss: 1.6592\n",
      " Epoch [284/300], Batch Step [150/323], D_loss: 0.6311,  G_loss: 1.6232\n",
      " Epoch [284/300], Batch Step [160/323], D_loss: 0.5688,  G_loss: 1.6041\n",
      " Epoch [284/300], Batch Step [170/323], D_loss: 0.6138,  G_loss: 1.5223\n",
      " Epoch [284/300], Batch Step [180/323], D_loss: 0.6424,  G_loss: 1.6659\n",
      " Epoch [284/300], Batch Step [190/323], D_loss: 0.6817,  G_loss: 1.5715\n",
      " Epoch [284/300], Batch Step [200/323], D_loss: 0.6143,  G_loss: 1.5480\n",
      " Epoch [284/300], Batch Step [210/323], D_loss: 0.6636,  G_loss: 1.5020\n",
      " Epoch [284/300], Batch Step [220/323], D_loss: 0.5238,  G_loss: 1.7391\n",
      " Epoch [284/300], Batch Step [230/323], D_loss: 0.5825,  G_loss: 1.5476\n",
      " Epoch [284/300], Batch Step [240/323], D_loss: 0.6826,  G_loss: 1.6159\n",
      " Epoch [284/300], Batch Step [250/323], D_loss: 0.7044,  G_loss: 1.6519\n",
      " Epoch [284/300], Batch Step [260/323], D_loss: 0.5244,  G_loss: 1.6451\n",
      " Epoch [284/300], Batch Step [270/323], D_loss: 0.6121,  G_loss: 1.7766\n",
      " Epoch [284/300], Batch Step [280/323], D_loss: 0.6889,  G_loss: 1.6083\n",
      " Epoch [284/300], Batch Step [290/323], D_loss: 0.6046,  G_loss: 1.6823\n",
      " Epoch [284/300], Batch Step [300/323], D_loss: 0.6394,  G_loss: 1.6080\n",
      " Epoch [284/300], Batch Step [310/323], D_loss: 0.8945,  G_loss: 1.5085\n",
      " Epoch [284/300], Batch Step [320/323], D_loss: 0.7411,  G_loss: 1.6365\n",
      " Epoch [285/300], Batch Step [0/323], D_loss: 0.6012,  G_loss: 1.6173\n",
      " Epoch [285/300], Batch Step [10/323], D_loss: 0.6922,  G_loss: 1.6402\n",
      " Epoch [285/300], Batch Step [20/323], D_loss: 0.6142,  G_loss: 1.6221\n",
      " Epoch [285/300], Batch Step [30/323], D_loss: 0.4061,  G_loss: 1.7326\n",
      " Epoch [285/300], Batch Step [40/323], D_loss: 0.6158,  G_loss: 1.7600\n",
      " Epoch [285/300], Batch Step [50/323], D_loss: 0.7522,  G_loss: 1.5132\n",
      " Epoch [285/300], Batch Step [60/323], D_loss: 0.4581,  G_loss: 1.6846\n",
      " Epoch [285/300], Batch Step [70/323], D_loss: 0.4460,  G_loss: 1.5829\n",
      " Epoch [285/300], Batch Step [80/323], D_loss: 0.7338,  G_loss: 1.7103\n",
      " Epoch [285/300], Batch Step [90/323], D_loss: 0.5434,  G_loss: 1.7895\n",
      " Epoch [285/300], Batch Step [100/323], D_loss: 0.4942,  G_loss: 1.7470\n",
      " Epoch [285/300], Batch Step [110/323], D_loss: 0.6575,  G_loss: 1.7238\n",
      " Epoch [285/300], Batch Step [120/323], D_loss: 0.6428,  G_loss: 1.6772\n",
      " Epoch [285/300], Batch Step [130/323], D_loss: 0.5546,  G_loss: 1.6242\n",
      " Epoch [285/300], Batch Step [140/323], D_loss: 0.6496,  G_loss: 1.6363\n",
      " Epoch [285/300], Batch Step [150/323], D_loss: 0.7846,  G_loss: 1.5767\n",
      " Epoch [285/300], Batch Step [160/323], D_loss: 0.7109,  G_loss: 1.5304\n",
      " Epoch [285/300], Batch Step [170/323], D_loss: 0.6189,  G_loss: 1.6958\n",
      " Epoch [285/300], Batch Step [180/323], D_loss: 0.5509,  G_loss: 1.6151\n",
      " Epoch [285/300], Batch Step [190/323], D_loss: 0.6684,  G_loss: 1.5561\n",
      " Epoch [285/300], Batch Step [200/323], D_loss: 0.6010,  G_loss: 1.5336\n",
      " Epoch [285/300], Batch Step [210/323], D_loss: 0.6780,  G_loss: 1.4910\n",
      " Epoch [285/300], Batch Step [220/323], D_loss: 0.7099,  G_loss: 1.5527\n",
      " Epoch [285/300], Batch Step [230/323], D_loss: 0.6904,  G_loss: 1.6518\n",
      " Epoch [285/300], Batch Step [240/323], D_loss: 0.6675,  G_loss: 1.6559\n",
      " Epoch [285/300], Batch Step [250/323], D_loss: 0.8026,  G_loss: 1.6222\n",
      " Epoch [285/300], Batch Step [260/323], D_loss: 0.5257,  G_loss: 1.6472\n",
      " Epoch [285/300], Batch Step [270/323], D_loss: 0.7320,  G_loss: 1.6345\n",
      " Epoch [285/300], Batch Step [280/323], D_loss: 0.7398,  G_loss: 1.6510\n",
      " Epoch [285/300], Batch Step [290/323], D_loss: 0.6236,  G_loss: 1.6000\n",
      " Epoch [285/300], Batch Step [300/323], D_loss: 0.5991,  G_loss: 1.6239\n",
      " Epoch [285/300], Batch Step [310/323], D_loss: 0.6107,  G_loss: 1.5402\n",
      " Epoch [285/300], Batch Step [320/323], D_loss: 0.6927,  G_loss: 1.4812\n",
      " Epoch [286/300], Batch Step [0/323], D_loss: 0.8538,  G_loss: 1.4850\n",
      " Epoch [286/300], Batch Step [10/323], D_loss: 0.5860,  G_loss: 1.5029\n",
      " Epoch [286/300], Batch Step [20/323], D_loss: 0.7082,  G_loss: 1.5487\n",
      " Epoch [286/300], Batch Step [30/323], D_loss: 0.5515,  G_loss: 1.7420\n",
      " Epoch [286/300], Batch Step [40/323], D_loss: 0.7105,  G_loss: 1.6984\n",
      " Epoch [286/300], Batch Step [50/323], D_loss: 0.6588,  G_loss: 1.5307\n",
      " Epoch [286/300], Batch Step [60/323], D_loss: 0.5992,  G_loss: 1.5487\n",
      " Epoch [286/300], Batch Step [70/323], D_loss: 0.5630,  G_loss: 1.6816\n",
      " Epoch [286/300], Batch Step [80/323], D_loss: 0.7250,  G_loss: 1.5861\n",
      " Epoch [286/300], Batch Step [90/323], D_loss: 0.6158,  G_loss: 1.6527\n",
      " Epoch [286/300], Batch Step [100/323], D_loss: 0.5986,  G_loss: 1.4728\n",
      " Epoch [286/300], Batch Step [110/323], D_loss: 0.5665,  G_loss: 1.5984\n",
      " Epoch [286/300], Batch Step [120/323], D_loss: 0.6950,  G_loss: 1.6549\n",
      " Epoch [286/300], Batch Step [130/323], D_loss: 0.5618,  G_loss: 1.5354\n",
      " Epoch [286/300], Batch Step [140/323], D_loss: 0.7631,  G_loss: 1.5563\n",
      " Epoch [286/300], Batch Step [150/323], D_loss: 0.7157,  G_loss: 1.5873\n",
      " Epoch [286/300], Batch Step [160/323], D_loss: 0.5793,  G_loss: 1.6832\n",
      " Epoch [286/300], Batch Step [170/323], D_loss: 0.5518,  G_loss: 1.7332\n",
      " Epoch [286/300], Batch Step [180/323], D_loss: 0.7002,  G_loss: 1.6031\n",
      " Epoch [286/300], Batch Step [190/323], D_loss: 0.6168,  G_loss: 1.5487\n",
      " Epoch [286/300], Batch Step [200/323], D_loss: 0.6719,  G_loss: 1.6534\n",
      " Epoch [286/300], Batch Step [210/323], D_loss: 0.6099,  G_loss: 1.6622\n",
      " Epoch [286/300], Batch Step [220/323], D_loss: 0.6213,  G_loss: 1.5431\n",
      " Epoch [286/300], Batch Step [230/323], D_loss: 0.6009,  G_loss: 1.5361\n",
      " Epoch [286/300], Batch Step [240/323], D_loss: 0.4974,  G_loss: 1.7831\n",
      " Epoch [286/300], Batch Step [250/323], D_loss: 0.5997,  G_loss: 1.6926\n",
      " Epoch [286/300], Batch Step [260/323], D_loss: 0.5581,  G_loss: 1.6057\n",
      " Epoch [286/300], Batch Step [270/323], D_loss: 0.4592,  G_loss: 1.4975\n",
      " Epoch [286/300], Batch Step [280/323], D_loss: 0.7331,  G_loss: 1.7564\n",
      " Epoch [286/300], Batch Step [290/323], D_loss: 0.7730,  G_loss: 1.5594\n",
      " Epoch [286/300], Batch Step [300/323], D_loss: 0.5340,  G_loss: 1.7329\n",
      " Epoch [286/300], Batch Step [310/323], D_loss: 0.6447,  G_loss: 1.6142\n",
      " Epoch [286/300], Batch Step [320/323], D_loss: 0.6640,  G_loss: 1.6868\n",
      " Epoch [287/300], Batch Step [0/323], D_loss: 0.5366,  G_loss: 1.6509\n",
      " Epoch [287/300], Batch Step [10/323], D_loss: 0.6014,  G_loss: 1.5922\n",
      " Epoch [287/300], Batch Step [20/323], D_loss: 0.5188,  G_loss: 1.6814\n",
      " Epoch [287/300], Batch Step [30/323], D_loss: 0.6920,  G_loss: 1.6133\n",
      " Epoch [287/300], Batch Step [40/323], D_loss: 0.5816,  G_loss: 1.5615\n",
      " Epoch [287/300], Batch Step [50/323], D_loss: 0.5318,  G_loss: 1.6520\n",
      " Epoch [287/300], Batch Step [60/323], D_loss: 0.6846,  G_loss: 1.5081\n",
      " Epoch [287/300], Batch Step [70/323], D_loss: 0.5703,  G_loss: 1.5827\n",
      " Epoch [287/300], Batch Step [80/323], D_loss: 0.5664,  G_loss: 1.6467\n",
      " Epoch [287/300], Batch Step [90/323], D_loss: 0.6107,  G_loss: 1.5635\n",
      " Epoch [287/300], Batch Step [100/323], D_loss: 0.7697,  G_loss: 1.5801\n",
      " Epoch [287/300], Batch Step [110/323], D_loss: 0.6498,  G_loss: 1.5245\n",
      " Epoch [287/300], Batch Step [120/323], D_loss: 0.6795,  G_loss: 1.6963\n",
      " Epoch [287/300], Batch Step [130/323], D_loss: 0.5519,  G_loss: 1.6738\n",
      " Epoch [287/300], Batch Step [140/323], D_loss: 0.7129,  G_loss: 1.6805\n",
      " Epoch [287/300], Batch Step [150/323], D_loss: 0.6404,  G_loss: 1.5649\n",
      " Epoch [287/300], Batch Step [160/323], D_loss: 0.5467,  G_loss: 1.7221\n",
      " Epoch [287/300], Batch Step [170/323], D_loss: 0.5575,  G_loss: 1.7571\n",
      " Epoch [287/300], Batch Step [180/323], D_loss: 0.5928,  G_loss: 1.5280\n",
      " Epoch [287/300], Batch Step [190/323], D_loss: 0.7596,  G_loss: 1.7058\n",
      " Epoch [287/300], Batch Step [200/323], D_loss: 0.6473,  G_loss: 1.5800\n",
      " Epoch [287/300], Batch Step [210/323], D_loss: 0.5674,  G_loss: 1.5816\n",
      " Epoch [287/300], Batch Step [220/323], D_loss: 0.6755,  G_loss: 1.6067\n",
      " Epoch [287/300], Batch Step [230/323], D_loss: 0.7792,  G_loss: 1.6669\n",
      " Epoch [287/300], Batch Step [240/323], D_loss: 0.4300,  G_loss: 1.5823\n",
      " Epoch [287/300], Batch Step [250/323], D_loss: 0.8460,  G_loss: 1.6488\n",
      " Epoch [287/300], Batch Step [260/323], D_loss: 0.6250,  G_loss: 1.6043\n",
      " Epoch [287/300], Batch Step [270/323], D_loss: 0.7213,  G_loss: 1.5736\n",
      " Epoch [287/300], Batch Step [280/323], D_loss: 0.5174,  G_loss: 1.6300\n",
      " Epoch [287/300], Batch Step [290/323], D_loss: 0.6448,  G_loss: 1.6565\n",
      " Epoch [287/300], Batch Step [300/323], D_loss: 0.6961,  G_loss: 1.5661\n",
      " Epoch [287/300], Batch Step [310/323], D_loss: 0.7779,  G_loss: 1.4936\n",
      " Epoch [287/300], Batch Step [320/323], D_loss: 0.5410,  G_loss: 1.6265\n",
      " Epoch [288/300], Batch Step [0/323], D_loss: 0.6406,  G_loss: 1.6703\n",
      " Epoch [288/300], Batch Step [10/323], D_loss: 0.6197,  G_loss: 1.7622\n",
      " Epoch [288/300], Batch Step [20/323], D_loss: 0.5166,  G_loss: 1.5451\n",
      " Epoch [288/300], Batch Step [30/323], D_loss: 0.5892,  G_loss: 1.6971\n",
      " Epoch [288/300], Batch Step [40/323], D_loss: 0.5246,  G_loss: 1.6120\n",
      " Epoch [288/300], Batch Step [50/323], D_loss: 0.6442,  G_loss: 1.5873\n",
      " Epoch [288/300], Batch Step [60/323], D_loss: 0.5892,  G_loss: 1.5814\n",
      " Epoch [288/300], Batch Step [70/323], D_loss: 0.7708,  G_loss: 1.7118\n",
      " Epoch [288/300], Batch Step [80/323], D_loss: 0.5616,  G_loss: 1.5976\n",
      " Epoch [288/300], Batch Step [90/323], D_loss: 0.6753,  G_loss: 1.5018\n",
      " Epoch [288/300], Batch Step [100/323], D_loss: 0.5753,  G_loss: 1.6362\n",
      " Epoch [288/300], Batch Step [110/323], D_loss: 0.8400,  G_loss: 1.6984\n",
      " Epoch [288/300], Batch Step [120/323], D_loss: 0.6984,  G_loss: 1.5244\n",
      " Epoch [288/300], Batch Step [130/323], D_loss: 0.6751,  G_loss: 1.7186\n",
      " Epoch [288/300], Batch Step [140/323], D_loss: 0.5794,  G_loss: 1.6034\n",
      " Epoch [288/300], Batch Step [150/323], D_loss: 0.7683,  G_loss: 1.5319\n",
      " Epoch [288/300], Batch Step [160/323], D_loss: 0.7370,  G_loss: 1.6829\n",
      " Epoch [288/300], Batch Step [170/323], D_loss: 0.5404,  G_loss: 1.5847\n",
      " Epoch [288/300], Batch Step [180/323], D_loss: 0.5699,  G_loss: 1.7007\n",
      " Epoch [288/300], Batch Step [190/323], D_loss: 0.6084,  G_loss: 1.7637\n",
      " Epoch [288/300], Batch Step [200/323], D_loss: 0.6494,  G_loss: 1.6302\n",
      " Epoch [288/300], Batch Step [210/323], D_loss: 0.6119,  G_loss: 1.5987\n",
      " Epoch [288/300], Batch Step [220/323], D_loss: 0.6178,  G_loss: 1.7642\n",
      " Epoch [288/300], Batch Step [230/323], D_loss: 0.4474,  G_loss: 1.6394\n",
      " Epoch [288/300], Batch Step [240/323], D_loss: 0.6756,  G_loss: 1.5280\n",
      " Epoch [288/300], Batch Step [250/323], D_loss: 0.5567,  G_loss: 1.6312\n",
      " Epoch [288/300], Batch Step [260/323], D_loss: 0.6898,  G_loss: 1.7351\n",
      " Epoch [288/300], Batch Step [270/323], D_loss: 0.6255,  G_loss: 1.5532\n",
      " Epoch [288/300], Batch Step [280/323], D_loss: 0.6729,  G_loss: 1.5585\n",
      " Epoch [288/300], Batch Step [290/323], D_loss: 0.5523,  G_loss: 1.6926\n",
      " Epoch [288/300], Batch Step [300/323], D_loss: 0.6122,  G_loss: 1.5138\n",
      " Epoch [288/300], Batch Step [310/323], D_loss: 0.6874,  G_loss: 1.6734\n",
      " Epoch [288/300], Batch Step [320/323], D_loss: 0.7719,  G_loss: 1.4709\n",
      " Epoch [289/300], Batch Step [0/323], D_loss: 0.6841,  G_loss: 1.4891\n",
      " Epoch [289/300], Batch Step [10/323], D_loss: 0.6501,  G_loss: 1.6642\n",
      " Epoch [289/300], Batch Step [20/323], D_loss: 0.6349,  G_loss: 1.5454\n",
      " Epoch [289/300], Batch Step [30/323], D_loss: 0.7378,  G_loss: 1.6755\n",
      " Epoch [289/300], Batch Step [40/323], D_loss: 0.5498,  G_loss: 1.5743\n",
      " Epoch [289/300], Batch Step [50/323], D_loss: 0.5876,  G_loss: 1.7938\n",
      " Epoch [289/300], Batch Step [60/323], D_loss: 0.7628,  G_loss: 1.6689\n",
      " Epoch [289/300], Batch Step [70/323], D_loss: 0.6394,  G_loss: 1.5218\n",
      " Epoch [289/300], Batch Step [80/323], D_loss: 0.7529,  G_loss: 1.7727\n",
      " Epoch [289/300], Batch Step [90/323], D_loss: 0.6117,  G_loss: 1.5537\n",
      " Epoch [289/300], Batch Step [100/323], D_loss: 0.5850,  G_loss: 1.6300\n",
      " Epoch [289/300], Batch Step [110/323], D_loss: 0.6342,  G_loss: 1.5958\n",
      " Epoch [289/300], Batch Step [120/323], D_loss: 0.6819,  G_loss: 1.5310\n",
      " Epoch [289/300], Batch Step [130/323], D_loss: 0.5666,  G_loss: 1.7160\n",
      " Epoch [289/300], Batch Step [140/323], D_loss: 0.7137,  G_loss: 1.6046\n",
      " Epoch [289/300], Batch Step [150/323], D_loss: 0.6793,  G_loss: 1.5636\n",
      " Epoch [289/300], Batch Step [160/323], D_loss: 0.6683,  G_loss: 1.5507\n",
      " Epoch [289/300], Batch Step [170/323], D_loss: 0.5506,  G_loss: 1.5807\n",
      " Epoch [289/300], Batch Step [180/323], D_loss: 0.6900,  G_loss: 1.5561\n",
      " Epoch [289/300], Batch Step [190/323], D_loss: 0.6764,  G_loss: 1.6500\n",
      " Epoch [289/300], Batch Step [200/323], D_loss: 0.7520,  G_loss: 1.7136\n",
      " Epoch [289/300], Batch Step [210/323], D_loss: 0.5839,  G_loss: 1.4690\n",
      " Epoch [289/300], Batch Step [220/323], D_loss: 0.5151,  G_loss: 1.6799\n",
      " Epoch [289/300], Batch Step [230/323], D_loss: 0.5871,  G_loss: 1.7588\n",
      " Epoch [289/300], Batch Step [240/323], D_loss: 0.4842,  G_loss: 1.5448\n",
      " Epoch [289/300], Batch Step [250/323], D_loss: 0.6136,  G_loss: 1.6399\n",
      " Epoch [289/300], Batch Step [260/323], D_loss: 0.5375,  G_loss: 1.8165\n",
      " Epoch [289/300], Batch Step [270/323], D_loss: 0.7687,  G_loss: 1.6559\n",
      " Epoch [289/300], Batch Step [280/323], D_loss: 0.6518,  G_loss: 1.5253\n",
      " Epoch [289/300], Batch Step [290/323], D_loss: 0.6929,  G_loss: 1.6566\n",
      " Epoch [289/300], Batch Step [300/323], D_loss: 0.4569,  G_loss: 1.5323\n",
      " Epoch [289/300], Batch Step [310/323], D_loss: 0.6417,  G_loss: 1.5705\n",
      " Epoch [289/300], Batch Step [320/323], D_loss: 0.6623,  G_loss: 1.6996\n",
      " Epoch [290/300], Batch Step [0/323], D_loss: 0.5871,  G_loss: 1.6473\n",
      " Epoch [290/300], Batch Step [10/323], D_loss: 0.5656,  G_loss: 1.5189\n",
      " Epoch [290/300], Batch Step [20/323], D_loss: 0.6365,  G_loss: 1.6008\n",
      " Epoch [290/300], Batch Step [30/323], D_loss: 0.7504,  G_loss: 1.6409\n",
      " Epoch [290/300], Batch Step [40/323], D_loss: 0.8189,  G_loss: 1.6195\n",
      " Epoch [290/300], Batch Step [50/323], D_loss: 0.6692,  G_loss: 1.7455\n",
      " Epoch [290/300], Batch Step [60/323], D_loss: 0.6734,  G_loss: 1.5067\n",
      " Epoch [290/300], Batch Step [70/323], D_loss: 0.5961,  G_loss: 1.5204\n",
      " Epoch [290/300], Batch Step [80/323], D_loss: 0.5080,  G_loss: 1.7477\n",
      " Epoch [290/300], Batch Step [90/323], D_loss: 0.5263,  G_loss: 1.6245\n",
      " Epoch [290/300], Batch Step [100/323], D_loss: 0.5060,  G_loss: 1.6005\n",
      " Epoch [290/300], Batch Step [110/323], D_loss: 0.7289,  G_loss: 1.6778\n",
      " Epoch [290/300], Batch Step [120/323], D_loss: 0.7153,  G_loss: 1.5943\n",
      " Epoch [290/300], Batch Step [130/323], D_loss: 0.5031,  G_loss: 1.6074\n",
      " Epoch [290/300], Batch Step [140/323], D_loss: 0.7116,  G_loss: 1.7448\n",
      " Epoch [290/300], Batch Step [150/323], D_loss: 0.5947,  G_loss: 1.5739\n",
      " Epoch [290/300], Batch Step [160/323], D_loss: 0.7146,  G_loss: 1.6571\n",
      " Epoch [290/300], Batch Step [170/323], D_loss: 0.6460,  G_loss: 1.6337\n",
      " Epoch [290/300], Batch Step [180/323], D_loss: 0.6152,  G_loss: 1.4172\n",
      " Epoch [290/300], Batch Step [190/323], D_loss: 0.5422,  G_loss: 1.6134\n",
      " Epoch [290/300], Batch Step [200/323], D_loss: 0.6607,  G_loss: 1.7553\n",
      " Epoch [290/300], Batch Step [210/323], D_loss: 0.4863,  G_loss: 1.4774\n",
      " Epoch [290/300], Batch Step [220/323], D_loss: 0.7113,  G_loss: 1.5273\n",
      " Epoch [290/300], Batch Step [230/323], D_loss: 0.4800,  G_loss: 1.5573\n",
      " Epoch [290/300], Batch Step [240/323], D_loss: 0.6470,  G_loss: 1.5488\n",
      " Epoch [290/300], Batch Step [250/323], D_loss: 0.7589,  G_loss: 1.6148\n",
      " Epoch [290/300], Batch Step [260/323], D_loss: 0.6898,  G_loss: 1.7139\n",
      " Epoch [290/300], Batch Step [270/323], D_loss: 0.7505,  G_loss: 1.4993\n",
      " Epoch [290/300], Batch Step [280/323], D_loss: 0.7601,  G_loss: 1.6838\n",
      " Epoch [290/300], Batch Step [290/323], D_loss: 0.6975,  G_loss: 1.5849\n",
      " Epoch [290/300], Batch Step [300/323], D_loss: 0.6446,  G_loss: 1.4515\n",
      " Epoch [290/300], Batch Step [310/323], D_loss: 0.6505,  G_loss: 1.7709\n",
      " Epoch [290/300], Batch Step [320/323], D_loss: 0.4683,  G_loss: 1.8233\n",
      " Epoch [291/300], Batch Step [0/323], D_loss: 0.6776,  G_loss: 1.8080\n",
      " Epoch [291/300], Batch Step [10/323], D_loss: 0.5502,  G_loss: 1.6039\n",
      " Epoch [291/300], Batch Step [20/323], D_loss: 0.5257,  G_loss: 1.7008\n",
      " Epoch [291/300], Batch Step [30/323], D_loss: 0.5601,  G_loss: 1.6736\n",
      " Epoch [291/300], Batch Step [40/323], D_loss: 0.6000,  G_loss: 1.6855\n",
      " Epoch [291/300], Batch Step [50/323], D_loss: 0.4134,  G_loss: 1.6660\n",
      " Epoch [291/300], Batch Step [60/323], D_loss: 0.7913,  G_loss: 1.5391\n",
      " Epoch [291/300], Batch Step [70/323], D_loss: 0.8118,  G_loss: 1.4799\n",
      " Epoch [291/300], Batch Step [80/323], D_loss: 0.5597,  G_loss: 1.6707\n",
      " Epoch [291/300], Batch Step [90/323], D_loss: 0.4231,  G_loss: 1.5974\n",
      " Epoch [291/300], Batch Step [100/323], D_loss: 0.7731,  G_loss: 1.5206\n",
      " Epoch [291/300], Batch Step [110/323], D_loss: 0.6570,  G_loss: 1.5407\n",
      " Epoch [291/300], Batch Step [120/323], D_loss: 0.5645,  G_loss: 1.7047\n",
      " Epoch [291/300], Batch Step [130/323], D_loss: 0.7142,  G_loss: 1.7351\n",
      " Epoch [291/300], Batch Step [140/323], D_loss: 0.5091,  G_loss: 1.5609\n",
      " Epoch [291/300], Batch Step [150/323], D_loss: 0.8149,  G_loss: 1.5538\n",
      " Epoch [291/300], Batch Step [160/323], D_loss: 0.5974,  G_loss: 1.5020\n",
      " Epoch [291/300], Batch Step [170/323], D_loss: 0.6967,  G_loss: 1.6503\n",
      " Epoch [291/300], Batch Step [180/323], D_loss: 0.5627,  G_loss: 1.6293\n",
      " Epoch [291/300], Batch Step [190/323], D_loss: 0.4514,  G_loss: 1.5315\n",
      " Epoch [291/300], Batch Step [200/323], D_loss: 0.6202,  G_loss: 1.6729\n",
      " Epoch [291/300], Batch Step [210/323], D_loss: 0.6624,  G_loss: 1.6444\n",
      " Epoch [291/300], Batch Step [220/323], D_loss: 0.6407,  G_loss: 1.6390\n",
      " Epoch [291/300], Batch Step [230/323], D_loss: 0.5175,  G_loss: 1.6126\n",
      " Epoch [291/300], Batch Step [240/323], D_loss: 0.7192,  G_loss: 1.6717\n",
      " Epoch [291/300], Batch Step [250/323], D_loss: 0.6362,  G_loss: 1.5645\n",
      " Epoch [291/300], Batch Step [260/323], D_loss: 0.8069,  G_loss: 1.5302\n",
      " Epoch [291/300], Batch Step [270/323], D_loss: 0.5849,  G_loss: 1.7168\n",
      " Epoch [291/300], Batch Step [280/323], D_loss: 0.6293,  G_loss: 1.6359\n",
      " Epoch [291/300], Batch Step [290/323], D_loss: 0.5737,  G_loss: 1.5938\n",
      " Epoch [291/300], Batch Step [300/323], D_loss: 0.7453,  G_loss: 1.5686\n",
      " Epoch [291/300], Batch Step [310/323], D_loss: 0.6045,  G_loss: 1.5649\n",
      " Epoch [291/300], Batch Step [320/323], D_loss: 0.8562,  G_loss: 1.6511\n",
      " Epoch [292/300], Batch Step [0/323], D_loss: 0.5965,  G_loss: 1.5857\n",
      " Epoch [292/300], Batch Step [10/323], D_loss: 0.6260,  G_loss: 1.7661\n",
      " Epoch [292/300], Batch Step [20/323], D_loss: 0.6901,  G_loss: 1.5297\n",
      " Epoch [292/300], Batch Step [30/323], D_loss: 0.5955,  G_loss: 1.6261\n",
      " Epoch [292/300], Batch Step [40/323], D_loss: 0.7162,  G_loss: 1.6995\n",
      " Epoch [292/300], Batch Step [50/323], D_loss: 0.5119,  G_loss: 1.5070\n",
      " Epoch [292/300], Batch Step [60/323], D_loss: 0.5820,  G_loss: 1.7094\n",
      " Epoch [292/300], Batch Step [70/323], D_loss: 0.5895,  G_loss: 1.6390\n",
      " Epoch [292/300], Batch Step [80/323], D_loss: 0.6835,  G_loss: 1.5337\n",
      " Epoch [292/300], Batch Step [90/323], D_loss: 0.5386,  G_loss: 1.6485\n",
      " Epoch [292/300], Batch Step [100/323], D_loss: 0.6767,  G_loss: 1.7577\n",
      " Epoch [292/300], Batch Step [110/323], D_loss: 0.7586,  G_loss: 1.5559\n",
      " Epoch [292/300], Batch Step [120/323], D_loss: 0.6094,  G_loss: 1.6111\n",
      " Epoch [292/300], Batch Step [130/323], D_loss: 0.6971,  G_loss: 1.7488\n",
      " Epoch [292/300], Batch Step [140/323], D_loss: 0.5952,  G_loss: 1.6657\n",
      " Epoch [292/300], Batch Step [150/323], D_loss: 0.7159,  G_loss: 1.7735\n",
      " Epoch [292/300], Batch Step [160/323], D_loss: 0.6138,  G_loss: 1.5262\n",
      " Epoch [292/300], Batch Step [170/323], D_loss: 0.5379,  G_loss: 1.5651\n",
      " Epoch [292/300], Batch Step [180/323], D_loss: 0.5399,  G_loss: 1.6956\n",
      " Epoch [292/300], Batch Step [190/323], D_loss: 0.5085,  G_loss: 1.8054\n",
      " Epoch [292/300], Batch Step [200/323], D_loss: 0.5582,  G_loss: 1.6359\n",
      " Epoch [292/300], Batch Step [210/323], D_loss: 0.4891,  G_loss: 1.7683\n",
      " Epoch [292/300], Batch Step [220/323], D_loss: 0.6990,  G_loss: 1.4962\n",
      " Epoch [292/300], Batch Step [230/323], D_loss: 0.7496,  G_loss: 1.6112\n",
      " Epoch [292/300], Batch Step [240/323], D_loss: 0.6895,  G_loss: 1.4873\n",
      " Epoch [292/300], Batch Step [250/323], D_loss: 0.6467,  G_loss: 1.6190\n",
      " Epoch [292/300], Batch Step [260/323], D_loss: 0.5652,  G_loss: 1.4955\n",
      " Epoch [292/300], Batch Step [270/323], D_loss: 0.4357,  G_loss: 1.5265\n",
      " Epoch [292/300], Batch Step [280/323], D_loss: 0.6298,  G_loss: 1.6563\n",
      " Epoch [292/300], Batch Step [290/323], D_loss: 0.5606,  G_loss: 1.6283\n",
      " Epoch [292/300], Batch Step [300/323], D_loss: 0.7830,  G_loss: 1.6867\n",
      " Epoch [292/300], Batch Step [310/323], D_loss: 0.6481,  G_loss: 1.6481\n",
      " Epoch [292/300], Batch Step [320/323], D_loss: 0.6913,  G_loss: 1.5210\n",
      " Epoch [293/300], Batch Step [0/323], D_loss: 0.6871,  G_loss: 1.5751\n",
      " Epoch [293/300], Batch Step [10/323], D_loss: 0.7711,  G_loss: 1.7765\n",
      " Epoch [293/300], Batch Step [20/323], D_loss: 0.7408,  G_loss: 1.6065\n",
      " Epoch [293/300], Batch Step [30/323], D_loss: 0.5815,  G_loss: 1.5968\n",
      " Epoch [293/300], Batch Step [40/323], D_loss: 0.5262,  G_loss: 1.5952\n",
      " Epoch [293/300], Batch Step [50/323], D_loss: 0.6567,  G_loss: 1.5349\n",
      " Epoch [293/300], Batch Step [60/323], D_loss: 0.9618,  G_loss: 1.6285\n",
      " Epoch [293/300], Batch Step [70/323], D_loss: 0.7064,  G_loss: 1.5656\n",
      " Epoch [293/300], Batch Step [80/323], D_loss: 0.6144,  G_loss: 1.6912\n",
      " Epoch [293/300], Batch Step [90/323], D_loss: 0.6502,  G_loss: 1.6386\n",
      " Epoch [293/300], Batch Step [100/323], D_loss: 0.5793,  G_loss: 1.6646\n",
      " Epoch [293/300], Batch Step [110/323], D_loss: 0.6450,  G_loss: 1.5854\n",
      " Epoch [293/300], Batch Step [120/323], D_loss: 0.6208,  G_loss: 1.6163\n",
      " Epoch [293/300], Batch Step [130/323], D_loss: 0.6110,  G_loss: 1.8257\n",
      " Epoch [293/300], Batch Step [140/323], D_loss: 0.4854,  G_loss: 1.5359\n",
      " Epoch [293/300], Batch Step [150/323], D_loss: 0.6409,  G_loss: 1.6175\n",
      " Epoch [293/300], Batch Step [160/323], D_loss: 0.8060,  G_loss: 1.5908\n",
      " Epoch [293/300], Batch Step [170/323], D_loss: 0.8934,  G_loss: 1.6194\n",
      " Epoch [293/300], Batch Step [180/323], D_loss: 0.5539,  G_loss: 1.6462\n",
      " Epoch [293/300], Batch Step [190/323], D_loss: 0.8056,  G_loss: 1.5345\n",
      " Epoch [293/300], Batch Step [200/323], D_loss: 0.5953,  G_loss: 1.6759\n",
      " Epoch [293/300], Batch Step [210/323], D_loss: 0.7312,  G_loss: 1.7256\n",
      " Epoch [293/300], Batch Step [220/323], D_loss: 0.5721,  G_loss: 1.6099\n",
      " Epoch [293/300], Batch Step [230/323], D_loss: 0.7227,  G_loss: 1.6945\n",
      " Epoch [293/300], Batch Step [240/323], D_loss: 0.7609,  G_loss: 1.5055\n",
      " Epoch [293/300], Batch Step [250/323], D_loss: 0.6422,  G_loss: 1.7038\n",
      " Epoch [293/300], Batch Step [260/323], D_loss: 0.5660,  G_loss: 1.6702\n",
      " Epoch [293/300], Batch Step [270/323], D_loss: 0.6508,  G_loss: 1.7379\n",
      " Epoch [293/300], Batch Step [280/323], D_loss: 0.5858,  G_loss: 1.6433\n",
      " Epoch [293/300], Batch Step [290/323], D_loss: 0.6774,  G_loss: 1.5468\n",
      " Epoch [293/300], Batch Step [300/323], D_loss: 0.6486,  G_loss: 1.6361\n",
      " Epoch [293/300], Batch Step [310/323], D_loss: 0.8238,  G_loss: 1.5482\n",
      " Epoch [293/300], Batch Step [320/323], D_loss: 0.5229,  G_loss: 1.4242\n",
      " Epoch [294/300], Batch Step [0/323], D_loss: 0.4689,  G_loss: 1.5722\n",
      " Epoch [294/300], Batch Step [10/323], D_loss: 0.6650,  G_loss: 1.6402\n",
      " Epoch [294/300], Batch Step [20/323], D_loss: 0.4660,  G_loss: 1.6392\n",
      " Epoch [294/300], Batch Step [30/323], D_loss: 0.5589,  G_loss: 1.6955\n",
      " Epoch [294/300], Batch Step [40/323], D_loss: 0.6165,  G_loss: 1.5192\n",
      " Epoch [294/300], Batch Step [50/323], D_loss: 0.6750,  G_loss: 1.6981\n",
      " Epoch [294/300], Batch Step [60/323], D_loss: 0.6334,  G_loss: 1.7021\n",
      " Epoch [294/300], Batch Step [70/323], D_loss: 0.7292,  G_loss: 1.5024\n",
      " Epoch [294/300], Batch Step [80/323], D_loss: 0.5767,  G_loss: 1.6733\n",
      " Epoch [294/300], Batch Step [90/323], D_loss: 0.6813,  G_loss: 1.8172\n",
      " Epoch [294/300], Batch Step [100/323], D_loss: 0.7729,  G_loss: 1.5539\n",
      " Epoch [294/300], Batch Step [110/323], D_loss: 0.9062,  G_loss: 1.5864\n",
      " Epoch [294/300], Batch Step [120/323], D_loss: 0.6626,  G_loss: 1.6822\n",
      " Epoch [294/300], Batch Step [130/323], D_loss: 0.7140,  G_loss: 1.6387\n",
      " Epoch [294/300], Batch Step [140/323], D_loss: 0.7026,  G_loss: 1.6265\n",
      " Epoch [294/300], Batch Step [150/323], D_loss: 0.7693,  G_loss: 1.6373\n",
      " Epoch [294/300], Batch Step [160/323], D_loss: 0.7286,  G_loss: 1.6528\n",
      " Epoch [294/300], Batch Step [170/323], D_loss: 0.7051,  G_loss: 1.6601\n",
      " Epoch [294/300], Batch Step [180/323], D_loss: 0.6270,  G_loss: 1.5545\n",
      " Epoch [294/300], Batch Step [190/323], D_loss: 0.5986,  G_loss: 1.7340\n",
      " Epoch [294/300], Batch Step [200/323], D_loss: 0.7941,  G_loss: 1.4899\n",
      " Epoch [294/300], Batch Step [210/323], D_loss: 0.7300,  G_loss: 1.6068\n",
      " Epoch [294/300], Batch Step [220/323], D_loss: 0.8673,  G_loss: 1.6795\n",
      " Epoch [294/300], Batch Step [230/323], D_loss: 0.7758,  G_loss: 1.5427\n",
      " Epoch [294/300], Batch Step [240/323], D_loss: 0.6140,  G_loss: 1.5807\n",
      " Epoch [294/300], Batch Step [250/323], D_loss: 0.6117,  G_loss: 1.7284\n",
      " Epoch [294/300], Batch Step [260/323], D_loss: 0.5554,  G_loss: 1.6519\n",
      " Epoch [294/300], Batch Step [270/323], D_loss: 0.5715,  G_loss: 1.5980\n",
      " Epoch [294/300], Batch Step [280/323], D_loss: 0.5846,  G_loss: 1.5211\n",
      " Epoch [294/300], Batch Step [290/323], D_loss: 0.6472,  G_loss: 1.6594\n",
      " Epoch [294/300], Batch Step [300/323], D_loss: 0.6686,  G_loss: 1.6658\n",
      " Epoch [294/300], Batch Step [310/323], D_loss: 0.5028,  G_loss: 1.6019\n",
      " Epoch [294/300], Batch Step [320/323], D_loss: 0.7830,  G_loss: 1.6930\n",
      " Epoch [295/300], Batch Step [0/323], D_loss: 0.4486,  G_loss: 1.6067\n",
      " Epoch [295/300], Batch Step [10/323], D_loss: 0.7154,  G_loss: 1.6975\n",
      " Epoch [295/300], Batch Step [20/323], D_loss: 0.6480,  G_loss: 1.6696\n",
      " Epoch [295/300], Batch Step [30/323], D_loss: 0.7322,  G_loss: 1.5464\n",
      " Epoch [295/300], Batch Step [40/323], D_loss: 0.7908,  G_loss: 1.7446\n",
      " Epoch [295/300], Batch Step [50/323], D_loss: 0.4493,  G_loss: 1.6353\n",
      " Epoch [295/300], Batch Step [60/323], D_loss: 0.7099,  G_loss: 1.6673\n",
      " Epoch [295/300], Batch Step [70/323], D_loss: 0.5440,  G_loss: 1.7034\n",
      " Epoch [295/300], Batch Step [80/323], D_loss: 0.5641,  G_loss: 1.6303\n",
      " Epoch [295/300], Batch Step [90/323], D_loss: 0.5041,  G_loss: 1.6156\n",
      " Epoch [295/300], Batch Step [100/323], D_loss: 0.6825,  G_loss: 1.7365\n",
      " Epoch [295/300], Batch Step [110/323], D_loss: 0.5768,  G_loss: 1.6034\n",
      " Epoch [295/300], Batch Step [120/323], D_loss: 0.6108,  G_loss: 1.5968\n",
      " Epoch [295/300], Batch Step [130/323], D_loss: 0.7748,  G_loss: 1.5392\n",
      " Epoch [295/300], Batch Step [140/323], D_loss: 0.5463,  G_loss: 1.5857\n",
      " Epoch [295/300], Batch Step [150/323], D_loss: 0.7095,  G_loss: 1.5820\n",
      " Epoch [295/300], Batch Step [160/323], D_loss: 0.5798,  G_loss: 1.4900\n",
      " Epoch [295/300], Batch Step [170/323], D_loss: 0.6459,  G_loss: 1.6444\n",
      " Epoch [295/300], Batch Step [180/323], D_loss: 0.5046,  G_loss: 1.7176\n",
      " Epoch [295/300], Batch Step [190/323], D_loss: 0.6039,  G_loss: 1.6711\n",
      " Epoch [295/300], Batch Step [200/323], D_loss: 0.7291,  G_loss: 1.5919\n",
      " Epoch [295/300], Batch Step [210/323], D_loss: 0.7427,  G_loss: 1.5416\n",
      " Epoch [295/300], Batch Step [220/323], D_loss: 0.7370,  G_loss: 1.5255\n",
      " Epoch [295/300], Batch Step [230/323], D_loss: 0.4746,  G_loss: 1.6022\n",
      " Epoch [295/300], Batch Step [240/323], D_loss: 0.6787,  G_loss: 1.5842\n",
      " Epoch [295/300], Batch Step [250/323], D_loss: 0.7785,  G_loss: 1.6865\n",
      " Epoch [295/300], Batch Step [260/323], D_loss: 0.5227,  G_loss: 1.5905\n",
      " Epoch [295/300], Batch Step [270/323], D_loss: 0.7724,  G_loss: 1.6161\n",
      " Epoch [295/300], Batch Step [280/323], D_loss: 0.6493,  G_loss: 1.5769\n",
      " Epoch [295/300], Batch Step [290/323], D_loss: 0.6255,  G_loss: 1.7514\n",
      " Epoch [295/300], Batch Step [300/323], D_loss: 0.7831,  G_loss: 1.6756\n",
      " Epoch [295/300], Batch Step [310/323], D_loss: 0.6613,  G_loss: 1.5239\n",
      " Epoch [295/300], Batch Step [320/323], D_loss: 0.6965,  G_loss: 1.6842\n",
      " Epoch [296/300], Batch Step [0/323], D_loss: 0.5254,  G_loss: 1.5855\n",
      " Epoch [296/300], Batch Step [10/323], D_loss: 0.7084,  G_loss: 1.5902\n",
      " Epoch [296/300], Batch Step [20/323], D_loss: 0.6641,  G_loss: 1.7457\n",
      " Epoch [296/300], Batch Step [30/323], D_loss: 0.6019,  G_loss: 1.6137\n",
      " Epoch [296/300], Batch Step [40/323], D_loss: 0.4494,  G_loss: 1.7213\n",
      " Epoch [296/300], Batch Step [50/323], D_loss: 0.5893,  G_loss: 1.6470\n",
      " Epoch [296/300], Batch Step [60/323], D_loss: 0.6574,  G_loss: 1.6634\n",
      " Epoch [296/300], Batch Step [70/323], D_loss: 0.7152,  G_loss: 1.8153\n",
      " Epoch [296/300], Batch Step [80/323], D_loss: 0.6574,  G_loss: 1.6933\n",
      " Epoch [296/300], Batch Step [90/323], D_loss: 0.5664,  G_loss: 1.6247\n",
      " Epoch [296/300], Batch Step [100/323], D_loss: 0.7789,  G_loss: 1.6565\n",
      " Epoch [296/300], Batch Step [110/323], D_loss: 0.7235,  G_loss: 1.5942\n",
      " Epoch [296/300], Batch Step [120/323], D_loss: 0.6237,  G_loss: 1.7517\n",
      " Epoch [296/300], Batch Step [130/323], D_loss: 0.6010,  G_loss: 1.6681\n",
      " Epoch [296/300], Batch Step [140/323], D_loss: 0.7502,  G_loss: 1.5507\n",
      " Epoch [296/300], Batch Step [150/323], D_loss: 0.5848,  G_loss: 1.5324\n",
      " Epoch [296/300], Batch Step [160/323], D_loss: 0.8776,  G_loss: 1.7199\n",
      " Epoch [296/300], Batch Step [170/323], D_loss: 0.6357,  G_loss: 1.4991\n",
      " Epoch [296/300], Batch Step [180/323], D_loss: 0.7232,  G_loss: 1.5358\n",
      " Epoch [296/300], Batch Step [190/323], D_loss: 0.6807,  G_loss: 1.5792\n",
      " Epoch [296/300], Batch Step [200/323], D_loss: 0.6740,  G_loss: 1.7020\n",
      " Epoch [296/300], Batch Step [210/323], D_loss: 0.5162,  G_loss: 1.6310\n",
      " Epoch [296/300], Batch Step [220/323], D_loss: 0.6519,  G_loss: 1.5207\n",
      " Epoch [296/300], Batch Step [230/323], D_loss: 0.6813,  G_loss: 1.5845\n",
      " Epoch [296/300], Batch Step [240/323], D_loss: 0.7185,  G_loss: 1.6071\n",
      " Epoch [296/300], Batch Step [250/323], D_loss: 0.4962,  G_loss: 1.5688\n",
      " Epoch [296/300], Batch Step [260/323], D_loss: 0.7443,  G_loss: 1.6072\n",
      " Epoch [296/300], Batch Step [270/323], D_loss: 0.4995,  G_loss: 1.6302\n",
      " Epoch [296/300], Batch Step [280/323], D_loss: 0.5563,  G_loss: 1.6887\n",
      " Epoch [296/300], Batch Step [290/323], D_loss: 0.7407,  G_loss: 1.7512\n",
      " Epoch [296/300], Batch Step [300/323], D_loss: 0.7827,  G_loss: 1.3836\n",
      " Epoch [296/300], Batch Step [310/323], D_loss: 0.6826,  G_loss: 1.6698\n",
      " Epoch [296/300], Batch Step [320/323], D_loss: 0.6042,  G_loss: 1.5613\n",
      " Epoch [297/300], Batch Step [0/323], D_loss: 0.6539,  G_loss: 1.5742\n",
      " Epoch [297/300], Batch Step [10/323], D_loss: 0.7188,  G_loss: 1.6619\n",
      " Epoch [297/300], Batch Step [20/323], D_loss: 0.5249,  G_loss: 1.6674\n",
      " Epoch [297/300], Batch Step [30/323], D_loss: 0.7310,  G_loss: 1.6744\n",
      " Epoch [297/300], Batch Step [40/323], D_loss: 0.5819,  G_loss: 1.6777\n",
      " Epoch [297/300], Batch Step [50/323], D_loss: 0.6968,  G_loss: 1.5819\n",
      " Epoch [297/300], Batch Step [60/323], D_loss: 0.5522,  G_loss: 1.5515\n",
      " Epoch [297/300], Batch Step [70/323], D_loss: 0.5861,  G_loss: 1.6285\n",
      " Epoch [297/300], Batch Step [80/323], D_loss: 0.6709,  G_loss: 1.6157\n",
      " Epoch [297/300], Batch Step [90/323], D_loss: 0.5789,  G_loss: 1.4578\n",
      " Epoch [297/300], Batch Step [100/323], D_loss: 0.6863,  G_loss: 1.6621\n",
      " Epoch [297/300], Batch Step [110/323], D_loss: 0.5919,  G_loss: 1.6626\n",
      " Epoch [297/300], Batch Step [120/323], D_loss: 0.7380,  G_loss: 1.6165\n",
      " Epoch [297/300], Batch Step [130/323], D_loss: 0.5110,  G_loss: 1.6936\n",
      " Epoch [297/300], Batch Step [140/323], D_loss: 0.6230,  G_loss: 1.6921\n",
      " Epoch [297/300], Batch Step [150/323], D_loss: 0.5367,  G_loss: 1.6536\n",
      " Epoch [297/300], Batch Step [160/323], D_loss: 0.6037,  G_loss: 1.7537\n",
      " Epoch [297/300], Batch Step [170/323], D_loss: 0.6512,  G_loss: 1.5613\n",
      " Epoch [297/300], Batch Step [180/323], D_loss: 0.7448,  G_loss: 1.5293\n",
      " Epoch [297/300], Batch Step [190/323], D_loss: 0.6388,  G_loss: 1.6171\n",
      " Epoch [297/300], Batch Step [200/323], D_loss: 0.5498,  G_loss: 1.6698\n",
      " Epoch [297/300], Batch Step [210/323], D_loss: 0.6119,  G_loss: 1.6479\n",
      " Epoch [297/300], Batch Step [220/323], D_loss: 0.6924,  G_loss: 1.7523\n",
      " Epoch [297/300], Batch Step [230/323], D_loss: 0.6824,  G_loss: 1.5844\n",
      " Epoch [297/300], Batch Step [240/323], D_loss: 0.5208,  G_loss: 1.6070\n",
      " Epoch [297/300], Batch Step [250/323], D_loss: 0.7005,  G_loss: 1.7012\n",
      " Epoch [297/300], Batch Step [260/323], D_loss: 0.5373,  G_loss: 1.5820\n",
      " Epoch [297/300], Batch Step [270/323], D_loss: 0.6648,  G_loss: 1.6537\n",
      " Epoch [297/300], Batch Step [280/323], D_loss: 0.6891,  G_loss: 1.5504\n",
      " Epoch [297/300], Batch Step [290/323], D_loss: 0.7029,  G_loss: 1.6576\n",
      " Epoch [297/300], Batch Step [300/323], D_loss: 0.4888,  G_loss: 1.5214\n",
      " Epoch [297/300], Batch Step [310/323], D_loss: 0.6831,  G_loss: 1.6272\n",
      " Epoch [297/300], Batch Step [320/323], D_loss: 0.7547,  G_loss: 1.5462\n",
      " Epoch [298/300], Batch Step [0/323], D_loss: 0.6281,  G_loss: 1.5040\n",
      " Epoch [298/300], Batch Step [10/323], D_loss: 0.7981,  G_loss: 1.5652\n",
      " Epoch [298/300], Batch Step [20/323], D_loss: 0.5413,  G_loss: 1.6019\n",
      " Epoch [298/300], Batch Step [30/323], D_loss: 0.6520,  G_loss: 1.6989\n",
      " Epoch [298/300], Batch Step [40/323], D_loss: 0.7671,  G_loss: 1.5359\n",
      " Epoch [298/300], Batch Step [50/323], D_loss: 0.5686,  G_loss: 1.6004\n",
      " Epoch [298/300], Batch Step [60/323], D_loss: 0.5686,  G_loss: 1.4784\n",
      " Epoch [298/300], Batch Step [70/323], D_loss: 0.5558,  G_loss: 1.6239\n",
      " Epoch [298/300], Batch Step [80/323], D_loss: 0.6206,  G_loss: 1.7258\n",
      " Epoch [298/300], Batch Step [90/323], D_loss: 0.6180,  G_loss: 1.5698\n",
      " Epoch [298/300], Batch Step [100/323], D_loss: 0.6324,  G_loss: 1.5724\n",
      " Epoch [298/300], Batch Step [110/323], D_loss: 0.6430,  G_loss: 1.5960\n",
      " Epoch [298/300], Batch Step [120/323], D_loss: 0.5307,  G_loss: 1.5290\n",
      " Epoch [298/300], Batch Step [130/323], D_loss: 0.6509,  G_loss: 1.6732\n",
      " Epoch [298/300], Batch Step [140/323], D_loss: 0.4810,  G_loss: 1.5461\n",
      " Epoch [298/300], Batch Step [150/323], D_loss: 0.7297,  G_loss: 1.7021\n",
      " Epoch [298/300], Batch Step [160/323], D_loss: 0.7604,  G_loss: 1.5552\n",
      " Epoch [298/300], Batch Step [170/323], D_loss: 0.5800,  G_loss: 1.5272\n",
      " Epoch [298/300], Batch Step [180/323], D_loss: 0.5598,  G_loss: 1.4984\n",
      " Epoch [298/300], Batch Step [190/323], D_loss: 0.4462,  G_loss: 1.6287\n",
      " Epoch [298/300], Batch Step [200/323], D_loss: 0.6562,  G_loss: 1.6181\n",
      " Epoch [298/300], Batch Step [210/323], D_loss: 0.6802,  G_loss: 1.8220\n",
      " Epoch [298/300], Batch Step [220/323], D_loss: 0.7018,  G_loss: 1.6223\n",
      " Epoch [298/300], Batch Step [230/323], D_loss: 0.7095,  G_loss: 1.5908\n",
      " Epoch [298/300], Batch Step [240/323], D_loss: 0.6043,  G_loss: 1.6739\n",
      " Epoch [298/300], Batch Step [250/323], D_loss: 0.6041,  G_loss: 1.5295\n",
      " Epoch [298/300], Batch Step [260/323], D_loss: 0.5177,  G_loss: 1.6407\n",
      " Epoch [298/300], Batch Step [270/323], D_loss: 0.5270,  G_loss: 1.7589\n",
      " Epoch [298/300], Batch Step [280/323], D_loss: 0.5794,  G_loss: 1.6621\n",
      " Epoch [298/300], Batch Step [290/323], D_loss: 0.6303,  G_loss: 1.7003\n",
      " Epoch [298/300], Batch Step [300/323], D_loss: 0.6632,  G_loss: 1.7106\n",
      " Epoch [298/300], Batch Step [310/323], D_loss: 0.5193,  G_loss: 1.4506\n",
      " Epoch [298/300], Batch Step [320/323], D_loss: 0.4870,  G_loss: 1.5581\n",
      " Epoch [299/300], Batch Step [0/323], D_loss: 0.6935,  G_loss: 1.6082\n",
      " Epoch [299/300], Batch Step [10/323], D_loss: 0.5822,  G_loss: 1.6820\n",
      " Epoch [299/300], Batch Step [20/323], D_loss: 0.6775,  G_loss: 1.5797\n",
      " Epoch [299/300], Batch Step [30/323], D_loss: 0.6375,  G_loss: 1.6486\n",
      " Epoch [299/300], Batch Step [40/323], D_loss: 0.6148,  G_loss: 1.7360\n",
      " Epoch [299/300], Batch Step [50/323], D_loss: 0.5063,  G_loss: 1.5704\n",
      " Epoch [299/300], Batch Step [60/323], D_loss: 0.8476,  G_loss: 1.8327\n",
      " Epoch [299/300], Batch Step [70/323], D_loss: 0.7201,  G_loss: 1.5205\n",
      " Epoch [299/300], Batch Step [80/323], D_loss: 0.5840,  G_loss: 1.6027\n",
      " Epoch [299/300], Batch Step [90/323], D_loss: 0.6714,  G_loss: 1.7588\n",
      " Epoch [299/300], Batch Step [100/323], D_loss: 0.7220,  G_loss: 1.5855\n",
      " Epoch [299/300], Batch Step [110/323], D_loss: 0.5940,  G_loss: 1.5718\n",
      " Epoch [299/300], Batch Step [120/323], D_loss: 0.6680,  G_loss: 1.7868\n",
      " Epoch [299/300], Batch Step [130/323], D_loss: 0.5934,  G_loss: 1.5115\n",
      " Epoch [299/300], Batch Step [140/323], D_loss: 0.5596,  G_loss: 1.5877\n",
      " Epoch [299/300], Batch Step [150/323], D_loss: 0.5974,  G_loss: 1.6080\n",
      " Epoch [299/300], Batch Step [160/323], D_loss: 0.5440,  G_loss: 1.5548\n",
      " Epoch [299/300], Batch Step [170/323], D_loss: 0.6366,  G_loss: 1.6580\n",
      " Epoch [299/300], Batch Step [180/323], D_loss: 0.6661,  G_loss: 1.5594\n",
      " Epoch [299/300], Batch Step [190/323], D_loss: 0.5590,  G_loss: 1.5748\n",
      " Epoch [299/300], Batch Step [200/323], D_loss: 0.6247,  G_loss: 1.6082\n",
      " Epoch [299/300], Batch Step [210/323], D_loss: 0.4707,  G_loss: 1.7717\n",
      " Epoch [299/300], Batch Step [220/323], D_loss: 0.7527,  G_loss: 1.5108\n",
      " Epoch [299/300], Batch Step [230/323], D_loss: 0.7820,  G_loss: 1.5941\n",
      " Epoch [299/300], Batch Step [240/323], D_loss: 0.6775,  G_loss: 1.5898\n",
      " Epoch [299/300], Batch Step [250/323], D_loss: 0.7274,  G_loss: 1.6417\n",
      " Epoch [299/300], Batch Step [260/323], D_loss: 0.6225,  G_loss: 1.5235\n",
      " Epoch [299/300], Batch Step [270/323], D_loss: 0.6348,  G_loss: 1.7550\n",
      " Epoch [299/300], Batch Step [280/323], D_loss: 0.6507,  G_loss: 1.7638\n",
      " Epoch [299/300], Batch Step [290/323], D_loss: 0.6342,  G_loss: 1.5246\n",
      " Epoch [299/300], Batch Step [300/323], D_loss: 0.6125,  G_loss: 1.6671\n",
      " Epoch [299/300], Batch Step [310/323], D_loss: 0.6258,  G_loss: 1.6220\n",
      " Epoch [299/300], Batch Step [320/323], D_loss: 0.6159,  G_loss: 1.6037\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, real_data in enumerate(dataloader):\n",
    "        # Adversarial ground truth labels\n",
    "        valid = torch.ones(real_data.size(0), 1)\n",
    "        fake = torch.zeros(real_data.size(0), 1)\n",
    "\n",
    "        # Train the discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        real_pred = discriminator(real_data)\n",
    "        d_real_loss = adversarial_loss(real_pred, valid)\n",
    "\n",
    "        z = torch.randn(real_data.size(0), 100)\n",
    "        fake_data = generator(z)\n",
    "        fake_pred = discriminator(fake_data.detach())\n",
    "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train the generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        z = torch.randn(real_data.size(0), 100)\n",
    "        generated_data = generator(z)\n",
    "        fake_pred = discriminator(generated_data)\n",
    "        g_loss = adversarial_loss(fake_pred, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\n",
    "                f\" Epoch [{epoch}/{num_epochs}], Batch Step [{i}/{len(dataloader)}],\"\n",
    "                f\" D_loss: {d_loss.item():.4f},  G_loss: {g_loss.item():.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27df93cf-2e3b-4895-ae36-6fe2e2417047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4698, -0.7564, -0.8364, -0.0569, -0.0765, -0.0394, -0.8818,  0.6957])\n",
      "tensor([-0.4888,  0.9998, -0.4053, -0.0449, -0.4048,  0.0500, -0.8179,  0.6407])\n",
      "tensor([-0.9799, -0.0028, -0.9977,  0.0787, -0.7824,  0.1656, -0.9112,  0.6996])\n",
      "tensor([ 0.4046, -0.5854,  0.5164, -0.1330,  0.0297, -0.0474,  0.9150, -0.4882])\n",
      "tensor([ 0.0185, -1.0000, -0.4563, -0.1531,  0.0083, -0.0806, -0.8463,  0.7203])\n",
      "tensor([-0.9989, -0.4726, -0.0561,  0.0695, -0.4967, -0.0629,  0.6374, -0.3592])\n",
      "tensor([-0.4662,  0.4351, -0.2064, -0.0839, -0.0271,  0.1298, -0.7779,  0.6304])\n",
      "tensor([-0.2304,  0.8199, -0.9440, -0.1088, -0.1856, -0.0710, -0.7066,  0.5482])\n",
      "tensor([-0.4999, -0.3969, -0.0875, -0.1872,  0.5188, -0.0376,  0.9808, -0.6532])\n",
      "tensor([ 0.2829,  0.4759, -0.0372, -0.0679, -0.0743, -0.0042, -0.7686,  0.7116])\n"
     ]
    }
   ],
   "source": [
    "# Set the generator network to evaluation mode\n",
    "generator.eval()\n",
    "\n",
    "# Generate new samples\n",
    "num_samples = 10\n",
    "z = torch.randn(num_samples, 100)  # Generate random noise as input\n",
    "with torch.no_grad():\n",
    "    generated_samples = generator(z)\n",
    "\n",
    "# Process the generated samples as needed\n",
    "# For example, you can denormalize them if necessary\n",
    "\n",
    "# Print or visualize the generated samples\n",
    "for i in range(num_samples):\n",
    "    sample = generated_samples[i]\n",
    "    print(sample)  # You can modify this to suit your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d5ac96e-3f67-4ba7-849a-7817662675d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate new samples\n",
    "num_samples = 10\n",
    "z = torch.randn(num_samples, 100)  # Generate random noise as input\n",
    "with torch.no_grad():\n",
    "    generated_samples = generator(z)\n",
    "\n",
    "# Convert the generated samples to a numpy array\n",
    "generated_samples = generated_samples.cpu().numpy()\n",
    "\n",
    "# Plot the generated samples\n",
    "for i in range(num_samples):\n",
    "    sample = generated_samples[i]\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.bar(range(sample.shape[0]), sample)\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'Generated Sample {i+1}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85ef4914-27d9-4564-90af-9775b2ccabac",
   "metadata": {},
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5123a014-70de-4387-a63b-5f517e2ab3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the GAN model\n",
    "torch.save( {\n",
    "            'scaler':                   scaler,\n",
    "            'generator_state_dict':     generator.state_dict(),\n",
    "            'discriminator_state_dict': discriminator.state_dict(),\n",
    "            }, \n",
    "    r'C:\\Users\\bhupe\\OneDrive\\AI-notebook-dir\\300 - ADL - Advanced Deep Learning\\50 - ADL - Generative Models\\51 - GANs - New folder\\model\\gan_model_cal_housing.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c531a3a7-69d0-4a41-a8e5-e948e0368500",
   "metadata": {},
   "source": [
    "#### Load model from saved artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcf34f38-88ec-4070-bae9-24f668d89647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72f1bbce-d8f1-4782-96c7-86eb375e6520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 8),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        generated_data = self.model(x)\n",
    "        return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4098b605-4e6d-456d-9d9e-ee7a1a699979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the networks\n",
    "#discriminator = Discriminator()\n",
    "generator     = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21d8bae8-2bca-4e48-a648-f3219c210679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the GAN model\n",
    "checkpoint = torch.load(r'C:\\Users\\bhupe\\OneDrive\\AI-notebook-dir\\300 - ADL - Advanced Deep Learning\\50 - ADL - Generative Models\\51 - GANs - New folder\\model\\gan_model_cal_housing.pt')\n",
    "\n",
    "generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "#discriminator.load_state_dict(checkpoint['discriminator_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64d895c1-817e-4949-8216-e93e1d07852a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=8, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the generator network to evaluation mode\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "406a3f4a-e110-43c6-b5d7-3ecc99f81086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new samples\n",
    "num_samples = 10\n",
    "z = torch.randn(num_samples, 100)  # Generate random noise as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3fa4039-dcad-447e-9a74-5861be53348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    generated_samples = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31200b96-3d1f-48d4-98e5-b8612e58b391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a491d-9881-45d3-846d-63e5500e7dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
