{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = cancer['data']\n",
    "y = cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns = cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit only to the training data\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why scale?\n",
    "\n",
    "- to bring the features to the same range\n",
    "\n",
    "- Is it needed always (in ML)\n",
    "    - No\n",
    "        - NB, DT, RF, Adaboost/GB/XGB (why?)\n",
    "            - computing any parameter in terms of the geometrical space\n",
    "    - Yes\n",
    "        - KNN\n",
    "        - Logistic Regression (?)\n",
    "        - SVM (?)\n",
    "        - NN (?)\n",
    "            - Compute the gradient (based on the errors, y - y_hat)\n",
    "                - y_hat is dependent on the col values\n",
    "                    - Xs have different scales, that will affect the error\n",
    "                        - computation of gradients - big/small numbers\n",
    "                            - CONVERGENCE to the min will be an issue\n",
    "                                - NN will take longer to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_std  = scaler.transform(X_train)\n",
    "X_test_std   = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `hidden_layer_sizes` tuple, length = n_layers - 2, default=(100,)\n",
    "    - The ith element represents the number of neurons in the ith hidden layer.\n",
    "    - [64, 32, 16, 8]\n",
    "        - 4 hidden layers\n",
    "            - 1st layer with 64 neurons\n",
    "            - 2nd layer with 32 neurons\n",
    "            - 3rd layer with 16 nodes\n",
    "            - 4th layer with  8 nodes\n",
    "- `activation` \n",
    "    - {â€˜identityâ€™, â€˜logisticâ€™, â€˜tanhâ€™, â€˜reluâ€™}, default=â€™reluâ€™\n",
    "        - we will use 'logistic`\n",
    "            - synonymous with `sigmoid`\n",
    "- `solver` {â€˜lbfgsâ€™, â€˜sgdâ€™, â€˜adamâ€™}, default=â€™adamâ€™\n",
    "    - choice of gradient descent\n",
    "    - simple GD will be `sgd`\n",
    "- `batch_size` int, default=â€™autoâ€™\n",
    "    - typical values \n",
    "        - 256, 200, 128, 64, 32\n",
    "- `learning_rate`\n",
    "    - {â€˜constantâ€™, â€˜invscalingâ€™, â€˜adaptiveâ€™}, default=â€™constantâ€™\n",
    "- `learning_rate_init` double, default=0.001\n",
    "    - The initial learning rate used. It controls the step-size in updating the weights. Only used when solver=â€™sgdâ€™ or â€˜adamâ€™.\n",
    "- `max_iter` int, default=200\n",
    "    - Maximum number of iterations. \n",
    "    - The `solver iterates until convergence` (determined by â€˜tolâ€™) or this `number of iterations`. \n",
    "    - For stochastic solvers (â€˜sgdâ€™, â€˜adamâ€™), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.\n",
    "- `shuffle` bool, default=True\n",
    "    - Whether to shuffle samples in each iteration. \n",
    "    - Only used when solver=â€™sgdâ€™ or â€˜adamâ€™.\n",
    "- `tol` float, default=1e-4\n",
    "    - threshold\n",
    "    - Tolerance for the optimization. \n",
    "    - When the loss or score is not improving by at least `tol` for `n_iter_no_change` consecutive iterations, unless learning_rate is set to â€˜adaptiveâ€™, convergence is considered to be reached and training stops.\n",
    "- `verbose` bool, default=False\n",
    "    - Whether to print progress messages to stdout.\n",
    "- `early_stopping` - bool, default=False\n",
    "    - Whether to use early stopping to terminate training when validation score is not improving. \n",
    "    - If set to true, it will automatically set aside 10% of training data as validation and terminate training when `validation score is not improving` by at least `tol` for `n_iter_no_change` consecutive epochs. \n",
    "    - The split is stratified, except in a multilabel setting. Only effective when solver=â€™sgdâ€™ or â€˜adamâ€™\n",
    "- `validation_fraction` float, default=0.1\n",
    "    - The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. \n",
    "    - Only used if early_stopping is True\n",
    "    - typical good values \n",
    "        - 20%, 25%, 30%\n",
    "- `n_iter_no_change` int, default=10\n",
    "    - Maximum number of epochs/iterations to not meet `tol` improvement. \n",
    "    - Only effective when solver=â€™sgdâ€™ or â€˜adamâ€™\n",
    "    - typical values \n",
    "        - 10, 15, 20\n",
    "- `random_state` int, RandomState instance, default=None\n",
    "    - Determines random number generation for `weights` and `bias` initialization, `train-test split` if early stopping is used, and batch sampling when solver=â€™sgdâ€™ or â€˜adamâ€™. \n",
    "    - Pass an `int` for reproducible results across multiple function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD \n",
    "- starts with as many samples you have\n",
    "    - compute the weights with however many samples you have right now in the training set\n",
    "    - later , more samples arrive, you push them to the ML model\n",
    "        - incrementally train the model\n",
    "            - the weights will be  adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64),           # with 1 l\n",
    "                    activation='logistic',             # same as sigmoid\n",
    "                    solver='sgd',\n",
    "                    batch_size=32,\n",
    "                    learning_rate='constant',\n",
    "                    learning_rate_init=.01,            # .01, .05, .005, .001\n",
    "                    max_iter=1500,\n",
    "                    shuffle=True,\n",
    "                    tol=.0001,                         # .0001, .001, .01, .05\n",
    "                    verbose=False,\n",
    "                    early_stopping=False,               # Always use this, set to True\n",
    "                    validation_fraction=.20,          # 20% is fine\n",
    "                    n_iter_no_change=10,               # 5, 10, 20, 50, less than the max_iter   \n",
    "                    random_state=100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mlp = MLPClassifier(hidden_layer_sizes=(64),           # with 1 l\n",
    "#                     activation='logistic',             # same as sigmoid\n",
    "#                     solver='sgd',\n",
    "#                     batch_size=32,\n",
    "#                     learning_rate='constant',\n",
    "#                     learning_rate_init=.001,           # .01, .05, .005, .001\n",
    "#                     max_iter=1500,\n",
    "#                     shuffle=True,\n",
    "#                     tol=.0001,                         # .0001, .001, .01, .05\n",
    "#                     verbose=False,\n",
    "#                     early_stopping=True,               # Always use this, set to True\n",
    "#                     validation_fraction=.20,           # 20% is fine\n",
    "#                     n_iter_no_change=10,               # 5, 10, 20, 50, less than the max_iter   \n",
    "#                     random_state=100\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config 3\n",
    "- play with more than 1 layer (32, 16, 8)\n",
    "- with activation set to 'sigmoid' \n",
    "    - this will degrade the performance\n",
    "        - sigmoid is not a good choice for hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(64),    # with 2 l\n",
    "                    activation='logistic',             # same as sigmoid\n",
    "                    solver='sgd',\n",
    "                    batch_size=32,\n",
    "                    learning_rate='constant',\n",
    "                    learning_rate_init=.01,           # .01, .05, .005, .001\n",
    "                    max_iter=1500,\n",
    "                    shuffle=True,\n",
    "                    tol=.0001,                         # .0001, .001, .01, .05\n",
    "                    verbose=False,\n",
    "                    early_stopping=True,               # Always use this, set to True\n",
    "                    validation_fraction=.20,           # 20% is fine\n",
    "                    n_iter_no_change=10,               # 5, 10, 20, 50, less than the max_iter   \n",
    "                    random_state=100\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config 4\n",
    "- play with more than 1 layer (32, 16, 8)\n",
    "- with activation set to 'relu' \n",
    "    - this will improve the performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mlp = MLPClassifier(hidden_layer_sizes=(32, 16, 8),    # with 2 l\n",
    "#                     activation='relu',                 # same as sigmoid\n",
    "#                     solver='sgd',\n",
    "#                     batch_size=32,\n",
    "#                     learning_rate='constant',\n",
    "#                     learning_rate_init=.001,           # .01, .05, .005, .001\n",
    "#                     max_iter=1500,\n",
    "#                     shuffle=True,\n",
    "#                     tol=.0001,                         # .0001, .001, .01, .05\n",
    "#                     verbose=False,\n",
    "#                     early_stopping=True,               # Always use this, set to True\n",
    "#                     validation_fraction=.20,           # 20% is fine\n",
    "#                     n_iter_no_change=10,               # 5, 10, 20, 50, less than the max_iter   \n",
    "#                     random_state=100\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config 5\n",
    "- 1 layer (32) --- try with 32/16/8/4/3\n",
    "- with activation set to 'relu' \n",
    "    - this will improve the performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mlp = MLPClassifier(hidden_layer_sizes=(4),           # with 1 l\n",
    "#                     activation='relu',                # same as sigmoid\n",
    "#                     solver='sgd',\n",
    "#                     batch_size=32,\n",
    "#                     learning_rate='constant',\n",
    "#                     learning_rate_init=.001,           # .01, .05, .005, .001\n",
    "#                     max_iter=1500,\n",
    "#                     shuffle=True,\n",
    "#                     tol=.0001,                         # .0001, .001, .01, .05\n",
    "#                     verbose=False,\n",
    "#                     early_stopping=True,               # Always use this, set to True\n",
    "#                     validation_fraction=.20,           # 20% is fine\n",
    "#                     n_iter_no_change=50,               # 5, 10, 20, 50, less than the max_iter   \n",
    "#                     random_state=100\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', batch_size=32, hidden_layer_sizes=64,\n",
       "              learning_rate_init=0.01, max_iter=1500, random_state=100,\n",
       "              solver='sgd', validation_fraction=0.2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions and Evaluation\n",
    " \n",
    "Now that we have a model it is time to use it to get predictions! We can do this simply with the predict() method off of our fitted model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47  3]\n",
      " [ 1 92]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96        50\n",
      "           1       0.97      0.99      0.98        93\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.96      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      "0.972027972027972\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mlp.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(mlp.loss_curve_)), mlp.loss_curve_)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract the MLP __weights__ and __biases__ after training your model, we use its public attributes __coefs___ and __intercepts___.\n",
    "\n",
    "coefs_ is a list of weight matrices, where weight matrix at index i represents the weights between layer i and layer i+1.\n",
    "\n",
    "intercepts_ is a list of bias vectors, where the vector at index i represents the bias values added to layer i+1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(mlp.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(mlp.coefs_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of weights matrix (between the input and the hidden layer)\n",
    "#mlp.coefs_[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the sizepf weights matrix (between the hidden layer and the output)\n",
    "#mlp.coefs_[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(mlp.intercepts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should match the number of neurons in the hidden layer\n",
    "#len(mlp.intercepts_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should match the number of neurons in the output layer\n",
    "#len(mlp.intercepts_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
