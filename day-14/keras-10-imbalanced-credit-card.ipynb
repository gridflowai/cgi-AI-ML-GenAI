{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True, linewidth=140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The datasets contains transactions made by credit cards in __September 2013__ by european cardholders.\n",
    "\n",
    "- This dataset presents transactions that occurred in __two days__, where we have 492 frauds out of 284,807 transactions. \n",
    "\n",
    "- The dataset is __highly unbalanced__, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "- It contains only numerical input variables which are the result of a __PCA transformation__. \n",
    "\n",
    "- Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. \n",
    "\n",
    "- Features V1, V2, â€¦ V28 are the principal components obtained with PCA, \n",
    "\n",
    "- the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
    "\n",
    "- Feature __'Time'__ contains the seconds elapsed between each transaction and the first transaction in the dataset. \n",
    "\n",
    "- The feature __'Amount'__ is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. \n",
    "\n",
    "- Feature __'Class'__ is the response variable and it takes value 1 in case of fraud and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r'D:\\MYLEARN\\datasets\\creditcard.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "all_targets  = []\n",
    "\n",
    "with open(fname) as f:\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        \n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "            \n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        \n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets  = np.array(all_targets, dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\",  targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "\n",
    "train_features  = features[:-num_val_samples]\n",
    "train_targets   =  targets[:-num_val_samples]\n",
    "\n",
    "val_features    = features[-num_val_samples:]\n",
    "val_targets     =  targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\",   len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze class imbalance in the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([227429,    417], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.      ,     -1.359807,     -0.072781, ...,      0.133558,     -0.021053,    149.62    ],\n",
       "       [     0.      ,      1.191857,      0.266151, ...,     -0.008983,      0.014724,      2.69    ],\n",
       "       [     1.      ,     -1.358354,     -1.340163, ...,     -0.055353,     -0.059752,    378.66    ],\n",
       "       ...,\n",
       "       [145245.      ,     -0.061507,      1.024901, ...,     -0.048916,      0.023871,     39.4     ],\n",
       "       [145247.      ,      2.050034,     -0.103557, ...,     -0.074529,     -0.074279,      0.17    ],\n",
       "       [145248.      ,      1.914027,     -0.490068, ...,     -0.023843,     -0.037139,     50.      ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize the data using training set statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "\n",
    "train_features -= mean\n",
    "val_features   -= mean\n",
    "\n",
    "std = np.std(train_features, axis=0)\n",
    "\n",
    "train_features /= std\n",
    "val_features   /= std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               7936      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 139,777\n",
      "Trainable params: 139,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(256, activation=\"relu\", input_shape=(train_features.shape[-1],)),\n",
    "        \n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Dense(256, activation=\"relu\"),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        \n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model with class_weight argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    keras.metrics.Precision(name=\"precision\"),\n",
    "    keras.metrics.Recall(name=\"recall\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "            optimizer=keras.optimizers.Adam(1e-2), \n",
    "            loss=\"binary_crossentropy\", \n",
    "            metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks    = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "112/112 [==============================] - 7s 66ms/step - loss: 2.3181e-06 - fn: 44.0000 - fp: 26721.0000 - tn: 200708.0000 - tp: 373.0000 - precision: 0.0138 - recall: 0.8945 - val_loss: 0.1204 - val_fn: 9.0000 - val_fp: 1854.0000 - val_tn: 55032.0000 - val_tp: 66.0000 - val_precision: 0.0344 - val_recall: 0.8800\n",
      "Epoch 2/30\n",
      "112/112 [==============================] - 6s 58ms/step - loss: 1.6147e-06 - fn: 39.0000 - fp: 7707.0000 - tn: 219722.0000 - tp: 378.0000 - precision: 0.0468 - recall: 0.9065 - val_loss: 0.0741 - val_fn: 9.0000 - val_fp: 1246.0000 - val_tn: 55640.0000 - val_tp: 66.0000 - val_precision: 0.0503 - val_recall: 0.8800\n",
      "Epoch 3/30\n",
      "112/112 [==============================] - 7s 58ms/step - loss: 1.2604e-06 - fn: 30.0000 - fp: 7768.0000 - tn: 219661.0000 - tp: 387.0000 - precision: 0.0475 - recall: 0.9281 - val_loss: 0.0902 - val_fn: 10.0000 - val_fp: 799.0000 - val_tn: 56087.0000 - val_tp: 65.0000 - val_precision: 0.0752 - val_recall: 0.8667\n",
      "Epoch 4/30\n",
      "112/112 [==============================] - 7s 59ms/step - loss: 9.3362e-07 - fn: 25.0000 - fp: 5624.0000 - tn: 221805.0000 - tp: 392.0000 - precision: 0.0652 - recall: 0.9400 - val_loss: 0.0552 - val_fn: 9.0000 - val_fp: 958.0000 - val_tn: 55928.0000 - val_tp: 66.0000 - val_precision: 0.0645 - val_recall: 0.8800\n",
      "Epoch 5/30\n",
      "112/112 [==============================] - 7s 63ms/step - loss: 8.9729e-07 - fn: 20.0000 - fp: 7051.0000 - tn: 220378.0000 - tp: 397.0000 - precision: 0.0533 - recall: 0.9520 - val_loss: 0.0484 - val_fn: 8.0000 - val_fp: 887.0000 - val_tn: 55999.0000 - val_tp: 67.0000 - val_precision: 0.0702 - val_recall: 0.8933\n",
      "Epoch 6/30\n",
      "112/112 [==============================] - 7s 61ms/step - loss: 8.8636e-07 - fn: 16.0000 - fp: 7331.0000 - tn: 220098.0000 - tp: 401.0000 - precision: 0.0519 - recall: 0.9616 - val_loss: 0.1135 - val_fn: 5.0000 - val_fp: 2253.0000 - val_tn: 54633.0000 - val_tp: 70.0000 - val_precision: 0.0301 - val_recall: 0.9333\n",
      "Epoch 7/30\n",
      "112/112 [==============================] - 7s 59ms/step - loss: 7.7048e-07 - fn: 17.0000 - fp: 7017.0000 - tn: 220412.0000 - tp: 400.0000 - precision: 0.0539 - recall: 0.9592 - val_loss: 0.0384 - val_fn: 8.0000 - val_fp: 778.0000 - val_tn: 56108.0000 - val_tp: 67.0000 - val_precision: 0.0793 - val_recall: 0.8933\n",
      "Epoch 8/30\n",
      "112/112 [==============================] - 7s 59ms/step - loss: 6.0000e-07 - fn: 15.0000 - fp: 6159.0000 - tn: 221270.0000 - tp: 402.0000 - precision: 0.0613 - recall: 0.9640 - val_loss: 0.0295 - val_fn: 8.0000 - val_fp: 615.0000 - val_tn: 56271.0000 - val_tp: 67.0000 - val_precision: 0.0982 - val_recall: 0.8933\n",
      "Epoch 9/30\n",
      "112/112 [==============================] - 7s 59ms/step - loss: 5.4973e-07 - fn: 10.0000 - fp: 5530.0000 - tn: 221899.0000 - tp: 407.0000 - precision: 0.0686 - recall: 0.9760 - val_loss: 0.2000 - val_fn: 1.0000 - val_fp: 6680.0000 - val_tn: 50206.0000 - val_tp: 74.0000 - val_precision: 0.0110 - val_recall: 0.9867\n",
      "Epoch 10/30\n",
      "112/112 [==============================] - 7s 60ms/step - loss: 9.5443e-07 - fn: 17.0000 - fp: 7355.0000 - tn: 220074.0000 - tp: 400.0000 - precision: 0.0516 - recall: 0.9592 - val_loss: 0.0199 - val_fn: 12.0000 - val_fp: 276.0000 - val_tn: 56610.0000 - val_tp: 63.0000 - val_precision: 0.1858 - val_recall: 0.8400\n",
      "Epoch 11/30\n",
      "112/112 [==============================] - 7s 61ms/step - loss: 5.8585e-07 - fn: 11.0000 - fp: 5303.0000 - tn: 222126.0000 - tp: 406.0000 - precision: 0.0711 - recall: 0.9736 - val_loss: 0.0806 - val_fn: 7.0000 - val_fp: 2150.0000 - val_tn: 54736.0000 - val_tp: 68.0000 - val_precision: 0.0307 - val_recall: 0.9067\n",
      "Epoch 12/30\n",
      "112/112 [==============================] - 7s 62ms/step - loss: 1.0680e-06 - fn: 15.0000 - fp: 8321.0000 - tn: 219108.0000 - tp: 402.0000 - precision: 0.0461 - recall: 0.9640 - val_loss: 0.0365 - val_fn: 11.0000 - val_fp: 381.0000 - val_tn: 56505.0000 - val_tp: 64.0000 - val_precision: 0.1438 - val_recall: 0.8533\n",
      "Epoch 13/30\n",
      "112/112 [==============================] - 7s 61ms/step - loss: 1.2211e-06 - fn: 19.0000 - fp: 8245.0000 - tn: 219184.0000 - tp: 398.0000 - precision: 0.0460 - recall: 0.9544 - val_loss: 0.0338 - val_fn: 11.0000 - val_fp: 365.0000 - val_tn: 56521.0000 - val_tp: 64.0000 - val_precision: 0.1492 - val_recall: 0.8533\n",
      "Epoch 14/30\n",
      "112/112 [==============================] - 7s 61ms/step - loss: 7.2742e-07 - fn: 14.0000 - fp: 5694.0000 - tn: 221735.0000 - tp: 403.0000 - precision: 0.0661 - recall: 0.9664 - val_loss: 0.0524 - val_fn: 8.0000 - val_fp: 1137.0000 - val_tn: 55749.0000 - val_tp: 67.0000 - val_precision: 0.0556 - val_recall: 0.8933\n",
      "Epoch 15/30\n",
      "112/112 [==============================] - 7s 62ms/step - loss: 4.8775e-07 - fn: 5.0000 - fp: 5324.0000 - tn: 222105.0000 - tp: 412.0000 - precision: 0.0718 - recall: 0.9880 - val_loss: 0.0308 - val_fn: 9.0000 - val_fp: 885.0000 - val_tn: 56001.0000 - val_tp: 66.0000 - val_precision: 0.0694 - val_recall: 0.8800\n",
      "Epoch 16/30\n",
      "112/112 [==============================] - 7s 62ms/step - loss: 3.0876e-07 - fn: 3.0000 - fp: 3553.0000 - tn: 223876.0000 - tp: 414.0000 - precision: 0.1044 - recall: 0.9928 - val_loss: 0.0306 - val_fn: 11.0000 - val_fp: 659.0000 - val_tn: 56227.0000 - val_tp: 64.0000 - val_precision: 0.0885 - val_recall: 0.8533\n",
      "Epoch 17/30\n",
      "112/112 [==============================] - 7s 63ms/step - loss: 6.9830e-07 - fn: 9.0000 - fp: 7332.0000 - tn: 220097.0000 - tp: 408.0000 - precision: 0.0527 - recall: 0.9784 - val_loss: 0.0311 - val_fn: 10.0000 - val_fp: 439.0000 - val_tn: 56447.0000 - val_tp: 65.0000 - val_precision: 0.1290 - val_recall: 0.8667\n",
      "Epoch 18/30\n",
      "112/112 [==============================] - 7s 60ms/step - loss: 4.3031e-07 - fn: 7.0000 - fp: 4429.0000 - tn: 223000.0000 - tp: 410.0000 - precision: 0.0847 - recall: 0.9832 - val_loss: 0.0319 - val_fn: 9.0000 - val_fp: 695.0000 - val_tn: 56191.0000 - val_tp: 66.0000 - val_precision: 0.0867 - val_recall: 0.8800\n",
      "Epoch 19/30\n",
      "112/112 [==============================] - 7s 61ms/step - loss: 4.5076e-07 - fn: 7.0000 - fp: 5827.0000 - tn: 221602.0000 - tp: 410.0000 - precision: 0.0657 - recall: 0.9832 - val_loss: 0.0247 - val_fn: 9.0000 - val_fp: 634.0000 - val_tn: 56252.0000 - val_tp: 66.0000 - val_precision: 0.0943 - val_recall: 0.8800\n",
      "Epoch 20/30\n",
      "112/112 [==============================] - 7s 62ms/step - loss: 3.8407e-07 - fn: 5.0000 - fp: 4766.0000 - tn: 222663.0000 - tp: 412.0000 - precision: 0.0796 - recall: 0.9880 - val_loss: 0.0319 - val_fn: 8.0000 - val_fp: 632.0000 - val_tn: 56254.0000 - val_tp: 67.0000 - val_precision: 0.0959 - val_recall: 0.8933\n",
      "Epoch 21/30\n",
      "112/112 [==============================] - 7s 60ms/step - loss: 3.7579e-07 - fn: 3.0000 - fp: 4351.0000 - tn: 223078.0000 - tp: 414.0000 - precision: 0.0869 - recall: 0.9928 - val_loss: 0.0292 - val_fn: 10.0000 - val_fp: 579.0000 - val_tn: 56307.0000 - val_tp: 65.0000 - val_precision: 0.1009 - val_recall: 0.8667\n",
      "Epoch 22/30\n",
      "112/112 [==============================] - 7s 63ms/step - loss: 2.2698e-07 - fn: 2.0000 - fp: 2242.0000 - tn: 225187.0000 - tp: 415.0000 - precision: 0.1562 - recall: 0.9952 - val_loss: 0.0959 - val_fn: 8.0000 - val_fp: 1372.0000 - val_tn: 55514.0000 - val_tp: 67.0000 - val_precision: 0.0466 - val_recall: 0.8933\n",
      "Epoch 23/30\n",
      "112/112 [==============================] - 7s 60ms/step - loss: 2.4584e-07 - fn: 1.0000 - fp: 2535.0000 - tn: 224894.0000 - tp: 416.0000 - precision: 0.1410 - recall: 0.9976 - val_loss: 0.0127 - val_fn: 12.0000 - val_fp: 255.0000 - val_tn: 56631.0000 - val_tp: 63.0000 - val_precision: 0.1981 - val_recall: 0.8400\n",
      "Epoch 24/30\n",
      "112/112 [==============================] - 7s 60ms/step - loss: 1.5301e-07 - fn: 0.0000e+00 - fp: 1993.0000 - tn: 225436.0000 - tp: 417.0000 - precision: 0.1730 - recall: 1.0000 - val_loss: 0.0125 - val_fn: 11.0000 - val_fp: 194.0000 - val_tn: 56692.0000 - val_tp: 64.0000 - val_precision: 0.2481 - val_recall: 0.8533\n",
      "Epoch 25/30\n",
      "112/112 [==============================] - 7s 59ms/step - loss: 3.1192e-07 - fn: 1.0000 - fp: 2774.0000 - tn: 224655.0000 - tp: 416.0000 - precision: 0.1304 - recall: 0.9976 - val_loss: 0.0751 - val_fn: 11.0000 - val_fp: 1383.0000 - val_tn: 55503.0000 - val_tp: 64.0000 - val_precision: 0.0442 - val_recall: 0.8533\n",
      "Epoch 26/30\n",
      "112/112 [==============================] - 7s 60ms/step - loss: 5.5518e-07 - fn: 7.0000 - fp: 5949.0000 - tn: 221480.0000 - tp: 410.0000 - precision: 0.0645 - recall: 0.9832 - val_loss: 0.0274 - val_fn: 9.0000 - val_fp: 563.0000 - val_tn: 56323.0000 - val_tp: 66.0000 - val_precision: 0.1049 - val_recall: 0.88000 - precision: 0.0642 - reca\n",
      "Epoch 27/30\n",
      "112/112 [==============================] - 7s 62ms/step - loss: 3.3740e-07 - fn: 6.0000 - fp: 3319.0000 - tn: 224110.0000 - tp: 411.0000 - precision: 0.1102 - recall: 0.9856 - val_loss: 0.0199 - val_fn: 10.0000 - val_fp: 407.0000 - val_tn: 56479.0000 - val_tp: 65.0000 - val_precision: 0.1377 - val_recall: 0.8667\n",
      "Epoch 28/30\n",
      "112/112 [==============================] - 7s 61ms/step - loss: 2.9769e-07 - fn: 2.0000 - fp: 3038.0000 - tn: 224391.0000 - tp: 415.0000 - precision: 0.1202 - recall: 0.9952 - val_loss: 0.0145 - val_fn: 13.0000 - val_fp: 311.0000 - val_tn: 56575.0000 - val_tp: 62.0000 - val_precision: 0.1662 - val_recall: 0.8267\n",
      "Epoch 29/30\n",
      "112/112 [==============================] - 7s 59ms/step - loss: 3.6221e-07 - fn: 5.0000 - fp: 3383.0000 - tn: 224046.0000 - tp: 412.0000 - precision: 0.1086 - recall: 0.9880 - val_loss: 0.0581 - val_fn: 8.0000 - val_fp: 1026.0000 - val_tn: 55860.0000 - val_tp: 67.0000 - val_precision: 0.0613 - val_recall: 0.8933\n",
      "Epoch 30/30\n",
      "112/112 [==============================] - 7s 58ms/step - loss: 2.5538e-07 - fn: 2.0000 - fp: 3027.0000 - tn: 224402.0000 - tp: 415.0000 - precision: 0.1206 - recall: 0.9952 - val_loss: 0.0672 - val_fn: 11.0000 - val_fp: 534.0000 - val_tn: 56352.0000 - val_tp: 64.0000 - val_precision: 0.1070 - val_recall: 0.8533\n",
      "Wall time: 3min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18b169866c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(\n",
    "    train_features,\n",
    "    train_targets,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(val_features, val_targets),\n",
    "    class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predictions.astype('int64')\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998490195045733"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(val_targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56843,    43],\n",
       "       [   43,    32]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(val_targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = dict(zip(np.unique(y_train), class_weight.compute_class_weight('balanced', np.unique(y_train), \n",
    "                y_train))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
