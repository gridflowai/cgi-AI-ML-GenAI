{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# CV and metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# for feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample example -- Principal Component Analysis\n",
    "# Generally this is called a data reduction technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "url   = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "df = pd.read_csv(url, names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data into arrays\n",
    "array = df.values\n",
    "\n",
    "X = array[:, 0:8]\n",
    "y = array[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "# n_components=4\n",
    "# instantiation of the PCA module\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  [8.88546635e-01 6.15907837e-02 2.57901189e-02 1.30861374e-02\n",
      " 7.44093864e-03 3.02614919e-03 5.12444875e-04 6.79264301e-06]\n"
     ]
    }
   ],
   "source": [
    "# fit the data and transform the X\n",
    "fit = pca.fit_transform(X)\n",
    "\n",
    "# summarize components\n",
    "# The amount of variance explained by each of the selected components.\n",
    "print(\"Explained Variance: \", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [.885, .061, .028, .013, .007, .003, .0005 ]\n",
    "# 88.5%  6.15%   2.57%  1.3%  .7%   .3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.02176587e-03,  9.78115765e-02,  1.60930503e-02,\n",
       "         6.07566861e-02,  9.93110844e-01,  1.40108085e-02,\n",
       "         5.37167919e-04, -3.56474430e-03],\n",
       "       [-2.26488861e-02, -9.72210040e-01, -1.41909330e-01,\n",
       "         5.78614699e-02,  9.46266913e-02, -4.69729766e-02,\n",
       "        -8.16804621e-04, -1.40168181e-01],\n",
       "       [-2.24649003e-02,  1.43428710e-01, -9.22467192e-01,\n",
       "        -3.07013055e-01,  2.09773019e-02, -1.32444542e-01,\n",
       "        -6.39983017e-04, -1.25454310e-01],\n",
       "       [-4.90459604e-02,  1.19830016e-01, -2.62742788e-01,\n",
       "         8.84369380e-01, -6.55503615e-02,  1.92801728e-01,\n",
       "         2.69908637e-03, -3.01024330e-01],\n",
       "       [ 1.51612874e-01, -8.79407680e-02, -2.32165009e-01,\n",
       "         2.59973487e-01, -1.72312241e-04,  2.14744823e-02,\n",
       "         1.64080684e-03,  9.20504903e-01],\n",
       "       [-5.04730888e-03,  5.07391813e-02,  7.56365525e-02,\n",
       "         2.21363068e-01, -6.13326472e-03, -9.70776708e-01,\n",
       "        -2.02903702e-03, -1.51133239e-02],\n",
       "       [ 9.86672995e-01,  8.83426114e-04, -1.22975947e-03,\n",
       "        -3.76444746e-04,  1.42307394e-03, -2.73046214e-03,\n",
       "        -6.34402965e-03, -1.62555343e-01],\n",
       "       [ 6.10123250e-03, -8.25459539e-04,  5.20865450e-04,\n",
       "        -2.54871909e-03, -2.68965921e-04, -2.67341863e-03,\n",
       "         9.99972146e-01, -1.95271966e-03]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so where are the features, which features ???\n",
    "\n",
    "# PCA does not \"discard\" or \"retain\" any of your pre-defined features \n",
    "# (encoded by the columns you specify). It mixes all of them \n",
    "# (by weighted sums) to find directions of maximum variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example - using iris dataset ****************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"  \n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']  \n",
    "dataset = pd.read_csv(url, names=names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first preprocessing step is to divide the dataset into a feature set and \n",
    "# corresponding labels. \n",
    "\n",
    "X = dataset.drop('Class', 1)  \n",
    "y = dataset['Class']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next preprocessing step is to divide data into training and test sets. \n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA performs best with a normalized feature set. We will perform standard \n",
    "# scalar normalization to normalize our feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()  \n",
    "\n",
    "X_train_std = sc.fit_transform(X_train)  \n",
    "\n",
    "X_test_std = sc.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA depends only upon the feature set and not the label data. \n",
    "# PCA can be considered as an unsupervised machine learning technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing PCA using Scikit-Learn is a two-step process:\n",
    "\n",
    "- Initialize the PCA class by passing the number of components to the constructor.\n",
    "- Call the fit and then transform methods by passing the feature set to these methods. \n",
    "\n",
    "The transform method returns the specified number of principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with all 4 dimensions ********************************************\n",
    "\n",
    "We did not specify the number of components in the constructor. \n",
    "Hence, all 4 of the features in the feature set will be returned for both the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()  \n",
    "\n",
    "X_train = pca.fit_transform(X_train_std)  \n",
    "\n",
    "X_test  = pca.transform(X_test_std)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA class contains __explained_variance_ratio__ which returns the variance caused by each of the principal components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72226528, 0.23974795, 0.03338117, 0.0046056 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance = pca.explained_variance_ratio_  \n",
    "\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that first principal component is responsible for 72.22% variance. \n",
    "\n",
    "Similarly, the second principal component causes 23.9% variance in the dataset. \n",
    "\n",
    "Collectively we can say that (72.22 + 23.9) 96.21% percent of the classification information contained in the feature set is captured by the first two principal components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's first try to use 1 principal component to train our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pca1 = PCA(n_components = 1)  \n",
    "\n",
    "X_train1 = pca.fit_transform(X_train_std)  \n",
    "X_test1  = pca.transform(X_test_std)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27228206,  0.35787873,  0.18033696, -0.21868382],\n",
       "       [ 0.15223177, -0.29983528,  0.65712963, -0.24932075],\n",
       "       [-2.18764183,  0.61715426, -0.18088705,  0.00366971],\n",
       "       [ 0.9419134 ,  0.01218105,  0.32961625, -0.01239281],\n",
       "       [ 1.76227837, -0.27106639,  0.33667892,  0.09299476]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, \n",
    "                                    max_depth=16, \n",
    "                                    random_state=0)  \n",
    "classifier.fit(X_train1, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the output that with 4 components, the random forest algorithm is able to correctly predict 28 out of 30 instances, resulting in 86.66% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with 2 dimensions **********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train2 = pca2.fit_transform(X_train_std)  \n",
    "X_test2  = pca2.transform(X_test_std)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72226528, 0.23974795])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance = pca2.explained_variance_ratio_  \n",
    "\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.27228206,  0.35787873],\n",
       "       [ 0.15223177, -0.29983528],\n",
       "       [-2.18764183,  0.61715426],\n",
       "       [ 0.9419134 ,  0.01218105],\n",
       "       [ 1.76227837, -0.27106639]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, max_depth=16, random_state=0)  \n",
    "classifier.fit(X_train2, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  1  5]]\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 2 principal components the classification accuracy decreases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results with 3 dimensions **********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train3 = pca3.fit_transform(X_train_std)  \n",
    "X_test3  = pca3.transform(X_test_std)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72226528, 0.23974795, 0.03338117])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance = pca3.explained_variance_ratio_  \n",
    "\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, max_depth=16, random_state=0)  \n",
    "classifier.fit(X_train3, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  1  5]]\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print(accuracy_score(y_test, y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72226528, 0.23974795, 0.03338117])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With three principal components the classification accuracy again increases to 93.33%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general rule of thumb is to take number of principal of principal components that contribute  to significant variance and ignore those with diminishing variance returns. \n",
    "\n",
    "A good way is to plot the variance against principal components and ignore the principal \n",
    "components with diminishing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
