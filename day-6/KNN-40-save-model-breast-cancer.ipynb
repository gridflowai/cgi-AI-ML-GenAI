{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "#### Model persistence\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lets us understand `pickle` module of python\n",
    "\n",
    "- is a part of your standard library with your installation of Python.\n",
    "- `Pickling` is the `serializing` and `de-serializing` of python objects to a byte stream. \n",
    "- `Unpicking` is the opposite.\n",
    "\n",
    "- Pickling is used to `store python objects`. This means things like lists, dictionaries, class objects, and more.\n",
    "\n",
    "- Examples\n",
    "    - `data analysis`, where you are performing routine tasks on the data, such as pre-processing. \n",
    "        - Save the data for later use\n",
    "            - such as dictionaries.\n",
    "\n",
    "    - save `trained machine learning` model. \n",
    "\n",
    "        - we just train the algorithm once, store it to a variable (an object), and then we pickle it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_dict = {1:\"6\",\n",
    "                2:\"2\",\n",
    "                3:\"f\"}\n",
    "\n",
    "pickle_out = open(\"dict.pickle\",\"wb\")\n",
    "\n",
    "pickle.dump(example_dict, pickle_out)\n",
    "\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle_in    = open(\"dict.pickle\",\"rb\")\n",
    "\n",
    "example_dict = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '6', 2: '2', 3: 'f'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Inside the Python pickle Module\n",
    "    - The Python pickle module basically consists of four methods:\n",
    "\n",
    "    - `pickle.dump`(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)\n",
    "    - `pickle.dumps`(obj, protocol=None, *, fix_imports=True, buffer_callback=None)\n",
    "    - `pickle.load`(file, *, fix_imports=True, encoding=\"ASCII\", errors=\"strict\", buffers=None)\n",
    "    - `pickle.loads`(bytes_object, *, fix_imports=True, encoding=\"ASCII\", errors=\"strict\", buffers=None)\n",
    "    \n",
    "The first two methods are used during the pickling process, and the other two are used during unpickling. \n",
    "\n",
    "The only `difference between dump() and dumps()` is that the first creates a file containing the serialization result, whereas the second returns a string.\n",
    "\n",
    "To differentiate dumps() from dump(), itâ€™s helpful to remember that the `s` at the end of the function name stands for `string`. \n",
    "\n",
    "The same concept also applies to load() and loads(): The first one reads a file to start the unpickling process, and the second one operates on a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one more example ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my pickled object:\n",
      "b'\\x80\\x04\\x95!\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x08__main__\\x94\\x8c\\rexample_class\\x94\\x93\\x94)\\x81\\x94.'\n",
      "\n",
      "This is a_dict of the unpickled object:\n",
      "{'first': 'a', 'second': 2, 'third': [1, 2, 3]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class example_class:\n",
    "    a_number = 35\n",
    "    a_string = \"hey\"\n",
    "    a_list   = [1, 2, 3]\n",
    "    a_dict   = {\"first\": \"a\", \"second\": 2, \"third\": [1, 2, 3]}\n",
    "    a_tuple  = (22, 23)\n",
    "\n",
    "my_object = example_class()\n",
    "\n",
    "my_pickled_object = pickle.dumps(my_object)  # Pickling the object\n",
    "print(f\"This is my pickled object:\\n{my_pickled_object}\\n\")\n",
    "\n",
    "my_object.a_dict = None\n",
    "\n",
    "my_unpickled_object = pickle.loads(my_pickled_object)  # Unpickling the object\n",
    "print(f\"This is a_dict of the unpickled object:\\n{my_unpickled_object.a_dict}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Example ML using KNN\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4. Relevant Information:\n",
    "       Samples arrive periodically as Dr. Wolberg reports his clinical cases.\n",
    "       The database therefore reflects this chronological grouping of the data.\n",
    "       This grouping information appears immediately below, having been removed\n",
    "       from the data itself:\n",
    "         Group 1: 367 instances (January 1989)\n",
    "         Group 2:  70 instances (October 1989)\n",
    "         Group 3:  31 instances (February 1990)\n",
    "         Group 4:  17 instances (April 1990)\n",
    "         Group 5:  48 instances (August 1990)\n",
    "         Group 6:  49 instances (Updated January 1991)\n",
    "         Group 7:  31 instances (June 1991)\n",
    "         Group 8:  86 instances (November 1991)\n",
    "         -----------------------------------------\n",
    "         Total:   699 points (as of the donated datbase on 15 July 1992)\n",
    "\n",
    "       Note that the results summarized above in Past Usage refer to a dataset\n",
    "       of size 369, while Group 1 has only 367 instances.  This is because it\n",
    "       originally contained 369 instances; 2 were removed.  The following\n",
    "       statements summarizes changes to the original Group 1's set of data:\n",
    "\n",
    "       #####  Group 1 : 367 points: 200B 167M (January 1989)\n",
    "       #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\n",
    "       #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\n",
    "       #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\n",
    "       #####                  : Changed 0 to 1 in field 6 of sample 1219406\n",
    "       #####                  : Changed 0 to 1 in field 8 of following sample:\n",
    "       #####                  : 1182404,2,3,1,1,1,2,0,1,1,1\n",
    "\n",
    "    5. Number of Instances: 699 (as of 15 July 1992)\n",
    "    6. Number of Attributes: 10 plus the class attribute\n",
    "    7. Attribute Information: (class attribute has been moved to last column)\n",
    "       #  Attribute                     Domain\n",
    "       -- -----------------------------------------\n",
    "       1. Sample code number            id number\n",
    "       2. Clump Thickness               1 - 10\n",
    "       3. Uniformity of Cell Size       1 - 10\n",
    "       4. Uniformity of Cell Shape      1 - 10\n",
    "       5. Marginal Adhesion             1 - 10\n",
    "       6. Single Epithelial Cell Size   1 - 10\n",
    "       7. Bare Nuclei                   1 - 10\n",
    "       8. Bland Chromatin               1 - 10\n",
    "       9. Normal Nucleoli               1 - 10\n",
    "      10. Mitoses                       1 - 10\n",
    "      11. Class:                        (2 for benign, 4 for malignant)\n",
    "\n",
    "    8. Missing attribute values: 16\n",
    "       There are 16 instances in Groups 1 to 6 that contain a single missing \n",
    "       (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
    "    9. Class distribution:\n",
    "\n",
    "       Benign: 458 (65.5%)\n",
    "       Malignant: 241 (34.5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a RandomForestClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file using pickle\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model back from the pickle file\n",
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda-16-FEB\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set using the loaded model\n",
    "predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = (predictions == y_test).mean()\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
